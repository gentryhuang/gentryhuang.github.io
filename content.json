{"meta":{"title":"gentryhuang‘s blog","subtitle":"blog","description":"博客","author":"gentryhuang","url":"https://gentryhuang.com","root":"/"},"pages":[{"title":"关于我","date":"2020-08-09T08:58:11.880Z","updated":"2020-08-09T08:58:11.880Z","comments":false,"path":"about/index.html","permalink":"https://gentryhuang.com/about/index.html","excerpt":"","text":"123456789101112131415161718&#x2F;**** * ┏┓ ┏┓ * ┃ ┃ + +* ┃ ━ ┃ ++ + + +* ████━████┃ 🚂🚂🚂-&lt;-&lt; 欢迎访问我的博客* ┃ ┃ + * ┃ ┻ ┃ + + * ┃ ┃ * ┗━┓ ┏━┛Code is far away from bug with the animal protecting * ┃ ┃ 神兽护体，永无bug * ┃ ┃ +* ┃ ┗━━━┓+* ┃ ┣┓ 📬 联系我：gentryhuang.xw@gmail.com* ┃ ┏┛ + + * ┗┓┓┏━┳┓┏┛ +* ┃┫┫ ┃┫┫ * ┗┻┛ ┗┻┛ *&#x2F;"},{"title":"分类","date":"2020-07-03T15:03:26.305Z","updated":"2020-07-03T15:03:26.305Z","comments":false,"path":"categories/index.html","permalink":"https://gentryhuang.com/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2020-07-05T10:07:05.047Z","updated":"2020-07-03T15:03:37.362Z","comments":true,"path":"links/index.html","permalink":"https://gentryhuang.com/links/index.html","excerpt":"","text":""},{"title":"标签","date":"2020-07-03T15:03:56.993Z","updated":"2020-07-03T15:03:56.993Z","comments":false,"path":"tags/index.html","permalink":"https://gentryhuang.com/tags/index.html","excerpt":"","text":""},{"title":"项目","date":"2020-07-06T16:29:08.229Z","updated":"2020-07-06T16:29:08.229Z","comments":false,"path":"repository/index.html","permalink":"https://gentryhuang.com/repository/index.html","excerpt":"","text":""}],"posts":[{"title":"并发 - JMM","slug":"concurrent/JMM","date":"2021-09-20T01:14:12.000Z","updated":"2021-10-05T15:04:18.327Z","comments":false,"path":"posts/11b0627b/","link":"","permalink":"https://gentryhuang.com/posts/11b0627b/","excerpt":"","text":"前言本篇文章将对 Java 的内存模型（JMM）进行介绍，本质上它是一种编程语言规范，用于尝试统一一个能够在各种处理器架构中为并发提供一致语义的内存模型（不同处理器架构一般具有不同强度的模型）。驱动 Java 内存模型产生的原因有很多，如编译器优化、处理器乱序执行和缓存等，这些因素导致并发程序中有些行为是非法的。因此，在介绍 Java 内存模型之前，我们先对并发编程相关概念进行说明，然后再引出 Java 内存模型。 硬件内存架构了解现代计算机硬件架构对理解 Java 内存模型非常重要，常见的硬件内存架构图如下： 下面我们重点对硬件内存架构的组成，缓存一致性问题进行介绍。 硬件内存组成现代计算机内存架构包括：多CPU、CPU寄存器、CPU缓存以及共享的内存。 多CPU 现代计算机通常有 2 个或更多 CPU ，其中一些 CPU 可能具有多个核。当只有一个 CPU 时，要运行多个程序（进程）的话，就意味着要经常进行进程上下文切换。尽管单 CPU 是多核，也只是多个处理器核心，其他设备都是共用的，所以多个进程就必然要经常进行进程上下文切换，这个代价是很高的。 CPU多核 一个多核的 CPU 也就是一个 CPU 上有多个处理器核心。 CPU寄存器 每个 CPU 都包含一组寄存器，它们是 CPU 内存的基础。CPU 在寄存器上执行操作的速度远大于在主存上执行的速度。这是因为 CPU 访问寄存器的速度远大于主存。 CPU缓存 每个 CPU 还可能有一个 CPU 缓存存储器层。事实上，大多数现代 CPU 都有一定大小的缓存层，位于 CPU 与主内存间的一种容量较小但速度很高的存储器，但通常不如访问其内部寄存器的速度快。由于 CPU 的速度远高于主内存，CPU 直接从主内存中存取数据要等待一定时间周期。CPU 缓存中保存着 CPU 刚用过或循环使用的一部分数据，当 CPU 再次使用该部分数据时可从缓存中直接获取, 减少了 CPU 的等待时间，提高了系统的效率。 一些 CPU 可能有多个缓存层，具体如下： 一级缓存(L1 Cache): 容量最小，速度最快，每个核独有。针对指令和数据分为数据缓存和指令缓存 二级缓存(L2 Cache): 容量比 L1 大，速度比 L1 慢，每个核独有 三级缓存(L3 Cache): 容量最大，速度最慢，多个核共享 由于Cache的容量很小，一般都是充分的利用局部性原理，按行/块来和主存进行批量数据交换，以提升数据的访问效率。 内存 计算机还包含一个主存储区 (RAM)，所有 CPU 都可以访问它。主内存区域通常比 CPU 的高速缓存大得多。 读取数据 取寄存器中的值: 只需要一步，直接读取即可。 取L1中的值: 先锁住缓存行，然后取出数据，最后解锁。如果没有锁住说明慢了。 取L2中的值: 先到 L1 中取，L1 中不存在再到 L2 中取。L2 开始加锁，将 L2 中的数据复制到 L1 ，再执行从 L1 中读取数据的步骤，解锁 L2。 取L3中的值: 同样地，先将数据由 L3 复制到 L2，然后从 L2 复制到 L1 ，从 L1 读取数据。 CPU 在读取数据时，先在 L1 中寻找，再从 L2 中寻找，再从 L3 中寻找，然后是内存，最后是外存储器。 CPU优化手段为了提高程序运行的性能，现代 CPU 在很多方面对程序进行了优化。 缓存CPU 高速缓存，尽可能地避免处理器访问主内存的时间开销，处理器大多会利用缓存提高性能。 运行时指令重排为了提高 CPU 处理性能，CPU 可能会乱序执行。如，当 CPU 写缓存时发现缓存曲块正被其它 CPU 占用，为了提高 CPU 处理性能，可能将后面的读缓存命令优先执行。 注意，CPU 指令重排并非随意重排，需要遵守 as-if-serial语义 ，该语义表示：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器，运行时和处理器都必须遵守 as-if-serial 语义。也就是说，编译器和处理器不会对存在数据依赖关系的操作做重排序。 问题基于高速缓存很好地解决了处理器与内存的速度矛盾，但是也引入了新的问题-缓存一致性(CacheCoherence)。缓存中的数据与主内存的数据并不是实时同步的，各 CPU（或 CPU 核）间缓存的数据也不是实时同步。也就是说，在同一个时间点，各 CPU 所看到同一内存地址的数据的值可能不一致。如，当多个处理器执行的任务都涉及到同一块主内存区域时，将可能导致各自的缓存数据不一致的情况，这样不一致的情况如果同步回主内存时以哪个处理为准呢？ 运行在左侧 CPU 上的一个线程将共享对象复制到其 CPU 缓存中，并将其count变量更改为 2。此更改对运行在右侧 CPU 上的其他线程不可见，因为更新的count尚未刷新回主内存. 总线锁所有内存的传输都发生在一条共享的总线上，所有的处理器都会使用该总线。虽然 CPU 缓存各自是独立的，但是主存是共享的，所有的内存访问都要经过总线加锁机制来决定是否可以进行内存的读写，也就是说在同一个指令周期中，只可能有一个 CPU 可以读写内存。 所谓总线锁就是使用处理器提供的一个 LOCK#信号 ，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，只有该处理器可以独占共享内存。 缓存一致性协议总线锁虽然可以保证缓存数据的一致性，但是它比较粗暴，当某个 CPU 对总线进行加锁后，所有后续其它 CPU 对主存的操作都是阻塞的，这样机制就必定会降低性能。因此，缓存一致性协议出现了，它是硬件程序的产物，用来保证缓存之间可见。 缓存一致性协议有多种，如 MSI、MESI 等，多数 CPU 厂商对缓存一致性协议进行了实现。下面我们以 MESI 协议为例，对其进行介绍。 MESI协议规定每个缓存行有个状态位，同时定义了下面四个状态： 专有态(Exclusive)锁住的缓存行内容只存在当前 CPU 缓存中且同于主存，不出现于其它缓存中，所以当 CPU 发现自己缓存中的共享数据是专有态(Exclusive)时，说明该数据是最新的，可以直接读取。 当缓存行处于专有态(Exclusive)时，在任何时刻当有其它 CPU 缓存了该数据时，那么缓存行会由专有态(Exclusive)变成共享态(Shared)。 共享态(Shared)锁住的缓存行同于主存，且该缓存行可能被多个 CPU 缓存，各个缓存与主内存数据一致，所以当 CPU 发现自己缓存中的共享数据是共享态(Shared)时，说明该数据是最新值，可以直接读取。 当缓存行处于共享态(Shared)时，当任一个 CPU 修改缓存行时，其它 CPU 中该缓存行变成无效态(Invalid)。 修改态(Modified)锁住的缓存行已被修改（脏行），内容已不同于主存。该状态是一个中间状态，缓存行的数据需要在未来某个时间点写回主内存，当被写回主内存之后，该缓存行就会变成专有状态。 当 CPU 对缓存行进行修改时，变为修改态(Modified)，并且同时会向其他缓存了该数据的 CPU 缓存发送一条 Invalid 指令，告诉其他缓存自己对数据进行了修改，让它们把数据对应的缓存行置为无效态(Invalid)； 当收到其它 CPU 缓存 Invalid 指令的成功响应时，当前 CPU 缓存会就会把数据同步到主存里面去，然后自己的缓存行由修改态(Modified)变为专有态(Exclusive)，当有其他 CPU 缓存从主存中读取到了最新的数据时，数据状态会变为共享态(Shared)。 无效态(Invalid)当缓存行处于无效态(Invalid)时，说明对应的数据已经被其它 CPU 修改过了，当前锁住的缓存行无效，必须从主存中重新读取。 无效态(Invalid)是由于收到其它 CPU 发来的 Invalid 指令，收到该指令的 CPU 缓存会把对应的缓存行状态标记为无效态(Invalid)，所以当数据处于无效态(Invalid)时表示数据已经被别人修改了，当前数据是无效的。 多处理器时，单个 CPU 对缓存中数据进行改动需要通知给其他 CPU 。也就意味着在缓存一致性协议下，CPU 处理要控制自己的读写操作，还要监听（嗅探）其它 CPU 发出的通知，从而保证最终一致。 这里需要说明下，MESI协议可以在 CPU 修改数据时向其他 CPU 发送消息，但不会出现两个CPU同时修改数据，进而向其他CPU进行消息通知。这样的并发修改通过缓存锁定机制解决的，它会锁定这块内存区域的缓存并回写到内存，并使用缓存一致性机制来确保修改的原子性。只有在数据修改的时候才会需要加缓存锁，修改数据的时候先锁定缓存行，不让其他CPU同时修改，其他CPU读取数据是允许的。缓存是否失效是由缓存一致性协议来处理的，它解决一个 CPU 修改其它 CPU 看不到的问题。缓存锁解决几个 CPU 并发修改的问题。 以下两种情况下处理器会使用总线锁： 当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行时 处理器不支持缓存锁定 Store Buffer前文在描述 MESI 协议时，如果对缓存行进行修改需要经历以下过程： 某个CPU修改自己缓存的值 修改缓存后通知其它CPU，等待其它CPU响应 收到所有CPU的响应 将缓存中的数据同步到主存 可以看到，以上整个过程都是同步的，CPU 发送完通知后必须同步等待所有其它 CPU 的响应，而这个过程中当前 CPU 又无法释放出来，所以为了避免这种 CPU 运算资源的浪费，就需要一种方式来进行优化了，此时 Store Buffer 就出来了。 当 CPU 对某个共享变量修改时，向其他 CPU 发出 Invalid 指令后不同步等待其他 CPU 指令的响应了，而是直接把最新值写入 Store Bufferes 缓冲区里，然后直接可以去干别的事情了，直到所有的 CPU 都对 Invalid 指令响应后，再把共享变量的值从 Store Buffere 里拿出来，然后写入到自己的缓存里同时同步到主存中。 Store ForwardStore Forward 称为存储转发。具体是：当 CPU 读取数据时需要先检查它的 Store Buffer 缓冲区中有没有，如果有则直接读取该缓冲区中的值，没有才会读取自己缓存中的值。解决了 Store Buffer 优化过程中由于只读取缓存导致的缓存脏数据问题。 至此，Store Buffer 优化提升了 CPU 效率。但由于修改共享变量先是放到了 Store Buffer 中，只有等到其它 CPU 返回 Invalid OK 后才会同步到缓冲和主存。可以看出执行写操作不是立即生效的，对于有相互依赖的共享数据相关指令，可能会出现CPU乱序执行的现象。解决手段是利用内存屏障禁用CPU缓存优化，也就是更新数据时必须立即更新到主存（也就是把store buffer里的指令全部执行完）。 Invalid Queue因为 Store Buffer 空间很小，如果有大量的变量修改，它会存储不下，那么这个时候又回到同步通知的状态。此外，有时候其它 CPU 很繁忙并不能马上进行响应，因此为了避免同步等待响应的时间太长，就为每个 CPU 加一个失效队列，当 Store Buffer 存不下的时候，就把失效通知发送到其它 CPU 的失效队列里，只要队列成功接收到了发送的消息就进行响应（发送 Invalid 指令的 CPU 就可以将修改同步到主存了），等到其他CPU闲下来了就从各自的失效队列里读取消息然后失效掉CPU的缓存数据。 MESI 优化到了 Invalid Queue 阶段，一般来说性能已经很高了，但是在极端的情况下会出现缓存可见性问题。具体来说就是，接收到 Invalid 指令的 CPU 没有来得及处理它的实效队列中的消息，没有及时失效掉对应的缓存行，导致继续使用了本应该失效的缓存数据。这种因为CPU缓存优化而导致后面的指令查看不到前面指令的执行结果，就好像指令之间的执行顺序错乱了一样，这类现象也就是我们俗称的CPU乱序执行。解决方法很简单，直接禁用 CPU 缓存优化即可，也就是修改共享数据的指令都同步完成就能保证数据的可见性了，但是这样又会降低整体的性能，这样有点得不偿失，因为毕竟大部分情况下数据都不存在这种共享的问题。不过我们必须要为这种场景提供一种手段来禁用CPU缓存优化，而这种手段同样也是内存屏障机制，读取数据时必须读取最新的数据（也就是必须先把失效队列的数据先读取应用完）。 内存屏障前文我们说的内存屏障可以同时作用于 Store Buffer 和 Invalidate Queue 。而实际上，对于写操作只需关心 Store Buffer ，读操作只需关心 Invalidate Queue 。因此，大多数 CPU 架构将内存屏障分为了读屏障和写屏障。内存屏障本质上是 CPU 提供的一组指令，不同的操作系统有不同的实现。 读屏障: 任何读屏障前的读操作都会先于读屏障后的读操作完成，即读屏障指令执行后就能保证后面的读取数据指令一定能读取到最新的数据。写屏障: 任何写屏障前的写操作都会先于写屏障后的写操作完成，即遇到写屏障指令就必须把该指令之前的所有写入指令执行完毕才可以往下执行，这样就可以让CPU修改的数据及时暴露给其它CPU。全屏障: 同时包含读屏障和写屏障的作用 实际的 CPU 架构中，可能提供多种内存屏障，常见的如下： LoadLoad: 相当于前面说的读屏障 LoadStore: 任何该屏障前的读操作都会先于该屏障后的写操作完成 StoreLoad: 任何该屏障前的写操作都会先于该屏障后的读操作完成 StoreStore: 相当于前面说的写屏障 实现原理都是类似的，如作用于Store Buffer和Invalidate Queue 。 指令重排问题CPU 指令重排虽然遵守了 as-if-serial 语义，但仅在单 CPU 执行的情况下能保证结果正确。在多核多线程中，指令逻辑无法分辨因果关联，为了更好地利用流水线可能出现乱序执行，导致程序运行结果错误。 前文中谈的是内存屏障的可见性功能，它能够让屏障前的操作（读/写）及时执行、刷新，被其它 CPU 看到。而内存屏障还有个功能就是限制指令重排（读/写指令），否则即使内存屏障可以保证可见性，但由于不能保证指令重排，保证可见性意义也不大。 也就是说，内存屏障提供了一套解决CPU缓存优化而导致的顺序性和可见性问题的方案，但是由于不同的硬件系统提供的内存屏障指令可能都不一样，因此像 JAVA 这种高级编程语言就把不同的内存屏障指令统一进行了封装，让开发者不需要关心到系统的底层，而封装这套解决方案的模型就是Java内存模型(Java Memory Model)。 注意，除了运行期间 CPU 的指令重排，编译器在编译期间，可能也对指令进行重排，以使其对CPU更友好。 并发了解了硬件内存架构后，从本小节开始，我们简单聊聊并发。 并发编程关键问题在并发编程中需要处理两个关键问题：线程之间如何通信及线程之间如何同步。 通信是指线程之间以何种机制来交换信息。在命令式编程中，线程之间的通信机制有两种，共享内存和消息传递。共享内存通信机制中，线程之间共享程序的公共状态，通过写-读内存中的公共状态进行隐式通信。消息传递通信机制中，线程之间没有公共状态，线程之间必须通过发送消息来显式通信。 同步是指程序中用于控制不同线程间操作发生的相对顺序的机制。在共享内存并发模型中，同步是显式进行的，也就是说程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行。在消息传递的并发模型中，由于消息的发送必须在消息的接收之前，因此同步是隐式进行的。 Java 的并发采用的是共享内存模型，Java 线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。 并发特性随着 CPU、内存、I/O设备都在不断迭代，不断朝着更快的方向努力的同时，有一个核心矛盾一直存在，那就是这三者的速度差异。为了合理利用 CPU 的高性能，平衡这三者的速度差异，计算机体系结构、操作系统和编译程序都做出了贡献，具体体现为： CPU 增加了缓存，以均衡与内存的速度差异。 操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O设备的速度差异。 编译程序优化指令执行次序 总结起来就是：硬件增加缓存、软件增加线程、编译程序优化指令顺序。 以上优化带来好处的同时，也给并发程序埋下了祸根。带来的问题可以总结为： 缓存导致可见性问题 线程切换导致原子性问题 指令优化导致有序性问题 下面我们对以上问题详细说明。 可见性一个线程对共享变量的修改，另外一个线程能够立刻看到，我们称为可见性。 在单核时代，所有的线程都是在一颗 CPU 上执行，CPU 缓存与内存的数据一致性容易解决。因为所有线程都是操作同一个 CPU 的缓存，一个线程对缓存的写，对另外一个线程来说一定是可见的。例如，线程 A 和线程 B 都是操作同一个 CPU 里面的缓存，所以线程 A 更新了变量 V 的值，那么线程 B 之后再访问变量 V，得到的一定是 V 的最新值（线程 A 写过的值）。 多核时代，每颗 CPU 都有自己的缓存，这时 CPU 缓存与内存的数据一致性就没那么容易解决了，当多个线程在不同的 CPU 上执行时，这些线程操作的是不同的 CPU 缓存，它们是无法直接通信的。 原子性一个或者多个操作在 CPU 执行的过程中不被中断的特性称为原子性。 Java 并发程序都是基于多线程的，自然会涉及到线程切换，切换的时机大多数是在时间片结束的时候。操作系统做任务切换，可以发生在任何一条CPU 指令执行完，注意是 CPU 指令而非高级语言中的一条语句，因为高级语言中的一条语句可能包含多条 CPU 指令。也就是说，CPU 能保证的原子操作是 CPU 指令级别的，而不是高级语言级别。因此，很多时候需要我们自己在高级语言层面保证操作的原子性。 有序性有序性指的是程序按照代码的先后顺序执行。但编译器、处理器为了优化性能有时会改变程序执行的次序，而这也是导致问题的原因。 缓存、线程、编译优化的目的都是提高程序性能的，但是技术在解决一个问题的同时，可能会带来另外一个问题，所以在采用一项技术的同时，一定要清楚它带来的问题是什么，以及如何规避。 JMMJava 的内存模型（JMM）本质上是一种编程语言规范，屏蔽了不同处理器内存模型的差异，它在不同的处理器平台之上为 Java 程序员呈现了一个一致的内存模型。不同点在于，JMM 是一个语言级的内存模型，处理器内存模型是硬件级的内存模型。JMM 通过定义多项规则对编译器和处理器进行限制，主要围绕原子性、有序性、可见性展开，具体来说包括 volatitle、synchronized 和 fianl 这三个关键字，以及系列 happens-before 原则。 注意：JVM 内存模型和 Java 内存模型是完全不同的两个东西。JVM内存模型是一种内存逻辑划分，便于JVM 管理内存；JMM内存模型是对计算机硬件（处理器模型）的统一抽象，用来屏蔽差异。 细化规范JMM 描述了程序的可能行为，程序执行产生的结果都可以由内存模型预测，它决定了在程序的每个点上可以读取什么值（读写是相互的，也就是写了后，读必须要读取到，这就要求写必须刷新到主内存）。既然 JMM 是一种规范，就需要给 JVM 开发者和厂商实现，需要细化规范。 共享变量可以在线程之间共享的内存称为共享内存或堆内存。所有实例字段，静态字段和数组元素都存储在堆内存中。Java 内存模型的抽象示意图如下： JMM 定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存中，每个线程都有一个私有的本地内存，本地内存中存储了该线程以读/写共享变量的副本，线程对变量的所有操作都必须在本地内存中进行，而不能直接操作主内存中的变量。注意，本地内存是 JMM 的一个抽象概念，并不真实存在。 如果线程 A 与线程 B 之间要通信的话，必须经历以下2个步骤： 线程 A 把本地内存中更新过的共享变量刷新到主内存中去。 线程 B 到主内存中去读取线程 A 之前已更新过的共享变量 关于主内存与本地内存之间的具体交互，即一个变量如何从主内存拷贝到本地内存、如何从本地内存同步到主内存之间的实现细节，Java内存模型定义了以下八种操作来完成。 lock：作用于主内存，把变量标识为线程独占状态 unlock：作用于主内存，解除独占状态 read：作用主内存，把一个变量的值从主内存传输到线程的本地内存 load：作用于本地内存，把 read 操作传过来的变量值放入本地内存的变量副本中 use：作用本地内存，把本地内存当中的一个变量值传给执行引擎 assign：作用本地内存，把一个从执行引擎接收到的值赋值给本地内存的变量 store：作用于本地内存的变量，把本地内存的一个变量的值传送到主内存中 write：作用于主内存的变量，把 store 操作传来的变量的值放入主内存的变量中 如果要把一个变量从主内存中复制到本地内存中，就需要按顺序地执行read和load操作， 如果把变量从本地内存中同步到主内存中，就需要按顺序地执行store和write操作。但Java内存模型只要求上述操作必须按顺序执行，而没有保证必须是连续执行。 如前所述，Java 内存模型和硬件内存架构是不同的。不管是本地内存的数据还是主内存的数据，对于计算机硬件来说都会存储在计算机主内存中，当然也有可能存储到CPU缓存或者寄存器中，因此总体上来说，Java内存模型和计算机硬件内存架构是一 个相互交叉的关系，是一种抽象概念划分与真实物理硬件的交叉。具体如下图所示： 当对象和变量可以存储在计算机中各种不同的内存区域时，可能会出现某些问题，两个主要问题是： 线程更新（写入）共享变量的可见性 读取、检查和写入共享变量时的竞争条件 happend-before 原则JMM 使用 happend-before 的概念来阐述操作之间的内存可见性。在 JMM 中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在 happend-before 关系。这里的两个操作既可以是一个线程内，也可以是在不同的线程之间。 重排序见文章几处 happend-before 定义happend-before 规则SynchnorizedVolatitlefinal小结扩展Java 编程语言的语义允许编译器和微处理器执行优化，这些优化可以与不正确的代码交互，从而产生看似矛盾的行为。注意，由 Java 源码到 .class 文件不会发生重排序。 运行时编译器 jit 把 Java 代码编译成汇编语言。即：class-&gt; 运行时jit编译-&gt;汇编指令=&gt;出现了重排序（汇编级别）","categories":[{"name":"JDK","slug":"JDK","permalink":"https://gentryhuang.com/categories/JDK/"}],"tags":[{"name":"JMM","slug":"JMM","permalink":"https://gentryhuang.com/tags/JMM/"}]},{"title":"网络通信 - Reactor模型","slug":"network/Reactor模型","date":"2021-09-12T13:10:23.000Z","updated":"2021-09-12T05:53:02.438Z","comments":false,"path":"posts/ae5dbc38/","link":"","permalink":"https://gentryhuang.com/posts/ae5dbc38/","excerpt":"","text":"概述Reactor 模型是高性能网络系统实现高并发请求处理的一个解决方案，具体来说就是网络服务端处理高并发网络 IO 请求的一种编程模型。Reactor 编程模型具有以下特征： 三种事件类型：连接事件、读事件、写事件 三种关键角色： Reactor、Acceptor、Handler Reactor 模型就是基于以上三种事件和三种角色来处理网络IO请求的，这就它工作的机制。 演化 上图是传统阻塞IO模型，每个处理程序在自己的线程中运行。 缺点如下： 每个连接都需要独立线程处理，当并发数大时会创建多个线程，过度消耗资源。由于每个连接都对应一个线程，当连接没有就绪时线程就会阻塞等待。 优化方案： 基于 IO 多路复用模型，多个连接可以共用一个线程。 使用线程池，将业务逻辑交给线程池处理。 基于以上问题，为了高效处理网络 IO 的事件，演化出了 Reactor 模型，该模型的思想就是基于IO多路复用和线程池的结合。 事件类型Reactor 模型处理的是客户端和服务器端的交互过程，而连接事件、读事件、写事件对应了客户端和服务器端交互过程中不同类型的请求在服务器端引发的待处理事件。 具体引发的待处理事件如下： 客户端向服务器端发送连接请求以建立连接，这对应了服务器端的一个连接事件。 连接建立后，客户端会给服务器端发送读或写请求，服务器端需要从客户端读取请求内容，这对应了服务器端的读事件。 服务器端在处理完请求后，需要向客户端写回数据，这对应了服务器端的写事件。 关键角色Reactor 模型中的不同类型事件的处理是由对应的角色完成的，三种关键角色的任务如下： Acceptor 用于处理客户端连接事件，负责接收连接。 Handler 用于处理读写事件。 Reactor 负责监听和分派事件。当有连接请求时，Reactor 将产生的连接事件交给 Acceptor 处理；当有读写请求时，Reactor 将读写事件交给 Handler 处理。 需要注意的是，以上三种角色是 Reactor 模型中实现功能的抽象。遵循 Reactor 模型进行服务器端网络框架开发时，需要对 Reactor、Acceptor 以及 Handler 进行逻辑实现。 分类根据 Reactor 的数量和处理资源的线程数量的不同，可以分为三类： 单 Reactor 单线程模型 单 Reactor 多线程模型 多 Reactor 多线程模型 下面依次介绍以上三种 Reactor 线程模型。 单Reactor单线程模型 在单 Reactor 单线程模型下，监听、分派事件由 Reactor 完成，处理连接事件由 Acceptor 完成，处理读写事件和业务逻辑由 Handler 完成，但始终只有一个线程去完成所有的工作。 缺点如下： 仅使用一个线程完成所有工作，不能充分利用多核机器资源 当处理任务导致线程负载过高，处理速度会下降，任务会堆积。请求并发量比较低的时候还是可以抗住的，一旦高并发可能将不堪重负 单线程不能保证可靠性 单Reactor多线程模型 单 Reactor 多线程模型下，不再采用所有工作都由 Reactor 线程独自完成。监听、分派事件由 Reactor 完成，处理连接事件由 Acceptor 完成，处理读写事件由 Handler 完成，这些操作由 Reactor 线程执行。对于业务逻辑的处理交给线程池（多线程），不再是 Reactor 线程。相比 单 Reactor 单线程模型，充分利用多核机器的资源、提高性能并且增加可靠性。 缺点如下：Reactor 线程承担了所有事件的处理，没有解决高并发场景下单线程存在的性能问题。如并发太高，Reactor 线程来不及处理连接请求和读写数据。 多Reactor多线程模型 多 Reactor 多线程模型是将 Reactor 拆分成了 mainReactor 和 subReactor 两个部分。主要有一个 mainReactor，多个 subReactor 以及每个 subReactor 附带一个线程池。mainReactor 主要负责监听客户端的连接请求，当有连接请求到达会分派给 Acceptor（位于 mainReactor 中）处理，并将产生的连接信息交给 subReactor ，后续 subReactor 监听到读写事件后，分派给 Handler 处理，业务逻辑交给线程池处理。 事件驱动框架至此，我们已经了解了 Reactor 模型的组件和工作机制，但是 Reactor 中的角色和事件是怎么联动起来的呢？这就需要事件驱动框架了。 在实现 Reactor 模型时，利用事件驱动框架对整体流程进行控制。事件驱动框架在设计时包括但不限于以下内容： 事件定义及初始化 事件监听、分派(分派给对应的程序处理)、处理 轮询（一般是循环逻辑） 事件初始化Reactor 模型是基于事件和角色工作的，事件驱动框架的实现自然也离不开事件的定义以及初始化。事件初始化的作用主要是创建需要监听的事件类型，并为该类型事件关联对应的处理程序，也就是处理连接事件的 Acceptor、处理读写事件的 Handler以及处理业务逻辑的其它处理程序。 事件分派、处理监听、分派事件是由 Reactor 来完成的，在事件驱动框架中通常会用一个主循环程序实现。在这个主循环中，监听发生的事件，并根据事件类型将待处理的事件分派给与之关联的 Acceptor 和 Handler 处理。 串联部件Reactor 模型的工作机制：客户端不同类型请求和服务器端结果处理会在服务器端触发连接、读、写事件，这三类事件的监听、分派和处理又是由 Reactor、Acceptor、Handler 三类角色来完成的，这三类角色会通过事件驱动框架来实现交互和事件处理。不难发现，实现一个 Reactor 模型的关键就是要实现一个事件驱动框架串联起 Reactor 所有部件。 Reactor 模型的工作机制整体流程图如下： 小结本篇文章对 Reactor 模型进行了介绍。先是对 Reactor 中涉及的部件及功能进行说明，接着对 Reactor 的演化进行了简单介绍，然后分别对不同种类的 Reactor 进行了逐一说明，最后介绍了事件驱动框架，它是串联 Reactor 模型下所有部件的关键程序。 参考：http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf","categories":[{"name":"网络通信","slug":"网络通信","permalink":"https://gentryhuang.com/categories/%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1/"}],"tags":[]},{"title":"并发 - ThreadLocal","slug":"concurrent/ThreadLocal","date":"2021-09-03T04:30:12.000Z","updated":"2021-09-13T15:06:41.480Z","comments":false,"path":"posts/151f44ae/","link":"","permalink":"https://gentryhuang.com/posts/151f44ae/","excerpt":"","text":"概述ThreadLocal 提供了线程局部变量，它是将线程需要访问的数据存储在线程对象自身中，从而避免多线程的数据竞争问题。ThreadLocal 实现原理如下图所示： 理解 ThreadLocal 原理，其实就是理解 Thread、ThreadLocal 以及 ThreadLocalMap 三者之间的关系。线程类 Thread 内部持有 ThreadLocalMap 的成员变量，而 ThreadLocalMap 是 ThreadLocal 的内部类，ThreadLocal 对外暴露操作数据的 API 都是操作 ThreadLocalMap 中的数据。总得来说，线程 Thread 在向 ThreadLocal 中设置值时，其实都是向自己所持有的 ThreadLocalMap 中设置数据；读的时候同理，先是从线程自身中取出持有的 ThreadLocalMap ，然后再根据 ThreadLocal 引用作为 key 取出对应的元素 Entry 进而取出 value。因此 ThreadLocal 可以轻松实现变量的线程隔离，毕竟变量都是维护在各个线程中的，自然没有竞争。 源码分析Thread根据前文中的 ThreadLocal 实现原理图可以发现 ThreadLocal 是 Thread 使用的一个工具，下面我们剥离出 Thread 中相关 ThreadLocal 信息。 12345678public class Thread implements Runnable &#123; /** 与此线程相关的 ThreadLocal 值，这个映射由 ThreadLocal 类维护 */ ThreadLocal.ThreadLocalMap threadLocals = null; /** 与此线程相关的 InheritableThreadLocal 值。这个映射由 InheritableThreadLocal 类维护。*/ ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;&#125; Thread 中维护了两个 ThreadLocalMap 类型的变量，threadLocals 用于存储当前线程使用的 ThreadLocal 相关信息；inheritableThreadLocals 用于存储当前线程使用的 InheritableThreadLocal 相关信息。使用 InheritableThreadLocal 可以实现多个线程访问 ThreadLocal 的值，即父线程中创建一个 InheritableThreadLocal 的实例，然后在子线程中就可以得到这个 InheritableThreadLocal 中设置的值。关于共享线程的 ThreadLocal 数据将在下面的内容中分析。 ThreadLocalThreadLocal 相关的 UML 类图如下所示： 属性1234567891011121314151617181920212223242526272829303132/** * 1 作为 ThreadLocal 实例的变量，私有、不可变。每当创建 ThreadLocal 时这个值都会累加 HASH_INCREMENT * 2 主要为了多个 ThreadLocal 实例的情况下，让哈希码能均匀的分布在2的N次方的数组里, 即 Entry[] table */ private final int threadLocalHashCode = nextHashCode(); /** * 二进制：-10011110001101110111100110111001 * 十进制：-2654435769 * 说明： * 1 Entry[] table 的大小必须是 2^N，那 2^N-1 的二进制表示就是低位连续的N个1， * 2 key.threadLocalHashCode &amp; (len-1) 的值就是 threadLocalHashCode 的低 N 位，这里使用位运算实现取模，和 HashMap 计算下标类似 * 3 要求 threadLocalHashCode 的值要均匀，这里给出 0x61c88647 就能达到。 * 原因： * 取该值与fibonacci hashing(斐波那契散列法)以及黄金分割有关，目的就是为了让哈希码能均匀的分布在2的n次方的数组里, 也就是Entry[] table中。 */ private static final int HASH_INCREMENT = 0x61c88647; /** * 作为 ThreadLocal 类变量 * &lt;p&gt; * 基于当前 ThreadLocal ，下一个要给出的哈希码，自动更新，从 0 开始计数。 * 每次获取当前值并加上固定的 HASH_INCREMENT */ private static AtomicInteger nextHashCode = new AtomicInteger(); /** * 返回下一个 ThreadLocal 的 hash */ private static int nextHashCode() &#123; return nextHashCode.getAndAdd(HASH_INCREMENT); &#125; ThreadLocal 关键属性分为两类。一类是 ThreadLocal 实例变量，另一类是 ThreadLocal 类变量。其中类变量在 ThreadLocal 类加载过程就进行初始化，也就是 nextHashCode 的初始化，后续实例变量 threadLocalHashCode 随着对象的创建而调用 nextHashCode 方法进行赋值，可以看出每次递增为 HASH_INCREMENT ，至于为什么选择这个值，是和斐波那契散列法以及黄金分割有关，目的就是为了让哈希码能均匀的分布在 2^n 次方的数组里，这个和 HashMap 中 hash 实现目的是一致的。 了解了核心属性后，下面以几个方法做为入口分析 ThreadLocal 源码。 Set 方法12345678910111213141516171819202122+--- ThreadLocal /** * 设置当前线程变量的值 value * * @param value */ public void set(T value) &#123; // 1 获取当前线程 Thread t = Thread.currentThread(); // 2 根据当前线程获取其成员变量 threadLocals 所指向的 ThreadLocalMap 对象 ThreadLocalMap map = getMap(t); // 3 判断当前线程的 ThreadLocalMap 是否为空 if (map != null) // 3.1 如果不为空，说明当前线程内部已经有ThreadLocalMap对象了 // 那么直接将当前对应的 ThreadLocal 对象的引用作为键，存入的 value 作为值存储到 ThreadLocalMap 中 map.set(this, value); else // 3.2 创建一个 ThreadLocalMap 对象并将值存入到该对象中，并赋值给当前线程的threadLocals成员变量 createMap(t, value); &#125; ThreadLocal 中的增、删、查方法基本都会有三个步骤。下面对 Set 方法进行小结: 获取当前线程 根据当前线程获取其持有的 ThreadLocalMap 映射表 操作映射表 ThreadLocalMap ，如果映射表存在就调用映射表的 set 方法放入数据，映射表不存在则先创建映射表再放入数据 Get 方法1234567891011121314151617181920212223242526+--- ThreadLocal /** * 获取当前线程的线程副本变量 * * @return */ public T get() &#123; // 1 获取当前线程 Thread t = Thread.currentThread(); // 2 根据当前线程获取其 ThreadLocalMap 实例 ThreadLocalMap map = getMap(t); // 3 如果当前线程的 ThreadLocalMap 不为空 if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(\"unchecked\") T result = (T) e.value; return result; &#125; &#125; // 4 如果当前线程的 ThreadLocalMap 为空或 ThreadLocalMap 中没有当前 ThreadLocal 对应的元素，则调用 initialValue() 方法初始化值 return setInitialValue(); &#125; 下面对 Get 方法进行小结: 获取当前线程 根据当前线程获取其持有的 ThreadLocalMap 映射表 操作映射表 ThreadLocalMap ，如果映射表存在就调用映射表的 getEntry 方法查询数据；映射表不存在或从映射表中没有找到当前 ThreadLocal 对应的元素，则调用 setInitialValue 方法完成映射表的创建或初始值的获取 Get 方法相比 Set 方法会涉及查询不到元素的情况，如果当前线程持有的映射表还没有或者找不到元素，那么 ThreadLocal 会尝试以初始化值的方式进行兜底处理，初始值的情况通过方法 initialValue() 交给具体实现。 setInitialValue 方法1234567891011121314151617181920212223242526272829303132333435+--- ThreadLocal /** * 设置初始化值 * * @return the initial value */ private T setInitialValue() &#123; // 1 调用 initialValue() 方法获取指定的初始化值，默认为 null T value = initialValue(); // 2 获取当前线程 Thread t = Thread.currentThread(); // 3 获取当前线程的 ThreadLocalMap ThreadLocalMap map = getMap(t); // 4 如果 ThreadLocalMap 不为空，则直接将初始值设置到 ThreadLocalMap 中 if (map != null) map.set(this, value); // 5 如果 ThreadLocalMap 为空，则创建 ThreadLocalMap 对象，并设置初始值 else createMap(t, value); return value; &#125; /** * 初始化值，子类覆盖 * * @return */ protected T initialValue() &#123; return null; &#125; Remove 方法12345678910111213+--- ThreadLocal /** * 清理 */ public void remove() &#123; // 1 获取当前线程持有的 ThreadLocalMap ThreadLocalMap m = getMap(Thread.currentThread()); // 2 删除 ThreadLocalMap 中当前 ThreadLocal 相关的信息 // 包括清理对应的引用和值 if (m != null) m.remove(this); &#125; 下面对 Remove 方法进行小结: 获取当前线程 根据当前线程获取其持有的 ThreadLocalMap 映射表 操作映射表 ThreadLocalMap ，如果映射表存在就调用映射表的 remove 方法根据当前 ThreadLocal 清理对应数据，可以防止内存泄漏 createMap 方法12345678910+--- ThreadLocal /** * 为线程 t 初始化 ThreadLocalMap 对象 * * @param t 当前线程 * @param firstValue 值 */ void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue); &#125; 线程中的 ThreadLocalMap 使用的是延迟初始化，即第一次调用 get() 或者 set() 方法的时候才会进行初始化。 getMap 方法12345+--- ThreadLocal // 返回线程 t 的 threadLocals ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals; &#125; 上述方法用于获取每个线程持有自身的 ThreadLocalMap 实例，因此它们是不存在并发竞争的，这就是我们说的每个线程都有自己的变量副本。 至此，ThreadLocal 相关属性以及暴露的方法已经分析完毕。可以看出，ThreadLocal 中并没有持有 ThreadLocalMap 的引用，该引用是在 Thread 类中。此外，ThreadLocal 暴露的 API 操作都是基于 ThreadLocalMap 的。因此，我们理解了 ThreadLocalMap 才算是掌握了 ThreadLocal 。下面我们重点对 ThreadLocalMap 进行分析。 ThreadLocalMapThreadLocalMap 是 ThreadLocal 的静态内部类，本质上是一个 Map ，和 HashMap 类似，依然是 key-value 的形式，具体由 Entry 结构封装。 属性123456789101112131415161718192021222324252627282930313233343536/** * 数组初始化容量 */private static final int INITIAL_CAPACITY = 16;/** * 存储数据的 Entry 数组，长度是 2 的幂。 */private Entry[] table;/** * 数组中元素的个数，初始值为 0 */private int size = 0;/** * 数组扩容阈值，默认为0，创建了 ThreadLocalMap 对象后会被重新设置 */private int threshold; // Default to 0/** * 设置调整大小阈值，以保持在最坏 2/3 的负载因子。 */private void setThreshold(int len) &#123; threshold = len * 2 / 3;&#125; /* ThreadLocalMap使用 开放地址法-线性探测法 来解决哈希冲突 */// 向后一个位置找，注意从头开始的情况private static int nextIndex(int i, int len) &#123; return ((i + 1 &lt; len) ? i + 1 : 0);&#125;// 向前一个位置找，注意跳到尾部的情况private static int prevIndex(int i, int len) &#123; return ((i - 1 &gt;= 0) ? i - 1 : len - 1);&#125; 整体属性类似 HashMap ，各个值的含义已经详细注释就不再说明。需要注意的是，由于 ThreadLocalMap 使用的是线性探测法解决 hash 冲突，因此定义向前和向后探测的方法以便于寻找合适的位置及定位元素。 存储结构12345678910111213141516+--- ThreadLocalMap static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; // 与传入 ThreadLocal 关联的值，也就是线程局部变量值 Object value; /** * Entry的 key 是对 ThreadLocal 的弱引用，当抛弃掉 ThreadLocal 对象时，垃圾收集器会忽略这个 key 的引用而清理掉 ThreadLocal 对象。 * * @param k * @param v */ Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; 一个线程可以使用多个 ThreadLocal 将不同的值存储到当前线程的 ThreadLocalMap 中。熟悉 HashMap 存储结构的可以发现，ThreadLocalMap 中的存储结构有两大不同点： 没有链表相关的指针，更没有树节点的左右链接 元素节点结构 Entry 继承了 WeakReference 类，以实现弱引用功能 作为一个映射表，必然会有元素冲突的可能，虽然和 HashMap 结构类似，但是没有 HashMap 中链表和树形结构，那么 ThreadLocalMap 是怎么解决 hash 冲突的呢？答案是线性探测法。关于 Entry 继承 WeakReference 的原因我们在后面的文章中进行分析。 构造方法123456789101112131415161718192021222324+--- ThreadLocalMap /** * 构造方法 * * @param firstKey ThreadLocal 引用 * @param firstValue 设置的值 */ ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; // 1 初始化 Entry 数组，大小为 16 table = new Entry[INITIAL_CAPACITY]; // 2 获取 ThreadLocal 的 hash 值(该值是累加的) // 计算当前 key 对应的数组下标位置， 和 HashMap 的位运算代替取模原理一样 int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); // 3 将 Entry 对象存入到数组指定的位置 table[i] = new Entry(firstKey, firstValue); // 4 记录数组元素个数 size = 1; // 5 初始化扩容阈值 setThreshold(INITIAL_CAPACITY); &#125; 当线程 Thread 持有的 ThreadLocalMap 还没有初始化时，在使用 ThreadLocal 存储或获取数据时都会先创建一个 ThreadLocalMap 对象然后挂载到当前线程 Thread 上，后续不管该线程使用了多少个 ThreadLocal ，都会使用创建的 ThreadLocalMap 进行储存相应值，有冲突就使用线性探测法解决。 了解了 ThreadLocalMap 的底层数据结构后，下面我们依然从它的核心操作方法出发分析底层实现。 getEntry 方法1234567891011121314151617181920+--- ThreadLocalMap /** * 获取与 key 关联的 Entry * * @param key the thread local object * @return the entry associated with key, or null if no such */ private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; // 1 根据 key 计算下标 int i = key.threadLocalHashCode &amp; (table.length - 1); // 2 根据下标获取 Entry Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; // 3 通过下标直接得到的 Entry 不是要找的，那么就线性探测找 else return getEntryAfterMiss(key, i, e); &#125; 获取线程局部变量值的 getEntry 方法是 ThreadLocal 暴露的 get() 方法的底层实现，它的主要流程如下： 根据 ThreadLocal 引用计算对应的数组下标，这个和 HashMap 类似 根据计算得到的下标尝试直接获取对应的 Entry，如果当前 Entry 为空或对应的 key 不是当前传入的 key ，那么进行线性探测获取 123456789101112131415161718192021222324252627282930313233343536+--- ThreadLocalMap /** * getEntry方法的版本，用于在键未在其直接散列槽中找到时使用。 * 注意，该方法会清理无效 Entry * * @param key the thread local object * @param i the table index for key's hash code * @param e the entry at table[i] * @return the entry associated with key, or null if no such */ private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; // 1 获取 Table 信息 Entry[] tab = table; int len = tab.length; // 2 线性探测 while (e != null) &#123; // 获取 Entry 的 key ThreadLocal&lt;?&gt; k = e.get(); // 2.1 命中，直接返回 if (k == key) return e; // 2.2 无效 Entry，执行连续段删除 if (k == null) expungeStaleEntry(i); // 2.3 获取下个位置 else i = nextIndex(i, len); e = tab[i]; &#125; // 3 遍历完也没查到，返回 null return null; &#125; 之所以要进行线性探测获取其实是和链表查询一样，可能目标元素由于 hash 冲突放到了后续位置。注意：查询流程也就是 get() 方法可能也会清理无效的元素，以防止内存泄漏，但不能保证。关于连续段清理无效元素逻辑暂略过。 set 方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748+--- ThreadLocalMap /** * 设置与 key 关联的值 * 说明： * ThreadLocal 的 set 方法，就是为了将指定的值存入到指定线程的 ThreadLocalMap 对象中，具体还是通过 ThreadLocalMap 的 set 方法 * * @param key the thread local object * @param value the value to be set */ private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; // 1 获取数组信息 Entry[] tab = table; int len = tab.length; // 2 计算当前 ThreadLocal 对象引用作为键在数组中的下标 int i = key.threadLocalHashCode &amp; (len - 1); // 3 根据获取到的下标进行线性探测，寻找空的位置。 for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; // 3.1 获取当前 Entry 中的 key ，即 ThreadLocal 的引用，注意是弱引用。 ThreadLocal&lt;?&gt; k = e.get(); // 3.2 判断和当前的 ThreadLocal 对象是否是同一个对象，如果是，那么直接进行值替换，并结束方法， if (k == key) &#123; e.value = value; return; &#125; // 3.3 判断当前 Entry 是否失效，即是否被回收（弱引用），如果失效，说明当前位置可以重新使用，就使用新的 key-value 将其替换 // 该过程还会进行连续段删除其它无效的 entry if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; // 4 找到某个空位置，直接将键值对设置到该位置上。 tab[i] = new Entry(key, value); int sz = ++size; // 5 尝试随机清理无效 entry ，如果没有可清理的 entry 且数组元素大小 &gt;= 扩容阈值，则进行 rehash if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash(); &#125; 设置线程局部变量值的 set 方法稍微复杂点，下面对其主要流程进行说明： 根据传入的 key 计算数组下标位置 根据计算得到的下标进行线性探测，寻找空的位置以存放元素 检测到存在相同 key 的元素，进行值覆盖，然后结束流程即可 检测到无效的元素，则重用无效元素位置，并尝试清理无效的元素 在某个空位置存放数据 如果不是值覆盖或重用无效元素位置的情况，那么需要判断是否需要 rehash 下面我们对上述关联的核心方法进行拆解分析。 replaceStaleEntry 方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364+--- ThreadLocalMap /** * 替换无效 Entry ，并尝试删除其它无效的 Entry。 * * @param key key * @param value value * @param staleSlot 无效 entry 的位置 */ private void replaceStaleEntry(ThreadLocal&lt;?&gt; key, Object value, int staleSlot) &#123; // 1 获取数组信息 Entry[] tab = table; int len = tab.length; Entry e; // 标志 Table 中是否存在无效 Entry。slotToExpunge != staleSlot 说明 table 中存在无效 Entry 需要进行清理，否则说明没有。 int slotToExpunge = staleSlot; // 2 根据传入的无效 Entry 的位置 staleSlot 向前扫描一段连续非空的 Entry ，并记录最后一个无效的 Entry 的位置。或者扫描完也没有找到。 for (int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len)) // 2.1 如果是无效 Entry ，则更新删除标记 slotToExpunge if (e.get() == null) slotToExpunge = i; // 3 根据传入的无效 Entry 向后扫描一段连续的 Entry（根据线性探测，具有相同的 key 的元素一定是从后找的） ,以寻找是否有相同 key 的 Entry，以及在需要时更新删除标记位 slotToExpunge // 找到相同 key 的元素或末尾的空槽，以最先出现的为准 for (int i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; // 3.1 获取当前 Entry 的 key ThreadLocal&lt;?&gt; k = e.get(); // 3.2 如果找到了具有相同的 key ，则更新其值。也就是更新其值并将其与传入的无效 Entry 替换，即与 table[staleSlot] 进行替换 if (k == key) &#123; // 3.2.1 更新为传入的 value e.value = value; // 3.2.2 使用相同 key 的 Entry 重用失效位置以避免新创建一个 Entry，以维持散列表的顺序。 tab[i] = tab[staleSlot]; tab[staleSlot] = e; // 3.2.3 如果向前查找没有找到无效的 Entry，则更新删除标记位 slotToExpunge 为当前位置 i，此时 i 位置对应的是无效 Entry if (slotToExpunge == staleSlot) slotToExpunge = i; // 3.3.4 将新过时的槽或在其上面遇到的任何其他过时槽发送到expungeStaleEntry，以删除或重新散列运行中的所有其他条目。 cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); return; &#125; // 如果向前查找没有找到无效 entry，并且当前向后扫描的entry无效，则更新 slotToExpunge 为当前值 i if (k == null &amp;&amp; slotToExpunge == staleSlot) slotToExpunge = i; &#125; // 4 执行到这里，说明 table 中不存在相同 key 的 Entry，此时只需直接重用无效位置即可 tab[staleSlot].value = null; tab[staleSlot] = new Entry(key, value); // 5 slotToExpunge != staleSlot 说明 table 中存在无效 Entry 需要进行清理 if (slotToExpunge != staleSlot) cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); &#125; 重用无效 Entry 位置有两种可能： 如果扫描到的 Table 中存在和要插入的 key 相同的 Entry，那么就使用更新 value 后的该 Entry 替换无效 Entry 以避免新创建 Entry，同时该 Entry 成为了无效 Entry，只需等待后续删除即可。 如果扫描到的 Table 中不存在和要插入的 key 相同的 Entry ，那么直接创建 Entry 替换无效 Entry 即可。 此外，上述方法还会对无效 Entry 进行清理，触发条件就是检测到其它无效 Entry 的存在。 rehash 操作123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354+--- ThreadLocalMap /** * rehash 操作 * 1 扫描整个 Table ，删除无效的 Entry * 2 执行清理后，如果还需要扩容，则将表扩大一倍 */ private void rehash() &#123; // 1 清理所有无效 Entry expungeStaleEntries(); // 2 threshold - threshold / 4 = 1en / 2，降低扩容阈值是因为上面做了一次全清理 size 可能会减小 if (size &gt;= threshold - threshold / 4) resize(); &#125; /** * Table 容量扩大为原来 2 倍 */ private void resize() &#123; // 1 获取 Table 信息 Entry[] oldTab = table; int oldLen = oldTab.length; // 2 容量扩大为原来 2 倍 int newLen = oldLen * 2; Entry[] newTab = new Entry[newLen]; int count = 0; // 3 重新映射旧数组中的元素 for (int j = 0; j &lt; oldLen; ++j) &#123; Entry e = oldTab[j]; if (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); // 清理无效 Entry if (k == null) &#123; e.value = null; // Help the GC // 线性探测重新设置值 &#125; else &#123; int h = k.threadLocalHashCode &amp; (newLen - 1); while (newTab[h] != null) h = nextIndex(h, newLen); newTab[h] = e; count++; &#125; &#125; &#125; // 4 设置新的阈值 setThreshold(newLen); size = count; table = newTab; &#125; 新增数据后，如果达到阈值就会触发 rehash 流程，进行数组扩容和数据重新映射，这个没什么可说的。 remove 方法12345678910111213141516171819202122232425262728+--- ThreadLocalMap /** * 删除 */ private void remove(ThreadLocal&lt;?&gt; key) &#123; // 1 获取 Table 信息 Entry[] tab = table; int len = tab.length; // 2 计算 key 对应的下标 int i = key.threadLocalHashCode &amp; (len - 1); // 3 进行线性探测，查找正确的 Entry for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; // 找到对应的 Entry if (e.get() == key) &#123; // 调用 WeakReference.clear() 方法清除对应的引用 e.clear(); // 连续段删除 Entry expungeStaleEntry(i); return; &#125; &#125; &#125; 上述方法是 ThreadLocal 暴露的 remove() 方法的底层实现，用来清理当前 ThreadLocal 关联的信息。具体清理信息如下： 清除对当前 ThreadLocal 的弱引用 清除当前 ThreadLcoal 对应的 Entry 中的 value 清除当前 ThreadLocal 对应的 Entry expungeStaleEntry 方法expungeStaleEntry 方法用于彻底删除指定位置的 Entry 所以信息，接着向后连续段扫描删除无效 Entry ，并对可能存在 hash 冲突的 Entry 进行 rehash 。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758+--- ThreadLocalMap /** * 删除过期的元素，是连续段方式的删除 * * */ private int expungeStaleEntry(int staleSlot) &#123; // 1 获取 Table 信息 Entry[] tab = table; int len = tab.length; // 2 清理 staleSlot 位置的无效 Entry ，并递减元素个数 tab[staleSlot].value = null; tab[staleSlot] = null; size--; // Rehash until we encounter null Entry e; int i; // 3 从 stateSlot 开始向后扫描一段连续的非空的 Entry for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; // 3.1 获取当前 Entry 的 k ThreadLocal&lt;?&gt; k = e.get(); // 3.2 如果遇到key为null,表示无效entry，进行清理. if (k == null) &#123; // value 置空 e.value = null; // 元素置空 tab[i] = null; // 元素个数递减 size--; // 3.3 如果 key 不为 null ，则对可能存在 hash 冲突的 Entry 进行 rehash &#125; else &#123; // 计算 key 对应的下标，如果与现在所在位置不一致，认为存在 hash 冲突，置空当前 table[i] ， // 并从 h 开始向后线性探测到第一个空的 slot，把当前的 entry 移动过去。 int h = k.threadLocalHashCode &amp; (len - 1); if (h != i) &#123; tab[i] = null; // Unlike Knuth 6.4 Algorithm R, we must scan until // null because multiple entries could have been stale. while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; &#125; &#125; &#125; // 下一个为空的下标 return i; &#125; 上述方法用于删除过期的元素，具体删除策略如下： 根据传入的 stateSlot 清理对应的无效 Entry，这个是绝对删除。 根据传入的 stateSlot 向后扫描一段连续非空的 Entry ，对可能存在 hash 冲突的 Entry 进行 rehash ，并且清理遇到的无效 Entry 。 expungeStaleEntries 方法12345678910111213/** * 扫描整个 Table ，删除无效的 Entry */private void expungeStaleEntries() &#123; Entry[] tab = table; int len = tab.length; for (int j = 0; j &lt; len; j++) &#123; Entry e = tab[j]; // 无效 Entry ，则调用 expungeStaleEntry 方法删除对应位置及连坐删除 Entry if (e != null &amp;&amp; e.get() == null) expungeStaleEntry(j); &#125;&#125; 该方法是在 expungeStaleEntry 方法的基础上，对整个 Table 中无效元素进行清理，一定会清理截止到当前 Table 中所有的无效 Entry 。需要说明的是，ThreadLocal 的所有一些列操作都是单线程的，也就是当前线程。 cleanSomeSlots 方法123456789101112131415161718192021222324252627282930313233+--- ThreadLocalMap /** * 启发式的扫描清除，扫描次数由传入的参数n决定 * * @param i 从i向后开始扫描（不包括i，因为索引为i的Slot肯定为null） * @param n 控制扫描次数，正常情况下为 log2(n) ，如果找到了无效 Entry ，会将 n 重置为 table 的长度 len 进行阶段删除 * @return true if any stale entries have been removed. */ private boolean cleanSomeSlots(int i, int n) &#123; // 1 删除标志 boolean removed = false; // 2 数组信息 Entry[] tab = table; int len = tab.length; // 从 i 位置向后遍历，删除无效的 Entry do &#123; i = nextIndex(i, len); Entry e = tab[i]; // 如果当前 Entry 无效，则进行清理并进行连坐 if (e != null &amp;&amp; e.get() == null) &#123; n = len; removed = true; i = expungeStaleEntry(i); &#125; // 无符号的右移动，可以用于控制扫描次数在log2(n) &#125; while ((n &gt;&gt;&gt;= 1) != 0); return removed; &#125; 启发式扫描删除具有随机性，启发式思想也用在其他代码中，如 Redis 中的定期删除逻辑。 自此，ThreadLocalMap 的源码实现分析完毕。 共享数据一般来说 ThreadLocal 数据都是线程独享的，但是 ThreadLocal 继承体系支持子线程共享父线程的变量副本数据。共享线程的 ThreadLocal 数据可以使用 InheritableThreadLocal 来实现。通过在父线程中创建一个 InheritableThreadLocal 的实例，然后在子线程中就可以获取该实例中设置的值。 使用示例代码 1234567891011121314151617181920public static void main(String[] args) throws InterruptedException &#123; // 1 创建 InheritableThreadLocal 对象 ThreadLocal&lt;String&gt; threadLocal = new InheritableThreadLocal&lt;&gt;(); // 2 创建的 ThreadLocalMap 挂载到当前 Thread 的 inheritableThreadLocals 属性 threadLocal.set(\"小芒果!\"); // 3 创建并启动子线程 Runnable runnable = () -&gt; &#123; // 打印子线程 ThreadLocal 的线程变量值 System.out.println(Thread.currentThread().getName() + \"-&gt; \" + threadLocal.get()); &#125;; Thread thread = new Thread(runnable); thread.start(); // 打印父线程（这里是主线程） ThreadLocal 的线程变量值 System.out.println(Thread.currentThread().getName() + \"-&gt; \" + threadLocal.get()); Thread.sleep(3000);&#125; 打印结果 1234main-&gt; 小芒果!Thread-0-&gt; 小芒果!Process finished with exit code 0 实现原理线程变量传递逻辑很简单，它隐藏在 Thread 的 init 方法中。 12345678910111213141516171819202122232425262728+--- Thread /** * 线程初始化 */ private void init(ThreadGroup g, Runnable target, String name, long stackSize) &#123; init(g, target, name, stackSize, null, true); &#125; // 省略无关代码 private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) &#123; // 获取初始化当前线程的线程 Thread parent = currentThread(); // 如果 parent 线程使用了 InheritableThreadLocal ，那么就把 parent 的 inheritableThreadLocals 给当前线程的 inheritableThreadLocals 。 if (inheritThreadLocals &amp;&amp; parent.inheritableThreadLocals != null) // 设置到当前线程的 inheritableThreadLocals 属性中 this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); /* Stash the specified stack size in case the VM cares */ this.stackSize = stackSize; /* Set thread ID */ tid = nextThreadID(); &#125; 从线程初始化逻辑中可以看出，如果父线程 ThreadLocalMap 类型的变量 inheritableThreadLocals 不为空，那么就把父线程的该属性设置给当前线程的 inheritableThreadLocals 属性。具体设置逻辑在 ThreadLocal 的 createInheritedMap 方法中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344+--- ThreadLocal // 继承式创建 ThreadLocal static ThreadLocalMap createInheritedMap(ThreadLocalMap parentMap) &#123; return new ThreadLocalMap(parentMap); &#125; // 仅由 createInheritedMap 方法调用 private ThreadLocalMap(ThreadLocal.ThreadLocalMap parentMap) &#123; // 1 获取 parentMap 的 Table 信息 ThreadLocal.ThreadLocalMap.Entry[] parentTable = parentMap.table; int len = parentTable.length; setThreshold(len); // 2 创建新的 Table table = new ThreadLocal.ThreadLocalMap.Entry[len]; // 3 将 parentMap 中的数据依次映射到新创建的 Table 中 for (int j = 0; j &lt; len; j++) &#123; // 3.1 获取当前 Entry ThreadLocal.ThreadLocalMap.Entry e = parentTable[j]; if (e != null) &#123; // 3.2 获取 Entry 中的 key @SuppressWarnings(\"unchecked\") ThreadLocal&lt;Object&gt; key = (ThreadLocal&lt;Object&gt;) e.get(); // 3.3 Entry 有效的话就进行映射 if (key != null) &#123; // 用于获取父线程变量值的转换，默认就是父线程 Entry.value 值 Object value = key.childValue(e.value); // 线性探测存储元素 ThreadLocal.ThreadLocalMap.Entry c = new ThreadLocal.ThreadLocalMap.Entry(key, value); int h = key.threadLocalHashCode &amp; (len - 1); while (table[h] != null) h = nextIndex(h, len); table[h] = c; size++; &#125; &#125; &#125; &#125; 通过以上逻辑可以发现，如果要使用线程变量共享需要使用到 InheritableThreadLocal 类，线程 Thread 的映射属性使用 inheritableThreadLocals 而非 threadLocals 。 InheritableThreadLocal123456789101112131415161718192021222324252627282930public class InheritableThreadLocal&lt;T&gt; extends ThreadLocal&lt;T&gt; &#123; /** * 默认是 Entry 的 value 值，使用方可继承 InheritableThreadLocal 覆盖该方法 * * @param parentValue the parent thread's value * @return the child thread's initial value */ protected T childValue(T parentValue) &#123; return parentValue; &#125; /** * 获取当前线程 t 的 ThreadLocalMap ，注意取的是 inheritableThreadLocals 属性 * * @param t the current thread */ ThreadLocalMap getMap(Thread t) &#123; return t.inheritableThreadLocals; &#125; /** * 创建当前线程 t 的 ThreadLocalMap ，注意设置的是 inheritableThreadLocals 属性 * * @param t the current thread * @param firstValue value for the initial entry of the table. */ void createMap(Thread t, T firstValue) &#123; t.inheritableThreadLocals = new ThreadLocalMap(this, firstValue); &#125;&#125; InheritableThreadLocal 继承了 ThreadLocal ，重写了以上三个方法，主要是将映射表挂在到 Thread 的 inheritableThreadLocals 属性上，用以实现线程变量的共享。注意，线程变量独享使用的是 Thread 中的 threadLocals 属性。InheritableThreadLocal 对比 ThreadLocal 唯一不同是子线程会继承父线程变量，并支持自定义赋值函数。 问题内存泄漏ThreadLocalMap 使用 ThreadLocal 的弱引用做为元素 Entry 的 key ,如果一个 ThreadLocal 没有外部强引用来引用它，那么系统 GC 时这个 ThreadLocal 会被回收。此时，ThreadLocalMap 中就会出现 key 为 null 的 Entry ，这样就没有办法访问这些 Entry，这些 Entry 理论上属于无效的，应该被 GC 回收。但是，如果存在持有这些 Entry 的线程迟迟不结束（如使用线程池），那么这些 key 为 null 的 Entry 的 value 就会一直存在一条强引用链 Thread Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value，导致无法回收，造成内存泄漏。 ThreadLocal 为了尽可能避免内存泄漏问题，在 get()、set() 以及 remove() 方法中都有清除线程的 ThreadLocalMap 中 key 为 null 的 value 逻辑。注意，其中 get()、set() 两个方法都不能完全防止内存泄漏，存在无效 Entry 无法扫描到的情况，因为只有在线性探测流程中才会尝试连续段清理无效 Entry 。最好的方式是每次使用完 ThreadLocal 都手动 remove 一下。 此外，以下措施会增加内存泄漏的风险： 使用 static 的 ThreadLocal ，这种方式延长了 ThreadLocal 的生命周期 分配使用了 ThreadLocal ，而不再调用其 get()、set() 以及 remove() 方法 为什么使用弱引用 key 使用强引用：ThreadLocal 对象没有外部引用，但是 ThreadLocalMap 持有 ThreadLocal 的强引用，如果没有手动删除，ThreadLocal 不会被回收，这会导致 Entry 内存泄漏。 key 使用弱引用：ThreadLocal 对象没有外部引用，由于 ThreadLocalMap 持有 ThreadLocal 的弱引用，即使没有手动删除，ThreadLcoal 也可以被回收。value 在下一次执行方法时被清除。 Entry 继承 WeakReference，并且使用 ThreadLocal 的弱引用作为 key，这样可以将 ThreadLocal 对象的生命周期和线程生命周期解绑。持有弱引用可以使得 ThreadLocal 在没有其他强引用的时候被回收掉，这样可以避免因为线程得不到销毁导致 ThreadLocal 对象无法被回收。 最佳实践每次使用完 ThreadLocal 都应该调用它的 remove() 方法，进行数据清理，防止内存泄漏。 应用场景 多线程之间需要拥有同一个信息，那么通常可以采用 initialValue() 方法进行初始化，直接将需要拥有的变量副本存储到 ThreadLocal 中。 多个线程中存储不同的信息，那么需要使用 set() 方法设置变量副本到 ThreadLocal 中。 上述描述存储到 ThreadLocal 中是不对的，需要注意，数据其实是存储到线程持有的 ThreadLocalMap 对象中，该对象是一个散列表。 小结本篇文章对 ThreadLocal 进行了深入的分析，它能保证数据安全是因为每个线程都有自己的线程变量，不会发生多个线程共享变量的情况。首先对 ThreadLocal 的关系进行了介绍，从总体上认识 ThreadLocal 。接着对 ThreadLocal 进行了分析，从其属性到暴露的 API 。然后对 ThreadLocal 底层的支持类 ThreadLocalMap 进行了分析，同样从属性到支撑上层的方法的分析。最后对父子线程就 ThreadLocal 如何共享线程变量进行了分析。在文章的最后，对内存泄漏问题进行了介绍。 参考资料https://www.cnblogs.com/lqlqlq/p/13302901.html","categories":[{"name":"JDK","slug":"JDK","permalink":"https://gentryhuang.com/categories/JDK/"}],"tags":[{"name":"Thread","slug":"Thread","permalink":"https://gentryhuang.com/tags/Thread/"}]},{"title":"Java基础 - Reference","slug":"java-base/Java引用","date":"2021-08-21T02:30:12.000Z","updated":"2021-09-13T15:06:20.781Z","comments":false,"path":"posts/55ae5a2b/","link":"","permalink":"https://gentryhuang.com/posts/55ae5a2b/","excerpt":"","text":"概述在 Java 中有 4 种引用类型，主要是在垃圾回收时 JVM 会根据不同的引用类型采取不同的措施。下面分别对这四种类型进行说明，特别是弱引用，将会结合示例进行分析。 引用类型Java 中的四种引用类型如下图所示： 强引用强引用是 Java 默认的引用类型。如果一个对象具有强引用，当内存空间不足时，JVM 宁可抛出 OutOfMemoryError 错误使程序异常终止，也不会回收具有强引用的对象来解决内存不足问题。 1234public void sayHello()&#123; Object object = new Object(); // ....&#125; 如上所示，在一个方法中有一个强引用 object ，该引用保存在栈中，而真正的引用内容 Object 对象保存在堆中。当上述方法运行完成后退出方法栈，强引用 object 就不存在了，引用的 Object 对象就会被回收。 注意，如果 Object object = new Object(); 是全局的，那么在不使用该对象时需要设置 object = null 以帮助垃圾收集器回收该对象。 也就是说，一个对象从根路径能找到强引用指向它，JVM 就不会回收。 软引用如果一个对象只具有软引用，在内存空间足够的情况下 JVM 就不会回收它；如果内存空间不足就会回收这些对象。更准确地来说，进行 Young GC 不会触发软引用所指向对象的回收；但如果触发Full GC，则软引用所指向的对象将被回收。前提是除了软引用之外没有其他强引用引用的情况下。 123456789// 强引用String str = \"hello world!\";// 软引用SoftReference&lt;String&gt; softReference = new SoftReference&lt;&gt;(str); // 内存不足if(isNotFullMemeory())&#123; str = null; System.gc(); &#125; 如上所示，在内存不足时会回收软引用。软引用可用来实现高速缓存。 弱引用如果一个对象只有弱引用指向它，当进行年轻代垃圾回收时，一旦发现该引用指向的对象就会立刻回收，不管当前内存空间是否足够。注意，由于垃圾回收器是一个优先级很低的线程，因此不一定及时发现那些具有弱引用的对象。 12345678// 强引用String str = \"hello world!\";// 弱引用WeakReference&lt;String&gt; weakReference = new WeakReference&lt;&gt;(str); // 垃圾回收str = null;System.gc(); 如上所示，在进行垃圾回收时发现弱引用立即回收。如果想使用一个对象且不想介入这个对象的生命周期，这时就可以使用弱引用。注意，下面的代码可以转为强引用。 1String str = weakReference.get(); 虚引用虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。 1234567// 强引用String str = \"hello world!\";// 虚引用PhantomReference phantomReference = new PhantomReference(str,new ReferenceQueue&lt;&gt;());str = null;// 随时可能会输 虚引用主要用来跟踪对象被垃圾回收器回收的活动。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中，该队列就是前文类图中的 ReferenceQueue 。 再谈弱引用由于在看 ThreadLocal 源码时考虑到涉及 弱引用 ，因此单独拿出来说明下。下面对 WeakReference 类进行分析。 WeakReference12345678910111213141516171819public class WeakReference&lt;T&gt; extends Reference&lt;T&gt; &#123; /** * 创建一个指向给定对象的弱引用 * * @param referent 给定对象的引用 */ public WeakReference(T referent) &#123; super(referent); &#125; /** * * @param referent 给定对象的引用 * @param q 对象被回收后会把弱引用对象，也就是WeakReference对象或者其子类的对象，放入队列ReferenceQueue中，注意不是被弱引用的对象，被弱引用的对象已经被回收了。 */ public WeakReference(T referent, ReferenceQueue&lt;? super T&gt; q) &#123; super(referent, q); &#125;&#125; 通过上述代码强调两个概念： 1 弱引用对象是指 WeakReference 实例或其子类实例。2 被弱引用的对象是指需要通过 WeakReference 封装的对象，形如：WeakReference&lt;Xxx&gt; appleWeakReference = new WeakReference&lt;&gt;(xxx)。这个时候我们说，持有了 xxx 指向对象的弱引用，也就是说当 xxx 也不再引用（可能不止 xxx 引用）时，就剩下弱引用，此时垃圾回收时是可以把对应的对象回收掉。 基本使用Fruit 类 12345678910111213141516171819202122232425@Data@Slf4jpublic class Fruit &#123; /** * 名称 */ private String name; public Fruit(String name) &#123; this.name = name; &#125; @Override protected void finalize() throws Throwable &#123; super.finalize(); log.info(name + \"finalize !\"); &#125; @Override public String toString() &#123; return \"Fruit&#123;\" + \"name='\" + name + '\\'' + '&#125;'; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435@Slf4jpublic class Client &#123; public static void main(String[] args) throws InterruptedException &#123; // 强引用 Fruit fruit = new Fruit(\"小芒果\"); // 创建弱引用对象 Animal animal = new Animal(fruit); // 通过 WeakReference.get() 方法获取对应的对象 log.info(\"Fruit: \" + animal.get()); // 消除强引用，确保只有弱引用（不消除强引用，不会回收） fruit = null; // 触发垃圾回收 System.gc(); // 保证 GC 的发生 Thread.sleep(5000); // 小芒果被回收 - 因此只有弱引用 log.info(animal.get() == null ? \" Fruit is Cleared\" : animal.get().toString()); &#125; /** * 继承 WeakReference ，持有 Fruit 的弱引用。 * 当垃圾回收时，回收的是弱引用 referent 指向的对象，而非 Animal */ static class Animal extends WeakReference&lt;Fruit&gt; &#123; public Animal(Fruit referent) &#123; super(referent); &#125; &#125;&#125; 执行结果如下： 12345678910111213141516[main] INFO com.code.concurrent.Client - Fruit: Fruit&#123;name&#x3D;&#39;小芒果&#39;&#125;[Finalizer] INFO com.code.concurrent.Fruit - 小芒果finalize ![GC (System.gc()) [PSYoungGen: 5242K-&gt;752K(76288K)] 5242K-&gt;760K(251392K), 0.0008122 secs] [Times: user&#x3D;0.00 sys&#x3D;0.00, real&#x3D;0.00 secs] [Full GC (System.gc()) [PSYoungGen: 752K-&gt;0K(76288K)] [ParOldGen: 8K-&gt;534K(175104K)] 760K-&gt;534K(251392K), [Metaspace: 3371K-&gt;3371K(1056768K)], 0.0042356 secs] [Times: user&#x3D;0.03 sys&#x3D;0.00, real&#x3D;0.00 secs] [main] INFO com.code.concurrent.Client - Fruit is ClearedHeap PSYoungGen total 76288K, used 7209K [0x000000076ab00000, 0x0000000770000000, 0x00000007c0000000) eden space 65536K, 11% used [0x000000076ab00000,0x000000076b20a738,0x000000076eb00000) from space 10752K, 0% used [0x000000076eb00000,0x000000076eb00000,0x000000076f580000) to space 10752K, 0% used [0x000000076f580000,0x000000076f580000,0x0000000770000000) ParOldGen total 175104K, used 534K [0x00000006c0000000, 0x00000006cab00000, 0x000000076ab00000) object space 175104K, 0% used [0x00000006c0000000,0x00000006c0085bf8,0x00000006cab00000) Metaspace used 3857K, capacity 4704K, committed 4864K, reserved 1056768K class space used 428K, capacity 464K, committed 512K, reserved 1048576KProcess finished with exit code 0 引用队列12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@Slf4jpublic class Client &#123; public static void main(String[] args) throws InterruptedException &#123; // 强引用 Fruit fruit = new Fruit(\"小芒果\"); // 创建弱引用对象及引用队列 ReferenceQueue&lt;Fruit&gt; referenceQueue = new ReferenceQueue&lt;&gt;(); Animal animal = new Animal(fruit, referenceQueue); // 通过 WeakReference.get() 方法获取对应的对象 log.info(\"Fruit 对象信息: \" + animal.get()); // GC 前 log.info(\"GC 前\"); if (referenceQueue.poll() == null) &#123; log.info(\"没有回收被弱引用的对象，不会加入队列中\"); &#125; // 记录弱引用对象地址，用于回收前后对比 log.info(\"弱引用对象地址：\"+ animal.toString()); // 消除强引用，确保只有弱引用（不消除强引用，不会回收） fruit = null; // 触发垃圾回收 log.info(\"GC 中\"); System.gc(); // 保证 GC 的发生 Thread.sleep(5000); // GC 后 log.info(\"GC 后\"); // 小芒果被回收 - 因此只有弱引用 log.info(animal.get() == null ? \" Fruit is Cleared\" : animal.get().toString()); Reference reference = null; if ((reference = referenceQueue.poll()) != null) &#123; log.info(\"回收被弱引用的对象，弱引用对象加入队列中，地址为：\" + reference.toString()); &#125; &#125; /** * 继承 WeakReference ，持有 Fruit 的弱引用。 * 当垃圾回收时，回收的是弱引用 referent 指向的对象，而非 Animal */ static class Animal extends WeakReference&lt;Fruit&gt; &#123; public Animal(Fruit referent, ReferenceQueue referenceQueue) &#123; super(referent, referenceQueue); &#125; &#125;&#125; 执行结果如下： 12345678910111213141516171819202122[main] INFO com.code.concurrent.Client - Fruit 对象信息: Fruit&#123;name&#x3D;&#39;小芒果&#39;&#125;[main] INFO com.code.concurrent.Client - GC 前[main] INFO com.code.concurrent.Client - 没有回收被弱引用的对象，不会加入队列中[main] INFO com.code.concurrent.Client - 弱引用对象地址：com.code.concurrent.Client$Animal@a09ee92[main] INFO com.code.concurrent.Client - GC 中[Finalizer] INFO com.code.concurrent.Fruit - 小芒果finalize ![GC (System.gc()) [PSYoungGen: 5242K-&gt;736K(76288K)] 5242K-&gt;744K(251392K), 0.0006983 secs] [Times: user&#x3D;0.00 sys&#x3D;0.01, real&#x3D;0.00 secs] [Full GC (System.gc()) [PSYoungGen: 736K-&gt;0K(76288K)] [ParOldGen: 8K-&gt;535K(175104K)] 744K-&gt;535K(251392K), [Metaspace: 3380K-&gt;3380K(1056768K)], 0.0035821 secs] [Times: user&#x3D;0.02 sys&#x3D;0.00, real&#x3D;0.00 secs] [main] INFO com.code.concurrent.Client - GC 后[main] INFO com.code.concurrent.Client - Fruit is Cleared[main] INFO com.code.concurrent.Client - 回收被弱引用的对象，弱引用对象加入队列中，地址为：com.code.concurrent.Client$Animal@a09ee92Heap PSYoungGen total 76288K, used 7209K [0x000000076ab00000, 0x0000000770000000, 0x00000007c0000000) eden space 65536K, 11% used [0x000000076ab00000,0x000000076b20a738,0x000000076eb00000) from space 10752K, 0% used [0x000000076eb00000,0x000000076eb00000,0x000000076f580000) to space 10752K, 0% used [0x000000076f580000,0x000000076f580000,0x0000000770000000) ParOldGen total 175104K, used 535K [0x00000006c0000000, 0x00000006cab00000, 0x000000076ab00000) object space 175104K, 0% used [0x00000006c0000000,0x00000006c0085e60,0x00000006cab00000) Metaspace used 3856K, capacity 4704K, committed 4864K, reserved 1056768K class space used 428K, capacity 464K, committed 512K, reserved 1048576KProcess finished with exit code 0 小结本篇文章对 Java 中的 4 种引用进行了介绍，重点对弱引用进行了详细分析，理解了弱引用再去看 ThreadLocal 就能更好地理解其内存泄漏问题。下一篇文章将对 ThreadLocal 进行分析。","categories":[{"name":"JDK","slug":"JDK","permalink":"https://gentryhuang.com/categories/JDK/"}],"tags":[]},{"title":"并发 - Thread","slug":"concurrent/Thread","date":"2021-08-14T13:50:21.000Z","updated":"2021-09-15T03:11:19.263Z","comments":false,"path":"posts/dbdf391f/","link":"","permalink":"https://gentryhuang.com/posts/dbdf391f/","excerpt":"","text":"概述现代操作系统在运行一个程序时，会为其创建一个进程，进程是分配系统资源的最小单位。例如，启动一个 Java 程序时，操作系统就会创建一个 Java 进程。现代操作系统调度 CPU 的最小单位是线程，一个进程可能包含一个或多个线程，这些线程都拥有各自的栈空间和局部变量等属性，并且能够访问共享的内存变量。 Java线程Java 中的线程本质上就是一块内存（对象），不等于操作系统的线程。 下面是一段 Java 中的线程相关的代码： 123456789public static void main(String[] args) &#123; // 1 创建线程 Thread Thread thread = new Thread(()-&gt;&#123; log.info(Thread.currentThread().getName() + \"is running!\"); &#125;); // 2 启动线程 thread.start();&#125; 对于 Java 语言来说，上述程序有两个动作，分别是创建线程和启动线程。但对于底层系统来说，Java 中的线程对象 Thread 执行 start() 方法后会间接调用操作系统函数库创建一个操作系统层面的线程并等待 CPU 调度。关于 Java 线程映射操作系统线程在下文会详细分析，我们先对 Java 线程的创建过程进行说明。 创建Java线程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * 初始化一个 Java 线程 * * @param g 线程所属的线程组 * @param target 任务体 * @param name 线程名 * @param stackSize 线程堆栈大小 * @param acc the AccessControlContext to inherit, or * AccessController.getContext() if null * @param inheritThreadLocals if &#123;@code true&#125;, inherit initial values for * inheritable thread-locals from the constructing thread */ private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) &#123; if (name == null) &#123; throw new NullPointerException(\"name cannot be null\"); &#125; this.name = name; // 当前线程是该线程（要创建的线程）的父线程 Thread parent = currentThread(); SecurityManager security = System.getSecurityManager(); if (g == null) &#123; if (security != null) &#123; g = security.getThreadGroup(); &#125; // 使用父线程组 if (g == null) &#123; g = parent.getThreadGroup(); &#125; &#125; g.checkAccess(); if (security != null) &#123; if (isCCLOverridden(getClass())) &#123; security.checkPermission(SUBCLASS_IMPLEMENTATION_PERMISSION); &#125; &#125; g.addUnstarted(); this.group = g; // 将 daemon、priority 属性设置为父线程的对应属性 this.daemon = parent.isDaemon(); this.priority = parent.getPriority(); // 类加载器 if (security == null || isCCLOverridden(parent.getClass())) this.contextClassLoader = parent.getContextClassLoader(); else this.contextClassLoader = parent.contextClassLoader; this.inheritedAccessControlContext = acc != null ? acc : AccessController.getContext(); this.target = target; setPriority(priority); // 将父线程的 InheritableThreadLocal 复制过来，ThreadLocal 的使用 if (inheritThreadLocals &amp;&amp; parent.inheritableThreadLocals != null) this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); /* Stash the specified stack size in case the VM cares */ this.stackSize = stackSize; // 分配一个线程 ID tid = nextThreadID(); &#125; 在创建 Thread 对象时会调用上面的 init 方法进行 Java 线程初始化。 启动Java线程123456789101112131415161718192021222324252627282930313233343536373839404142/** * 启动线程方法 * * 调用该方法启动 Java 线程；Java 虚拟机会调用该线程的 run 方法 * * 多次启动一个线程是不合法的 * * 特别是，线程一旦完成执行，就不能重新启动。 * * @exception IllegalThreadStateException if the thread was already * started. * @see #run() * @see #stop() */public synchronized void start() &#123; if (threadStatus != 0) throw new IllegalThreadStateException(); /* Notify the group that this thread is about to be started * so that it can be added to the group's list of threads * and the group's unstarted count can be decremented. */ group.add(this); boolean started = false; try &#123; // 调用 native 方法 start0(); started = true; &#125; finally &#123; try &#123; if (!started) &#123; group.threadStartFailed(this); &#125; &#125; catch (Throwable ignore) &#123; /* do nothing. If start0 threw a Throwable then it will be passed up the call stack */ &#125; &#125;&#125;// native 方法private native void start0(); 我们知道的是，Java 线程调用 start 方法后就启动了，获取到 CPU 资源就可以执行任务。那么这和底层系统线程是怎么对应的呢？下面我们就来详细分析 Java 线程是怎么映射操作系统线程的。在分析 Java 线程是怎么映射到操作系统线程之前，我们需要先说明 JDK 的组成。JDK 的代码有两部分，一部分是 Java 语言库，另一部分是实现更底层功能的本地方法，他们由 C++ 实现，位于 openJdk 代码中。 映射系统线程下面我们从调用本地方法 start0 出发，对执行链路进行跟踪，跟踪代码是 openJdk 中的源码。 Thread.c12345678910111213141516 static JNINativeMethod methods[] = &#123; &#123;\"start0\", \"()V\", (void *)&amp;JVM_StartThread&#125;, &#123;\"stop0\", \"(\" OBJ \")V\", (void *)&amp;JVM_StopThread&#125;, &#123;\"isAlive\", \"()Z\", (void *)&amp;JVM_IsThreadAlive&#125;, &#123;\"suspend0\", \"()V\", (void *)&amp;JVM_SuspendThread&#125;, &#123;\"resume0\", \"()V\", (void *)&amp;JVM_ResumeThread&#125;, &#123;\"setPriority0\", \"(I)V\", (void *)&amp;JVM_SetThreadPriority&#125;, &#123;\"yield\", \"()V\", (void *)&amp;JVM_Yield&#125;, &#123;\"sleep\", \"(J)V\", (void *)&amp;JVM_Sleep&#125;, &#123;\"currentThread\", \"()\" THD, (void *)&amp;JVM_CurrentThread&#125;, &#123;\"interrupt0\", \"()V\", (void *)&amp;JVM_Interrupt&#125;, &#123;\"holdsLock\", \"(\" OBJ \")Z\", (void *)&amp;JVM_HoldsLock&#125;, &#123;\"getThreads\", \"()[\" THD, (void *)&amp;JVM_GetAllThreads&#125;, &#123;\"dumpThreads\", \"([\" THD \")[[\" STE, (void *)&amp;JVM_DumpThreads&#125;, &#123;\"setNativeName\", \"(\" STR \")V\", (void *)&amp;JVM_SetNativeThreadName&#125;,&#125;; 可以看到，Thread 中的本地方法 start0 维护在一个方法表中，对应的处理函数是 JVM_StartThread，下面我们看这个函数的作用。 jvm.cpp12345678910111213141516171819202122232425JVM_ENTRY(void, JVM_StartThread(JNIEnv* env, jobject jthread))JavaThread *native_thread = NULL;bool throw_illegal_thread_state = false;// 在 Thread::start 方法调用执行，必须先释放 Threads_lock&#123; // 确保 C++ Thread 和 OSThread结构 在我们操作之前没有被释放。 MutexLocker mu(Threads_lock); // 忽略 if (java_lang_Thread::thread(JNIHandles::resolve_non_null(jthread)) != NULL) &#123; throw_illegal_thread_state = true; &#125; else &#123; jlong size = java_lang_Thread::stackSize(JNIHandles::resolve_non_null(jthread)); NOT_LP64(if (size &gt; SIZE_MAX) size = SIZE_MAX;) size_t sz = size &gt; 0 ? (size_t) size : 0; // 创建 JavaThread 对象 native_thread = new JavaThread(&amp;thread_entry, sz);&#125;// 创建完 JavaThread 后，启动 JavaThread Thread::start(native_thread);JVM_END 可以看到，在执行本地方法 start0 后会创建一个 C++ JavaThread 对象，创建后才会启动 JavaThread 并执行 thread_entry 函数。 jvm.cpp12345678910111213static void thread_entry(JavaThread* thread, TRAPS) &#123;HandleMark hm(THREAD);Handle obj(THREAD, thread-&gt;threadObj());JavaValue result(T_VOID);// thread_entry 中 JavaCalls::call_virtual 就是通过 JVM 调用 run 方法的JavaCalls::call_virtual(&amp;result, obj, vmClasses::Thread_klass(), // vmSymbols::run_method_name() 映射的就是 run 方法 vmSymbols::run_method_name(), vmSymbols::void_method_signature(), THREAD);&#125; 可以看到，JavaThread 执行的回调函数 thread_entry 是关联 Java 线程的直接入口，是通过 Java 虚拟机调用 Thread 对象的 run 方法的。至此，从 Java 线程到 C++ 线程就结束了，不过这两个都不是真正意义上的线程。下面我们继续跟，寻找创建操作系统线程的信息，其实操作系统线程的创建与启动的线索都在创建 C++ JavaThread 对象的逻辑中。 thread.cpp123456789101112JavaThread::JavaThread(ThreadFunction entry_point, size_t stack_sz) : JavaThread() &#123;_jni_attach_state = _not_attaching_via_jni;// 1 为 JavaThread 设置运行函数 entry_pointset_entry_point(entry_point);// Create the native thread itself.// %note runtime_23os::ThreadType thr_type = os::java_thread;thr_type = entry_point == &amp;CompilerThread::thread_entry ? os::compiler_thread : os::java_thread;// 2 根据不同的操作系统，调用对应底层函数创建线程os::create_thread(this, thr_type, stack_sz);&#125; 哇，终于要见到了操作系统创建线程的流程了。在创建 C++ 的线程对象 JavaThread 时会根据不同的操作系统调用不同的函数创建线程。 os_linux.cpp123456789101112131415161718192021222324252627// thread-&gt;JavaThreadbool os::create_thread(Thread* thread, ThreadType thr_type, size_t req_stack_size) &#123; // 创建 OSThread OSThread* osthread = new OSThread(NULL, NULL);if (osthread == NULL) &#123; return false; &#125;// set the correct thread stateosthread-&gt;set_thread_type(thr_type);// Initial state is ALLOCATED but not INITIALIZEDosthread-&gt;set_state(ALLOCATED);// 为 JavaThread 设置 OSThreadthread-&gt;set_osthread(osthread);ThreadState state;&#123; ResourceMark rm; pthread_t tid; int ret = 0; int limit = 3; do &#123; // 我们的线程来了 // 调用 Linux 操作系统函数创建真正意义上的线程并运行函数 thread_native_entry，该函数参数是 JavaThread ret = pthread_create(&amp;tid, &amp;attr, (void* (*)(void*)) thread_native_entry, thread); &#125; while (ret == EAGAIN &amp;&amp; limit-- &gt; 0); 这里以 Linux 操作系统为例，我们看到调用 Linux 的 pthread_create 库函数 创建线程并执行回调函数 thread_native_entry 。该回调用函数涉及到操作系统线程的状态。 os_linux.cpp12345678910111213141516171819202122232425262728293031323334353637383940414243 // 所有在 Linux 操作系统下新创建的线程运行的函数。 // 也就是当在 Java 中创建一个线程并执行 start 方法，后续会创建对应的操作系统线程并执行该方法 // thread-&gt;JavaThread static void *thread_native_entry(Thread *thread) &#123; thread-&gt;record_stack_base_and_size(); thread-&gt;initialize_thread_current(); // 获取 JavaThread 中的 OSThread OSThread* osthread = thread-&gt;osthread(); Monitor* sync = osthread-&gt;startThread_lock(); osthread-&gt;set_thread_id(os::current_thread_id()); if (UseNUMA) &#123; int lgrp_id = os::numa_get_group_id(); if (lgrp_id != -1) &#123; thread-&gt;set_lgrp_id(lgrp_id); &#125; &#125; // initialize signal mask for this thread PosixSignals::hotspot_sigmask(thread); // initialize floating point control register os::Linux::init_thread_fpu_state(); // handshaking with parent thread &#123; MutexLocker ml(sync, Mutex::_no_safepoint_check_flag); // notify parent thread // 设置OSThread 为初始状态 osthread-&gt;set_state(INITIALIZED); sync-&gt;notify_all(); // wait until os::start_thread() // 如果 OSThread 是初始化状态，则让它阻塞。 while (osthread-&gt;get_state() == INITIALIZED) &#123; sync-&gt;wait_without_safepoint_check(); &#125; &#125; // OSThread 从阻塞中醒来，调用 JavaThread.call_run 方法 thread-&gt;call_run(); return 0; &#125; 可以看到，Linux 在创建线程后先是将状态设置为了 INITIALIZED，然后阻塞自己，等待执行 os::start_thread() 唤醒自己。醒来后会间接调用 C++ 的 JavaThread 对象的回调函数，进而通过 JVM 调用 Java 的 Thread 对象的 run 方法。至此，C++ 的 JavaThread 对象创建完毕，接着执行它的 start 方法去唤醒阻塞的 OSThread。 thread.cpp1234567891011121314151617 // thread -&gt; JavaThread void Thread::start(Thread* thread) &#123; // Start is different from resume in that its safety is guaranteed by context or // being called from a Java method synchronized on the Thread object. if (thread-&gt;is_Java_thread()) &#123; // Initialize the thread state to RUNNABLE before starting this thread. // Can not set it after the thread started because we do not know the // exact thread state at that time. It could be in MONITOR_WAIT or // in SLEEPING or some other state. java_lang_Thread::set_thread_status(JavaThread::cast(thread)-&gt;threadObj(), JavaThreadStatus::RUNNABLE); &#125; // 根据不同的操作系统，调用 start_thread 函数 // 注意 OS线程还在等待该函数执行 os::start_thread(thread);&#125; 可以看到，C++ 的 JavaThread 对象的启动方法 start 会调用 os::start_thread 方法通过设置 OSThread 的状态为 RUNNABLE 进而唤醒阻塞的 OSThread ，下面我们依次看更新状态和唤醒方法。 os.cpp12345678910111213141516171819202122// thead-&gt;JavaThread void os::start_thread(Thread* thread) &#123; // 从 JavaThread 中取出 OSThread OSThread* osthread = thread-&gt;osthread(); // 设置 OSThread 状态为 RUNNABLE osthread-&gt;set_state(RUNNABLE); // 启动线程 pd_start_thread(thread); &#125; void os::pd_start_thread(Thread* thread) &#123; OSThread * osthread = thread-&gt;osthread(); // 检查 OSThread 状态 Monitor* sync_with_child = osthread-&gt;startThread_lock(); MutexLocker ml(sync_with_child, Mutex::_no_safepoint_check_flag); // 唤醒阻塞的OSThread （阻塞在 thread_native_entry 函数中） sync_with_child-&gt;notify(); // OSThread 被唤醒后会执行 JavaThread.call_run 方法 &#125; thread.cpp123456789101112131415161718192021void Thread::call_run() &#123;register_thread_stack_with_NMT();MACOS_AARCH64_ONLY(this-&gt;init_wx());JFR_ONLY(Jfr::on_thread_start(this);)this-&gt;pre_run();// JavaThread.runthis-&gt;run();this-&gt;post_run();&#125;void JavaThread::run() &#123; // initialize thread-local alloc buffer related fieldsinitialize_tlab();_stack_overflow_state.create_stack_guard_pages();cache_global_variables();set_thread_state(_thread_in_vm);// JavaThread.thread_main_inner// 运行可以执行 Java 线程的函数thread_main_inner();&#125; thread.cpp12345678910111213 void JavaThread::thread_main_inner() &#123; if (!this-&gt;has_pending_exception() &amp;&amp; !java_lang_Thread::is_stillborn(this-&gt;threadObj())) &#123; &#123; ResourceMark rm(this); this-&gt;set_native_thread_name(this-&gt;name()); &#125; HandleMark hm(this); // 调用 JavaThread 的运行函数 thread_entry this-&gt;entry_point()(this, this); &#125;&#125; 以上方法用于执行创建 C++ 的 JavaThread 对象时指定的回调函数。目的只有一个，那就是利用 JVM 调用 Java 中我们创建的 Thread 对象的 run 方法。 至此，Java 线程映射 OS 线程就介绍完毕了。下面我们进行简单小结： Java 中的 Thread 对象初始化完毕后调用 start 方法开始映射内核线程。注意，Thread 对象创建完毕后调用 start 方法之前和底层线程一毛钱的关系都没有。 通过调用本地方法 start0 创建 C++ 的 JavaThread 对象，并设置内核线程启动后触发的用于使用 JVM 执行的 Thread 对象的 run 方法的函数。 JavaThread 会创建底层操作系统的 native thread 底层的 native thread 开始运行，通过 JVM 调用 Thread 的 run() 方法 当 Thread 的run()方法执行完毕返回后,或者抛出异常终止后，终止 native thread 可以看出，Java 中的线程是和内核线程一一对应的，几乎对线程的所有操作都需要借助系统调用完成。Java 线程映射内核线程的关系图如下： 线程生命周期线程也有自己的生命周期，Java 中的线程有六种状态，具体如下： 123456789101112131415161718192021222324252627282930313233343536373839404142+--- Thread public enum State &#123; /** * 新建状态，线程尚未启动 */ NEW, /** * 可运行状态。 * 处于可运行状态的线程正在Java虚拟机中执行，但它可能正在等待操作系统的其他资源，如处理器。 */ RUNNABLE, /** * 阻塞状态，等待对象监视器锁 * * &#123;@link Object#wait() Object.wait&#125;. */ BLOCKED, /** * 等待状态 */ WAITING, /** * 计时等待 */ TIMED_WAITING, /** * 终止状态 */ TERMINATED; &#125; /** * 获取线程的状态。 * 注意：线程在任何时刻只可能处于 1 种状态。 * * @return this thread's state. * @since 1.5 */ public State getState() &#123; // get current thread state return sun.misc.VM.toThreadState(threadStatus); &#125; 注意：Java 线程中的 BLOCKED、WAITING、TIMED_WAITING 统称为阻塞状态（非 BLOCKED），这三种状态永远没有 CPU 的使用权。了解了线程的六个状态后，下面我们对状态之间的转换进行说明。 NEW 新建NEW 新建表示线程被创建但尚未启动的状态，当我们 new Thread() 新建一个线程时，在线程运行 start() 方法之前，那么它的状态就是 NEW。而一旦线程调用了 start() 方法，它的状态就会从 NEW 变成 RUNNABLE。新建状态的展示如下图： 从 NEW 到 RUNNABLE 状态NEW 状态的线程，不会被操作系统调度，因此不会执行。Java 线程要执行，就必须转换到 RUNNABLE 状态。从 NEW 状态转换到 RUNNABLE 状态很简单，只要调用线程对象的 start() 方法就可以了。Java 中的 RUNNABLE 状态对应操作系统线程状态中的两种状态，分别是 Running 和 Ready 。也就是说，Java 中处于 RUNNABLE 状态的线程有可能正在执行，也有可能没有正在执行，正在等待被分配 CPU 资源。因此，对于处于 RUNNABLE 状态的 Java 线程来说，即使当它的 CPU 时间片使用完了导致该线程不能使用，它的状态依然不会改变，还是 RUNNABLE 状态。转换图如下： RUNNABLE 与 BLOCKED 的状态转换从 RUNNABLE 状态进入到 BLOCKED 状态只有一种可能，就是线程等待 synchronized 的隐式锁。synchronized 修饰的方法、代码块同一时刻只允许一个线程执行，其他线程只能等待，这种情况下，等待的线程就会从 RUNNABLE 转换到 BLOCKED 状态。转换图如下： 想要从 BLOCKED 状态进入 RUNNABLE 状态，需要等待的线程获得 synchronized 隐式锁，获得锁后就又会从 BLOCKED 转换到 RUNNABLE 状态。转换图如下： RUNNABLE 与 WAITING 的状态转换线程进入 Waiting 状态有三种可能性，具体如下图： 下面对三种可能进行描述： Object.wait()：获得 synchronized 隐式锁的线程，调用无参的 Object.wait() 方法，会进入到当前锁对象的 ObjectMonitor 中的 WaitSet 等待队列中，当前线程状态由 RUNNABLE 转换为 WAITING 状态。 Thread.join()：其中的 join() 是一种线程同步方法，如有一个线程对象 A，当调用 A.join() 的时候，执行这条语句的线程会等待 A 执行完，而等待中的这个线程，其状态会从 RUNNABLE 转换到 WAITING。当线程 A 执行完，原来等待它的线程又会从 WAITING 状态转换到 RUNNABLE 。 LockSupport.park()：调用 LockSupport.park() 方法，当前线程会阻塞，线程的状态会从 RUNNABLE 转换到 WAITING。调用 LockSupport.unpark(Thread thread) 可唤醒目标线程，目标线程的状态又会从 WAITING 状态转换到 RUNNABLE 。 注意：从 WAITING 状态流转到其他状态则比较特殊，因为 WAITING 是不限时的，也就是说无论过了多长时间它都不会主动恢复。 这里分情况进行讨论： 执行了 LockSupport.unpark() 进入 RUNNABLE 状态 join 的线程运行结束进入 RUNNABLE 状态。 被中断进入 RUNNABLE 状态。 其他线程调用 notify() 或 notifyAll()来唤醒它，它会直接进入 BLOCKED 状态。因为唤醒 WAITING 线程的线程如果调用 notify() 或 notifyAll()，要求必须首先持有 synchronized 的隐式锁，所以处于 WAITING 状态的线程被唤醒时拿不到该锁，就会进入 BLOCKED 状态，直到执行了 notify()/notifyAll() 的唤醒它的线程执行完毕并释放 synchronized 的隐式锁，才可能轮到它去抢夺这把锁，如果它能抢到，就会从 BLOCKED 状态回到 RUNNABLE 状态。 具体流转图如下： RUNNABLE 与 TIMED_WAITING 的状态转换线程进入 TIMED_WAITING 有五种可能，具体如下图： 下面对五种可能进行描述： 调用带超时参数的 Thread.sleep(long millis) 方法 获得 synchronized 隐式锁的线程，调用带超时参数的 Object.wait(long timeout) 方法 调用带超时参数的 Thread.join(long millis) 方法 调用带超时参数的 LockSupport.parkNanos(Object blocker, long deadline) 方法 调用带超时参数的 LockSupport.parkUntil(long deadline) 方法 这里可以发现 TIMED_WAITING 和 WAITING 状态的区别，仅仅是触发条件多了超时参数。 同样地，TIMED_WAITING 进入其它状态和 WAITING 类似，只是在其基础上增加了超时限制，也就是超时时间到达时将会返回到 RUNNABLE 状态，注意调用带超时参数的 Object.wait(long timeout) 方法，即使超时时间到了也是先进入阻塞状态（自行进入阻塞队列），获取到锁后才会返回到 RUNNABLE 状态。 具体流转图如下： 从 RUNNABLE 到 TERMINATED 状态线程进入 TERMINATED 状态有两种情况，具体如下： 线程执行完 run() 方法后，会自动转换到 TERMINATED 状态 执行 run() 方法的时候异常抛出，也会导致线程终止 此外，有时候我们需要强制终止 run() 方法的执行，Java 的 Thread 类中提供了 stop() 方法，不过已经标记为 @Deprecated，所以不建议使用了。正确的姿势是利用线程中断进行交互。 状态小结 线程生命周期不可逆，一旦进入 RUNNABLE 状态就不能回到 NEW 状态 一旦被终止就不可能再有任何状态的变化 一个线程只能有一次 NEW 和 TERMINATED 状态，只有处于中间状态才可以相互转换，注意相互转换的方向和时机 并发与并行并发 如果某个系统支持两个或多个动作同时存在，那么这个系统就是一个并发系统。处理器在不同线程之间高速切换，让使用者感觉到这些线程在同时执行。 并行 如果某个系统支持两个或多个动作同时执行，那么这个系统就是一个并行系统。 并发系统与并行系统这两个定义之间的差异在于是同时存在还是同时执行。对于单核 CPU 并发执行任务，这些任务是同时存在的，CPU 会在不同任务之间进行切换，直到所有任务执行完成。并行意味着一定在多核 CPU 上，多个任务（线程）会被分配到独立的处理器上，因此可以同时运行。并行其实是并发的一个子集 理解中断Java 中的中断可以理解为线程的一个标识位属性，它表示一个运行中的线程是否被其他线程进行了中断操作。注意，中断某个线程，并不是说该线程就立即停止运行了，仅仅对该线程打了个标记。每个线程都关联了一个中断标识位，是一个 boolean 类型的变量，初始值为 false 。 关于线程中断，在 Thread 类中定义了以下几个方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 中断线程，即设置线程的中断状态为 true * * @revised 6.0 * @spec JSR-51 */ public void interrupt() &#123; if (this != Thread.currentThread()) checkAccess(); synchronized (blockerLock) &#123; Interruptible b = blocker; if (b != null) &#123; interrupt0(); // Just to set the interrupt flag b.interrupt(this); return; &#125; &#125; interrupt0(); &#125; /** * Thread 类中的静态方法，用于检测调用该方法的线程的中断状态，并重置中断标识位 * * @return 如果当前线程已经被中断过了，那么返回 true ，否则返回 false * @revised 6.0 */ public static boolean interrupted() &#123; return currentThread().isInterrupted(true); &#125; /** * Thread 类中的实例方法，检测线程的中断状态。注意，不会重置中断标识位。 * * @return 如果当前线程已经被中断过了，那么返回 true ，否则返回 false * @revised 6.0 */ public boolean isInterrupted() &#123; return isInterrupted(false); &#125; /** * 检测线程是否已被中断。检测后是否重置中断状态基于传入的 参数 */ private native boolean isInterrupted(boolean ClearInterrupted); 我们说中断线程，其实就是将线程的中断标识位置为 true ，至于被中断的线程怎么处理那就是线程自己的事了。线程通过检查自身是否被中断来进行响应，通过方法 isInterrupted() 判断是否被中断，通过调用静态方法 Thread.interupted() 对当前线程的中断标识位进行重置。如下代码： 1234567public static void main(String[] args) &#123; // 没有被中断就执行任务，被中断则结束执行任务 while (!Thread.interrupted())&#123; // 执行任务 work(); &#125;&#125; 需要注意的是，在 Java 提供的抛出 InterruptedException 方法在被调用抛出这个中断异常之前，Java 虚拟机会先把该线程的中断标识位清除然后抛出中断异常。 Object: wait() 系列方法Thread: join() 系列方法、sleep() 系列方法 如上 JDK 提供的几个可中断方法，它们会让线程阻塞。如果线程阻塞在这些方法上，这个时候如果其他线程对这个线程进行了中断，那么这个线程会从这些方法中立即返回，抛出中断异常，同时重置中断状态为 false。日常开发中我们也可以根据需要，自定义可中断方法，在必要的时候通过线程中断实现特定功能。 此外，如果线程阻塞在 LockSupport.park(Object obj) 方法上，此时如果其他线程对该线程进行中断也会唤醒该阻塞线程，但是唤醒后不会重置中断状态。 安全地终止线程：线程中断是一种简便的线程间交互方式，而这种交互方式最适合用来取消或停止任务。 小结本篇文章对 Java 中的线程进行了介绍。先是从线程的创建与启动出发，分析了 Java 线程与内核线程的关系；然后对 Java 中的线程状态及流转进行了详细说明；最后对线程的中断进行了介绍，它是停止线程的正确姿势，也是线程通信的一种方式。 参考： Java编发编程的艺术书籍Java并发编程78讲专栏","categories":[{"name":"JDK","slug":"JDK","permalink":"https://gentryhuang.com/categories/JDK/"}],"tags":[{"name":"Thread","slug":"Thread","permalink":"https://gentryhuang.com/tags/Thread/"}]},{"title":"时间轮算法 - HashedWheelTimer","slug":"concurrent/HashedWheelTimer","date":"2021-07-24T02:06:24.000Z","updated":"2021-10-12T15:49:10.112Z","comments":false,"path":"posts/1d01ceec/","link":"","permalink":"https://gentryhuang.com/posts/1d01ceec/","excerpt":"","text":"概述时间轮是一种高效利用线程资源来进行批量化调度的一种调度模型。将大批量的调度任务全部都绑定到同一个调度器上，使用这一调度器来进行所有任务的管理、触发以及执行。本篇文章将对 HashedWheelTimer 进行分析。 示例编码 123456789101112131415161718192021222324252627import io.netty.util.HashedWheelTimer;import io.netty.util.Timeout;import io.netty.util.Timer;import io.netty.util.TimerTask;import java.util.concurrent.TimeUnit;public class HashedWheelTimerClient &#123; public static void main(String[] args) &#123; // 1 创建一个 HashedWheelTimer，内部参数全部使用默认值 Timer timer = new HashedWheelTimer(); // 2 编写 TimeTask 任务 TimerTask timerTask = new TimerTask() &#123; @Override public void run(Timeout timeout) throws Exception &#123; System.out.println(Thread.currentThread().getName() + \"is working !\"); &#125; &#125;; // 3 提交任务 // 创建 HashedWheelTimeout 对象，并将该对象放入任务队列中，等待被加入到 Hash 轮中被调用。 Timeout timeout = timer.newTimeout(timerTask, 1, TimeUnit.SECONDS); &#125;&#125; 调度结果 1pool-1-thread-1is working ! 算法简介时间轮调度模型如下图所示： HashedWheelTimer 时间轮算法可以通过上图来描述。假设时间轮大小为 8 即 8 个格子，1s 转一格，每格都对应一个链表，链表每个节点都保存着待执行的任务。某一时刻，时间轮走到编号为 2 的格子，此时添加了一个 3s 后执行的任务，对应 3 个格子，则 2 + 3 = 5，在编号为 5 的格子对应链表中添加一个任务节点即可，轮次 round 为 0 ；如果添加一个 10s 后执行的任务，同理得 (2 + 10) % 8 = 4，在编号为 4 的格子对应的链表中添加一个任务节点，并标识轮次 round 为 1，当时间轮第二次经过编号为 4 的格子时就会执行该任务。注意，时间轮只会执行 round = 0 的任务，并会把该格子上的其他任务的 round 减 1 。 时间轮算法的原理还是非常容易理解的，下面我们从源码层面进行分析。 源码分析HashedWheelTimer 相关的核心类图如下： TimerHashedWheelTimer 是接口 io.netty.util.Timer 的实现，Timer 是任务调度器，负责对延时任务进行管理、触发和调度。 12345678910111213141516171819public interface Timer &#123; /** * 调度指定的 TimerTask ，在指定的延迟后执行 * * @return 与指定任务相关联的句柄 * @throws IllegalStateException if this timer has been &#123;@linkplain #stop() stopped&#125; already * @throws RejectedExecutionException if the pending timeouts are too many and creating new timeout * can cause instability in the system. */ Timeout newTimeout(TimerTask task, long delay, TimeUnit unit); /** * 停止所有的还没被执行的定时任务 * * @return 与被此方法取消的任务相关联的句柄 */ Set&lt;Timeout&gt; stop();&#125; TimerTask延时任务，由业务方自行实现。Timer 会在触发时间对延时任务进行调度。 123456789101112/** * Timer 调度的任务，由业务方实现 */public interface TimerTask &#123; /** * Executed after the delay specified with * &#123;@link Timer#newTimeout(TimerTask, long, TimeUnit)&#125;. * * @param timeout 任务执行的时候会将该任务对应的 Timeout 传进来 */ void run(Timeout timeout) throws Exception;&#125; TimeoutTimeout 是一个非常重要的接口，它的唯一实现类是 HashedWheelTimer 内部类 HashedWheelTimeout ，该内部类聚合了时间轮主要的核心对象，关于该内部类下文会详细分析。 1234567891011121314151617181920212223242526272829303132/** * 与&#123;@link TimerTask&#125;关联的句柄，由&#123;@link Timer&#125;返回。 */public interface Timeout &#123; /** * 返回创建此句柄的&#123;@link Timer&#125;。 */ Timer timer(); /** * 返回与此句柄关联的&#123;@link TimerTask&#125;。 */ TimerTask task(); /** * 当且仅当与此句柄关联的&#123;@link TimerTask&#125;已过期时返回 true */ boolean isExpired(); /** * 当且仅当与此句柄关联的&#123;@link TimerTask&#125;已被取消时返回 true */ boolean isCancelled(); /** * 尝试取消与此句柄关联的&#123;@link TimerTask&#125;。如果任务已经被执行或取消，它将返回而没有副作用。 * * @return 如果取消成功，则为 true，否则为 false */ boolean cancel();&#125; HashedWheelTimerHashedWheelTimer 是对 Timer 的实现，也就是我们说的时间轮。 属性12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class HashedWheelTimer implements Timer &#123; // HashedWheelTimer 实例统计原子变量 private static final AtomicInteger INSTANCE_COUNTER = new AtomicInteger(); // 过多 HashedWheelTimer 阈值开关 private static final AtomicBoolean WARNED_TOO_MANY_INSTANCES = new AtomicBoolean(); // HashedWheelTimer 数量的阈值 private static final int INSTANCE_COUNT_LIMIT = 64; // 最小延时时间，默认是 1 毫秒 private static final long MILLISECOND_NANOS = TimeUnit.MILLISECONDS.toNanos(1); private static final ResourceLeakDetector&lt;HashedWheelTimer&gt; leakDetector = ResourceLeakDetectorFactory.instance() .newResourceLeakDetector(HashedWheelTimer.class, 1); // 时间轮状态，可以控制工作线程执行任务的状态。 private static final AtomicIntegerFieldUpdater&lt;HashedWheelTimer&gt; WORKER_STATE_UPDATER = AtomicIntegerFieldUpdater.newUpdater(HashedWheelTimer.class, \"workerState\"); private final ResourceLeakTracker&lt;HashedWheelTimer&gt; leak; // 工作任务 private final Worker worker = new Worker(); // 工作线程 private final Thread workerThread; // 状态 0 - init, 1 - started, 2 - shut down public static final int WORKER_STATE_INIT = 0; public static final int WORKER_STATE_STARTED = 1; public static final int WORKER_STATE_SHUTDOWN = 2; @SuppressWarnings(&#123;\"unused\", \"FieldMayBeFinal\"&#125;) private volatile int workerState; // 0 - init, 1 - started, 2 - shut down // 走一个 bucket 需要花费的纳秒时长 private final long tickDuration; // bucket 数组，用于存储任务，即 HashedWheelTimeout 实例们 private final HashedWheelBucket[] wheel; // 掩码，用于 与运算 ，计算属于 wheel 哪个下标 private final int mask; // 调用 newTimeout 方法线程等待工作线程 workerThread 开启执行任务 private final CountDownLatch startTimeInitialized = new CountDownLatch(1); // HashedWheelTimeout 任务队列。MPSC 队列，适用于这里的多生产线程，单消费线程的场景 // 提交的任务会先进入到该队列中，每次 tick 才会将队列中的任务（一次最多 10 万个）加入到 bucket 中的链表里 private final Queue&lt;HashedWheelTimeout&gt; timeouts = PlatformDependent.newMpscQueue(); // HashedWheelTimeout 任务取消队列 // 取消的任务会加入到该队列中，此次 tick 会将该队列中的任务从 bucket 中移除 private final Queue&lt;HashedWheelTimeout&gt; cancelledTimeouts = PlatformDependent.newMpscQueue(); // 时间轮中处于等待执行的任务数 private final AtomicLong pendingTimeouts = new AtomicLong(0); // 允许最大的等待任务数 private final long maxPendingTimeouts; // 工作线程启动时间，作为时间轮的基准时间 private volatile long startTime;&#125; 构造方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107+--- HashedWheelTimer /*----------------- 系列构造方法 -------------------*/ public HashedWheelTimer() &#123; this(Executors.defaultThreadFactory()); &#125; public HashedWheelTimer(long tickDuration, TimeUnit unit) &#123; this(Executors.defaultThreadFactory(), tickDuration, unit); &#125; public HashedWheelTimer(long tickDuration, TimeUnit unit, int ticksPerWheel) &#123; this(Executors.defaultThreadFactory(), tickDuration, unit, ticksPerWheel); &#125; public HashedWheelTimer(ThreadFactory threadFactory) &#123; this(threadFactory, 100, TimeUnit.MILLISECONDS); &#125; public HashedWheelTimer( ThreadFactory threadFactory, long tickDuration, TimeUnit unit) &#123; this(threadFactory, tickDuration, unit, 512); &#125; public HashedWheelTimer( ThreadFactory threadFactory, long tickDuration, TimeUnit unit, int ticksPerWheel) &#123; this(threadFactory, tickDuration, unit, ticksPerWheel, true); &#125; public HashedWheelTimer( ThreadFactory threadFactory, long tickDuration, TimeUnit unit, int ticksPerWheel, boolean leakDetection) &#123; this(threadFactory, tickDuration, unit, ticksPerWheel, leakDetection, -1); &#125; /** * 创建 HashedWheelTimer 对象 * * @param threadFactory 线程工厂，用于创建执行 TimerTask 任务的工作线程 * @param tickDuration tick 之间的持续时间，即一次 tick 的时间长度。默认是 100 * @param unit tickDuration 的时间单位。默认是 毫秒 * @param ticksPerWheel 定义一圈有多少个 bucket 。 默认是 512 * @param leakDetection 用于追踪内存泄漏 * @param maxPendingTimeouts 最大允许等待的任务数，也就是 Timeout 实例数（调用 newTimeout 方法产生），可以根据该参数控制不允许太多的任务等待。 * 如果未执行任务数达到阈值，那么再次提交任务会抛出 RejectedExecutionException 异常。如果该值为 0 或 负数，则不限制。 * 默认不限制。 */ public HashedWheelTimer( ThreadFactory threadFactory, long tickDuration, TimeUnit unit, int ticksPerWheel, boolean leakDetection, long maxPendingTimeouts) &#123; // 1 参数校验 ObjectUtil.checkNotNull(threadFactory, \"threadFactory\"); ObjectUtil.checkNotNull(unit, \"unit\"); ObjectUtil.checkPositive(tickDuration, \"tickDuration\"); ObjectUtil.checkPositive(ticksPerWheel, \"ticksPerWheel\"); // 2 创建时间轮 bucket 结构，这里做向上取整，保证 bucket 数组长度是 2 的 n 次方 // wheel 就是一个个 bucket。时间轮会以循环的方式走这个 wheel 数组 wheel = createWheel(ticksPerWheel); // 3 掩码，bucket - 1，用来做取模，计算任务应该放到哪个 bucket 中 // HashMap 在进行 hash 之后，进行index的hash寻址寻址的算法也是和这个一样的 mask = wheel.length - 1; // 4 将延迟时间统一转为纳秒 long duration = unit.toNanos(tickDuration); // 5 防止延迟时间溢出 if (duration &gt;= Long.MAX_VALUE / wheel.length) &#123; throw new IllegalArgumentException(String.format( \"tickDuration: %d (expected: 0 &lt; tickDuration in nanos &lt; %d\", tickDuration, Long.MAX_VALUE / wheel.length)); &#125; // 6 延迟时间不能小于 1 毫秒 if (duration &lt; MILLISECOND_NANOS) &#123; logger.warn(\"Configured tickDuration &#123;&#125; smaller then &#123;&#125;, using 1ms.\", tickDuration, MILLISECOND_NANOS); this.tickDuration = MILLISECOND_NANOS; &#125; else &#123; this.tickDuration = duration; &#125; // 7 根据线程工厂创建线程。注意，这里并没有立即启动线程，启动线程是在第一次提交延迟任务的时候。 workerThread = threadFactory.newThread(worker); // 追踪内存泄露的，略 leak = leakDetection || !workerThread.isDaemon() ? leakDetector.track(this) : null; // 8 最大允许等待的 Timeout 实例数 this.maxPendingTimeouts = maxPendingTimeouts; // 9 如果超过 64 个 HashedWheelTimer 实例，它会打印错误日志提醒你 // 因为时间轮是一个非常耗费资源的结构，所以一个 jvm 中的实例数目不能太高 if (INSTANCE_COUNTER.incrementAndGet() &gt; INSTANCE_COUNT_LIMIT &amp;&amp; WARNED_TOO_MANY_INSTANCES.compareAndSet(false, true)) &#123; // 打印错误日志 reportTooManyInstances(); &#125; &#125; 通过以上构造方法可以初始化一个时间轮对象，默认情况下，时间轮大小是 512，也就是一圈有 512 个 bucket，走一个 bucket 需要时间为 100ms 。 初始化 bucket1234567891011121314151617181920212223242526272829303132333435363738394041424344454647+--- HashedWheelTimer/** * 初始化时间轮 bucket 数组，用来存储任务 * * @param ticksPerWheel 一圈有多少个 bucket ，默认是 512 * @return */ private static HashedWheelBucket[] createWheel(int ticksPerWheel) &#123; if (ticksPerWheel &lt;= 0) &#123; throw new IllegalArgumentException( \"ticksPerWheel must be greater than 0: \" + ticksPerWheel); &#125; // 时间轮 tick 不能多大 if (ticksPerWheel &gt; 1073741824) &#123; throw new IllegalArgumentException( \"ticksPerWheel may not be greater than 2^30: \" + ticksPerWheel); &#125; // 标准化时间轮大小 ticksPerWheel = normalizeTicksPerWheel(ticksPerWheel); // 创建 HashedWheelBucket 数组 HashedWheelBucket[] wheel = new HashedWheelBucket[ticksPerWheel]; for (int i = 0; i &lt; wheel.length; i++) &#123; wheel[i] = new HashedWheelBucket(); &#125; return wheel; &#125; /** * 标准化时间轮大小，原则：向上取整，达到 2 的 n 次方 * * @param ticksPerWheel * @return */ private static int normalizeTicksPerWheel(int ticksPerWheel) &#123; int normalizedTicksPerWheel = 1; // 取第一个大于 ticksPerWheel 的 2 的 n 次方的值 while (normalizedTicksPerWheel &lt; ticksPerWheel) &#123; // 左移一位，即 扩大 2 倍 normalizedTicksPerWheel &lt;&lt;= 1; &#125; return normalizedTicksPerWheel; &#125; 初始化 bucket 的过程就是初始化时间轮的格子，每个格子用于管理落在当前位置的延时任务们，这些任务由链表组织起来，且任务具有轮次的语义，只有任务的轮次为 0 时才能被时间轮执行。注意，时间轮中的每个 bucket 和延时时间是通过 tick 来间接关联的，通过延时任务的时间可以计算出它对应 N 个 tick ，而 tick 数对 bucket 数组长度取模运算就能确定具体的 bucket。延时任务完成 Bucket 分配后，时间轮不断进行 tick 的过程就可以通过计算找到 tick 对应的 Bucket ，进而处理延时任务。 HashedWheelTimeout延时任务的包装类，该类聚合了时间轮所有的核心对象及属性，也就是说通过该对象可以拿到所有核心的对象和属性，并且该类包含了延时任务执行的方法expire()。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253private static final class HashedWheelTimeout implements Timeout &#123; // 初始化 private static final int ST_INIT = 0; // 取消 private static final int ST_CANCELLED = 1; // 到期 private static final int ST_EXPIRED = 2; // 用CAS方式更新任务状态 private static final AtomicIntegerFieldUpdater&lt;HashedWheelTimeout&gt; STATE_UPDATER = AtomicIntegerFieldUpdater.newUpdater(HashedWheelTimeout.class, \"state\"); /** * Timer */ private final HashedWheelTimer timer; /** * TimerTask */ private final TimerTask task; /** * 任务触发时间 */ private final long deadline; @SuppressWarnings(&#123;\"unused\", \"FieldMayBeFinal\", \"RedundantFieldInitialization\"&#125;) private volatile int state = ST_INIT; // 离任务执行的轮数，0 表示当前轮次执行。当任务从队列加入 bucket 时会计算这个值。 // 对与轮次非 0 的任务，那么时间轮执行到对应的 bucket 时会将该任务的该属性值 -1 long remainingRounds; // 这将用于通过双向链表在 hashhedwheeltimerbucket 中链接超时 的前后指针 HashedWheelTimeout next; HashedWheelTimeout prev; // 当前 HashedWheelTimeout 所在的 bucket HashedWheelBucket bucket; /** * HashedWheelTimeout 用于封装 HashedWheelTimer、TimerTask 以及 deadLine 触发时间 * * @param timer * @param task * @param deadline */ HashedWheelTimeout(HashedWheelTimer timer, TimerTask task, long deadline) &#123; this.timer = timer; this.task = task; this.deadline = deadline; &#125;&#125; 执行任务12345678910111213141516171819+---HashedWheelTimeout /** * 到期并执行任务 */ public void expire() &#123; if (!compareAndSetState(ST_INIT, ST_EXPIRED)) &#123; return; &#125; try &#123; // 执行 TimerTask.run 方法 task.run(this); &#125; catch (Throwable t) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"An exception was thrown by \" + TimerTask.class.getSimpleName() + '.', t); &#125; &#125; &#125; &#125; 执行任务本质上是调用 HashedWheelTimeout 对象中封装的 TimerTask 对象的 run 方法。需要注意的是，即使任务执行过程抛出异常工作线程也不会退出；为了提高时间轮的精准度，任务执行最好使用异步方式。 取消任务1234567891011121314151617+---HashedWheelTimeout /** * 取消任务 * * @return */ @Override public boolean cancel() &#123; // 这里只是修改状态为取消，实际会在下次tick的时候移除 if (!compareAndSetState(ST_INIT, ST_CANCELLED)) &#123; return false; &#125; // 加入到时间轮的全局待取消队列，并在每次tick的时候，从相应 bucket 中移除。 timer.cancelledTimeouts.add(this); return true; &#125; 取消任务只是将待执行的 HashedWheelTimeout 对象加入到全局取消队列中，在后续的 tick 过程才会从对应的 bucket 中删除。 移除任务123456789101112+--- HashedWheelTimeout/** * 将当前 Timeout 从对应的 bucket 链表中移除 */void remove() &#123; HashedWheelBucket bucket = this.bucket; if (bucket != null) &#123; bucket.remove(this); &#125; else &#123; timer.pendingTimeouts.decrementAndGet(); &#125; &#125; 将 HashedWheelTimeout 对象从对应的 bucket 中删除。 HashedWheelBucket用来存放包装任务的 HashedWheelTimeout ，以链表结构的形式进行管理，链表中的每一个节点都是 HashedWheelTimeout。 链表结构123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869private static final class HashedWheelBucket &#123; // 头指针 private HashedWheelTimeout head; // 尾指针 private HashedWheelTimeout tail; /** * Add &#123;@link HashedWheelTimeout&#125; to this bucket. * * 添加 HashedWheelTimeout 到 当前 bucket 中，即加入到链中 */ public void addTimeout(HashedWheelTimeout timeout) &#123; assert timeout.bucket == null; // 设置 timeout 的桶，即聚合桶对象 timeout.bucket = this; // 维护桶中的 HashedWheelTimeout if (head == null) &#123; head = tail = timeout; &#125; else &#123; tail.next = timeout; timeout.prev = tail; tail = timeout; &#125; &#125; /** * 将 timeout 从链表中移除 * * @param timeout * @return */ public HashedWheelTimeout remove(HashedWheelTimeout timeout) &#123; HashedWheelTimeout next = timeout.next; // remove timeout that was either processed or cancelled by updating the linked-list if (timeout.prev != null) &#123; timeout.prev.next = next; &#125; if (timeout.next != null) &#123; timeout.next.prev = timeout.prev; &#125; if (timeout == head) &#123; // if timeout is also the tail we need to adjust the entry too if (timeout == tail) &#123; tail = null; head = null; &#125; else &#123; head = next; &#125; &#125; else if (timeout == tail) &#123; // if the timeout is the tail modify the tail to be the prev node. tail = timeout.prev; &#125; // null out prev, next and bucket to allow for GC. timeout.prev = null; timeout.next = null; timeout.bucket = null; // timeout 对应的 timer 的等待任务数减 1 timeout.timer.pendingTimeouts.decrementAndGet(); return next; &#125; // 省略其他代码&#125; 执行任务123456789101112131415161718192021222324252627282930313233343536373839404142434445464748+--- HashedWheelBucket/** * Expire all &#123;@link HashedWheelTimeout&#125;s for the given &#123;@code deadline&#125;. * &lt;p&gt; * 执行 bucket 中的到期任务。注意，只执行 bucket 中轮次为 0 且到期的任务 */ public void expireTimeouts(long deadline) &#123; // 获取时间任务链表的头 HashedWheelTimeout timeout = head; // 处理链表上的所有 timeout 实例 while (timeout != null) &#123; HashedWheelTimeout next = timeout.next; // 尝试执行任务 if (timeout.remainingRounds &lt;= 0) &#123; // 调整当前 bucket 的任务链表 next = remove(timeout); // 到达触发时间 if (timeout.deadline &lt;= deadline) &#123; // 执行具体的任务，即执行 timeout 中的 TimerTask.run 方法 timeout.expire(); &#125; else &#123; // 不可能进入到这个分支 // The timeout was placed into a wrong slot. This should never happen. throw new IllegalStateException(String.format( \"timeout.deadline (%d) &gt; deadline (%d)\", timeout.deadline, deadline)); &#125; // 任务被取消了 &#125; else if (timeout.isCancelled()) &#123; next = remove(timeout); // 轮次减 1 &#125; else &#123; timeout.remainingRounds--; &#125; // 处理下个任务 timeout = next; &#125; &#125; 工作线程 tick 时会找到当前 tick 对应的 bucket ，然后执行上述方法进而调度延时任务。 WorkerWorker 是工作线程的任务体，里面封装了时间轮任务触发和执行的逻辑。一旦工作线程启动后，就会不停地 “滴答” bucket ，直到时间轮关闭。 任务体1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980 private final class Worker implements Runnable &#123; // 记录没有处理的时间任务 private final Set&lt;Timeout&gt; unprocessedTimeouts = new HashSet&lt;Timeout&gt;(); // 记录走了几个 bucket ，不拥堵的情况下每隔 tickDuration 时间走一个 bucket private long tick; @Override public void run() &#123; // 初始化启动时间。 // 注意，在 HashedWheelTimer 中用的都是相对时间，因此需要以启动时间为基准。这里使用 volatile 修饰 startTime = System.nanoTime(); if (startTime == 0) &#123; // 因为 startTime = 0 作为工作线程未开始执行任务的标志。这里开始执行了，需要设置非 0 startTime = 1; &#125; // 第一个提交任务的线程在 start() 处等待，需要唤醒它 startTimeInitialized.countDown(); /** * do-while 执行任务逻辑： * * 工作线程是逐个 bucket 顺序处理的，所以即使有些任务执行时间超过了一次 tick 时间，也没关系，这些任务并不会被漏掉。 * 但是可能被延迟执行，毕竟工作线程是单线程。 */ do &#123; // 等待下次 tick 到来，理论上每次等待 tickDuration 就会返回，然后继续往下走 final long deadline = waitForNextTick(); if (deadline &gt; 0) &#123; // 当前 tick 下 bucket 数组对应 index，即哪个 bucket int idx = (int) (tick &amp; mask); // 处理已经取消的任务 processCancelledTasks(); // 获取当前 tick 对应的桶 HashedWheelBucket bucket = wheel[idx]; // 将 timeouts 队列中的 HashedWheelTimeout 转移到相应的桶中 transferTimeoutsToBuckets(); // 执行进入到 bucket 中的任务 bucket.expireTimeouts(deadline); // 记录走了多少个 tick tick++; &#125; &#125; while (WORKER_STATE_UPDATER.get(HashedWheelTimer.this) == WORKER_STATE_STARTED); /* 执行到这里，说明当前 Timer 要关闭了，做一些清理工作 */ // 将所有 bucket 中没有执行的任务，添加到 unprocessedTimeouts 这个 HashSet 中，用于 stop() 方法返回。 for (HashedWheelBucket bucket : wheel) &#123; // 将当前 bucket 上链表节点任务都加入到 unprocessedTimeouts bucket.clearTimeouts(unprocessedTimeouts); &#125; // 将任务队列中的任务也添加到 unprocessedTimeouts 中 for (; ; ) &#123; HashedWheelTimeout timeout = timeouts.poll(); if (timeout == null) &#123; break; &#125; if (!timeout.isCancelled()) &#123; unprocessedTimeouts.add(timeout); &#125; &#125; // 处理已经取消的任务 processCancelledTasks(); &#125; // 省略其他方法&#125; 工作线程启动的第一步是初始化全局的 startTime，它将作为时间轮的基准时间，用来计算延时任务的触发时间。并调用 countDown 方法来通知阻塞在 start 方法上的线程。接着进入主循环中，循环中的行为是每隔一段时间（tickDuration）走一个 bucket ，下面我们拆解执行部分。 waitForNextTick12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152+--- Worker private long waitForNextTick() &#123; // 1 计算当前 tick 下的 deadline，这值是确定的。即一次 tick 期限是一个固定值 // 注意，这里就体现了时间轮的核心，理论上每隔 tickDuration 就会 \"滴答\" 一次 long deadline = tickDuration * (tick + 1); // 2 等待当前 tick 时间到达 for (; ; ) &#123; // 2.1 基于 startTime 计算距离当前时间的时间戳，该值的理论值认为等于 dealine ，但由于任务执行时间没法控制，实际值一般大于 deadline // 注意，startTime 值是固定的，在工作线程启动就定了 final long currentTime = System.nanoTime() - startTime; // 2.2 判断是否可以进行 tick // 标准是：tick 触发的时间值 - currentTime &lt;= 0，没有到触发时间则休眠 sleepTimeMs 毫秒 // 这里加 999999 是补偿精度，不足 1ms 的补足 1ms long sleepTimeMs = (deadline - currentTime + 999999) / 1000000; // 2.3 因为每次执行任务消耗的时间是不受控制的，因此计算出来的 sleepTimeMs 可能为负数 // 当为负数时，说明前面的任务执行时间过长，导致本该 tick 的时候错过了。这个时候不需要休眠等待，需要立刻处理 if (sleepTimeMs &lt;= 0) &#123; if (currentTime == Long.MIN_VALUE) &#123; return -Long.MAX_VALUE; &#125; else &#123; // 返回值是基于 startTime 计算的距离当前时间的时间戳 return currentTime; &#125; &#125; // windows 平台特别处理。先除以10再乘以10，是因为windows平台下最小调度单位是10ms，如果不处理成10ms的倍数，可能导致sleep更不准了 if (PlatformDependent.isWindows()) &#123; sleepTimeMs = sleepTimeMs / 10 * 10; if (sleepTimeMs == 0) &#123; sleepTimeMs = 1; &#125; &#125; try &#123; // 2.4 没有到 tick 时间，则休眠 Thread.sleep(sleepTimeMs); &#125; catch (InterruptedException ignored) &#123; // 如果工作线程已经关闭，那么返回 Long.MIN_VALUE if (WORKER_STATE_UPDATER.get(HashedWheelTimer.this) == WORKER_STATE_SHUTDOWN) &#123; return Long.MIN_VALUE; &#125; &#125; &#125; &#125; waitForNextTick 方法的逻辑已经详细注释，该方法就是用来控制每隔一定的时间 “滴答” 一次即跳一个 bucket，此外还处理了因上一个 tick 处理任务时间过长问题，采用的是立即触发执行的方式。不难看出，当遇到较长时间执行的任务时，会打乱原本正常 tick 的节奏，导致其他任务延期执行。 tickDuration 控制着时间的精准度，值越小精准度越高，工作线程则越繁忙。 processCancelledTasks123456789101112131415161718192021222324+--- Worker /** * 处理已经取消的任务。将已经取消的任务从对应的 bucket 中移除 */ private void processCancelledTasks() &#123; // 遍历任务取消队列 for (; ; ) &#123; HashedWheelTimeout timeout = cancelledTimeouts.poll(); if (timeout == null) &#123; // all processed break; &#125; try &#123; // 将 timeout 从对应的 bucket 中移除 // 通过 timeout 持有的 bukcet 进行的操作，即从bucket 链表中删除该 timeout timeout.remove(); &#125; catch (Throwable t) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"An exception was thrown while process a cancellation task\", t); &#125; &#125; &#125; &#125; 该方法是为了处理那些被取消的任务，将被取消的任务从队列和 bucket 中分别移除。 transferTimeoutsToBuckets1234567891011121314151617181920212223242526272829303132333435363738394041424344+--- Worker /** * 将 HashedWheelTimeout 队列中的任务加入到相应的 bucket 中 */ private void transferTimeoutsToBuckets() &#123; // 限制每 tick 最大转移 10 万个 HashedWheelTimeout 到 bucket，以免阻塞工作线程 // todo 如果有 100万 个，并且 tickDuration 时间为几分钟级别，那这种情况下就会有一批任务延迟。从侧面说明一个时间轮不能一下子添加特别多的任务 for (int i = 0; i &lt; 100000; i++) &#123; HashedWheelTimeout timeout = timeouts.poll(); // 队列为空 if (timeout == null) &#123; // all processed break; &#125; // 被取消了 if (timeout.state() == HashedWheelTimeout.ST_CANCELLED) &#123; // Was cancelled in the meantime. continue; &#125; /*--- 将任务放到相应的 bucket 中 ----*/ // 计算任务触发时间需要经过多少个 tick long calculated = timeout.deadline / tickDuration; // 计算任务所属的轮次 timeout.remainingRounds = (calculated - tick) / wheel.length; // 如果任务在 timeouts 队列里面放久了, 以至于已经过了执行时间(calculated &lt; tick), 这个时候就使用当前 tick 对应的 bucket，从而让那些本应该在过去执行的任务在当前 tick 快速执行掉。 // 此方法调用完后就会立即执行当前 tick 对应的 bucket 中的任务 final long ticks = Math.max(calculated, tick); // Ensure we don't schedule for past. // 计算 ticks 对应 bucket int stopIndex = (int) (ticks &amp; mask); HashedWheelBucket bucket = wheel[stopIndex]; // 单个 bucket 是由 HashedWheelTimeout 实例组成的一个链表，单个线程不存在并发 // 这里将 timeout 加入到 bucket 的链表中 bucket.addTimeout(timeout); &#125; &#125; 在每次执行 tick 对应的 bucket 中的延时任务时，会先将全局任务队列中待执行的任务加入到对应的 bucket 中。 expireTimeouts一次 tick 到来后找到对应的 Bucket，然后就可以处理当前 Bucket 中的延时任务了，具体实现见前文。expireTimeouts 方法中会间接执行 TimeTask.run 方法，如果延时任务执行时间过久则会阻塞工作线程，进一步拖慢超时检测流程。 以上对 HashedWheelTimer 主要源码进行了分析，但没有串起来。下面我们以执行过程的形式进一步说明。 提交任务123456789101112131415161718192021222324252627282930313233343536373839404142434445464748+--- HashedWheelTimer /** * 提交任务 * * @param task 任务 * @param delay 延时时间 * @param unit 延迟时间单位 * @return */ @Override public Timeout newTimeout(TimerTask task, long delay, TimeUnit unit) &#123; // 1 校验参数 ObjectUtil.checkNotNull(task, \"task\"); ObjectUtil.checkNotNull(unit, \"unit\"); // 2 校验等待任务数是否达到阈值 long pendingTimeoutsCount = pendingTimeouts.incrementAndGet(); if (maxPendingTimeouts &gt; 0 &amp;&amp; pendingTimeoutsCount &gt; maxPendingTimeouts) &#123; pendingTimeouts.decrementAndGet(); throw new RejectedExecutionException(\"Number of pending timeouts (\" + pendingTimeoutsCount + \") is greater than or equal to maximum allowed pending \" + \"timeouts (\" + maxPendingTimeouts + \")\"); &#125; // 3 如果工作线程没有启动，则启动工作线程。一般由第一个提交任务的线程负责工作线程的启动 start(); /* 将任务添加到队列中，该队列将在下一个 tick 时进行处理，在处理过程中，所有排队的 HashedWheelTimeout 将被添加到正确的 HashedWheelBucket 中 */ // 4 deadline 是一个相对时间，相对于工作线程启动时间。 // 注意，该值作为延时任务触发的时间，后续流程虽然会判断，但是貌似用处不大。主要还是用在根据该值计算 tick 进而确定将任务分配到哪个 Bucket，因为任务触发是跟着 tick 走的。 long deadline = System.nanoTime() + unit.toNanos(delay) - startTime; // Guard against overflow. if (delay &gt; 0 &amp;&amp; deadline &lt; 0) &#123; deadline = Long.MAX_VALUE; &#125; // 5 创建 HashedWheelTimeout 对象，进一步封装任务对象 HashedWheelTimeout timeout = new HashedWheelTimeout(this, task, deadline); // 6 加入到 timeouts 队列中，等待被加入到 Bucket 中 // 注意，还没有加入到时间轮中 timeouts.add(timeout); return timeout; &#125; 时间轮在初始化后就可以接收业务方提交的延时任务请求了，任务的处理都是交给工作线程这个后台线程。提交任务的流程主要包含 3 个关键步骤： 1 尝试启动工作线程 workerThread2 计算延时任务的触发时间，创建 HashedWheelTimeout 对象进一步封装任务对象3 将创建的 HashedWheelTimeout 对象加入到任务队列 值得一提的是启动工作线程的逻辑，源码逻辑如下： 123456789101112131415161718192021222324252627282930313233+--- HashedWheelTimer /** * 启动工作线程 * * @throws IllegalStateException if this timer has been * &#123;@linkplain #stop() stopped&#125; already */ public void start() &#123; switch (WORKER_STATE_UPDATER.get(this)) &#123; // 如果是初始化状态 case WORKER_STATE_INIT: if (WORKER_STATE_UPDATER.compareAndSet(this, WORKER_STATE_INIT, WORKER_STATE_STARTED)) &#123; // 启动工作线程 workerThread.start(); &#125; break; case WORKER_STATE_STARTED: break; case WORKER_STATE_SHUTDOWN: throw new IllegalStateException(\"cannot be started once stopped\"); default: throw new Error(\"Invalid WorkerState\"); &#125; // 阻塞等待，直到 startTime 被工作线程初始化 while (startTime == 0) &#123; try &#123; startTimeInitialized.await(); &#125; catch (InterruptedException ignore) &#123; // Ignore - it will be ready very soon. &#125; &#125; &#125; 可以看到上述方法是 public 修饰的，也就是说用户可以显示的调用，而无需等待第一次提交任务时再启动。但一般没必要显示调用，没有任务提交没必要启动。 执行任务前文也说了，时间轮中的任务都是由工作线程触发执行的。具体是一次 tick 到来后找到对应的 Bucket，然后就可以处理当前 Bucket 中的延时任务了。源码见前文。 取消任务123456789101112+--- HashedWheelTimeoutpublic boolean cancel() &#123; // only update the state it will be removed from HashedWheelBucket on next tick. if (!compareAndSetState(ST_INIT, ST_CANCELLED)) &#123; return false; &#125; // 加入到取消任务队列中 timer.cancelledTimeouts.add(this); return true; &#125; 未到期但被取消的任务会放到 cancelledTimeouts 队列中，工作线程周期性调用 processCancelledTasks() 会从 bucket 中删除对应的 HashedWheelTimeout。 终止时间轮12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152+--- HashedWheelTimer @Override public Set&lt;Timeout&gt; stop() &#123; // 工作线程不能停止时间轮 if (Thread.currentThread() == workerThread) &#123; throw new IllegalStateException( HashedWheelTimer.class.getSimpleName() + \".stop() cannot be called from \" + TimerTask.class.getSimpleName()); &#125; // 尝试 CAS 替换当前状态为 “停止： if (!WORKER_STATE_UPDATER.compareAndSet(this, WORKER_STATE_STARTED, WORKER_STATE_SHUTDOWN)) &#123; // workerState can be 0 or 2 at this moment - let it always be 2. if (WORKER_STATE_UPDATER.getAndSet(this, WORKER_STATE_SHUTDOWN) != WORKER_STATE_SHUTDOWN) &#123; INSTANCE_COUNTER.decrementAndGet(); if (leak != null) &#123; boolean closed = leak.close(this); assert closed; &#125; &#125; return Collections.emptySet(); &#125; try &#123; // 中断 worker线程，尝试把正在进行任务的线程中断掉,如果某些任务正在执行则会抛出interrupt异常，并且任务会尝试立即中断 boolean interrupted = false; while (workerThread.isAlive()) &#123; workerThread.interrupt(); try &#123; workerThread.join(100); &#125; catch (InterruptedException ignored) &#123; interrupted = true; &#125; &#125; // 当前前程会等待stop的结果 if (interrupted) &#123; Thread.currentThread().interrupt(); &#125; &#125; finally &#123; INSTANCE_COUNTER.decrementAndGet(); if (leak != null) &#123; boolean closed = leak.close(this); assert closed; &#125; &#125; //返回未处理的任务 return worker.unprocessedTimeouts(); &#125; 流程图 HashWheelTimer 是基于时间轮算法，提交的任务会被封装成 HashedWheelTimeout 对象并存放到全局任务队列中。时间轮的格子是用 bucket 数组表示，bucket 内部维护一个 HashedWheelTimeout 类型的双向链表，每一个节点都是一个 HashedWheelTimeout 对象。其内部使用一个工作线程自旋地进行 tick ，tick 到来后会先将全局任务队列中的任务添加到对应的 bucket 中，接着轮训当前 tick 对应 bucket 中的任务链表，执行轮次为 0 的任务，轮次非 0 的任务将其轮次减 1 。 特点优点 1 本地机器直接执行，效率非常高。2 无需扫描所有任务。通过将环切成 N 份，将查询到期延时任务的耗时降到 1/N，N 视任务量的大小可以灵活设置(1024,2048 等) 缺点 1 可靠性： - 机器重启，数据即丢失，可以使用 MySQL 等持久化存储，机器重启时从数据库 load 进内存。 - 机器宕机，数据丢失，需要使用方自行处理，如由其它机器接管宕机机器的任务2 时间轮调度器的时间精度可能不是很高，对于精度要求特别高的调度任务可能不太合适。因为时间轮算法的精度取决于一次 tick 的时间。3 时间轮是通过单线程实现的，如果在执行任务的过程中出现阻塞，会影响后面任务执行。这个缺点也就是缺点 2 的直接体现。 小结时间轮算法不难理解，但 HashedWheelTimer 源码中有很多细节需要注意。任务的管理，体现在任务队列和 bucket 数组的使用；任务的触发，体现在工作线程自旋进行 tick ；任务的执行，体现在工作线程轮询 bucket 的任务链表，对 TimerTask.run 的执行；需要注意的是，整个时间轮的调度都是在一个线程中完成的，因此对于那些耗时较大的定时任务会影响其他任务的正常触发和执行，但任务执行异常并不会导致工作线程退出，这是不同于 JDK 中的 Timer 。 参考：https://www.javadoop.com/post/HashedWheelTimer","categories":[{"name":"任务调度","slug":"任务调度","permalink":"https://gentryhuang.com/categories/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6/"}],"tags":[{"name":"HashedWheelTimer","slug":"HashedWheelTimer","permalink":"https://gentryhuang.com/tags/HashedWheelTimer/"}]},{"title":"并发 - ReentrantReadWriteLock","slug":"concurrent/ReentrantReadWriteLock","date":"2021-07-10T12:46:36.000Z","updated":"2021-08-21T09:39:31.780Z","comments":false,"path":"posts/f3292e6c/","link":"","permalink":"https://gentryhuang.com/posts/f3292e6c/","excerpt":"","text":"前言独占锁（排它锁）在同一时刻只允许一个线程进行访问，如 并发 - ReentrantLock 一文中介绍的 ReentrantLock 就是一个独占锁。而读写锁在同一时刻可以允许多个读线程访问，但是在写线程访问时，所有的读线程和其它写线程都会被阻塞。读写锁维护了一对锁，一个读锁和一个写锁，通过分离读锁和写锁，不仅保证了写操作对读操作的可见性，还使得并发性相比一般的排它锁有更大提升。在读多写少的情况下，读写锁能够提供比排它锁更好的并发性和吞吐量。 场景读写锁除了保证写操作对读操作的可见性以及并发性的提升之外，读写锁还能够简化读写交互场景的编码实现。对于一个共享的缓存数据，一般都是读多写少，但是写操作完成之后的更新需要对后续的读操作可见，这样做的目的是使读操作能读取到正确的数据。使用读写锁实现这样的功能，只需要在读操作时获取读锁，写操作时获取写锁即可。当写锁被获取时，后续其它线程的读写操作都会被阻塞，写锁释放之后，所有操作才会继续执行。相比于使用等待-通知机制，更加简单化。 概述Java 并发包提供读写锁的实现是 ReentrantReadWriteLock ，它支持以下特性： 公平性选择：支持非公平（默认）和公平的锁获取方式，吞吐量还是非公平优于公平 重入性：支持锁重入，包括读锁和写锁 锁降级：同一个线程获取的写锁能够降级为读锁，反之不行。遵循获取写锁、获取读锁、释放写锁、释放读锁 读写状态读写锁 ReentrantReadWriteLock 同样是基于 AQS 实现的锁功能，而读写状态就是 AQS 的同步状态。在 ReentrantLock 中同步状态表示锁被一个线程持有的次数，而读写锁需要在同步状态上维护多个读线程和一个写线程的信息，这就使得同步状态的设计成为读写锁实现的关键。由于同步状态 state 是一个整型变量，4 个字节 32 位，因此读写锁将该变量切分成了两部分，高 16 位表示读，低 16 位表示写，划分方式如下图所示： 上图中的同步状态表示一个线程已经获取了写锁且重入了 2 次，同时也连续获取了两次读锁。读写锁是通过位运算来确定读和写各自的状态的。下面对状态的变化过程进行说明。 假设当前同步状态 state 的值为 S 获取写状态 S &amp; (1 &lt;&lt; 16 -1) -&gt; 将高16位全部抹去 获取读状态 S&gt;&gt;&gt;16 -&gt; 无符号补0，右移16位 更新操作 写状态增加 1 时 -&gt; S + 1读状态增加 1 时 -&gt; S + (1&lt;&lt;16)，也就是 S + 0x00010000 注意：读写锁 ReentrantReadWriteLock 虽然使用同步状态 state 的高低位来表示读写状态，但是同步队列依然是共用一个。 源码分析ReentrantReadWriteLock 的类继承关系类图如下: 由继承关系图可知，读写锁 ReentrantReadWriteLock 是通过内部类 Sync 继承 AQS 来行使同步器的职能。由于该读写锁支持公平和非公平模式，因此通过继承内部类 Sync 的方式定义了非公平模式的 NonfairSync 和公平模式的 FairSync 。读写锁的实现依赖组合的 Sync ，也就是说 ReadLock 和 WriteLock 获取和释放锁的功能是交给 Sync 去实现的，公平模式下使用 FairSync ，非公平模式下使用 NonfairSync 。 读写锁 ReentrantReadWriteLock 组合关系如下图所示： ReentrantReadWriteLock 分为读锁 ReadLock 和写锁 WriteLock 。读锁是共享锁，可被多个线程同时占有；写锁是独占锁，同时只能有一个线程占有，且写锁被线程占有后其它线程既不能获取读锁也不能获取写锁，但占有写锁的线程可以在不释放写锁的情况下继续获取读锁，这是锁降级的特点。 代码结构123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107public class ReentrantReadWriteLock implements ReadWriteLock, java.io.Serializable &#123; private static final long serialVersionUID = -6992448646407690164L; /** * 读锁 */ private final ReentrantReadWriteLock.ReadLock readerLock; /** * 写锁 */ private final ReentrantReadWriteLock.WriteLock writerLock; /** * 获取写锁 * * @return */ public ReentrantReadWriteLock.WriteLock writeLock() &#123; return writerLock; &#125; /** * 获取读锁 * * @return */ public ReentrantReadWriteLock.ReadLock readLock() &#123; return readerLock; &#125; /** * Sync 继承自 AQS ,执行所有同步机制 * 根据 ReentrantReadWriteLock 构造函数传入的布尔值决定要构造哪一种 Sync 实例 */ final Sync sync; /** * 默认创建非公平的 ReentrantReadWriteLock */ public ReentrantReadWriteLock() &#123; this(false); &#125; /** * 根据传入的公平策略创建 ReentrantReadWriteLock * 说明：创建 ReentrantReadWriteLock 对象同时，会依次创建对应模式的 AQS 对象、读锁对象、写锁对象 * * @param fair 公平策略 */ public ReentrantReadWriteLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync(); readerLock = new ReadLock(this); writerLock = new WriteLock(this); &#125; /** * 静态内部类 Sync ，继承 AQS * 1 具体子类包括：非公平模式 NonfairSync 和 公平模式 FairSync * 2 实现 AQS 中的独占和共享模式的两对方法 */ abstract static class Sync extends AbstractQueuedSynchronizer &#123;...&#125; /** * 非公平版本的 Sync */ static final class NonfairSync extends Sync &#123;...&#125; /** * 公平版本的 Sync */ static final class FairSync extends Sync &#123;...&#125; /** * 读锁 */ public static class ReadLock implements Lock, java.io.Serializable &#123; private static final long serialVersionUID = -5992448646407690164L; /** * 使用外层的 ReentrantReadWriteLock 的 AQS 管理同步状态 */ private final Sync sync; protected ReadLock(ReentrantReadWriteLock lock) &#123; sync = lock.sync; &#125; // 省略其它方法 &#125; /** * 写锁 */ public static class WriteLock implements Lock, java.io.Serializable &#123; private static final long serialVersionUID = -4992448646407690164L; /** * 使用外层的 ReentrantReadWriteLock 的 AQS 管理同步状态 */ private final Sync sync; protected WriteLock(ReentrantReadWriteLock lock) &#123; sync = lock.sync; &#125; // 省略其它方法 &#125; 通过前文分析的 ReentrantReadWriteLock UML 类图和相关的组合关系图，不难发现与上述代码结构是一一对应的。下面我们依次对读锁和写锁依赖的 AQS 相关实现进行介绍，理解了相关的实现后也就基本理解了读写锁的实现。 Sync123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106/** * 静态内部类 Sync ，继承 AQS * 具体子类包括：非公平模式 NonfairSync 和 公平模式 FairSync */ abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = 6317671515068378041L; /** * 将同步状态 state 分为两段：高 16 位用于共享模式；低 16 位用于独占模式 */ static final int SHARED_SHIFT = 16; // 读锁的值操作单位 // 由于高 16 位用于读锁，因此每次操作基于 1 左移 16 位的值，也就是从高 16 位的末尾进行计算 // 即，同步状态 state 加减 1 &lt;&lt; 16 =&gt; 1 00000000 00000000 // 写锁是低 16 位，直接对同步状态 state 加减 static final int SHARED_UNIT = (1 &lt;&lt; SHARED_SHIFT); // 锁持有次数溢出的阈值，即 2^16 -1 static final int MAX_COUNT = (1 &lt;&lt; SHARED_SHIFT) - 1; // 独占模式掩码，即 1 &lt;&lt; 16 -1 =&gt; 11111111 11111111 static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1; /** * 取 c 的高 16 位的值，代表读锁的获取次数，包括重入 * 注意：该值是所有线程获取次数总和，包括每个线程重入情况 */ static int sharedCount(int c) &#123; return c &gt;&gt;&gt; SHARED_SHIFT; &#125; /** * 取 c 的低 16 位的值，代表写锁的重入次数（写锁是独占模式） */ static int exclusiveCount(int c) &#123; return c &amp; EXCLUSIVE_MASK; &#125; //----------------------- 🌟线程读锁计数器 --------------------/ // 用于记录每个线程持有的读锁次数(包括读锁重入) static final class HoldCounter &#123; // 线程持有读锁次数 int count = 0; // Use id, not reference, to avoid garbage retention final long tid = getThreadId(Thread.currentThread()); &#125; // ThreadLocal 的子类，保存线程变量副本 HoldCounter static final class ThreadLocalHoldCounter extends ThreadLocal&lt;HoldCounter&gt; &#123; /** * 初始化 HoldCounter * * @return */ @Override public HoldCounter initialValue() &#123; return new HoldCounter(); &#125; &#125; // 当前线程读锁计数器 // 说明：使用 ThreadLocal 来记录当前线程持有的读锁次数 private transient ThreadLocalHoldCounter readHolds; // 最后获取读锁的线程读锁计数器 // 说明：缓存最后一个获取读锁的线程持有读锁的次数，这里不是全局的概念，所以不管哪个线程获取到读锁后，就把这个值占为已用 private transient HoldCounter cachedHoldCounter; // 首个获取读锁的线程(并且其未释放读锁)读锁计数器 // 说明： // 1 这里不是全局的概念，该值被设置的条件是，当获取读锁时此时读锁没有线程持有。等这个 firstReader 代表的线程释放掉读锁以后，会有新的线程占用这个属性，也就是这个\"第一个\"是动态的。 // 2 在读锁不产生竞争的情况下，记录读锁重入次数是非常方便的 // 3 如果一个线程使用了 firstReader，那么它就不需要占用 cachedHoldCounter 变量了 private transient Thread firstReader = null; private transient int firstReaderHoldCount; //-------------------- 线程读锁计数器🌟 --------------------/ // 构造方法中初始化 Sync() &#123; // 初始化 readHolds 这个 ThreadLocal 属性 readHolds = new ThreadLocalHoldCounter(); // 为了保证 readHolds 的内存可见性 setState(getState()); // ensures visibility of readHolds &#125; /** * 获取读锁是否需要阻塞，交给子类实现 */ abstract boolean readerShouldBlock(); /** * 获取写锁是否需要阻塞，交给子类实现 */ abstract boolean writerShouldBlock(); // 省略获取和释放同步状态方法对，即获取和释放读锁/写锁方法。 // 在分析读锁和写锁时结合分析，这里先不展示源码&#125; 继承 AQS 的静态内部类 Sync 负责读锁 ReadLock 和写锁 WriteLock 的获取与释放工作，对读写锁 ReentrantReadWriteLock 的公平和非公平支持交给了两个子类实现。下面对 Sync 中的属性和抽象方法进行介绍，这些属作为最基础的数据支持读写锁的运行与统计。 同步状态 读写锁将 int 类型的同步状态 state 同时赋予两种语义，高 16 位表示读锁的持有次数，包括线程重入锁的情况。获取到读锁一次：state + (1&lt;&lt;16)，释放掉读锁一次：state - (1&lt;&lt;16)； 低 16 位表示写锁的获取次数，因为写锁是独占锁，同时只能被一个线程获取，因此它代表的重入次数。获取写锁一次：state + 1，释放写锁一次：state -1 。 线程读锁计数器 每个线程都需要记录获取的读锁次数，这样才能知道到底是不是读锁重入。注意，判断读锁重入和写锁重入完全不一样。写锁属于独占锁，同一时刻写锁只能一个线程持有，因此同步状态的低 16 位的值就是该线程持有写锁的次数（包括重入）；读锁属于共享锁，同一时刻允许多个线程持有，而同步状态的高 16 位的值是所有线程持有的总次数（包括各个线程重入），因此不能借助同步状态得出各个读线程持有读锁的次数，也就不能判断是否读锁重入，因此需要线程读锁计数器来辅助完成该诉求。 读写锁使用 ThreadLocal 维护每个线程读锁计数器，这样就能识别出哪个线程持有多少次读锁，进而可以判断线程是否是读锁重入以及线程持有读锁的次数。此外，读写锁基于性能考虑，又引入 “首个线程读锁计数器” 和 “最后线程读锁计数器”。其实 ThreadLocal&lt;HoldCounter&gt; readHolds 完全可以完成计数，只是 ThreadLocal 内部基于 Map 来查询的，相比直接使用变量记录线程读锁计数信息性能要差了那么一丢丢，不过这两个计数器只能记录一个线程持读锁信息，并且是动态变化的，提升性能的依据是尽可能先用这两个计数器，然后才使用通用的 ThreadLocal&lt;HoldCounter&gt; readHolds 记录线程读锁信息。 “首个线程读锁计数器” 是使用 firstReader 和 firstReaderHoldCount 两个属性组合而成的。“最后线程读锁计数器” 是使用 HoldCounter 类型的 cachedHoldCounter 属性表示。 读写公平策略 读写锁 ReentrantReadWriteLock 具体分为读锁 ReadLock 和写锁 WriteLock ，在公平和非公平模式下读锁和写锁的表现不同，因此将具体的实现交给公平和非公平子类实现。 非公平 Sync1234567891011121314151617181920212223242526272829303132+--- ReentrantReadWriteLock /** * 非公平版本的 Sync */ static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = -8159625535654395037L; /** * 获取写锁是否需要阻塞 * @return */ final boolean writerShouldBlock() &#123; // 如果是非公平模式，那么 lock 的时候就可以直接用去抢锁，抢不到再排队 return false; // writers can always barge &#125; /** * 获取读锁是否需要阻塞 * @return */ final boolean readerShouldBlock() &#123; // 判断同步队列中 head 的第一个后继节点是否是来获取写锁的，如果是，就算是非公平模式，也先让该节点获取写锁，避免线程饥饿 return apparentlyFirstQueuedIsExclusive(); // final boolean apparentlyFirstQueuedIsExclusive() &#123; // Node h, s; // return (h = head) != null &amp;&amp; // (s = h.next) != null &amp;&amp; // !s.isShared() &amp;&amp; // s.thread != null; // &#125; &#125; &#125; 在非公平模式下，写锁优先尝试抢占锁，抢占失败才会去排队；一般来说，非公平模式下读锁也应该直接尝试抢占锁，但是写锁被定义了更高的优先级，读锁会先判断队列中等待的第一个线程节点是否是获取写锁的，如果是就算是非公平模式也先让该节点获取写锁，避免线程饥饿。 公平 Sync12345678910111213141516171819202122232425+--- ReentrantReadWriteLock /** * 公平版本的 Sync */ static final class FairSync extends Sync &#123; private static final long serialVersionUID = -2274990926593161451L; /** * 获取写锁是否需要阻塞 * @return */ final boolean writerShouldBlock() &#123; // 那么如果阻塞队列有线程等待的话，就乖乖去排队 return hasQueuedPredecessors(); &#125; /** * 判断读是否要阻塞 * @return */ final boolean readerShouldBlock() &#123; // 同步队列中有线程节点在等待 return hasQueuedPredecessors(); &#125; &#125; 在公平模式下，无论是写锁还是读锁，都遵循先来后到原则。需要说明的是，对于读锁的获取，无论是公平还是非公平模式，它都没有抢占的概念，即使是在非公平模式下，还是需要判断同步队列中的第一个线程节点是否是写线程。 至此，读锁和写锁的前置准备已经完成，下面我们进入到读锁和写锁的源码。 读锁读锁内部持有 ReentrantReadWriteLock 中的 Sync 类型的对象，可能是 FairSync 对象，也可能是 NonfairSync 对象，具体由 ReentrantReadWriteLock 构造函数决定。ReadLock 锁获取与释放功能全部委托给 sync 对象完成。 属性123456789101112131415161718+--- ReentrantReadWriteLock public static class ReadLock implements Lock, java.io.Serializable &#123; private static final long serialVersionUID = -5992448646407690164L; /** * 使用 AQS 管理同步状态 */ private final Sync sync; /** * 构造方法 * * @param lock */ protected ReadLock(ReentrantReadWriteLock lock) &#123; sync = lock.sync; &#125; &#125; 获取读锁1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495+--- ReadLock /** * 获取读锁 */ public void lock() &#123; // AQS 模版方法，获取共享同步状态 sync.acquireShared(1); &#125;+--- AQSpublic final void acquireShared(int arg) &#123; // 尝试获取读锁 if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125;+--- Sync /** * AQS 模版方法，获取共享同步状态 - 获取读锁 * 说明： * 1 读锁是一个支持重入的共享锁，它能被多个线程同时获取，在没有其它写线程访问时（注意非公平模式下同步队列中首个获取写锁的线程节点的情况），读锁总会被成功地获取，而所做的也只是增加读状态。 * 2 如果当前线程已经获取了读锁，则增加读状态。如果当前线程在获取读锁时，写锁已被其它线程获取，则进入等待状态。 * 3 读锁的实现有两部分逻辑，一个是获取读锁，另一个是设置线程的读锁计数器。 * * @param unused * @return */ protected final int tryAcquireShared(int unused) &#123; // 1 获取当前线程 Thread current = Thread.currentThread(); // 2 获取同步状态 int c = getState(); // 3 exclusiveCount(c) != 0 ，说明有线程持有写锁。如果不是当前线程持有的写锁，那么当前线程获取读锁失败。 // 由于读写锁的降级，如果当前线程持有写锁，是可以继续获取读锁的 if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; // 4 读锁的获取次数 int r = sharedCount(c); // 5 获取读锁是否需要被阻塞（需要考虑公平与非公平的情况） if (!readerShouldBlock() &amp;&amp; // 判断持有读锁次数是否会溢出 (2^16-1) r &lt; MAX_COUNT &amp;&amp; // 使用 CAS 是将 state 属性的高 16 位加 1，低 16 位不变，如果成功就代表获取到了读锁 // c + 1 00000000 00000000 compareAndSetState(c, c + SHARED_UNIT)) &#123; /* 进入当前代码区域，表示获取到了读锁。下面的逻辑是记录线程读锁计数器，用于标记当前线程持读锁次数，为判断是否读锁重入以及线程获取读锁次数做基础数据准备 */ // 5.1 r == 0 说明当前线程是第一个获取读锁的线程，或者是在它之前的读锁都已经释放了 // 记录 firstReader 为当前线程，及其持有的读锁数量：1 if (r == 0) &#123; firstReader = current; firstReaderHoldCount = 1; // 5.2 当前线程重入锁，加 1 即可 &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; // 5.3 当前线程不是第一个获取读锁，并且已经有其它线程获取了读锁 // - 使用 readHolds 保存当前线程持有的读锁次数 // - 将当前线程持有读锁信息更新为 cachedHoldCounter 的值，该变量用于记录最后一个获取读锁的线程持锁信息 &#125; else &#123; // 获取最后一个获取读锁的线程信息。 Sync.HoldCounter rh = cachedHoldCounter; // 如果 cachedHoldCounter 缓存的不是当前线程，则将当前线程持有读锁信息缓存到 HoldCounter if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); // cachedHoldCounter 缓存的是当前线程，但 count 为 0 else if (rh.count == 0) readHolds.set(rh); // 将当前线程持有读锁次数 count 加 1 rh.count++; &#125; // return 大于 0 代表获取到了共享锁 return 1; &#125; // 进入下面方法，可能是以下三种情况： // - compareAndSetState(c, c + SHARED_UNIT) 存在竞争，CAS 失败 // - 公平模式 FairSync 下同步队列中有其它线程节点在等待锁 // - 非公平模式 NonFairSync 下，同步队列中第一个线程节点（head.next）是获取写锁的，为了避免写锁饥饿，获取读锁的线程不应该和它竞争 return fullTryAcquireShared(current); &#125; 读锁获取使用 AQS 的共享模式获取同步状态，整个流程如下： 判断写锁是否被其它线程占有（支持锁降级获取读锁），如果被其它线程占有直接获取读锁失败。 根据具体的公平或非公平模式判断获取读锁是否需要阻塞，阻塞的话会进入后续二次确认方法，即判断是否是重入获取读锁，重入获取读锁不需要阻塞。 获取读锁成功后，记录线程读锁计数器。 获取读锁的注意事项如下： 获取读锁前提条件是写锁没有被其它线程持有，当前线程持有写锁是可以继续获取读锁的，这是读写锁的锁降级特性。 在公平模式下，获取读锁时同步队列中有等待的线程节点，如果此时不是重入获取读锁，那么获取锁失败。 在非公平模式下，获取读锁时同步队列中第一个线程节点是获取写锁的情况，此时如果不是重入获取读锁，那么获取锁失败。写锁被定义更高的优先级。 获取锁成功后，需要记录当前线程读锁计数器。线程读锁计数器有两个作用，一个是用于判断线程是否是重入读锁，另一个是提供当前线程获取读锁的次数。 fullTryAcquireShared1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798+--- Sync /** * 这段代码与 tryAcquireShared 中的代码在一定程度上是冗余的，但由于没有使用重试和惰性读取保持计数之间的交互使 tryAcquireShared 复杂化，所以总体上更简单。 * * @param current 当前线程 * @return */ final int fullTryAcquireShared(Thread current) &#123; // 记录线程获取读锁的次数 Sync.HoldCounter rh = null; // for 循环 for (; ; ) &#123; // 1 获取同步状态 int c = getState(); // 2 如果其它线程获取了写锁，那么当前线程是不能获取到读锁的，只能去同步队列中排队 if (exclusiveCount(c) != 0) &#123; if (getExclusiveOwnerThread() != current) return -1; // else we hold the exclusive lock; blocking here // would cause deadlock. // 3 获取读锁应该阻塞，说明同步队列中有其它线程在等待。 // 注意： 既然是获取读锁应该阻塞，那么进入有什么用呢？ 是用来处理读锁重入的 &#125; else if (readerShouldBlock()) &#123; // firstReader 线程重入锁，暂不做操作，直接执行后面的 CAS if (firstReader == current) &#123; // assert firstReaderHoldCount &gt; 0; // 非 firstReader 线程重入锁，则继续判断其它情况重入锁 &#125; else &#123; if (rh == null) &#123; // 判断是否是 cachedHoldCounter 重入锁，如果也不是，那就是既不是 firstReader 可重入也不是 lastReader 可重入， // 这是只需从 ThreadLocal 取出当前线程持有读锁信息，如果没有占有，则进行兜底操作，让线程去排队 rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) &#123; // 那么到 ThreadLocal 中获取当前线程的 HoldCounter // 注意，如果当前线程从来没有初始化过 ThreadLocal 中的值，get() 会执行初始化 rh = readHolds.get(); // 如果发现 count == 0，也就是说是上一行代码初始化的，之前该线程并没有持有读锁，那么执行 remove 操作清空信息，因为接下来该线程要入队等待了 // 然后往下两三行，乖乖排队去 if (rh.count == 0) readHolds.remove(); &#125; &#125; // 非重入，去同步队列中排队 if (rh.count == 0) return -1; &#125; &#125; if (sharedCount(c) == MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); // 这里 CAS 成功，那么就意味着成功获取读锁了 // 下面需要做的是设置 firstReader 或 cachedHoldCounter，以及 readHolds，记录线程读锁信息 if (compareAndSetState(c, c + SHARED_UNIT)) &#123; // 注意这里 c 是上面的快照，上面修改的不是 c 而是 state // 如果发现 sharedCount(c) 等于 0，也就是当前没有线程持有读锁，就将当前线程设置为 firstReader if (sharedCount(c) == 0) &#123; firstReader = current; firstReaderHoldCount = 1; // 如果是重 firstReader 重入，直接累加持有读锁的次数即可 &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; // 将 cachedHoldCounter 设置为当前线程持有读锁信息，并且使用 ThreadLocal 记录当前线程持有读锁信息 &#125; else &#123; if (rh == null) rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); // 累加当前线程持读锁次数 rh.count++; // 更新 cachedHoldCounter 为当前线程持有读锁信息 cachedHoldCounter = rh; // cache for release &#125; // 返回大于 0 的数，代表获取到了读锁 return 1; &#125; &#125; &#125; 上述方法在一定程度上是对 tryAcquireShared 方法的冗余，主要是对并发获取读锁失败以及重入获取锁的处理。具体作用如下： tryAcquireShared 方法中 CAS 获取同步状态失败后增加获取读锁成功的机会，尽可能不进入同步队列。 处理 tryAcquireShared 中因获取读锁需要阻塞的情况（上述方法只会处理重入读锁的情况，因为重入读锁不需要阻塞，非重入就需要阻塞，也就是获取读锁再次失败） 在非公平模式 NonFairSync 情况下，如果同步队列中 head.next 是获取写锁的节点，那么如果该线程不是重入读锁则获取失败，如果是重入读锁则获取成功，因为重入优先级更高。 在公平模式 FairSync 情况下，如果同步队列中有线程节点等待，那么如果不是重入读锁则获取失败，如果是重入读锁则获取成功，同样地，因为重入优先级更高。 释放读锁1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677+--- ReadLock /** * 释放读锁 */ public void unlock() &#123; sync.releaseShared(1); &#125; +--- AQS public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false; &#125;+--- Sync /** * AQS模版方法，释放共享同步状态 - 释放读锁 * 说明： * 读锁的每次释放均减少读状态，减少的值是 1&lt;&lt;16 * * @param unused * @return */ protected final boolean tryReleaseShared(int unused) &#123; // 1 获取当前线程 Thread current = Thread.currentThread(); // 2 如果当前线程是 firstReader ，说明当前线程是第一个读线程 if (firstReader == current) &#123; // 如果 firstReaderHoldCount 等于 1 ，那么本次解锁后就不再持有锁了，需要把 firstReader 置为 null // 没有设置 firstReaderHoldCount = 0 ，是因为没必要，其他线程使用的时候自己会重新设置该值 if (firstReaderHoldCount == 1) firstReader = null; else firstReaderHoldCount--; // 3 当前线程不是首个获取读锁的线程 &#125; else &#123; // 判断当前线程是不是最后获取读锁的线程，不是的话要到 ThreadLocal 中取 Sync.HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) rh = readHolds.get(); // 获取计数 int count = rh.count; if (count &lt;= 1) &#123; // 将 ThreadLocal remove 掉，防止内存泄漏。因为已经不再持有读锁了 readHolds.remove(); // 防止释放锁和获取锁次数不匹配 if (count &lt;= 0) throw unmatchedUnlockException(); &#125; // count 减 1 --rh.count; &#125; // 4 将同步状态 state 的高 16 位减 1，如果发现读锁和写锁都释放完了，那么唤醒后继的等待线程节点 for (; ; ) &#123; // 获取同步状态 state int c = getState(); // nextc 是 state 高 16 位减 1 后的值 int nextc = c - SHARED_UNIT; // 如果 nextc == 0，那就是 state 全部 32 位都为 0，也就是读锁和写锁都没有被占有 if (compareAndSetState(c, nextc)) // 释放读锁对读操作没有影响，但是如果现在读锁和写锁都是空闲的，那么释放读锁可能允许等待的写操作继续进行。 return nextc == 0; &#125; &#125; 读锁释放过程比较简单，主要还是对应的两个操作，具体如下： 更新当前释放读锁的线程对应的读锁计数器，如果是完全释放锁，则需要销毁对应的读锁计数器。 更新同步状态的高 16 位的值，表示释放读锁。如果是完全释放锁，则当前线程去唤醒同步队列中的线程节点。 写锁写锁是一个支持重入的排它锁。如果当前线程已经获取了写锁，则增加写状态。如果当前线程在获取写锁时，读锁已经被获取或者该线程不是已经获取写锁的线程，则当前线程进入等待状态。 写锁内部持有 ReentrantReadWriteLock 中的 Sync 类型的对象，可能是 FairSync 对象，也可能是 NonfairSync 对象，具体由 ReentrantReadWriteLock 构造函数决定。ReadLock 锁获取与释放功能全部委托给 sync 对象完成。 属性1234567891011121314+--- ReentrantReadWriteLock /** * 写锁 * 1 写锁是独占锁 * 2 如果有读锁被占用，写锁获取要进入同步队列中等待 */ public static class WriteLock implements Lock, java.io.Serializable &#123; private static final long serialVersionUID = -4992448646407690164L; private final Sync sync; protected WriteLock(ReentrantReadWriteLock lock) &#123; sync = lock.sync; &#125;&#125; 获取写锁123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869+--- WriteLock /** * 获取写锁 */ public void lock() &#123; sync.acquire(1); &#125;+--- AQS public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125;+--- Sync /** * AQS 模版方法，获取独占同步状态 - 获取写锁 * 说明： * 1 该方法除了重入条件（当前线程是获取了写锁的线程）之外，增加了一个读锁是否存在的判断。 * 2 如果存在读锁，则写锁不能被获取，原因在于，读写锁要确保写锁的操作对读锁可见，如果允许读锁在已经被获取的情况下对写锁的获取， * 那么正在运行的其它读线程就无法感知到当前写线程的操作。因此，只有等待其它读线程都释放了读锁，写锁才能被当前线程获取。 * 3 写锁一旦被获取，则其它读写线程的后续访问都被阻塞。 * * @param acquires * @return */ protected final boolean tryAcquire(int acquires) &#123; // 1 获取当前线程 Thread current = Thread.currentThread(); // 2 获取同步状态 state int c = getState(); // 3 根据 state 获取写锁的持有次数 int w = exclusiveCount(c); // 4 c != 0 表示要么有线程持有读锁，要么有线程持有写锁 // 由于该方法是获取写锁，因此下面只能是写锁重入分支（存在持有读锁的情况直接失败） if (c != 0) &#123; // c != 0 &amp;&amp; w == 0: 写锁可用，但是有线程持有读锁(也可能是自己持有，但由于不支持锁升级，因此不能获取写锁) if (w == 0 || // c != 0 &amp;&amp; w !=0 &amp;&amp; current != getExclusiveOwnerThread(): 非重入，其他线程持有写锁 current != getExclusiveOwnerThread()) // 存在读锁或者当前获取线程不是已经获取写锁的线程 return false; // 判断写锁持有次数是否超过阈值（65535） if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); // 能到这里的，只可能是写锁重入，更新同步状态即可 setState(c + acquires); return true; &#125; // 执行到这里，此时 state == 0 ，读锁和写锁都没有被获取 // 5 获取写锁，这里判断是否需要阻塞（这里考虑到公平还是非公平） if (writerShouldBlock() || // 不需要阻塞，则更新 state !compareAndSetState(c, c + acquires)) return false; // 6 当前线程独占锁 setExclusiveOwnerThread(current); return true; &#125; 写锁获取使用 AQS 的独占模式获取同步状态的流程，整个流程如下： 判断读锁是否被线程持有（包括当前线程自身），如果被持有则获取写锁直接失败。 判断是否是重入获取写锁，如果不是直接获取写锁失败。 根据具体的公平或非公平模式判断获取写锁是否需要阻塞，如果不需要阻塞则尝试获取写锁，成功后当前线程独占锁。 释放写锁123456789101112131415161718192021222324252627282930313233343536373839404142434445+--- WriteLock /** * 写锁释放 */ public void unlock() &#123; sync.release(1); &#125;+-- AQS public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false; &#125;+--- Sync /** * AQS 模版方法，释放独占同步状态 - 释放写锁 * * @param releases * @return */ protected final boolean tryRelease(int releases) &#123; // 当前线程是否占有锁，否则没有资格尝试释放写锁 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); // 计算同步状态剩余值 int nextc = getState() - releases; // 写锁重入次数是否为 0 ，为 0 表示可以释放 boolean free = exclusiveCount(nextc) == 0; // 完全释放 if (free) // 清空独占线程 setExclusiveOwnerThread(null); // 更新 state setState(nextc); return free; &#125; 写锁的释放与 ReentrantLock 的释放过程基本类似，每次释放均减少写状态，当写状态为 0 时表示写锁可以被释放。 锁降级ReentrantReadWriteLock 锁降级指的是写锁降级成为读锁。如果当前线程拥有写锁，然后将其释放，最后再获取读锁，这种分段完成的过程不能称之为锁降级。锁降级是指持有写锁的线程在不释放写锁的同时，再获取到读锁，随后释放写锁，最后释放读锁。 锁降级示例 1234567891011121314151617181920212223242526272829303132333435363738394041424344 ReentrantReadWriteLock reentrantReadWriteLock = new ReentrantReadWriteLock(); ReentrantReadWriteLock.ReadLock readLock = reentrantReadWriteLock.readLock(); ReentrantReadWriteLock.WriteLock writeLock = reentrantReadWriteLock.writeLock(); public volatile Boolean updateFlag = Boolean.FALSE;/** * 读取缓存，一旦缓存被修改破坏，需要更新 */ private void processData() &#123; // 获取读锁，该方法主要是读取缓存数据 readLock.lock(); // 共享数据发生改变，需要重新计算缓存数据 if (updateFlag) &#123; // 必须先释放掉读锁，后续加写锁更新缓存 readLock.unlock(); // 1 获取写锁，用于只有一个线程更新缓存 writeLock.lock(); try &#123; if (updateFlag) &#123; // 更新缓存值 cacheData = caculateCacheData(); updateFlag = Boolean.FALSE; &#125; // 2 获取读锁 readLock.lock(); &#125; finally &#123; // 3 释放写锁 writeLock.unlock(); &#125; // 以上 1、2、3 步完成锁降级，即写锁降级为读锁 &#125; try &#123; // 使用缓存 System.out.println(\"print cache: \" + cacheData); &#125; finally &#123; readLock.unlock(); &#125; &#125; 上述示例中，缓存数据可用时，每个线程只需获取读锁然后访问，数据访问完成后释放读锁。但当共享的缓存数据被破坏，此时所有访问 processData 方法的线程都能感知到，但只有一个线程能够获取写锁然后更新缓存，其它线程都会被阻塞。当线程更新完缓存数据后，会接着获取读锁，随后才会释放写锁，完成锁的降级。 锁降级中的读锁获取是否有必要？答案是必要的，主要是为了保证数据的可见性。如果线程计算完缓存后没有获取读锁而是直接释放掉了写锁，那么此时如果存在另一个线程 t 获取了写锁并修改了缓存，那么当前线程就无法感知线程 t 的数据更新。如果当前线程在释放掉写锁前获取读取，也就是遵循锁降级的步骤，则线程 t 就无法获取写锁，直到当前线程访问数据并释放掉读锁后，线程 t 才能有机会获取写锁更新缓存数据。 注意: ReentrantReadWriteLock 不支持锁升级，即持有读锁时再获取写锁，随后释放读锁。不支持的目的是保证数据可见性，如果读锁已被多个线程获取，其中任意线程成功获取了写锁并更新数据，则其更新对其它获取到读锁的线程是不可见的。此外，是为了避免发生死锁，试想一个线程先获取读锁，然后再获取写锁，那么该线程会由于获取写锁失败进入同步队列中等待，可能之后就不会被唤醒了。 小结ReentrantReadWriteLock 读写锁正如其名，具体分为读锁和写锁。无论是读锁还是写锁，整个获取与释放锁的流程都是交给实现 AQS 的 Sync 类型的对象完成，准确来说是公平 Sync 或者非公平 Sync 对象。对于读锁和写锁的语义，是将同步状态 state 划分为高低位，高 16 位表示读锁状态，低 16 位表示写锁状态。写锁的获取和释放锁类似重入锁 ReentrantLock 过程，唯一不同的是写锁需要考虑读锁的占有情况。读锁的获取和释放比较复杂，复杂的主要原因是读锁允许多个线程同时获取且支持可重入，此时同步状态的高 16 位的值没办法表示各个线程持有读锁的情况，因此读写锁新增了线程读锁计数器的概念，有了这个概念就可以很轻松判断读线程重入锁的情况以及实时获取当前线程持有读锁的次数。","categories":[{"name":"JDK","slug":"JDK","permalink":"https://gentryhuang.com/categories/JDK/"}],"tags":[{"name":"JUC","slug":"JUC","permalink":"https://gentryhuang.com/tags/JUC/"},{"name":"AQS","slug":"AQS","permalink":"https://gentryhuang.com/tags/AQS/"},{"name":"Lock","slug":"Lock","permalink":"https://gentryhuang.com/tags/Lock/"}]},{"title":"Redis原理 - Redis主流程","slug":"redis_theory/themory/Redis全流程","date":"2021-06-24T06:59:01.000Z","updated":"2021-09-12T02:21:24.471Z","comments":false,"path":"posts/19fe4bc5/","link":"","permalink":"https://gentryhuang.com/posts/19fe4bc5/","excerpt":"","text":"前言本篇文章将从源码层面对 Redis 主干轮廓进行说明。以主线程执行流程为主干，对途径的枝枝蔓蔓简单介绍，不会过度展开，后续将针对每一个模块进行详细分析。由于 Redis 是用 C 语言实现的，当然应该从 main 函数开启阅读源码旅程。需要说明的是，笔者阅读的 Redis 版本是 #define REDIS_VERSION &quot;6.2.4&quot;，之所以选择较新的版本，因为笔者对 Redis 一些新特性比较感兴趣，特别是 Redis 在 6.0 版本中提出的 IO 多线程。 main 函数Redis 服务器启动的入口是 main 函数，其它的无需多说，下面直接上代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293/* * Redis Server 启动入口 * * 说明： * Redis是用C语言实现的，从 main 函数启动。 */int main(int argc, char **argv) &#123; struct timeval tv; int j; char config_from_stdin = 0;#ifdef INIT_SETPROCTITLE_REPLACEMENT // 1 初始化库 spt_init(argc, argv);#endif // 2 检查服务器是否以 Sentinel 模式启动 // 这一点非常重要，因为 Sentinel 和普通的实例不同 server.sentinel_mode = checkForSentinelMode(argc, argv); // 3 初始化服务器配置 initServerConfig(); // 4 ACL 初始化（6.0 对 ACL 进行了功能丰富） ACLInit(); /* The ACL subsystem must be initialized ASAP because the basic networking code and client creation depends on it. */ // 5 如果服务器以 Sentinel 模式启动，那么需要进行 Sentinel 功能相关的初始化，并为要监视的主服务器创建一些相应的数据结构 if (server.sentinel_mode) &#123; // Sentinel 所属的属性覆盖服务器默认的属性 initSentinelConfig(); // 哨兵模式初始化 initSentinel(); &#125; // 6 是否需要在 redis-check-rdb/aof模式下启动，这样可以校验持久化文件 if (strstr(argv[0], \"redis-check-rdb\") != NULL) redis_check_rdb_main(argc, argv, NULL); else if (strstr(argv[0], \"redis-check-aof\") != NULL) redis_check_aof_main(argc, argv); // 7 检查用户是否指定了配置文件，或者配置选项 if (argc &gt;= 2) &#123;...&#125; int background = server.daemonize &amp;&amp; !server.supervised; // 8 将服务器设置为守护进程运行 if (background) daemonize(); // 9 创建并初始化服务器 initServer(); // 🌟 服务器不是运行在 SENTINEL 模式，那么执行以下代码 if (!server.sentinel_mode) &#123; // 10 bio 和 io 线程的初始化 InitServerLast(); // 11 从 AOF 文件或者 RDB 文件中载入数据 loadDataFromDisk(); if (server.cluster_enabled) &#123; if (verifyClusterConfigWithData() == C_ERR) &#123; serverLog(LL_WARNING, \"You can't have keys in a DB different than DB 0 when in \" \"Cluster mode. Exiting.\"); exit(1); &#125; &#125; // 以 SENTINEL 模式运行 &#125; else &#123; ACLLoadUsersAtStartup(); // bio 和 io 线程的初始化 InitServerLast(); // Sentinel 准备就绪后执行 sentinelIsRunning(); &#125; // 12 🌟 启动事件处理循环 // 主要围绕 IO多路复用 展开的，驱动注册的时间事件回调和 IO 事件回调 aeMain(server.el); // 12 退出事件循环，回收内存 aeDeleteEventLoop(server.el); // retun 0 return 0;&#125; Redis 服务启动后，主线程 main 会依次执行以上流程，直到进入 aeMain 事件处理循环方法中。需要说明的是，上述代码片段删除掉了不关心的逻辑，本篇文章我们只关注以下两个逻辑： 执行各种初始化 执行事件循环 Redis 服务器初始化逻辑较为复杂，从底层的数据结构到服务器不同的角色，初始化的逻辑和属性都不一样，这里就不展开了。下面对流程进行概括： 事件循环事件循环逻辑是 Redis 核心的直接体现，它就是在这个循环中不断处理网络请求和内部自身逻辑的。下面我们直接上代码。 1234567891011void aeMain(aeEventLoop *eventLoop) &#123; eventLoop-&gt;stop = 0; // 主线程进入主循环，一直处理事件，直到服务器关闭 while (!eventLoop-&gt;stop) &#123; // 开始处理事件 aeProcessEvents(eventLoop, AE_ALL_EVENTS | AE_CALL_BEFORE_SLEEP | AE_CALL_AFTER_SLEEP); &#125;&#125; 可以看到，只要事件循环 aeEventLoop 没有被停止，主线程 main 就会一直自旋，不断执行 aeProcessEvents 方法。不难看出 aeProcessEvents 方法封装了 Redis 的所有功能逻辑，这里提前说下，Redis 的功能逻辑总共两大类：一个是网络事件，也称为文件事件；另一个是时间事件；前者用于处理网络中的交互，后者用于处理 Redis 自身的一些逻辑。 下面继续贴出 aeProcessEvents 方法的代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104int aeProcessEvents(aeEventLoop *eventLoop, int flags) &#123; int processed = 0, numevents; /* Nothing to do? return ASAP */ if (!(flags &amp; AE_TIME_EVENTS) &amp;&amp; !(flags &amp; AE_FILE_EVENTS)) return 0; if (eventLoop-&gt;maxfd != -1 || ((flags &amp; AE_TIME_EVENTS) &amp;&amp; !(flags &amp; AE_DONT_WAIT))) &#123; int j; struct timeval tv, *tvp; int64_t usUntilTimer = -1; // 1 获取最近的时间事件 if (flags &amp; AE_TIME_EVENTS &amp;&amp; !(flags &amp; AE_DONT_WAIT)) usUntilTimer = usUntilEarliestTimer(eventLoop); // 1.1 使用 usUntilTimer 来决定文件事件的阻塞时间 if (usUntilTimer &gt;= 0) &#123; tv.tv_sec = usUntilTimer / 1000000; tv.tv_usec = usUntilTimer % 1000000; tvp = &amp;tv; // 1.2 执行到这里，说明没有时间事件。那么根据 AE_DONT_WAIT 是否设置来决定是否阻塞，以及阻塞的时间长度 &#125; else &#123; if (flags &amp; AE_DONT_WAIT) &#123; // 设置文件事件不阻塞 tv.tv_sec = tv.tv_usec = 0; tvp = &amp;tv; &#125; else &#123; /* Otherwise we can block */ // 文件事件阻塞直到有事件到达为止 tvp = NULL; /* wait forever */ &#125; &#125; if (eventLoop-&gt;flags &amp; AE_DONT_WAIT) &#123; tv.tv_sec = tv.tv_usec = 0; tvp = &amp;tv; &#125; /* 2 前置回调函数 - beforeSleep */ if (eventLoop-&gt;beforesleep != NULL &amp;&amp; flags &amp; AE_CALL_BEFORE_SLEEP) eventLoop-&gt;beforesleep(eventLoop); 3 调用多路复用 API，只会在超时或某些事件触发时返回。即等待事件产生 numevents = aeApiPoll(eventLoop, tvp); /* 4 后置回调函数 - beforeSleep */ if (eventLoop-&gt;aftersleep != NULL &amp;&amp; flags &amp; AE_CALL_AFTER_SLEEP) eventLoop-&gt;aftersleep(eventLoop); // 5 遍历所有已产生的事件，并调用相应的事件处理器来处理这些事件 for (j = 0; j &lt; numevents; j++) &#123; // 5.1 从已就绪数组中获取文件描述符信息 aeFileEvent *fe = &amp;eventLoop-&gt;events[eventLoop-&gt;fired[j].fd]; int mask = eventLoop-&gt;fired[j].mask; int fd = eventLoop-&gt;fired[j].fd; int fired = 0; /* Number of events fired for current fd. */ int invert = fe-&gt;mask &amp; AE_BARRIER; // 5.2 如果是套接字上发生读事件，调用读事件处理器处理读事件 if (!invert &amp;&amp; fe-&gt;mask &amp; mask &amp; AE_READABLE) &#123; fe-&gt;rfileProc(eventLoop, fd, fe-&gt;clientData, mask); fired++; fe = &amp;eventLoop-&gt;events[fd]; /* Refresh in case of resize. */ &#125; /* Fire the writable event. */ // 5.3 如果是套接字上发生写事件，调用写事件处理器处理写事件 if (fe-&gt;mask &amp; mask &amp; AE_WRITABLE) &#123; if (!fired || fe-&gt;wfileProc != fe-&gt;rfileProc) &#123; fe-&gt;wfileProc(eventLoop, fd, fe-&gt;clientData, mask); fired++; &#125; &#125; /* If we have to invert the call, fire the readable event now * after the writable one. * * 如果需要反转调用，在可写事件之后触发可读事件 */ if (invert) &#123; fe = &amp;eventLoop-&gt;events[fd]; /* Refresh in case of resize. */ if ((fe-&gt;mask &amp; mask &amp; AE_READABLE) &amp;&amp; (!fired || fe-&gt;wfileProc != fe-&gt;rfileProc)) &#123; fe-&gt;rfileProc(eventLoop, fd, fe-&gt;clientData, mask); fired++; &#125; &#125; processed++; &#125; &#125; // 6 如果是时间事件 if (flags &amp; AE_TIME_EVENTS) // 执行时间事件 processed += processTimeEvents(eventLoop); return processed; /* return the number of processed file/time events */&#125; 从上述代码片段中也可以看到，主线程在不断轮询时间事件和文件事件，找到就尝试执行。上述代码虽然简短，但是却几乎包含了 Redis 的所有功能，秘密就在以下几个组件中： 前置处理器 beforeSleep IO多路复用库（及多种回调函数） 后置处理器 afterSleep 关于以上代码片段背后的信息，会在后面的文章中介绍 Redis 事件一文中详细说明，这里先不展开。下面对以上方法进行概括： 小结本篇文章简单介绍了 Redis 启动的入口以及执行的主干流程，这里有个印象即可，后续会对每个模块展开说明。","categories":[{"name":"Redis","slug":"Redis","permalink":"https://gentryhuang.com/categories/Redis/"}],"tags":[]},{"title":"网络通信 - IO多路复用","slug":"network/IO多路复用","date":"2021-06-12T02:43:23.000Z","updated":"2021-09-11T10:07:55.008Z","comments":false,"path":"posts/b25f5b99/","link":"","permalink":"https://gentryhuang.com/posts/b25f5b99/","excerpt":"","text":"概述IO多路复用简单来说就是，单线程或单进程同时监测若干个文件描述符是否可以执行IO操作的能力，IO多路复用解决的本质问题是用更少的资源完成更多的事。需要说明的是，处理IO多路复用的问题需要操作系统提供内核级别的支持，操作系统充当观察者的角色。本篇文章我们就来分析IO多路复用底层实现原理，我们以 Linux 操作系统提供的IO复用API select、poll 以及epoll 为例，逐一进行分析。 思考实现IO多路复用直接使用用户线程轮询查看若干个文件描述符的状态难道不行吗？为什么要操作系统内核支持？在请求量比较小的时候确实可以使用该方案，但是在大量请求的情况下，这对于 CPU 的使用率来说无疑是种灾难。而使用操作系统内核帮我们观察文件描述符就可以优雅、高效地实现IO多路复用。 操作系统内核虽然清楚知道每个文件描述符对应的 Socket 的状态变化，但是内核如何知道该把哪个文件描述符信息给哪个进程呢？一个 Socket 文件可以由多个进程使用，而一个进程也可以使用多个 Socket 文件，进程和 Socket 之间是多对多的关系。此外，一个 Socket 也会对应多个事件类型。操作系统表示太难了，它很难判断将哪种事件触发的 Socket 给哪个进程。因此，在进程内部就需要维护自己关注哪些 Socket 文件的哪些事件，如读事件、写事件以及异常事件等。也就是说，内核帮应用程序盯着感兴趣的 Socket ，应用程序可以根据内核反馈的信息进一步处理网络请求。 综上，我们需要关注以下三个问题： 多路复用机制可以监听哪些套接字 多路复用机制会监听套接字上的哪些事件 套接字就绪时，多路复用机制要如何找到就绪的套接字 下面我们带着这些问题，结合 Linux 下的IO复用API进行分析。 selectselect 实现IO多路复用的思想是：操作系统内核会扫描用户进程传入的 3 类 fd_set 文件描述数组(本质是 bitmap)，当对应的 Socket 准备就绪时会置位（标志对应的 Socket 有数据来了） fd_set 数组中对应的元素，最后将内核置位后的 fd_set 数组们拷贝回用户空间。由于 select 并不会明确指出是哪些文件描述符就绪（一股脑返回全部 fd），因此用户进程需要根据内核返回的 fd_set 数组们自行判断哪个文件描述符对应的 Socket 发生了哪种事件，然后再进一步处理。 API定义123456789101112131415161718192021222324#include &lt;sys/select.h&gt;/* According to earlier standards */#include &lt;sys/time.h&gt;#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;// 0 监听感兴趣的文件描述符上的事件int select(int nfds, fd_set *readfds, fd_set *writefds,fd_set *exceptfds, struct timeval *timeout);// fd_set 可以理解为一个集合，这个集合中存放的是文件描述符，可通过以下四个宏进行设置：// 1 将一个文件描述符移除集合中 void FD_CLR(int fd, fd_set *set);// 2 检查一个文件描述符是否在集合中，可以用这个来检测一次select调用之后有哪些文件描述符可以进行IO操作int FD_ISSET(int fd, fd_set *set);// 3 添加一个文件描述符到集合中void FD_SET(int fd, fd_set *set);// 4 清空给定集合void FD_ZERO(fd_set *set); select 将监听的文件描述符分为了 3 类，每一类都对应一个 fd_set 数组，本质上是一个 bitmap，也就是字节数组。分别是 writefds（写文件描述符）、readfds（读文件描述符）以及 exceptfds（异常事件文件描述符）。每一类都代表 Socket 对应的事件，每一类存储的都是 Socket 对应的文件描述符。用户进程可以根据需要，准备相关 fd_set 数组，在调用 select 函数时，这三个事件参数可以用 NULL 来表示对应的事件不需要监听。其实也不难看出，select 模型下操作系统内核并没有维护存储文件描述符相关的数据结构，只是定义了 fd_set ，将维护工作交给了用户进程。 下面我们对 select 相关的每个函数进行说明。 void FD_SET 用户进程可以调用 FD_SET 函数将指定的文件描述符 fd 设置到准备的 fd_set 数组中。 void FD_CLR 用户进程可以调用 FD_CLR 函数将指定的文件描述符 fd 从准备的 fd_set 数组移除。 void FD_ZERO 用户进程可以调用 FD_ZERO 函数将 fd_set 数组清空。该函数主要用来每次调用 select 函数之前，清空 fd_set 数组，因为每次调用 select 函数监听就绪的 Socket 时，内核会根据就绪的 Socket 情况修改用户进程传入的数组，将就绪的 Socket 对应在 fd_set 数组中元素置位，也就是说 fd_set 不可重用。 int select 用户进程可以在超时时间内，监听感兴趣的文件描述符上的事件（读/写/异常事件）发生。下面我们对相关参数和返回值进行说明。 参数： int nfds: fd_set 数组当中最大描述符加 1，用来告知内核扫描的bitmap的范围。 fd_set *readfds: 要监听的读事件就绪的 Socket 的文件描述符数组，传 NULL 表示对应的事件不需要监听。 fd_set *writefds: 要监听的写事件就绪的 Socket 的文件描述符数组，传 NULL 表示对应的事件不需要监听。 fd_set *exceptfds: 要监听的异常事件对应的 Socket 的文件描述符数组，传 NULL 表示对应的事件不需要监听。 struct timeval *timeout: 超时时间 返回值： 监听的就绪 Socket 的描述符其数目，若超时则为0，若出错则为-1 int FD_ISSET 用户进程可以调用 FD_ISSET 函数判断文件描述符是否置位了，如果置位就说明对应的 Socket 已就绪。 原理准备监听的文件描述符上的事件 应用程序可以根据具体需要，将 Socket 对应的文件描述符放入到 fd_set 数组中，在调用 select 函数时根据要监听的事件类型传入对应的 fd_set 数组。注意，Socket 不限于客户端的 Socket，服务端的 Socket 也可以，比如监听服务端 Socket 的连接事件发生。其中的用户进程通过调用 FD_SET 函数，将文件描述符写入到 fd_set 数组中，也就是将对应的位设置为 1，具体如下： 对于 select 模型，操作系统内核只是定义了文件描述符事件相关数据结构 fd_set，并没有在内核中提供维护文件描述符事件的数据结构。也就是说，应用程序需要根据系统内核提供的 fd_set 自行处理文件描述符相关数据。 等待文件描述符就绪 应用进程调用 select 函数，操作系统内核会依次遍历传入的每类 fd_set 数组，判断 fd_set 中元素对应的 Socket 有没有数据，这个过程的事件复杂度为 O(n)。如果有数据就对 fd_set 数组中的该 Socket 对应的元素进行置位，最后内核将 fd_set 拷贝回用户空间，不会阻塞当前调用进程。如果要监听的 fd_set 中的所有 Socket 都没有数据，那么进程将会阻塞在 select 函数上，直到超时或有 Socket 就绪，才会唤醒进程。 在内核遍历 fd_set 数组时，如果对应的 Socket 没有数据，那么内核会将用户进程加入到该 Socket 的等待队列中，这一点非常重要。 文件描述符就绪 当监听的任何一个 Socket 就绪时，中断程序将唤醒 Socket 等待队列中的进程，即每次唤醒都需要从每个 Socket 等待队列中移除进程。当用户进程被唤醒时，它知道至少有一个监视的 Socket 发生了感兴趣的事件。同时，内核会对该 Socket 对应在 fd_set 数组中的元素进行置位，然后将修改后的 fd_set 数组们拷贝回用户空间。 注意，select 虽然可以拿到内核修改后的 fd_set 数组，但是它并不知道是哪个 Socket 发生了哪个事件，需要用户进程自己去判断。 处理网络请求 用户进程拿到内核返回的 fd_set 数组包含整个文件描述符，程序不知道哪些 Socket 就绪，因此需要自行判断是哪个或哪些 Socket 发生了哪个事件，找到对应的 Socket 后，处理网络请求。 使用示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// 创建一个服务端 Socket 套接字，sockfd = socket(AF_INET, SOCK_STREAM, 0);memset(&amp;addr, 0, sizeof (addr));addr.sin_family = AF_INET;addr.sin_port = htons(2000);addr.sin_addr.s_addr = INADDR_ANY;bind(sockfd,(struct sockaddr*)&amp;addr ,sizeof(addr));listen (sockfd, 5);// 准备客户端连接对应的文件描述符 for (i=0;i&lt;5;i++) &#123; memset(&amp;client, 0, sizeof (client)); addrlen = sizeof(client); // 创建客户端 Socket 套接字,并保存对应的文件描述符 // 注意，文件描述符是操作系统随机分配的一个非负整数 fds[i] = accept(sockfd,(struct sockaddr*)&amp;client, &amp;addrlen); // 保存最大的文件描述符 if(fds[i] &gt; max) max = fds[i]; &#125;// select 实现多路复用while(1)&#123; // 1 调用 FD_ZERO 清理 rset 数组 FD_ZERO(&amp;rset); // 2 调用 FD_SET 设置监听的文件描述符到 rset 数组中 for (i = 0; i&lt; 5; i++ ) &#123; FD_SET(fds[i],&amp;rset); &#125; puts(\"round again\"); // 3 调用 slect 函数阻塞等待数据的到来，内核会判断 Socket 就绪情况 // max+1 告知内核扫描 fd_set 数组范围 // 这里只传入了 fd_set *readfds 参数，表示只监听读事件 select(max+1, &amp;rset, NULL, NULL, NULL); // 4 监听的 Socket 有读就绪 for(i=0;i&lt;5;i++) &#123; // 调用 FD_ISSET 判断 rset 是否有置位 if (FD_ISSET(fds[i], &amp;rset))&#123; memset(buffer,0,MAXBUF); read(fds[i], buffer, MAXBUF); puts(buffer); &#125; &#125; &#125; 特点 单个进程能够监视的文件描述符的数量存在最大限制，通常是 1024 ，当然可以更改数量，但由于 select 采用轮询的方式扫描文件描述符，文件描述符数量越多，性能越差。 每次调用 select，都需要把 fd 数组在用户空间与内核空间来回拷贝，并且内核需要遍历传递进来的所有 fd 才能知道是否有 fd 准备就绪，这个开销随着 fd 变多而增大。 select 返回的是含有整个文件描述符的数组，并非明确指出哪些文件描述符就绪了，因此应用程序需要遍历整个数组才能发现哪些文件描述符号对应的 Socket 发生了事件。 pollpoll 的实现和 select 非常相似，只是描述 fd 集合的方式不同，它们的工作原理是一样的。select 是将文件描述符分为了 3 类，使用 fd_set 结构存储，针对每一类文件描述符可关联对应的事件。poll 对所有文件描述符一视同仁，针对每个文件描述关联事件即可。具体的做法是通过定义了一个结构体 pollfd，将文件描述符和感兴趣的事件绑定在一起。这就是 poll 和 select 的主要区别，也就是说 poll 使用 pollfd 数组解决了 select 使用 bitmap 存储文件描述符数量限制问题。需要注意的是，poll 仍然没有解决 select 中的其它问题。 API 定义123456789101112131415161718#include &lt;poll.h&gt;#include &lt;signal.h&gt;#include &lt;poll.h&gt;int poll(struct pollfd *fds, nfds_t nfds, int timeout);// 文件描述符和关联的事件结构体struct pollfd &#123; // 文件描述符 int fd; /* file descriptor */ // 感兴趣的事件 short events; /* requested events to watch */ // 内核检测到的实际事件 short revents; /* returned events witnessed */ &#125;; 下面对 poll 函数的参数和返回值说明： 参数： struct pollfd *fds: 该数组用于存放用户进程监听的 Socket 文件描述符事件信息，每一个元素都是 pollfd 结构。fd 属性用于存放关注的 Socket 文件描述符；events 属性用于存方关注的事件；revents 是内核检测到 fd 对应的 Socket 实际发生的事件。 nfds_t nfds: 用于告诉内核 fds 数组的大小，内核会根据该参数去遍历 fds 数组。 int timeout: 阻塞等待的超时时间 返回值： fds 集合中就绪的描述符数量，返回 0 表示超时，返回 -1 表示出错。 使用示例123456789101112131415161718192021222324252627for (i=0;i&lt;5;i++) &#123; memset(&amp;client, 0, sizeof (client)); addrlen = sizeof(client); // 1 使用 pollfd 结构准备文件描述符 pollfds[i].fd = accept(sockfd,(struct sockaddr*)&amp;client, &amp;addrlen); // 设置感兴趣的事件 pollfds[i].events = POLLIN; &#125; sleep(1); while(1)&#123; puts(\"round again\"); // 2 调用 poll 阻塞等待数据的到来，内核会判断 Socket 就绪情况 poll(pollfds, 5, 50000); for(i=0;i&lt;5;i++) &#123; // 3 用户进程自己判断哪个 Socket 发生了 POLLIN if (pollfds[i].revents &amp; POLLIN)&#123; // 重置 revents ， pollfds[i].revents = 0; memset(buffer,0,MAXBUF); read(pollfds[i].fd, buffer, MAXBUF); puts(buffer); &#125; &#125; &#125; poll 的改进主要是围绕着存储文件描述符事件的结构体 pollfd 来展开的，用户进程准备的各种文件描述符事件都是由该结构体存储的，此外内核检测到 Socket 就绪会设置对应的 pollfd 中的 revents 属性的值。虽然 poll 提供了更优质的编程接口，但是本质和 select 模型相同。因此千级并发以下的 I/O，可以考虑 select 和 poll 模型，但是如果出现更大的并发量，就需要用 epoll 模型。可以看到，当套接字 Socket 比较多的时候，不管哪个 Socket 是活跃的，对于使用 select 或 poll 模型都需要遍历一遍,这会浪费很多CPU资源。如果能给套接字 Socket 注册某个回调函数，当他们活跃时自动完成相关操作，那就避免了轮询，这正是 epoll 做的。 epollepoll 是对 select 和 poll 的改进。它的核心思想是基于事件驱动来实现的，操作系统内核维护一颗红黑树来存储文件描述符相关信息和维护一个链表来存放准备就绪的文件描述符对应的 Socket 相关的事件信息。其实，这两个数据结构存储的元素都和 epitem 结构有关，不过为了方便描述，通常都会说存储的是文件描述符，后面我们会详细介绍 epitme 结构。 API 定义下面列举 epoll 提供的API： 1234567891011#include &lt;sys/epoll.h&gt; // 创建 epoll 实例，返回 epoll 专用文件描述符（Linux 优化后废弃了参数） int epoll_create(int size); // 用于往 epoll 实例中增删改要检测的文件描述符事件 // 根据具体操作调整调整红黑树和就绪链表 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); // 用于阻塞等待可以执行IO操作的文件描述符事件，直到超时 int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); 上面列举了Linux中提供的epoll相关API，下面我们依次介绍这些函数。 epoll_create当某一进程成功调用epoll_create函数时，Linux 内核会创建一个 epoll 实例，并返回其文件描述符。下面是 epoll 实例对应的结构体，我们只关注核心属性。 12345678910111213struct eventpoll &#123; // epoll_wait 使用的等待队列，和用户进程唤醒有关 wait_queue_head_t wq; // 就绪队列，用于存放就绪的文件描述符事件信息 struct list_head rdllist; // 红黑树的根节点，这颗树中存储着所有添加到 epoll 中的文件描述符信息 struct rb_root rbr; //.....&#125;; 一般一个进程对应一个 epoll 实例，每个 epoll 实例都有一个独立的 eventpoll 结构体。更详细的结构如下图所示： 值得注意的是，进程在调用以上函数创建 epoll 对象的同时，会初始化以上三个核心数据结构： wq: 等待队列链表。中断数据就绪的时候会通过 wq 来找到阻塞在 epoll 对象上的用户进程（调用 epoll_wait 函数的进程）。 rdllist: 就绪链表。当有文件描述符对应的 Socket 就绪时，内核会将该 Scocket 等待队列中的 epitem 的 rdllink 成员添加到该就绪链表中。 rbr: 一颗红黑树。为了支持对海量连接的高效查找、插入和删除，eventpoll 内部使用了一颗红黑树。通过这颗树来管理用户进程下添加进来的文件描述符。注意，红黑树节点并不是文件描述符，而是内核对文件描述符和事件信息封装的 epitem 的 rbn 成员。 至此，这些成员其实还只是刚被定义或初始化，都还没有用到，它们会在下面被用到。 epoll_ctl某一进程通过调用 epoll_ctl 函数向 epoll 对象中添加、删除、修改感兴趣的文件描述符事件信息，返回0标识成功，返回-1表示失败。该方法的参数很重要，下面我们详细分析各个参数的作用。 int epfd表示 epoll 实例的文件描述符，也就是 epoll_create 函数调用成功返回的值。顺便说一句，文件描述符是一个非负整数。 int op表示对文件描述符 fd 的监听事件的操作，操作类型如下： EPOLL_CTL_ADD：注册新的 fd 的监听事件 EPOLL_CTL_MOD：修改已经注册的 fd 的监听事件 EPOLL_CTL_DEL：删除 fd 的监听事件 int fd表示要监听的文件描述符，该文件描述符对应的 Socket 可能发生不同的操作，进而产生不同的事件。 struct epoll_event *event表示要监听的文件描述符 fd 对应的 Socket 发生的事件，该事件的结构定义如下： 12345678910111213141516// 用户附加数据定义typedef union epoll_data &#123; void *ptr; /*指向用户自定义数据*/ int fd; /*注册的文件描述符*/ uint32_t u32; uint64_t u64;&#125; epoll_data_t;// epoll 监听事件定义struct epoll_event &#123; // 描述 epoll 事件 uint32_t events; /* Epoll events */ // 专门给用户使用的，具体见上面的结构体 epoll_data_t data; /* User data variable */&#125;; epoll_event 包括两部分信息，一个是文件描述符的事件信息，另一个是为使用方提供的属性。这个结构非常重要，使用方向 epoll 实例注册监听事件信息时，需要在 data 域写入文件描述符相关信息，当有文件描述符对应的 Socket 准备就绪时，会间接将对应的 epoll_event 拷贝会用户空间，用户进程就可以根据 epoll_event 中的 events 事件信息和 data 中用户指定的文件描述符 fd，进而可以根据事件信息去操作文件描述符对应 Socket 。 常用的 epoll 事件描述如下： EPOLLIN：描述符处于可读状态 EPOLLOUT：描述符处于可写状态 EPOLLET：将epoll event通知模式设置成 edge triggered EPOLLONESHOT：第一次进行通知，之后不再监测 EPOLLHUP：本端描述符产生一个挂断事件，默认监测事件 EPOLLRDHUP：对端描述符产生一个挂断事件 EPOLLPRI：描述符有紧急的数据可读 EPOLLERR：描述符产生错误时触发，默认检测事件 下面我们只考虑注册新的文件描述符的监听事件。在调用 epoll_clt 函数注册文件描述符事件时，Linux 内核会做以下工作： 根据传入的参数初始化一个 epitem 对象，该对象是内核管理文件描述符的基础，后续红黑树和就绪链表中的数据都要用到它。 为传入的文件描述符对应的 Socket 新建一个等待队列项，其中的回调函数为 ep_poll_callback（该回调函数会在 Socket 准备就绪后触发），base 指针指向步骤 1 初始化的 epitem，它将来会作为添加到就绪链表的数据源。然后将该等待队列项加入到 Socket 的等待队列中。 将 epitem 的 rbn 成员插入到红黑树中。红黑树主要用来维护进程添加的文件描述符，这样就可以避免每次获取就绪 Socket 信息时都要重新拷贝一遍所有的文件描述符到内核态，并能在插入，查找和删除的操作发生高效执行。 在 epoll 中，内核会根据传入的文件描述符和事件，将相关信息封装成 epitem 对象，epitem 结构如下所示： 123456789101112131415161718192021222324struct epitem&#123; // 红黑树节点 struct rb_node rbn; // 就绪链表节点 struct list_head rdllink; // 文件描述符具体信息 struct epoll_filefd ffd; //指向其所属的 eventpoll 对象 struct eventpoll *ep; // 监听的事件信息 struct epoll_event event; &#125;struct epoll_filefd&#123; // Socket 文件地址 struct file *file; // 文件描述符 int fd;&#125; 这里简单说明下，epoll 为啥要使用红黑树呢？使用红黑树是基于 epoll 在查询效率、插入效率、删除效率以及内存开销等多方面均衡的结果。 epoll_wait某一进程通过调用 epoll_wait 函数阻塞等待就绪文件描述符，成功时返回就绪的事件数目，调用失败时返回 -1，等待超时返回 0。 参数int epfd表示 epoll 实例的文件描述符，也就是 epoll_create 函数调用成功返回的值。 struct epoll_event *events关注的文件描述符对应的 Socket 有事件触发时，内核会将对应的事件信息写入 events 数组中并拷贝回用户空间。 int maxevents通知内核 events 的大小，内核会根据该值从就绪链表中写数据到 events 数组中。 原理epoll_wait 做的事情相对比较简单，当用户进程调用它时会直接观察就绪链表中有没有数据即可。 有数据内核会将就绪链表中元素对应的事件信息写入到 events 并拷贝回用户空间就结束了。 等待文件描述符就绪没有数据，则创建一个等待队列项，将用户进程设置到等待队列项，并且设置一个 default_wake_function 回调函数（将来用来唤醒当前进程），然后添加到 eventpoll 的等待队列上，阻塞当前用户进程。需要注意的是，epoll_ctl 过程中是为文件描述符对应的 Socket 创建等待队列项，这里是为 epoll 创建等待队列项。从这个过程也可以看出，epoll 也是会阻塞当前进程的，这个是合理的，因为当前进程没有事情可做了占着 CPU 也没啥意义。 文件描述符就绪 当 Socket 就绪时，内核会找到 Socket 等待队列中设置的回调函数 ep_poll_callback 并执行该函数，该函数会根据等待队列项的 base 属性找到 epitem 对象，进而也可以找到 eventpoll 对象。接着将找到的 epitem 的 rdllink 添加到 epoll 的就绪链表中，最后会查看 eventpoll 的等待队列中是否有等待项，也就是查看是否有用户进程在等待，如果没有则执行中断的事情就做完了。如果有就查找到等待项里设置的回调函数 default_wake_function 并执行，唤醒阻塞的用户进程。 处理网络请求 当进程醒来之后，继续从 epoll_await 时暂停的代码继续执行，同时内核向用户空间拷贝就绪事件信息到 events 参数中，用户进程可以根据返回的具体信息处理网络请求。 使用示例12345678910111213141516171819202122232425262728293031323334353637struct epoll_event events[5];// 1 创建一个 epoll 实例int epfd = epoll_create(10); ... ...for (i=0;i&lt;5;i++) &#123; // 2 epoll 监听事件定义 static struct epoll_event ev; memset(&amp;client, 0, sizeof (client)); addrlen = sizeof(client); // 2.1 设置 fd ev.data.fd = accept(sockfd,(struct sockaddr*)&amp;client, &amp;addrlen); // 2.2 设置监听事件 ev.events = EPOLLIN; // 3 向 epoll 注册 文件描述符事件 epoll_ctl(epfd, EPOLL_CTL_ADD, ev.data.fd, &amp;ev); &#125;while(1)&#123; puts(\"round again\"); // 4 调用 epoll_wait 阻塞等待数据的到来，内核会判断 Socket 就绪情况，并把就绪的 Socket 相关的 epoll_event 拷贝出用户空间 // 返回的就绪 Socket 的个数 nfds = epoll_wait(epfd, events, 5, 10000); // 只需要遍历 nfds 个数即可 for(i=0;i&lt;nfds;i++) &#123; memset(buffer,0,MAXBUF); read(events[i].data.fd, buffer, MAXBUF); puts(buffer); &#125; &#125; 特点 epoll 为了减少文件描述符频繁的拷贝开销，在内核中维护了一颗红黑树用来存储文件描述符信息。并不是说 epoll 完全避免了文件描述符的拷贝，epoll 只会在新增/修改/删除的时候进行拷贝工作，避免了每次获取就绪数据信息时的重复拷贝。 epoll 使用了一个就绪链表来解决准确通知问题，也就是只会将就绪的 Socket 信息返回给用户空间，即可以直接从 events 参数中获取就绪的文件描述符的信息，无需遍历整个所有文件描述符集合。 epoll 阻塞用户进程时只会将其添加到 epoll 实例的等待队列中，而不需要将用户进程轮流加入到文件描述符对应的 Socket 的等待队列中。并且 epoll 模型为文件描述符对应的 Socket 设置一个回调函数，当 Socket 就绪时会触发该函数的调用，这就是基于事件驱动模型。基于事件驱动内核就可以避免遍历所有文件描述符的开销。 方案比较 select 和 poll 基本类似，都是使用内核定义的数据结构来进行文件描述符的存储，select 采用 bitmap ，poll 采用数组。select 会受到最大连接数的限制，而 poll 在一定程度上解决了这个问题。而 epoll 则是内核专门维护了一颗红黑树来存储文件描述符信息。前两个文件描述符信息需要用户空间维护，而后者是在内核空间维护的。 select 和 poll 都需要将有关文件描述符的数据结构在用户空间和内核空间来回拷贝，而 epoll 只会在新增/修改/删除的时候进行拷贝工作。 select 和 poll 采用轮询的方式来检查文件描述符是否处于就绪状态，而 epoll 采用回调机制。造成的结果是，随着文件描述符的增加，select 和 poll 的效率会线性降低，而 epoll 受到的影响较小，除非活跃的 Socket 较多。 select 、poll 以及 epoll 虽然都会返回就绪的文件描述符数量。但是 select 和 poll 并不会明确指出是哪些文件描述符就绪，而 epoll 可以做到。用户进程返回后，调用 select 和 poll 的程序需要遍历监听整个文件描述符，而 epoll 得益于内核就绪链表则可以直接处理。 注意，虽然 epoll 的性能最好，但是在连接数少并且连接都十分活跃的情况下，select 和 poll 的性能可能比 epoll 好，毕竟 epoll 的通知机制需要很多函数回调，这也是需要有开销的。 触发方式水平触发当内核有事件到达，会拷贝给用户空间，如果应用程序没有处理完或者压根都没有处理，那么会在下一次再次返回没有处理的事件。这样，如果应用程序永远不处理这个事件，就导致每次都会有该事件从内核空间到用户空间的拷贝，消耗性能。但是水平触发相对安全，最起码事件不会丢掉，除非用户处理完毕。 边缘触发边缘触发，相对跟水平触发相反，当内核有事件到达，只会通知应用程序一次，至于应用程序处理还是不处理，以后将不会再通知。这样减少了拷贝过程，增加了性能，但是会产生事件丢失的情况。 对于 select 和 poll 来说，其触发都是水平触发。而 epoll 既支持水平触发也支持边缘触发。 小结本篇文章对IO多路复用的实现方案进行了介绍，主要以 Linux 系统的 slect、poll 和 epoll 为主线进行说明。下面给出总结表：","categories":[{"name":"网络通信","slug":"网络通信","permalink":"https://gentryhuang.com/categories/%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1/"}],"tags":[{"name":"I/O","slug":"I-O","permalink":"https://gentryhuang.com/tags/I-O/"}]},{"title":"网络通信 - IO模型","slug":"network/I-O模型","date":"2021-06-05T07:36:47.000Z","updated":"2021-09-11T09:09:17.334Z","comments":false,"path":"posts/51fff883/","link":"","permalink":"https://gentryhuang.com/posts/51fff883/","excerpt":"","text":"基本概念I/O输入输出(input/output)的对象可以是文件(file)、网络(socket)、进程之间的管道。在Linux系统中，都用文件描述符(fd)来表示。 阻塞与非阻塞没有数据传过来时，读会阻塞直到有数据；缓冲区满了，写操作也会阻塞。非阻塞都是直接返回。阻塞和非阻塞强调的是调用者是否等待。 同步与异步数据就绪后需要应用程序自己去读是同步。数据就绪后通过回调给到应用程序是异步。同步与异步强调的是获取数据的操作是由调用者还是被调用者完成。 内核空间与用户空间在 Linux 中，应用程序的稳定性远远比不上操作系统程序，为了保证操作系统的稳定性，分出了内核空间和用户空间。内核空间运行操作系统程序和驱动程序，用户空间运行应用程序。所有的系统资源操作都在内核空间进行，比如读写磁盘文件、内存分配和回收以及网络接口调用等。不难看出，一次网络IO读取过程中，数据并不是直接从网卡读取到用户空间中的应用程序缓冲区，而是先从网卡拷贝到内核空间缓冲区，然后再从内核拷贝到用户空间中的应用程序缓冲区。对于网络IO写入过程则相反，先将数据从用户空间中的应用程序缓冲区拷贝到内核缓冲区，再从内核缓冲区把数据通过网卡发送出去。 零拷贝零拷贝是一种避免多次内存复制的技术，用来优化读写IO操作。 Linux 内核中的 mmap 函数可以将用户空间的一块地址和内核空间的一块地址同时映射到相同的一块物理内存地址，不管是用户空间还是内核空间都是虚拟地址，最终要通过地址映射映射到物理内存地址。这种方式实现用户空间和内核空间共享一个缓存数据，避免了内核空间与用户空间的数据交换。I/O 复用中的 epoll 函数中就是使用了 mmap 减少了内存拷贝。 Java 中，在用户空间中又存在一个拷贝，即从 Java 堆内存中拷贝到临时的直接内存中，通过临时的直接内存拷贝到内核空间中去。此时的直接内存和堆内存都是属于用户空间。DirectBuffer 是直接分配物理内存（非堆内存）的，它直接将过程简化为数据直接保存到非堆内存，这样就减少了一次拷贝。注意，DirectBuffer 只优化了用户空间内部的拷贝。而在 NIO 中，MappedByteBuffer 是通过本地类调用 mmap 进行文件内存映射的，可以直接将文件从网卡拷贝到用户空间，只进行一次数据拷贝，从而减少了传统的 read() 方法从网卡拷贝到内核空间这一步。 网络IO模型Linux 网络IO模型包括：同步阻塞 I/O、同步非阻塞 I/O、I/O 多路复用、信号驱动 I/O 和异步 I/O 。需要说明的是，操作系统层面的IO模型和Java中的IO模型是一一对应的，Java只是对操作系统API进行了封装。 对于一个网络IO通信过程会涉及两个对象，一个是执行IO操作的用户线程，另一个是操作系统内核。一个进程的地址空间分为用户空间和内核空间，用户线程不能直接访问内核空间。 同步阻塞IO用户线程发起read 请求后就阻塞了，此时会让出 CPU ，不能再干其它事情 。内核等待网卡数据到来，把数据从网卡拷贝到内核空间，接着把数据拷贝到用户空间，再把用户线程唤醒。这样情况下，需要为每个连接都分配一个线程，在大量连接的场景下就需要大量的线程，会造成巨大的性能损耗，这也是传统阻塞IO的最大缺陷。 同步非阻塞IO用户线程在发起 read 请求后立即返回，如果没读取到数据，用户线程会不断轮询发起 read 请求，直到数据到达（内核准备好数据）后才停止轮询，在等待数据从内核空间拷贝到用户空间这段时间里，线程还是阻塞的，等数据到了用户空间再把线程唤醒。非阻塞IO模型虽然避免了由于线程阻塞问题带来的大量线程消耗，但是频繁地重复轮询大大增加了请求次数，对CPU消耗也比较明显。 IO多路复用用户线程的读取操作分成两步了，线程先发起 select 调用，目的是问内核数据准备好了吗？等内核把数据准备好了，用户线程再发起 read 调用。在等待数据从内核空间拷贝到用户空间这段时间里，线程还是阻塞的。注意，等待 select 返回过程也是阻塞的，所以说IO多路复用并非完全非阻塞。那为什么叫 I/O 多路复用呢？因为一次 select 调用可以向内核查多个数据通道（Channel）的状态，所以叫多路复用。 信号驱动式IO用户线程发起 read 请求，会通过系统调用 sigaction 函数，给对应的套接字注册一个信号回调，此时不阻塞用户进程，进程会继续工作。当内核数据就绪时，内核就为该进程生成一个 SIGIO 信号，通过信号回调通知进程进行相关 IO 操作。 异步IO用户线程发起 read 请求的同时注册一个回调函数，read 立即返回，等内核已经读取完数据并把数据放到了应用进程的缓冲区中，再调用指定的回调函数完成处理。在这个过程中，用户线程一直没有阻塞。 介绍完常见的网络IO模型后，下面我们对 Socket(套接字) 进行说明。 套接字所谓套接字(Socket)，可以抽象成两个程序进行通讯连接中的一个端点，提供了应用层进程利用网络协议交换数据的机制。要通过互联网进行通信，至少需要一对套接字，一个运行于客户机端，另一个运行于服务器端。不同编程语言对套接字（Socket）都有对应的封装，如 Java 中的 ServerSocket/Socket，Python 中引用套接字的模式是 socket 。本质上来说，套接字是操作系统层面的产物，它既是一种编程模型，同时又是一个文件（操作系统提供支持网络通信的一种文件格式）。 Socket 编程模型套接字（Socket）通信过程如下图所示，这里以流式套接字（TCP）为例： 下面对上图的流程简单说明： 应用程序通过系统调用 socket 创建一个套接字，它是操作系统分配给应用程序的一个文件描述符（用来标识套接字（Socket）的）。 应用程序会通过系统调用 bind，绑定地址和端口，给套接字命名一个名称。 系统会调用 listen 创建一个队列用于存放客户端进来的连接。 应用服务会通过系统调用 accept 来监听客户端的连接请求。 双向管道文件套接字（Socket）是一个支持网络通信的文件，存储的是数据。服务端 Socket 文件存储的是客户端 Socket 文件描述符；客户端 Socket 文件存储的是传输数据。 当一个客户端连接到服务端的时候，操作系统就会创建一个客户端 Socket 的文件。然后操作系统将这个文件的文件描述符写入服务端程序创建的服务端 Socket 文件中。进程可以通过 accept() 方法，从服务端 Socket 文件中读出客户端的 Socket 文件描述符，从而拿到客户端的 Socket 文件。Socket 是一个双向的管道文件，当线程想要读取客户端传输来的数据时，就从客户端 Socket 文件中读取数据；当线程想要发送数据到客户端时，就向客户端 Socket 文件中写入数据。 注意： 1 服务端维护的 Socket 数量是 N+1，包括 N 个与客户端对应的 Socket 和一个监听 Socket 。2 操作系统创建的 Socket 是由文件系统管理的，内核中有一个文件列表(fd)管理这些 Socket。 IO 多路复用如何同时监视多个 Socket 呢？答案就是多路复用。 在 IO 多路复用技术中，应用进程（或线程）需要维护一个 Socket 集合（可以是数组、链表等），然后定期遍历这个集合，判断每个 Socket 文件的状态。这些 Socket 文件的状态如：服务端 Socket 文件写入客户端 Socket 文件描述符，客户端 Socket 文件的读、写等操作。这样的做法在客户端 Socket 较少的情况下没有问题，但是如果接入的客户端 Socket 较多，比如达到上万，那么每次轮询的开销都会很大。 为了解决这个问题，就需要一个观察者角色，观察者需要知道每个 Socket 文件的状态，这样就可以在 Socket 文件状态发生改变时，把相关信息推送应用进程了。这种方式就不需要应用进程主动轮询。不难发现，最合适的观察者其实就是操作系统本身，因为操作系统非常清楚每一个 Socket 文件的状态（包括服务端和客户端的 Socket），毕竟对 Socket 文件的读写都要经过操作系统。具体来说，每个 Socket 对应着一个端口号，而网络数据包中包含了 ip 和端口的信息，内核可以通过端口号找到对应的 Socket 。 总结起来就是：单线程或单进程同时监测若干个文件描述符是否可以执行IO操作的能力，IO多路复用解决的本质问题是用更少的资源完成更多的事。注意，处理IO多路复用的问题，需要操作系统提供内核级别的支持。如 Linux 下有三种提供IO多路复用的 API，分别是 select、poll 以及epoll。 小结本篇文章对网络通信相关的基本概念进行了说明，并重点对常见的 I/O 模型进行介绍，接着介绍套接字并引出 I/O 多路复用。","categories":[{"name":"网络通信","slug":"网络通信","permalink":"https://gentryhuang.com/categories/%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1/"}],"tags":[{"name":"I/O","slug":"I-O","permalink":"https://gentryhuang.com/tags/I-O/"}]},{"title":"Redis原理 - 事务","slug":"redis_theory/themory/事务","date":"2021-05-27T12:08:59.000Z","updated":"2021-06-28T06:23:41.355Z","comments":false,"path":"posts/a26fab1/","link":"","permalink":"https://gentryhuang.com/posts/a26fab1/","excerpt":"","text":"概述Redis 通过 MULTI、EXEC、DISCARD 以及 WATCH 命令来实现事务功能。与我们所熟知的事务最大的不同是，Redis 实现的事务不支持回滚特性。此外，Redis 事务的 ACID 特性也并不完整，不同的情况下表现会有不同。Redis 事务也被称为 半事务，它是简单地使用队列存放一组 Redis 命令。 事务的实现Redis 事务的执行过程包含三个阶段，如下： 开启事务 命令入队 事务执行/取消 下面我们分别对以上三个阶段进行说明，并介绍核心的实现逻辑。 开启事务Redis 客户端执行 MULTI 命令标志着事务的开启: script123127.0.0.1:6379&gt; MULTIOK127.0.0.1:6379(TX)&gt; MULTI 命令可以将执行该命令的客户端从非事务状态切换到事务状态，这一切换是将客户端的 flags 属性设置为 CLIENT_MULTI 标识来完成的。 MULTI 命令的实现逻辑如下： 12345678910111213141516/* * multi 命令对应的函数 */void multiCommand(client *c) &#123; // 1 检测客户端状态，不支持在事务中嵌套事务 if (c-&gt;flags &amp; CLIENT_MULTI) &#123; addReplyError(c, \"MULTI calls can not be nested\"); return; &#125; // 2 开启事务，即设置客户端的状态标志为 CLIENT_MULTI c-&gt;flags |= CLIENT_MULTI; addReply(c, shared.ok);&#125; 注意，Redis 开启事务主要是将当前客户端的状态标志属性 flags 设置为 CLIENT_MULTI。Redis 事务的生命周期是和该状态标志紧密相关的，除此状态外，命令入队出错需要将客户端的状态设置为 REDIS_DIRTY_EXEC，客户端监视的键被改动需要将客户端的状态设置为 REDIS_DIRTY_CAS，这两种情况将在下文进行介绍。 命令入队Redis 在没有开启事务时，即一个客户端处于非事务状态时，这个客户端发送的命令会立即被服务器执行，这个也是我们日常多使用的方式。与此不同的是，当一个客户端开启事务，即一个客户端处于事务状态之后，服务器会根据这个客户端发来的不同命令执行不同的操作： 如果客户端发送的命令为 EXEC 或 DISCARD ，那么服务器会立即执行这个命令，进行事务的提交或取消。 如果客户端发送的命令是操作数据命令，那么服务器并不会立即执行这个命令，而是将这个命令加入到事务队列中，然后向客户端返回 QUEUED 回复，标识加入事务队列完成。 将命令入队的实现逻辑如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243/* Add a new command into the MULTI commands queue * * 将一个新命令添加到事务队列中 */void queueMultiCommand(client *c) &#123; multiCmd *mc; int j; // 1 检测客户端状态，如果要入队的命令出现类似语法错误，则不允许入队 if (c-&gt;flags &amp; CLIENT_DIRTY_EXEC) return; // 2 为命令分配对应的空间，如存储命令结构的队列、封装命令的命令结构 multiCmd c-&gt;mstate.commands = zrealloc(c-&gt;mstate.commands, sizeof(multiCmd) * (c-&gt;mstate.count + 1)); // 3 指向新元素 mc = c-&gt;mstate.commands + c-&gt;mstate.count; // 3.1 设置命令、命令参数数量、以及命令的参数 mc-&gt;cmd = c-&gt;cmd; mc-&gt;argc = c-&gt;argc; mc-&gt;argv = zmalloc(sizeof(robj *) * c-&gt;argc); memcpy(mc-&gt;argv, c-&gt;argv, sizeof(robj *) * c-&gt;argc); for (j = 0; j &lt; c-&gt;argc; j++) incrRefCount(mc-&gt;argv[j]); // 4 事务队列长度增一 c-&gt;mstate.count++; c-&gt;mstate.cmd_flags |= c-&gt;cmd-&gt;flags; c-&gt;mstate.cmd_inv_flags |= ~c-&gt;cmd-&gt;flags;&#125;/* * 每次在入队的命令出现类似语法错误时调用，将客户端的状态设置为 DIRTY_EXEC，让之后的 EXEC 命令失败 */void flagTransaction(client *c) &#123; // 如果当前客户端的状态处于事务状态 if (c-&gt;flags &amp; CLIENT_MULTI) // 将客户端的状态设置为 CLIENT_DIRTY_EXEC，表示该客户端的事务安全性已经被破坏 c-&gt;flags |= CLIENT_DIRTY_EXEC;&#125; 注意，以上函数只是命令入队逻辑，在该方法上层会对当前客户端的状态标志进行判断，并结合当前命令选择对应处理方式，因为涉及的内容相对较多且不是本文的重点，暂不展开说明。 事务队列前文介绍了 Redis 事务中的命令入队逻辑，但是并没有详细说明事务队列的结构以及命令封装结构，本小节就来对 Redis 事务中涉及的相关数据结构进行介绍。 每个 Redis 客户端都有自己的状态，其它状态我们暂不介绍，这里我们围绕着事务相关状态进行说明。下面只列举客户端结构体中涉及事务相关的属性： 1234567891011121314151617181920212223typedef struct client &#123; // 当前正在使用的数据库 redisDb *db; /* Pointer to currently SELECTed DB. */ // 参数数量 int argc; /* Num of arguments of current command. */ // 参数对象数组 robj **argv; /* Arguments of current command. */ // 记录被客户端执行的命令 struct redisCommand *cmd, *lastcmd; /* Last command executed. */ // 客户端的状态标志 uint64_t flags; /* Client flags: CLIENT_* macros. */ // 事务状态（本质上是事务队列的封装） multiState mstate; /* MULTI/EXEC state */ // 被监视的键，用于存放当前客户端使用 WATCH 命令监视键的链表 list *watched_keys; /* Keys WATCHED for MULTI/EXEC CAS */&#125; client; 客户端的状态标志是通过 flags 属性记录的。如果客户端开启事务，那么客户端的 mstate 属性封装了事务队列信息，用来管理事务中的命令；客户端的 watched_keys 链表结构用来管理客户端使用 WATCH 命令监视的键信息。下文我们会分别详细介绍这些关键属性。 客户端的 mstate 属性主要包含一个事务队列和一个记录事务队列长度的属性，具体结构如下： 1234567891011121314151617/* * 主要包含一个事务队列，以及一个已入队命令的计数器 */typedef struct multiState &#123; // 事务队列，是一个 multiCmd 类型的数组 multiCmd *commands; /* Array of MULTI commands */ // 已入队命令计数（事务队列的长度） int count; /* Total number of MULTI commands */ int cmd_flags; /* The accumulated command flags OR-ed together. So if at least a command has a given flag, it will be set in this field. */ int cmd_inv_flags; /* Same as cmd_flags, OR-ing the ~flags. so that it is possible to know if all the commands have a certain flag. */&#125; multiState; 从 multiState 结构中可以看出，事务队列本质上是一个 multiCmd 类型的数组。multiCmd 结构用于封装了一个已入队命令的信息，具体结构如下： 12345678910111213/* * 保存了一个已入队命令的相关信息 */typedef struct multiCmd &#123; // 参数数组 robj **argv; // 参数数量 int argc; // 命令指针，指向具体的命令（命令结构中封装了对应的命令函数） struct redisCommand *cmd;&#125; multiCmd; 事务队列以先进先出（FIFO）的方式保存入队的命令信息，较先入队的命令会被放到数组的前面，而较后入队的命令则会放到数组的后面。下面结合示例，对事务队列结构进行说明。 事务中的命令入队过程： script1234567891011127.0.0.1:6379&gt; MULTIOK127.0.0.1:6379(TX)&gt; SET name \"Practical Common Lisp\"QUEUED127.0.0.1:6379(TX)&gt; GET \"name\"QUEUED127.0.0.1:6379(TX)&gt; SET author \"Peter Seibel\"QUEUED127.0.0.1:6379(TX)&gt; GET authorQUEUED127.0.0.1:6379(TX)&gt; 事务队列结构如下图所示： 上图很直观地展示了客户端中的 multiState 属性的平铺结构。 了解了 Redis 事务的开启以及事务相关的数据结构后，下面我们看看 Redis 提交事务的逻辑。 执行事务当一个处于事务状态的客户端向服务器发送 EXEC 命令时，该命令将立即被服务器执行。服务器会遍历这个客户端的事务队列，依次执行队列中保存的命令，最后将执行命令得到的结果全部返回给客户端。 script123456127.0.0.1:6379(TX)&gt; EXEC1) OK2) \"Practical Common Lisp\"3) OK4) \"Peter Seibel\"127.0.0.1:6379&gt; 执行事务逻辑如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119/* * exec 命令对应的函数 */void execCommand(client *c) &#123; int j; robj **orig_argv; int orig_argc; struct redisCommand *orig_cmd; int was_master = server.masterhost == NULL; // 1 检测当前客户端状态，非事务状态直接结束 if (!(c-&gt;flags &amp; CLIENT_MULTI)) &#123; addReplyError(c, \"EXEC without MULTI\"); return; &#125; /* * 2 检查是否需要阻止事务执行，因为： * * 1) Some WATCHed key was touched. * 存在被客户端监视的键被修改 * * 2) There was a previous error while queueing commands. * 命令在入队时发生错误 * * A failed EXEC in the first case returns a multi bulk nil object * (technically it is not an error but a special behavior), while * in the second an EXECABORT error is returned. */ if (c-&gt;flags &amp; (CLIENT_DIRTY_CAS | CLIENT_DIRTY_EXEC)) &#123; addReply(c, c-&gt;flags &amp; CLIENT_DIRTY_EXEC ? shared.execaborterr : shared.nullarray[c-&gt;resp]); // 执行 discard 逻辑，即取消事务 discardTransaction(c); return; &#125; // 保存当前客户端的状态标记 uint64_t old_flags = c-&gt;flags; /* we do not want to allow blocking commands inside multi */ // 我们不希望在multi中允许阻塞命令 c-&gt;flags |= CLIENT_DENY_BLOCKING; // 3 已经可以保证安全性了，取消客户端对所有键的监视 // 将当前客户端的 watched_keys 链表回收 // 从当前客户端操作的数据库的 watched_keys 字典中移除当前客户端 unwatchAllKeys(c); /* Unwatch ASAP otherwise we'll waste CPU cycles */ server.in_exec = 1; // 4 因为事务中的命令在执行时可能会修改命令和命令的参数，所以为了正确地传播命令，需要现备份这些命令和参数 orig_argv = c-&gt;argv; orig_argc = c-&gt;argc; orig_cmd = c-&gt;cmd; addReplyArrayLen(c, c-&gt;mstate.count); // 5 执行事务队列中的命令 for (j = 0; j &lt; c-&gt;mstate.count; j++) &#123; // 5.1 因为 Redis 的命令必须在客户端的上下文中执行，所以需要将事务队列中的命令、命令参数等设置到客户端 c-&gt;argc = c-&gt;mstate.commands[j].argc; c-&gt;argv = c-&gt;mstate.commands[j].argv; c-&gt;cmd = c-&gt;mstate.commands[j].cmd; /* 省略 ACL权限检查逻辑 */ // 5.2 执行命令 call(c, server.loading ? CMD_CALL_NONE : CMD_CALL_FULL); serverAssert((c-&gt;flags &amp; CLIENT_BLOCKED) == 0); /* Commands may alter argc/argv, restore mstate. */ /* * 因为命令执行后命令、命令参数可能会被改变，比如 SPOP 会被改写为 SREM * 所以这里需要更新事务队列中的命令和参数，确保附属节点和 AOF 的数据一致性 */ c-&gt;mstate.commands[j].argc = c-&gt;argc; c-&gt;mstate.commands[j].argv = c-&gt;argv; c-&gt;mstate.commands[j].cmd = c-&gt;cmd; &#125; // restore old DENY_BLOCKING value if (!(old_flags &amp; CLIENT_DENY_BLOCKING)) c-&gt;flags &amp;= ~CLIENT_DENY_BLOCKING; // 还原命令 c-&gt;argv = orig_argv; c-&gt;argc = orig_argc; c-&gt;cmd = orig_cmd; // 6 清理事务状态 // 释放事务队列相关的资源 &amp; 重置客户端的状态 discardTransaction(c); /* Make sure the EXEC command will be propagated as well if MULTI * was already propagated. * * 如果已经传播了 MULTI，也要确保传播 EXEC 命令 */ if (server.propagate_in_transaction) &#123; int is_master = server.masterhost == NULL; server.dirty++; /* If inside the MULTI/EXEC block this instance was suddenly * switched from master to slave (using the SLAVEOF command), the * initial MULTI was propagated into the replication backlog, but the * rest was not. We need to make sure to at least terminate the * backlog with the final EXEC. */ if (server.repl_backlog &amp;&amp; was_master &amp;&amp; !is_master) &#123; char *execcmd = \"*1\\r\\n$4\\r\\nEXEC\\r\\n\"; feedReplicationBacklog(execcmd, strlen(execcmd)); &#125; afterPropagateExec(); &#125; server.in_exec = 0;&#125; 事务执行逻辑比较复杂，下面进行概要总结： 在事务执行时会判断客户端的状态，如果没有开启事务直接返回。 对阻止事务执行的情况进行检查，检测到任何一种非法的情况，需要取消事务。 取消客户端对所有键的监视 依次执行事务队列中的任务 清理事务列表并重置客户端状态 传播 EXEC 命令 事务执行时涉及的监视机制会在下文进行介绍，这里暂不展开。 取消事务当一个处于事务状态的客户端向服务器发送 DISCARD 命令时，该命令将立即被服务器执行。服务器会释放事务状态资源并重置客户端的状态。 1234567891011121314151617181920212223242526272829303132/* * discard 命令对应的函数 */void discardCommand(client *c) &#123; // 检测当前客户端状态，非事务状态直接结束 if (!(c-&gt;flags &amp; CLIENT_MULTI)) &#123; addReplyError(c, \"DISCARD without MULTI\"); return; &#125; // discard 逻辑 discardTransaction(c); addReply(c, shared.ok);&#125;/* * discard 操作 */void discardTransaction(client *c) &#123; // 重置事务状态 // 释放所有事务状态相关的资源 freeClientMultiState(c); // 初始化客户端的事务状态 initClientMultiState(c); // 重置客户端状态标志 c-&gt;flags &amp;= ~(CLIENT_MULTI | CLIENT_DIRTY_CAS | CLIENT_DIRTY_EXEC); // 取消对所有键的监视 unwatchAllKeys(c);&#125; WATCH 机制WATCH 命令可以在 EXEC 命令执行之前，监视任意数量的数据库键，并在 EXEC 命令执行时检查是否存在被监视的键被修改的情况，如果存在服务器会拒绝执行事务。前文介绍事务执行和取消时，都有 WATCH 机制逻辑，它是 Redis 事务实现的一部分，本小节我们就来详细说明该机制。 监视键信息客户端监视键的时候，被监视的键信息会分别保存在客户端的监视键链表中和当前数据库的监视键字典中，下面我们分别介绍。 客户端的监视键链表 每个客户端创建的时候都会初始化一个用于存放监视键的链表。前文在介绍客户端的结构有列举对应的属性，这里直接拿过来。 123456typedef struct client &#123; // 用于存放被监视的键的链表 list *watched_keys; /* Keys WATCHED for MULTI/EXEC CAS */&#125; client; 客户端结构中的这个链表的节点的结构如下： 1234567891011/* * 在监视一个键时： * 我们既需要保存被监视的键，还需要保存该键所在的数据库 */typedef struct watchedKey &#123; // 被监视的键对象 robj *key; // 键所在的数据库 redisDb *db;&#125; watchedKey; watched_keys 链表数据举例如下： 123456789101112131415161718# before: [ &#123; 'key': 'key1', # 被监视的键 'db': 0 # 客户端操作的数据库 &#125; ]# after client watch key-2 in db 0: [ &#123; 'key': 'key1', 'db': 0 &#125;, &#123; 'key': 'key2', 'db': 0 &#125; ] 数据库的监视键字典 每个 Redis 数据库都有一个 watched_keys 字典，这个字典的键就是被 WATCH 命令监视的键，而字典的值则是一个链表，该链表中记录了监视当前键的客户端。 1234typedef struct redisDb &#123; // 正在被 WATCH 命令监视的键 dict *watched_keys; /* WATCHED keys for MULTI/EXEC CAS */&#125; redisDb; watched_keys 字典数据举例如下： 123456789 # before : &#123; 'key1' : [c1, c2] &#125; # after c3 WATCH key1 and key2:&#123; 'key1' : [c1, c2, c3], 'key2' : [c3] &#125; 监视键监视键命令操作如下： script123127.0.0.1:6379&gt; WATCH nameOK127.0.0.1:6379&gt; 客户端监视给定键的逻辑如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243/* Watch for the specified key * * 客户端监视给定的键 */void watchForKey(client *c, robj *key) &#123; list *clients = NULL; listIter li; listNode *ln; watchedKey *wk; /* Check if we are already watching for this key */ // 1 检查 key 是否已经保存在 watched_keys 链表中，如果已经存在，则直接返回 listRewind(c-&gt;watched_keys, &amp;li); while ((ln = listNext(&amp;li))) &#123; wk = listNodeValue(ln); if (wk-&gt;db == c-&gt;db &amp;&amp; equalStringObjects(key, wk-&gt;key)) return; /* Key already watched */ &#125; /* This key is not already watched in this DB. Let's add it */ // 2 检查 key 是否存在于数据库的 watched_keys 字典中 clients = dictFetchValue(c-&gt;db-&gt;watched_keys, key); // 2.1 如果不存在则，添加它 if (!clients) &#123; // 值是一个链表 clients = listCreate(); // 关联键值对到字典 dictAdd(c-&gt;db-&gt;watched_keys, key, clients); incrRefCount(key); &#125; // 将客户端添加到链表的末尾 listAddNodeTail(clients, c); /* Add the new key to the list of keys watched by this client */ // 3 构建 watchedKey 结构并添加到客户端的 watched_key 链表的末尾 wk = zmalloc(sizeof(*wk)); wk-&gt;key = key; wk-&gt;db = c-&gt;db; incrRefCount(key); listAddNodeTail(c-&gt;watched_keys, wk);&#125; 以上方法是监视给定的键，本质上就是将指定的键关联上当前客户端，然后分别添加到客户端的监视键链表中和数据库监视字典中。关于取消监视的键逻辑就不再介绍。 监视机制的触发所有对数据库进行写操作的命令，在执行后都会尝试触发监视机制，试图将正在监视当前键的客户端的状态设置为 CLIENT_DIRTY_CAS，表示该客户端的事务安全性已经被破坏了(客户端开启事务的前提下，没开启则没影响)。监视机制的触发逻辑如下： 123456789101112131415161718192021222324252627282930/* \"Touch\" a key, so that if this key is being WATCHed by some client the * next EXEC will fail. * * \"触碰\" key，如果该 key 正在被某个/某些客户端监视着，那么这个/这些客户端在执行 EXEC 时，事件将失败 */void touchWatchedKey(redisDb *db, robj *key) &#123; list *clients; listIter li; listNode *ln; // 1 当前数据库的 watched_leys 字典为空，没有任何键被监视 if (dictSize(db-&gt;watched_keys) == 0) return; // 2 从监视键字典中获取所有监视这个键的客户端 clients = dictFetchValue(db-&gt;watched_keys, key); if (!clients) return; /* Mark all the clients watching this key as CLIENT_DIRTY_CAS */ /* Check if we are already watching for this key * * 3 遍历所有客户端，打开它们的 CLIENT_DIRTY_CAS */ listRewind(clients, &amp;li); while ((ln = listNext(&amp;li))) &#123; client *c = listNodeValue(ln); // 将客户端的状态设置为 CLIENT_DIRTY_CAS，表示该客户端的事务安全性已经被破坏 c-&gt;flags |= CLIENT_DIRTY_CAS; &#125;&#125; 当服务器执行客户端的 EXEC 命令时，服务器会校验客户端的状态来决定是否执行事务。如果客户端的状态是 CLIENT_DIRTY_EXEC 或者 CLIENT_DIRTY_CAS 时，服务器会拒绝执行客户端提交的事务。 至此，Redis 的事务原理已经全部介绍完毕了。下面我们从事务的 ACID 特性角度对 Redis 的事务进行说明。 事务的 ACID 性质原子性对于 Redis 的事务功能来说，事务队列中的命令要么全部执行，要么一个都不执行。Redis 事务的原子性需要分以下三种情况来考虑。 命令入队时出错 在执行 EXEC 命令前，客户端发送的操作命令本身就有错误，比如语法错误或者使用了不存的命令，在命令入队过程就被 Redis 实例检测出来了，进而导致事务失败。 命令操作如下： script12345678910111213# 开启事务127.0.0.1:6379&gt; MULTIOK# 执行一个 Redis 不支持的命令，返回报错信息127.0.0.1:6379(TX)&gt; SETT num 1(error) ERR unknown command `SETT`, with args beginning with: `num`, `1`, (51.33s)# 继续执行命令127.0.0.1:6379(TX)&gt; SET num 1QUEUED# 提交事务，但由于存在命令入队失败的情况，因此 Redis 拒绝执行事务127.0.0.1:6379(TX)&gt; EXEC(error) EXECABORT Transaction discarded because of previous errors. 对于这种情况，Redis 实例检测出错误后会记录错误信息并调用 flagTransaction 函数将客户端的状态设置为 CLIENT_DIRTY_EXEC，然后执行入队逻辑时，命令入队就会失败。此时，虽然还能继续提交命令操作，但是等到执行 EXEC 命令时，Redis 服务器就会拒绝执行提交的事务，返回事务失败的结果，因为此时客户端的状态为 CLIENT_DIRTY_EXEC。关于命令入队和事务执行逻辑，上文已经详细说明。 结论：命令入队时出现错误，会放弃事务的执行，能够保证原子性。 命令执行时出错 客户端发送的操作命令和操作的数据类型不匹配，在命令入队过程 Redis 实例无法检测出错误。但是在执行 EXEC 命令时，当 Redis 从事务队列中取出异常操作命令并执行时就会报错。需要注意的是，虽然 Redis 会对异常操作命令报错，但还是会继续将事务队列中的命令执行完。在这种情况下，事务的原子性就无法得到保证了，根本原因在于 Redis 并没有提供回滚机制。 命令操作如下： script1234567891011121314# 开始事务127.0.0.1:6379&gt; MULTIOK# 执行 SADD 命令127.0.0.1:6379(TX)&gt; SADD st gentryhuangQUEUED# 执行 GET 命令，GET 命令操作的数据类型不匹配，此时不会影响入队127.0.0.1:6379(TX)&gt; GET stQUEUED# 提交事务，事务中的第二个命令会报错127.0.0.1:6379(TX)&gt; EXEC1) (integer) 12) (error) WRONGTYPE Operation against a key holding the wrong kind of value127.0.0.1:6379&gt; 结论：命令入队时没有出错，实际执行时报错，不能保证原子性。 实例故障 在执行 EXEC 命令时，Redis 实例发生了故障，导致事务执行失败。由于 Redis 的持久化机制，实例重启后会加载 AOF 日志文件或 RDB 快照，如果只有部分的事务操作被记录，那么就无法保证原子性。但是事实是，RDB 快照不会在事务执行时执行，所以事务命令操作的结果不会被保存到 RDB 快照中。即使开启了 AOF 日志，我们可以使用 redis-check-aof 工具检查 AOF 日志文件，这个工具可以把未完成的事务操作从 AOF 文件中去除。这样一来，不管 AOF 日志文件中是否保存完整的事务操作，还是根本就没有保存事务操作，AOF 文件不再是导致原子性问题的因素。 结论：实例故障可以保证原子性。 一致性事务的一致性指的是数据符合数据库本身的定义和要求，事务执行过程不会产生非法或者无效的错误数据。Redis 通过语法错误检查机制和简单的设计来保证事务的一致性。Redis 事务的一致性依然需要分以下三种情况来考虑。 命令入队时出错 命令入队时出错，事务本身就会被放弃，所以可以保证事务的一致性。 命令执行时出错 在事务执行的过程中，出错的命令会被服务器识别出来，并进行相应的错误处理，这些出错的命令不会对数据库做任何改动。也就不会对事务的一致性产生任何影响。如果硬从无效的错误数据角度来看，这种情况是破坏了事务的一致性，毕竟出错的命令虽然没有执行，但没有达到预期的目的。 实例故障 Redis 实例发生了故障，无论 Redis 使用哪种持久化模式，都不会影响数据库的一致性。这种情况和前文介绍的实例故障是否影响原子性的因素是一致的。 隔离性事务的隔离性指的是，即使数据库中有多个事务并发地执行，各个事务之间也不会互相影响，并且在并发状态下执行的事务和串行执行的事务产生的结果完全相同。 由于 Redis 使用单线程的方式来执行事务，并且在执行事务期间不会对事务进行中断，也就是说 Redis 的事务总是以串行的方式运行的，事务具有隔离性。 需要特别说明的是，一个客户端在开启事务之前可以利用 WATCH 机制来监视要操作的键，通过这种方式可以自定义隔离规则，规定如果在事务执行时发现要操作的键发生了改变(也就是被其它客户端修改了)，那么就认为破坏了事务的隔离性，就需要放弃事务的执行。 持久性事务的持久性指的是，当一个事务执行完毕时，执行这个事务的结果会永久性存储起来，即使服务器在事务执行完毕后宕机了，执行事务所得到的结果也不会丢失。 Redis 并没有为事务提供任何额外的持久化功能，Redis 事务的持久性由 Redis 的持久化配置模式决定。由事务的持久性特点不难看出，Redis 要实现事务的持久性必须满足以下条件： 使用 AOF 模式，并且刷盘机制 appendfsync 必须设置为 always，这样数据才能尽量不丢失。 Redis 为了提高性能尽可能不阻塞主线程，允许打开 no-appendfsync-on-rewrite 配置项（默认是关闭的），控制在执行快照或重写 AOF 日志文件时停止对 AOF 文件进行刷盘。那么这种情况下即使 Redis 实例运行在 always 模式的 AOF 持久化之下，事务也不具有持久性。因此，要保证事务的持久性就不能打开 no-appendfsync-on-rewrite 配置项. 注意，Redis 本身是内存数据库，持久性并不是一个必须的属性，具体可以根据使用场景进行取舍。 回滚实现Redis 的事务和传统的关系型数据库事务最大的区别在于，Redis 不支持事务回滚机制，即使事务队列中的某个命令在执行时出错，整个事务也会继续执行下去，直到将事务队列中的所有命令都执行完毕为止。需要说明的是 Redis 提供的 DISCARD 命令，并没有回滚事务的能力，它只是用来放弃事务，把事务队列清空并重置客户端的事务状态。只要开启一个事务，就能通过 DISCARD 命令放弃事务。DISCARD 命令具体使用如下： script123456789# 开启事务127.0.0.1:6379&gt; MULTIOK127.0.0.1:6379(TX)&gt; SADD num (error) ERR wrong number of arguments for 'sadd' command(5.99s)# 放弃事务127.0.0.1:6379(TX)&gt; discardOK Redis 不支持事务回滚的原因有两点：其一，较为复杂的事务回滚功能和 Redis 追求简单高效的设计主旨不相符；其二，Redis 事务执行时的错误通常都是编程错误产生的，需要使用方去避免。 小结本篇文章对 Redis 的事务进行了详细介绍，并结合源码层面对整个事务的执行流程进行了梳理。可以对比 MySQL 的事务机制，对比学习 Redis 的事务机制，两者使用的场景不同，对应的实现机制也有很大差别。","categories":[{"name":"Redis","slug":"Redis","permalink":"https://gentryhuang.com/categories/Redis/"}],"tags":[]},{"title":"MySQL - 事务与隔离级别","slug":"sql/事务隔离级别与锁","date":"2021-05-21T10:49:59.000Z","updated":"2021-07-01T02:32:51.502Z","comments":false,"path":"posts/d80e61c2/","link":"","permalink":"https://gentryhuang.com/posts/d80e61c2/","excerpt":"","text":"前言本篇文章将以事务为主线，分别介绍事务的基本特性、事务并发问题、封锁协议、隔离级别及基本实现，最后简单介绍下 MySQL 对标准的隔离级别规范的实现。 事务基本特性 原子性(Atomicity) 要么全部完成，要么全部不完成。 一致性(Consistency) 一个事务单元需要提交之后才会被其它事务可见。 隔离性(Isolation) 并发事务之间不会相互影响。 持久性(Durability) 事务提交后即持久化到存储设备上。 注意，隔离性和一致性是有冲突的，有时候为了提高性能，会适度的破坏一致性，而这个权衡的结果会造成事务并发问题。 事务并发问题 丢失修改 回滚覆盖：回滚一个事务时，在该事务内的写操作要回滚，把其它已提交的事务写入的数据覆盖了。提交覆盖：提交一个事务时，把其它已提交的事务写入的数据覆盖了。上图描述的是回滚覆盖问题。 脏读 一个事务读取到另一个未提交事务修改过的数据。 不可重复读 一个事务中先后根据相同条件读取到的数据不一致。强调更新和删除操作。 幻读 一个事务中先后根据相同条件读取的数据记录数不一致。强调新增操作。 封锁协议封锁类型为了解决并发问题，数据库系统引入了锁锁机制。在事务T对某个数据对象操作之前，先向系统发出请求对其加锁。基本的封锁类型有两种，排它锁(Exclusive locks 简记为X锁) 和 共享锁(Share locks 简记为S锁)，其中前者又称写锁，后者又称读锁。 排它锁（X锁）：若事务T对数据对象A加上X锁，其它任何事务都不能在对A加任何类型的锁，直到事务T释放A上的锁为止。这就保证了其他事务在T释放A上的锁之前不能再读取和修改A。 共享锁（S锁）：若事务T对数据对象A加上S锁，其它事务只能再对A加S锁而不能加X锁，直到事务T释放A上的S锁为止。 封锁协议在运用X锁和S锁对数据对象加锁时，还需要约定一些规则，例如何时申请X锁或S锁、持锁时间、何时释放等，称这些加锁规则为封锁协议（Locking Protocol）。对封锁方式规定不同的规则，就形成了各种不同的封锁协议。 一级封锁协议 定义：事务T在修改数据R之前必须先对其加X锁，直到事务结束才释放。事务结束包括正常结束（COMMIT）和非正常结束（ROLLBACK）。说明：一级封锁协议可以防止丢失修改，并保证事务T是可恢复的。使用一级封锁协议可以解决丢失修改问题。在一级封锁协议中，如果仅仅是读数据不对其进行修改，是不需要加锁的，它不能保证可重复读和不读“脏”数据。 二级封锁协议 定义：一级封锁协议基础上加事务T在读取数据R之前必须先对其加S锁，读完后方可释放S锁。说明：二级封锁协议除防止了丢失修改，还可以进一步防止读“脏”数据。但在二级封锁协议中，由于读完数据后即可释放S锁，所以它不能保证可重复读。 三级封锁协议 定义：一级封锁协议基础上加事务T在读取数据R之前必须先对其加S锁，直到事务结束才释放。说明：三级封锁协议除防止了丢失修改和不读“脏”数据外，还进一步防止了不可重复读。 上述三级协议的主要区别在于什么操作需要申请封锁，以及何时释放。 事务隔离级别为了解决事务并发问题，进行并发控制，数据库系统提供了四种事务隔离级别。本质上三级封锁协议反映在实际的数据库系统上，就是四种事务隔离机制。总的来说，四种事务隔离机制就是在逐渐的限制事务的自由度，以满足对不同并发控制程度的要求。 隔离级别 读未提交(Read Uncommitted) 可以读取未提交的记录，会出现脏读，幻读，不可重复读，所有并发问题都可能遇到。 读已提交(Read Committed) 只能读取到已经提交的数据。不会出现脏读现象，但是会出现幻读，不可重复读；（大多数数据库的默认隔离级别都是 RC，但是 MySQL InnoDb 默认是 RR）。 可重复读(Repeated Read) 在同一个事务内的查询都是事务开始时刻一致的，MySQL InnoDb 默认的隔离级别，解决了不可重复读问题，但是仍然存在幻读问题。 串行化(Serializable) 所有的增删改查串行执行，啥并发问题都没有。 需要明确的是，以上的隔离级别是在SQL规范层面的定义，不同数据库的实现方式和使用方式并不相同，类似于JVM规范和JVM厂商的关系。 传统的隔离级别实现SQL 规范中定义的四种隔离级别，分别是为了解决事务并发时可能遇到的四种问题，至于如何解决，实现方式是什么，规则中并没有严格定义。锁作为最简单最显而易见的实现方式被广为人知，因此我们在讨论某个隔离级别的时候，通常会说这个隔离级别的加锁方式是什么样的。其实，锁只是实现隔离级别的方式之一，除了锁，实现并发问题的方式还有时间戳，多版本控制等等，这些也可以称为无锁的并发控制。 采用基于锁的并发控制实现，通过对读写操作加不同的锁，以及对释放锁的时机进行不同的控制，就可以实现四种隔离级别。 MySQL事务隔离级别虽然数据库的四种隔离级别通过基于锁的并发控制（Lock-Based Concurrent Control，简写 LBCC） 技术都可以实现，但是它最大的问题是只实现了并发的读读，对于并发的读写还是冲突的，写时不能读，读时不能写，当读写操作都很频繁时，数据库的并发性将大大降低。针对这种场景，MVCC 技术应运而生，全称叫做 Multi-Version Concurrent Control（多版本并发控制），为了兼容落后的规范，数据库引擎厂商都想办法贴近四大隔离级别，但是和标准可能会有差别。 InnoDB 对事务隔离级别的实现依赖两个重要手段：LBCC、MVCC(多版本并发控制)。MVCC 可以认为是对锁机制的优化，让普通 SELECT 避免加锁，同时保证事务隔离级别的语义。 InnoDB 默认的事务隔离级别是 RR 隔离级别，它采用通过 MVCC 和 间隙锁 解决了标准的 RR 级别下存在的幻读问题。因为 幻读 的这个读字在 MySQL 里本身就存在歧义，这个读指的是快照读还是当前读呢？如果是快照读，MySQL 通过版本链来保证同一个事务里每次查询得到的结果集都是一致的；如果是当前读，MySQL 通过间隙锁保证其他事务无法插入新的数据，从而避免幻读问题。当然，如果场景中一会是快照读，一会是当前读，导致幻读现象，那就太为难 MySQL 了。 InnoDB 对串行化隔离级别是通过 临键锁 实现的，普通 SELECT 语句使用 S临键锁，当前读语句使用 X临键锁，加锁规则和 RR 隔离级别一致。 小结本篇文章主要对事务隔离级别的规范以及传统实现原理进行了介绍，并对 MySQL 的事务隔离级别的实现进行了简单说明。有了对事务整体的深入了解，对于理解 MySQL 中的锁机制、MVCC 原理会有很大的帮助。如果不知道事务隔离级别的基本实现，或者不清楚事务隔离级别和锁的关系，那么对于 MySQL 只能是管中窥豹。关于锁机制、MVCC原理会在后面的文章详细说明。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://gentryhuang.com/categories/MySQL/"}],"tags":[]},{"title":"MySQL - 慢查询日志","slug":"sql/MySQL慢查询","date":"2021-05-14T11:17:14.000Z","updated":"2021-05-25T03:06:04.878Z","comments":false,"path":"posts/4132ef9f/","link":"","permalink":"https://gentryhuang.com/posts/4132ef9f/","excerpt":"","text":"概述MySQL 慢查询日志是排查问题 SQL 语句，以及检查当前 MySQL 性能的一个重要手段。默认情况下，MySQL 并不启动慢查询日志，需要我们手动来开启。如果不是调优需要的话，一般不建议开启慢查询，毕竟开启慢查询或多或少会带来一定的性能影响。 关键参数 slow_query_log: 是否开启慢查询日志，默认 OFF，开启则设置为 ON。 slow_query_log_file: 慢查询日志文件存储位置。 long_query_time: 超过多少秒的查询才会记录到日志中。单位是秒。 log_queries_not_using_indexes: 是否把没有使用到索引的 SQL 记录到日志中，默认 OFF,开启则设置为 ON。 配置默认情况下是没有开启慢查询日志，下面通过两种配置方式进行设置。 临时配置12345678mysql&gt; set global slow_query_log='ON';Query OK, 0 rows affected (0.00 sec) mysql&gt; set global slow_query_log_file='/var/lib/mysql/instance-1-slow.log';Query OK, 0 rows affected (0.00 sec) mysql&gt; set global long_query_time=2; # 下次会话才会生效Query OK, 0 rows affected (0.00 sec) 永久配置12345&#x2F;etc&#x2F;mysql&#x2F;conf.d&#x2F;mysql.cnf[mysqld]slow_query_log &#x3D; ONslow_query_log_file &#x3D; &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;instance-1-slow.loglong_query_time &#x3D; 2 配置好慢 SQL 相关参数后，重启 MySQL 即可。 查看慢查询功能12345678mysql&gt; show variables like 'slow_query%';+---------------------+----------------------------------+| Variable_name | Value |+---------------------+----------------------------------+| slow_query_log | ON || slow_query_log_file | /var/lib/mysql/mysql001-slow.log |+---------------------+----------------------------------+2 rows in set (0.05 sec) 1234567mysql&gt; show variables like 'long_query_time';+-----------------+----------+| Variable_name | Value |+-----------------+----------+| long_query_time | 1.000000 |+-----------------+----------+1 row in set (0.02 sec) 1234567mysql&gt; show variables like 'log_queries_not_using_indexes';+-------------------------------+-------+| Variable_name | Value |+-------------------------------+-------+| log_queries_not_using_indexes | OFF |+-------------------------------+-------+1 row in set (0.01 sec) mysqldumpslowmysqldumpslow 是 MySQL 官方提供的慢查询日志分析工具，使用 mysqldumpslow 命令可以非常明确的得到各种我们需要的查询语句。 小结慢查询日志是排查SQL问题以及优化的重要手段，在生产环境中一般都会实时采集慢查询日志，对 MySQL 查询语句监控、分析。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://gentryhuang.com/categories/MySQL/"}],"tags":[{"name":"慢查询日志","slug":"慢查询日志","permalink":"https://gentryhuang.com/tags/%E6%85%A2%E6%9F%A5%E8%AF%A2%E6%97%A5%E5%BF%97/"}]},{"title":"缓存一致性问题","slug":"architecture/缓存一致性问题","date":"2021-05-04T04:44:15.000Z","updated":"2021-06-24T09:59:07.100Z","comments":false,"path":"posts/fa9a5340/","link":"","permalink":"https://gentryhuang.com/posts/fa9a5340/","excerpt":"","text":"概述使用 DB + Cache 的架构时，会带来缓存和数据库一致性问题。理论上来说，给缓存设置过期时间是保证最终一致性的解决方案。基于此，所有的写操作以 DB 为准，对 Cache 操作尽最大努力即可，也就是说如果 DB 写成功，缓存更新失败，那么只要到达过期时间缓存就会失效，后续的读请求获取的自然就是最新的数据并回填 Cache。 对于缓存和数据库一致性问题有很多的解决方案，没有最完美的方案，只有适合业务场景的方案。注意，本文讨论的相关更新策略是不考虑缓存过期时间问题。 Cache 操作方式当数据 data 发生改变时，对 Cache 的操作有两种方式：更新 Cache 中的数据和淘汰 Cache 中的数据 。 更新 Cache 更新 Cache 是指数据 data 不仅会写入 DB，还会写入 Cache 。更新 Cache 的优点：缓存不会增加一次 miss，命中率高。 淘汰 Cache 淘汰 Cache 是指数据 data 只会写入 DB，不会写入 Cache，并且把 Cache 清除。 使用更新 Cache 还是淘汰 Cache 取决于设置 Cache 的复杂度。Cache 可能是单一的值，也可能是通过复杂的计算得到的值，前者适合使用更新 Cache，后者适合使用淘汰 Cache。但从总体上考虑，淘汰 Cache 操作简单，并且带来的副作用只是增加了一次 Cache miss，因此推荐使用淘汰 Cache 的处理方式。 Cache 和 DB 操作序列当数据 data 发生改变时，除了需要对 Cache 的操作进行选择（推荐使用淘汰 Cache），还需要对 Cache 和 DB 的操作序列进行选择： 先更新 DB，后淘汰 Cache 先淘汰 Cache，后更新 DB 对于不能保证事务性的操作，选择标准是：当出现不一致，哪个操作影响较小，就选择该操作先执行。由于更新 DB 和淘汰 Cache 不能保证原子性，因此需要判断哪一个先执行影响更小。 先更新 DB，后淘汰 Cache 操作 DB 失败没有影响，重试即可。一旦更新 DB 成功，淘汰 Cache 失败，则会出现 DB 中是新数据，Cache 中是旧数据，导致数据不一致。 先淘汰 Cache，后更新 DB 淘汰 Cache 失败没有影响，重试即可。一旦淘汰 Cache 成功，更新 DB 失败，只会引发一次 Cache miss。 结论：先淘汰 Cache，再更新 DB 。 特别说明：这里给出的先淘汰 Cache ，再更新 DB 是针对没有额外处理手段的情况下，这种操作序列即使出现问题影响是最小的。如果使用类似重试机制保证操作序列的完整性，那么这两种序列就没有多大差异了，下文会着重分析。 更新策略淘汰 Cache 是一种推荐的处理方式，先淘汰 Cache 后更新 DB 的时序产生问题相对更小。下面我们对常见方案进行分析： 先更新 DB，再更新 Cache 先淘汰 Cache，再更新 DB 先更新 DB，再淘汰 Cache 需要说明的是，先更新 Cache，再更新 DB 的策略问题较大，一旦出现不一致就存在超前的脏数据，这样的不一致是要不得的。根据上文我们分析的，先更新 DB，再更新 Cache 也是不推荐的。 先更新 DB 后更新 Cache该策略也是不推荐使用的，主要原因如下： 并发更新导致缓存更新顺序问题如上图，线程 A、B 同时进行更新操作，那么会出现： 线程 A 更新了 DB 线程 B 更新了 DB 线程 B 更新了 Cache 线程 A 更新了 Cache 线程 A 先进行了 DB 更新操作，理论上也应该是线程 A 先更新 Cache，但因为线程 A 处理的较慢，缓存最后是线程 A 更新后的值。这就导致了脏数据。可以使用串行化解决，但是会导致效率变低。2. 更新 DB 成功，但更新 Cache 失败时会导致 Cache 中的脏数据。 这里为了完整性，把该策略列举出来，了解即可。我们重点关注另外两种方式。 先淘汰 Cache 后更新 DB针对以上更新 Cache 出现的问题，有人就提出淘汰 Cache 的策略。先淘汰 Cache ，如果成功，则更新 DB；如果失败则不更新 DB，后续可以通过重试来解决失败的问题，但是增加了一次 Cache 的 miss。该策略导致不一致的原因不在于后更新 DB 失败了，而是汰 Cache 成功，但更新 DB 完成前存在读请求将旧数据设置到 Cache 中造成脏数据（并发问题），具体场景如下图所示：如上图，同时有一个线程 A 进行更新操作，另一个线程 B 进行查询操作，那么就会出现： 线程 A 淘汰 Cache 线程 B 没有命中 Cache 线程 B 查询 DB 线程 B 将查询结果写入 Cache ，对后续读就是脏数据 线程 A 更新 DB 上述情况会导致不一致的问题，而且，如果不采用给 Cache 设置过期时间策略，该脏数据会一直保留到下次更新操作。 针对以上问题可以采用 延时双删策略 将 Cache 脏数据删除，伪代码如下： 12345678910/** * @param key 数据 key * @param data 数据 */public void update(String key, Object data) &#123; cache.delKey(key);// 1 淘汰 Cache db.updateData(data); // 2 更新 DB Thread.sleep(1000); // 3 延时 delay cache.delKey(key);// 4 再次淘汰 Cache&#125; 在更新 DB 完成后，评估一定的延时时间再次淘汰 Cache 。这里的延时时间不好确定，一般需要评估项目读数据业务逻辑的耗时，在此基础上加一定的毫秒值即可。值得一说的是，延时一定的时间才会再次淘汰 Cache 是为了确保读请求结束，写请求可以删除读请求造成的缓存脏数据。这里也可以看出，并不是更新 DB 后立刻再次淘汰 Cache ，因为可能有线程读取到了更新前的旧数据还没来得及写入缓存，因此需要等待它写入缓存。 如果 DB 采用读写分离架构，可能产生以下问题：如上图，过程如下： 线程 A 淘汰 Cache 线程 A 更新 DB 线程 B 没有命中缓存 线程 B 查询从库 DB，此时并没有完成主从同步，因此查询的是旧值 线程 B 将旧值放入 Cache 主从同步完成 上述解决方案还是使用 延时双删策略，只需要延时时间确保完成主从同步，即主从同步完成再删一次 Cache 即可。 存在问题 第二次淘汰 Cache 是为了防止 Cache 中的脏数据（旧的数据）而做的操作，而非业务要求。因此，延时双删策略虽然在一定程度上能保证 Cache 中不会有脏数据，但对业务是有损的，具体表现为： 吞吐量降低 问题描述：因为要实现延时淘汰 Cache，写的请求需要休眠等待一段时间。解决方案：将第二次淘汰 Cache 以异步处理，这样写请求完成后就能立即返回，提高吞吐量。 第二次淘汰 Cache 失败 问题描述：写请求完成了 DB 更新，再次淘汰 Cache 失败了，导致 Cache 和 DB 一致性问题解决方案：理论上可以依赖 Cache 的失效时间，但是可能不及时，因此最好采用重试机制，具体实现下文详细分析。 此外，延时双删策略只能在一定程度上能保证 Cache 中不会有脏数据，具体哪种程度要看延时时间的准确性。 先更新 DB 后淘汰 Cache基于同样套路，我们先分别从并发和操作完整性出发，分析该策略存在的问题。 并发问题如上图，线程 A 执行查询，线程 B 执行更新，那么会有如下情况： 线程 A 没有命中 Cache 线程 A 查询 DB 线程 B 更新 DB 线程 B 淘汰 Cache 线程 A 将查询到的旧值放入 Cache 由于 DB 读操作速度远快于写操作，因此这样的并发问题（放入值到缓存还没有一次磁盘IO快）导致的脏数据概率非常非常低。如果非要解决，依然可以采用延时双删策略，即保证读请求完成后再一次淘汰 Cache。 淘汰 Cache 时延问题在更新 DB 后还没来得及淘汰 Cache，其它请求就开始读取数据了，那么此时由于能命中缓存，就会直接从缓存中取旧数据，因此会有不一致数据短暂存在。不过，在这种情况下如果并发读缓存的请求不多，对业务影响还是小的，毕竟缓存很快就会被淘汰，后续请求就不会读取到旧的值了。再严格就需要使用分布式事务了。 淘汰 Cache 失败淘汰 Cache 失败也是延时双删策略中存在的问题，也同样会产生脏数据问题，根本策略就是重试，保证淘汰 Cache 成功。 如果对一致性要求不是很高，可以使用以下两种方案： 等待 Cache 过期失效 直接在程序中另起一个线程，定时重试 如果对一致性要求相对较高，就需要采用其它手段来保证及时淘汰掉 Cache 。下面就先更新 DB 后淘汰 Cache 给出两个具体方案，其中淘汰 Cache 的流程是通用的。 消息队列重试通过消息 MQ 来实现重试，即将淘汰 Cache 失败的数据 key 发送到 MQ 中，然后消费MQ，执行淘汰 Cache 操作，直到淘汰成功。流程图如下： 上图流程描述如下： 更新 DB 淘汰 Cache 失败 将数据 key 发送到消息队列 消费消息，获得数据 key 继续重试淘汰 Cache 操作，直到成功 使用该方案有一个缺点，会对业务代码造成一定侵入，因为业务方需要关心将数据 key 写入到 MQ 中。采用订阅 binlog 的方式就可以做到对业务代码无侵入，下面我们就来看这种方式。 订阅 binlog 重试启动一个订阅程序去订阅 DB 的 binlog，获取 binlog 中的数据的key，然后执行淘汰 Cache 操作，如果失败，则发送数据 key 到 MQ，后续同方案一。流程图如下： 上图流程描述如下： 更新 DB DB 将操作信息写入 binlog 日志中 binlog 订阅程序提取出所需的数据 key 非业务代码获取数据 key 尝试根据数据 key 淘汰 Cache 如果淘汰 Cache 失败，则将数据 key 发送到消息队列 重新从消息队列中获得数据 key 继续重试淘汰 Cache，直到成功 其中订阅程序在 Mysql 中有 Canal 中间件，可以直接使用它完成订阅 binlog 日志的功能。 补充本文介绍的缓存一致性解决方案都不能保证操作的原子性。如果需要严格保证缓存和数据库的一致性，也就是保证两者操作的原子性，就需要用到分布式事务来解决。常见的解决方案：两阶段提交（2PC）、三阶段提交（3PC）、TCC、消息队列等，这些方案相对比较复杂，一般用在对于一致性要求较高的业务场景中。 小结本篇文章着重点在于，DB 更新完成后，Cache 淘汰失败了，基于这种情况可以根据业务的特点选择对应的方式进行处理。如果对一致性要求不是很高，那么在淘汰 Cache 失败后可以选择等待缓存失效和异步定时重试；如果对一致性要求相对较高，那么可以使用消息队列和订阅 binlog 的方式重试淘汰 Cache 。","categories":[{"name":"分布式","slug":"分布式","permalink":"https://gentryhuang.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"https://gentryhuang.com/tags/%E7%BC%93%E5%AD%98/"}]},{"title":"Dubbo源码分析 - 健康检测","slug":"rpc/健康检测","date":"2021-05-01T10:56:21.000Z","updated":"2021-05-08T08:48:14.312Z","comments":false,"path":"posts/4760cec/","link":"","permalink":"https://gentryhuang.com/posts/4760cec/","excerpt":"","text":"概述Dubbo 心跳检测是为了保证连接的可用性，在需要的时候及时采取重连、断开等措施。需要说明的是，Dubbo 心跳检测是针对 TCP 层面的协议（如：Dubbo 协议），HTTP 层面的协议是无需进行连接管理的。心跳检测需要容错，一次心跳失败不能认定连接不通，多次心跳失败才能采取相应措施。此外，心跳检测不应该忙检测，如果一条通道上有频繁的 RPC 调用，会给系统带来额外的负担。 连接长短连接TCP 本身并没有长短连接之分，长短连接与否取决于对它的使用。 短连接： 每次通信时创建一个连接，一次通信结束关闭连接即可。短连接的好处是管理简单，存在的连接都是可用的连接，不需要额外的控制手段。 长连接： 每次通信完毕后，不会立即关闭连接，这样可以做到连接的复用。长连接的好处是省去了创建连接的开销。 长短连接各自的优势，分别是对方的劣势。对于不追求高性能，使用短连接合适，省去了连接状态管理的工作。追求性能最好使用长连接，但是需要额外工作，如端点之间连接的维护和保活。 Dubbo 中的长连接Dubbo 协议是基于 TCP 进行网络传输的，它采用的就是长连接。下面分别启动服务提供者应用和服务消费者应用，提供者负责监听本地 20880 端口（Dubbo 默认端口），服务消费者负责发起请求。 服务提供方启动完成从上图可知，Dubbo 正在监听本地的 20880 端口，处理发送到本地 20880 端口的请求。 服务消费方发起请求从上图可以验证，TCP 是一个双向的通信过程。 连接的保活当端点间建立长连接后，由于网络问题，建立的连接可能不可用，这时就需要保证连接的可用。保证连接的可用常用的手段就是连接保活。 TCP KeepAliveTCP KeepAlive 是面向网络的，并不是面向应用的。连接不可用并不一定是网络问题，可能是由于应用本身的负载过高、GC频繁等导致的，此时应用失去了活性，连接也不可用。 应用层心跳网络层面的 KeepAlive 不足以支撑应用层面的连接可用性，这种情况下应该使用应用层的心跳机制来实现连接保活，这也是业内常用的检测方法。 Dubbo 心跳检测介绍完健康检测相关基础后，下面我们详细介绍 Dubbo 是如何设计应用层心跳的。注意，以下讨论的 Dubbo 版本是 2.7.7 。 Dubbo 在改进心跳方案之前是双向心跳设计，客户端会给服务端发送心跳，反之，服务端也会向客户端心跳。关于双向心跳设计可以参见心跳任务，这里介绍的是 Dubbo 2.6.x 版本，任务执行没有使用时间轮，依然使用 schedule 方案。 Dubbo 心跳机制改进后，主要分为两类。其一，对于底层使用 Netty 通信的连接检测交给 Netty 本身而非 Dubbo 心跳检测逻辑，即完全使用 IdleStateHandler 来检测连接空闲状态。其二，对于其它 NIO 通信组件，Dubbo 优化了之前的双向心跳设计，改为了客户端在连接空闲时发送单向心跳，服务端定时检测连接可用性。下面我们就结合 Dubbo 心跳检测改进后的版本进行说明。 IdleStateHandlerNetty 对空闲连接的检测提供了天然的支持，使用 IdleStateHandler 可以很方便的实现空闲检测逻辑。其内部使用了 EventLoop.schedule(task) 来实现定时任务，使用该线程可以保证线程安全。 12345public IdleStateHandler( long readerIdleTime, long writerIdleTime, long allIdleTime, TimeUnit unit) &#123; this(false, readerIdleTime, writerIdleTime, allIdleTime, unit);&#125; readerIdleTime： 读超时时间 writerIdleTime： 写超时时间 allIdleTime： 所有类型的超时时间 IdleStateHandler 会根据设置的超时参数，循环检测通道 Channel 的读写多久没有调用。当在 Netty 的 Pipeline 中加入 IdleStateHandler 后，可以在此 Pipeline 的任意 Handler 的 userEventTriggered 方法之中检测 IdleStateEvent 空闲事件。 IdleSensible12345678910public interface IdleSensible &#123; /** * 是否具有处理空闲连接的能力 * * @return */ default boolean canHandleIdle() &#123; return false; &#125;&#125; Dubbo 新增该接口，以区分 Netty 和其它通信组件对空闲连接的处理能力。NettyServer 和 NettyClient 作为 Netty 通信组件的封装类实现了该接口，重写了接口中的方法，返回值为 true，表示具有处理空闲连接的能力。也就是说，如果使用 Netty 作为通信组件，那么监控空闲连接就交给 Netty 底层自己处理。而其它通信组件暂不支持，因此仍然需要 Dubbo 框架的心跳设计方案。 网络传输层下面我们先从 Dubbo 的网络传输层分析心跳检测的实现，需要说明的是网络传输层主要针对的是 Netty 组件，其它 NIO 组件几乎没有在网络传输层实现心跳逻辑（这里不包括统一处理心跳交互的 HeartbeatHandler）。 NettyServer12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152+--- NettyServer /** * Init and start netty server * * @throws Throwable */ @Override protected void doOpen() throws Throwable &#123; bootstrap = new ServerBootstrap(); bossGroup = NettyEventLoopFactory.eventLoopGroup(1, \"NettyServerBoss\"); workerGroup = NettyEventLoopFactory.eventLoopGroup(getUrl().getPositiveParameter(IO_THREADS_KEY, Constants.DEFAULT_IO_THREADS), \"NettyServerWorker\"); final NettyServerHandler nettyServerHandler = new NettyServerHandler(getUrl(), this); channels = nettyServerHandler.getChannels(); bootstrap.group(bossGroup, workerGroup) .channel(NettyEventLoopFactory.serverSocketChannelClass()) .option(ChannelOption.SO_REUSEADDR, Boolean.TRUE) .childOption(ChannelOption.TCP_NODELAY, Boolean.TRUE) .childOption(ChannelOption.ALLOCATOR, PooledByteBufAllocator.DEFAULT) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; // 1 心跳超时时间，是心跳间隔的 3 倍。心跳间隔默认 60s int idleTimeout = UrlUtils.getIdleTimeout(getUrl()); NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec(), getUrl(), NettyServer.this); if (getUrl().getParameter(SSL_ENABLED_KEY, false)) &#123; ch.pipeline().addLast(\"negotiation\", SslHandlerInitializer.sslServerHandler(getUrl(), nettyServerHandler)); &#125; // 2 设置 ChannelPipeline 上的 ChannelHandler ch.pipeline() // 2.1 编解码 Handler .addLast(\"decoder\", adapter.getDecoder()) .addLast(\"encoder\", adapter.getEncoder()) // 2.2 心跳检测 Handler，注意超时时间针对所有类型 .addLast(\"server-idle-handler\", new IdleStateHandler(0, 0, idleTimeout, MILLISECONDS)) // 2.3 Netty 融合 Dubbo Handler 的 处理器 .addLast(\"handler\", nettyServerHandler); &#125; &#125;); // bind ChannelFuture channelFuture = bootstrap.bind(getBindAddress()); channelFuture.syncUninterruptibly(); channel = channelFuture.channel(); &#125; // 重写 IdleSensible 中的方法，表示自己实现心跳检测 @Override public boolean canHandleIdle() &#123; return true; &#125; 在初始化和启动 Netty Server 时，会为 Pipeline 设置 IdleStateHandler 处理器，用于检测空闲连接。注意，IdleStateHandler 是 Netty 提供的一个工具型 Handler，用于定时心跳请求的功能以及自动关闭长时间空闲连接。如果超过设置的阈值（超时时间），则会触发 IdleStateEvent 事件并传递给后续的 ChannelHandler 进行处理，后续的 ChannelHandler 的 userEventTriggered() 方法会根据接收到的 IdleStateEvent 事件，决定是关闭空闲连接还是发送心跳探活。这里提到的 ChannelHandler 其实就是下文要介绍的 NettyServerHandler 和 NettyClientHandler 。 NettyClient12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455+--- NettyClient /** * Init bootstrap * * @throws Throwable */ @Override protected void doOpen() throws Throwable &#123; final NettyClientHandler nettyClientHandler = new NettyClientHandler(getUrl(), this); bootstrap = new Bootstrap(); bootstrap.group(NIO_EVENT_LOOP_GROUP) .option(ChannelOption.SO_KEEPALIVE, true) .option(ChannelOption.TCP_NODELAY, true) .option(ChannelOption.ALLOCATOR, PooledByteBufAllocator.DEFAULT) //.option(ChannelOption.CONNECT_TIMEOUT_MILLIS, getTimeout()) .channel(socketChannelClass()); bootstrap.option(ChannelOption.CONNECT_TIMEOUT_MILLIS, Math.max(3000, getConnectTimeout())); bootstrap.handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; // 1 心跳间隔，默认 60s int heartbeatInterval = UrlUtils.getHeartbeat(getUrl()); if (getUrl().getParameter(SSL_ENABLED_KEY, false)) &#123; ch.pipeline().addLast(\"negotiation\", SslHandlerInitializer.sslClientHandler(getUrl(), nettyClientHandler)); &#125; NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec(), getUrl(), NettyClient.this); // 2 设置 ChannelPipeline 上的 ChannelHandler ch.pipeline()//.addLast(\"logging\",new LoggingHandler(LogLevel.INFO))//for debug // 2.1 编解码 Handler .addLast(\"decoder\", adapter.getDecoder()) .addLast(\"encoder\", adapter.getEncoder()) // 2.2 心跳检测 Handler，注意超时时间针对读类型 .addLast(\"client-idle-handler\", new IdleStateHandler(heartbeatInterval, 0, 0, MILLISECONDS)) // 2.3 Netty 融合 Dubbo Handler 的处理 .addLast(\"handler\", nettyClientHandler); String socksProxyHost = ConfigUtils.getProperty(SOCKS_PROXY_HOST); if (socksProxyHost != null) &#123; int socksProxyPort = Integer.parseInt(ConfigUtils.getProperty(SOCKS_PROXY_PORT, DEFAULT_SOCKS_PROXY_PORT)); Socks5ProxyHandler socks5ProxyHandler = new Socks5ProxyHandler(new InetSocketAddress(socksProxyHost, socksProxyPort)); ch.pipeline().addFirst(socks5ProxyHandler); &#125; &#125; &#125;); &#125; // 重写 IdleSensible 中的方法，表示自己实现心跳检测 @Override public boolean canHandleIdle() &#123; return true; &#125; NettyClient 的初始化逻辑和 NettyServer 类似，这里就不再重复说明。 IdleStateHandler 参数 客户端和服务端配置的超时时间不一致 由于客户端有重试机制，不断发送心跳失败 N 次后才会进行断开、重连。而服务端超时后是直接断开的，留给服务端时间需要长一点，默认情况是服务端超时时间是客户端超时时间的 3 倍。此外，两端都拥有断开连接的能力，但连接的创建是客户端主动发起的，那么客户端也更有权利去主动断开连接。 客户端检测的是读超时，服务端检测的是读写超时 这属于心跳的共识。一般情况下客户端先发起心跳（写）[IdleStateHandler 是单向的，客户端-&gt;服务端]，所以整个链路中不通的情况只可能是：（1）服务接收（读） （2）服务端发送（写） （3）客户端接收（读） 。 NettyServerHandler12345678910111213141516171819202122232425+--- NettyServerHandler@io.netty.channel.ChannelHandler.Sharablepublic class NettyServerHandler extends ChannelDuplexHandler &#123; /** * 收到 IdleStateEvent 事件时会断开连接 * * @param ctx * @param evt * @throws Exception */ @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123; // server will close channel when server don't receive any heartbeat from client util timeout. if (evt instanceof IdleStateEvent) &#123; NettyChannel channel = NettyChannel.getOrAddChannel(ctx.channel(), url, handler); try &#123; logger.info(\"IdleStateEvent triggered, close channel \" + channel); // 断开链接 channel.close(); &#125; finally &#123; NettyChannel.removeChannelIfDisconnected(ctx.channel()); &#125; &#125; super.userEventTriggered(ctx, evt); &#125; NettyServerHandler 作为 Netty 服务端侧的 ChannelHandler，当收到 IdleStateEvent 事件时会断开连接。 NettyClientHandler12345678910111213141516171819202122232425262728293031323334+--- NettyClientHandler@io.netty.channel.ChannelHandler.Sharablepublic class NettyClientHandler extends ChannelDuplexHandler &#123; /** * 收到 IdleStateEvent 事件会发送心跳消息 * * @param ctx * @param evt * @throws Exception */ @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123; // send heartbeat when read idle. if (evt instanceof IdleStateEvent) &#123; try &#123; NettyChannel channel = NettyChannel.getOrAddChannel(ctx.channel(), url, handler); if (logger.isDebugEnabled()) &#123; logger.debug(\"IdleStateEvent triggered, send heartbeat to channel \" + channel); &#125; // 发送心跳请求 Request req = new Request(); req.setVersion(Version.getProtocolVersion()); req.setTwoWay(true); req.setEvent(HEARTBEAT_EVENT); // 发送心跳消息 channel.send(req); &#125; finally &#123; NettyChannel.removeChannelIfDisconnected(ctx.channel()); &#125; &#125; else &#123; super.userEventTriggered(ctx, evt); &#125; &#125; NettyClientHandler 作为 Netty 客户端侧的 ChannelHandler，当收到 IdleStateEvent 事件时会进行心跳探活。 信息交换层信息交换层是触发心跳检测的入口。 HeaderExchangeServer12345678910111213141516171819202122232425262728293031323334353637383940public class HeaderExchangeServer implements ExchangeServer &#123; protected final Logger logger = LoggerFactory.getLogger(getClass()); private final RemotingServer server; private AtomicBoolean closed = new AtomicBoolean(false); private static final HashedWheelTimer IDLE_CHECK_TIMER = new HashedWheelTimer(new NamedThreadFactory(\"dubbo-server-idleCheck\", true), 1, TimeUnit.SECONDS, TICKS_PER_WHEEL); private CloseTimerTask closeTimerTask; public HeaderExchangeServer(RemotingServer server) &#123; Assert.notNull(server, \"server == null\"); this.server = server; // 开始心跳检测任务 startIdleCheckTask(getUrl()); &#125; private void startIdleCheckTask(URL url) &#123; // server 自己是否可以心跳检测，如果自己不能，则启动一个 CloseTimerTask 定时任务，定期关闭长时间空闲的连接 // NettyServer 是自己完成心跳检测的，具体依赖 NettyServerHandler 和 IdleStateHandler 实现，原理与 NettyClient 类似 if (!server.canHandleIdle()) &#123; AbstractTimerTask.ChannelProvider cp = () -&gt; unmodifiableCollection(HeaderExchangeServer.this.getChannels()); // 心跳超时时间 int idleTimeout = getIdleTimeout(url); // 根据心跳超时时间计算出一个 tick 时间（除以了 3 得到），作为定时任务执行的频率 long idleTimeoutTick = calculateLeastDuration(idleTimeout); // 创建闭关连接的任务 CloseTimerTask closeTimerTask = new CloseTimerTask(cp, idleTimeoutTick, idleTimeout); this.closeTimerTask = closeTimerTask; // 将任务加载到时间轮 IDLE_CHECK_TIMER.newTimeout(closeTimerTask, idleTimeoutTick, TimeUnit.MILLISECONDS); &#125; &#125;&#125; 创建 Exchange 层的 Server 时会开启心跳检测任务，如果使用的是 Netty 通信组件则不会使用 Dubbo 的心跳检测逻辑而是直接使用 Netty 提供的心跳检测机制，如果是其它通信组件则依赖 Dubbo 提供的心跳检测逻辑。 HeaderExchangeServer 启动的心跳检测任务用于服务端侧连接超时关闭连接，这个针对非 Netty 通信组件。Netty 实现的服务端侧心跳检测是交给 IdleStateHandler 完成的， 连接超时关闭连接由 NettyServerHandler 完成。 以上关闭空闲连接相关的定时任务不再展开说明。 HeaderExchangeClient123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public class HeaderExchangeClient implements ExchangeClient &#123; private final Client client; private final ExchangeChannel channel; private static final HashedWheelTimer IDLE_CHECK_TIMER = new HashedWheelTimer(new NamedThreadFactory(\"dubbo-client-idleCheck\", true), 1, TimeUnit.SECONDS, TICKS_PER_WHEEL); private HeartbeatTimerTask heartBeatTimerTask; private ReconnectTimerTask reconnectTimerTask; /** * @param client 封装 Transport 层的 Client 对象 * @param startTimer 参与控制是否开启心跳定时任务和重连任务 */ public HeaderExchangeClient(Client client, boolean startTimer) &#123; Assert.notNull(client, \"Client can't be null\"); this.client = client; this.channel = new HeaderExchangeChannel(client); // 开启心跳定时任务和重连任务 if (startTimer) &#123; URL url = client.getUrl(); startReconnectTask(url); startHeartBeatTask(url); &#125; &#125; // 开启心跳任务 private void startHeartBeatTask(URL url) &#123; // client 是否可以自己检测心跳，如果自己可以发送心跳请求，则无须 HeaderExchangeClient 再启动一个定时任务 // 这里的 client 是 NettyClient ，它依靠 IdleStateHandler 中的定时任务来触发心跳事件，依靠 NettyClientHandler 来发送心跳请求，对于无法自己发送心跳请求的 Client 实现，HeaderExchangeClient 会为其启动 HeartbeatTimerTask 心跳定时任务 if (!client.canHandleIdle()) &#123; // 获取客户端测通道 AbstractTimerTask.ChannelProvider cp = () -&gt; Collections.singletonList(HeaderExchangeClient.this); // 获取心跳间隔 int heartbeat = getHeartbeat(url); // 处理心跳间隔，最小间隔不能低于 1s long heartbeatTick = calculateLeastDuration(heartbeat); // 创建心跳任务 this.heartBeatTimerTask = new HeartbeatTimerTask(cp, heartbeatTick, heartbeat); // 将心跳任务加载到时间轮 IDLE_CHECK_TIMER.newTimeout(heartBeatTimerTask, heartbeatTick, TimeUnit.MILLISECONDS); &#125; &#125; /** * 注意，无论使用哪种 NIO 组件，重连逻辑使用的都是 Dubbo 提供的 * * @param url */ private void startReconnectTask(URL url) &#123; // 从 URL 中读取重连配置，判断是否开启重连 if (shouldReconnect(url)) &#123; // 获取客户端测通道 AbstractTimerTask.ChannelProvider cp = () -&gt; Collections.singletonList(HeaderExchangeClient.this); // 心跳超时时间 int idleTimeout = getIdleTimeout(url); // 处理心跳超时时间 long heartbeatTimeoutTick = calculateLeastDuration(idleTimeout); // 创建重连任务 this.reconnectTimerTask = new ReconnectTimerTask(cp, heartbeatTimeoutTick, idleTimeout); // 将重连任务加载到时间轮 IDLE_CHECK_TIMER.newTimeout(reconnectTimerTask, heartbeatTimeoutTick, TimeUnit.MILLISECONDS); &#125; &#125; 创建 Exchange 层的 Client 时会开启心跳检测任务和重连任务。如果使用的 Netty 通信组件则不会使用 Dubbo 的心跳检测逻辑，同样是使用 Netty 提供的心跳检测机制，如果是其它通信组件则依赖 Dubbo 提供的心跳检测逻辑。重连任务无论是使用 Netty 通信组件还是其它通信组件，都会依赖 Dubbo 提供的重连逻辑。 HeaderExchangeClient 启动的心跳检测任务用于客户端侧连接超时不断发送心跳，这个针对非 Netty 通信组件。Netty 实现客户端侧心跳检测是交给 IdleStateHandler 完成的， 连接超时发送心跳由 NettyClientHandler 完成。HeaderExchangeClient 启动的重连任务针对所有的 NIO 通信组件，它们都依赖 Dubbo 实现的重连逻辑。 以上相关的定时任务不再展开说明。 健康检测精度Dubbo 中默认的心跳间隔是 60s ，心跳超时时间是 3 * 60s，由于时间窗口问题，非健康连接可能不能够被及时检测出来，最坏情况为一个周期。Dubbo 目前的解决方案是，根据心跳间隔时间和心跳超时时间计算出对应的实际触发频率，使它们的值缩小，通过减少检测间隔时间来增大及时发现非健康状态连接的概率。实际触发频率需要根据场景进行权衡折中，要考虑到资源消耗问题。 注意，几乎所有的定时检测逻辑都会存在时间窗口问题，解决方案就是根据具体的场景合理地计算检测任务的触发频率。 HeartbeatHandlerHeartbeatHandler 是专门用于心跳消息处理的 ChannelHandler 实现。注意哦，它是一个 ChannelHandler，意味着会接收到各种消息（不仅限心跳消息）并能处理相关消息，它的主要职能就是处理心跳消息。在通信的不同阶段会更新通道中的 读写时间戳(这些读写时间戳是判断超时的依据)，不仅是心跳消息会更新对应值其它消息也会更新。对收到的心跳消息进行处理，如接收到心跳请求，则生成对应的心跳响应并返回；如接收到心跳响应，则打印日志即可；如果接收到其它消息，则传递给底层的通道处理器。 HeartbeatHandler 更多详情可参考 HeartbeatHandler 。 补充介绍完 Dubbo 的心跳检测后，我们再从宏观上对健康检测进行说明。 调用方跟服务集群节点之间的网络状况是瞬息万变的，两者之间可能出现各种情况，保证连接的可靠终极解决方案：让调用方实时感知到节点的状态变化。 应用心跳检测 应用心跳检测是目前通用的健康检测方案，它能相对及时发现非健康的连接以及非健康的应用，本质上来说还是根据心跳请求结果做判断，这在一定程度上也可以应对应用僵死情况（应用失去活性会影响到心跳请求的响应）。但是对一些相对特殊的情况，应用层心跳检测就不能很好的感知了。比如心跳失败率较高（可能是服务节点网络问题、应用活性等问题），但是总能在阈值内恢复正常，这种情况应用层心跳就显得力不从心了，理论来说该连接或者服务属于不可用的，但是应用层心跳依然认为是正常情况。针对这类情况，就需要其它维度的健康检测。 业务请求可用率 判断连接或节点状态只有心跳检测维度是不够完美的，可以增加服务调用可用率来协助检测逻辑，这样健康检测就完整了。 小结分布式系统中健康检测是非常有必要的，通过健康检测机制可以及时地发现连接是否可用或服务是否可用，调用方根据检测结果做出正确的选择，如重连、断开连接、将服务移除健康列表等。健康检测可从 TCP KeepAlive、应用心跳 以及 业务请求可用率 等多维度进行考虑。应用健康状况不仅包括 TCP 连接状况，还包括应用本身是否存活，很多情况下 TCP 连接没有断开，但应用可能已经“僵死了”。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"Gossip 协议","slug":"architecture/Gossip协议","date":"2021-04-28T16:00:00.000Z","updated":"2021-07-13T11:56:45.438Z","comments":false,"path":"posts/6001717d/","link":"","permalink":"https://gentryhuang.com/posts/6001717d/","excerpt":"","text":"前言通过对 Raft 等算法的了解，我们知道它们都需要大多数节点正常运行才能稳定运行。如果我们需要系统在极端的情况下也要保证正常运行，比如集群中只有一个节点，那么就必须另辟蹊径了。其实，要求系统在极端的情况下也能稳定运行，根据 BASE 理论，这需要实现最终一致性，而 Gossip 协议就能实现这种系统。 概述Gossip 协议，顾名思义就像流言蜚语一样，利用一种随机、带有传染性的方式，将信息传播到整个网络中，并在一定时间内，使得系统内的所有节点数据一致。 思考集群中一个节点上有数据被改动，如果想让这个改动迅速传遍整个集群中的节点，进而达到一致性的状态。一般常见的做法是发生改动的节点将最新的数据发送到其它节点，或者其它节点去定期拉取数据。但是上述的解决方案在分布式的情况下会存在以下问题： 发生改动的节点还没有将最新数据给到其它节点宕机了 由于网络原因，可能存在某个或某些节点不能连接上发生改动的节点，那么也不能获取到数据，即使其它节点已经同步到了最新的数据。以上两个问题虽然在像 Raft 等算法中能解决，但是存在效率问题。而我们今天的主角 Gossip 协议就能很好的解决以上问题，以一传十，十传百的方式最后迅速传遍整个集群。 过程Gossip 过程是由种子节点发起，它会周期性的随机选择周围几个节点散播消息，收到消息的节点也会重复该过程，直至最终网络中所有的节点都收到了消息。这个过程可能需要一定的时间，由于不能保证某个时刻所有节点都收到消息，但是理论上最终所有节点都会收到消息，因此它是一个最终一致性协议。需要注意的是，Gossip 过程是异步的，也就是说发消息的节点不会关注对方是否收到，即不等待响应； 类型Gossip 有两种类型： 反熵：传播所有的数据 谣言传播：仅传播新到达的数据 反熵反熵指的是集群中的节点，每隔段时间就随机选择其它节点，然后通过相互交换自己的所有数据来消除两者之间的差异，实现数据的最终一致性。 需要注意的是，反熵需要节点两两交换和对比自己所有的数据，执行反熵时通讯成本会很高。其次，反熵虽然实用，但是执行反熵时相关的节点都是已知的，而且节点数量不能太多，如果是一个动态变化或节点比较多的分布式环境，这时反熵就不适用了。 谣言传播谣言传播，指的是当一个节点有了新数据后，这个节点变成活跃状态，并周期性地联系其它节点向其发送数据，直到所有的节点都存储了该新数据。谣言传播非常具有传染性，它适合动态变化的分布式系统。 通信模式Gossip 协议最终目的是将数据分发到网络中的每一个节点。根据不同的具体应用场景，网络中两个节点之间存在三种通信方式。 Push: 节点 A 将数据 (key,value,version) 及对应的版本号推送给 B 节点，B 节点更新 A 中比自己新的数据。 Pull：A 仅将数据 key, version 推送给 B，B 将本地比 A 新的数据（Key, value, version）推送给 A，A 更新本地。 Push/Pull：与 Pull 类似，只是多了一步，A 再将本地比 B 新的数据推送给 B，B 则更新本地。 如果把两个节点数据同步一次定义为一个周期，则在一个周期内，Push 需通信 1 次，Pull 需 2 次，Push/Pull 则需 3 次。虽然消息数增加了，但从效果上来讲，Push/Pull 最好，理论上一个周期内可以使两个节点完全一致。直观上，Push/Pull 的收敛速度也是最快的。 特点优势扩展性：允许节点的任意增加和减少，新增节点的状态最终会与其他节点一致。容错性：任意节点的宕机和重启都不会影响 Gossip 消息的传播，一方面一个节点会多次传播信息，另一方面即使不能连通某个节点，其他被“感染”的节点也会尝试向这个节点传播信息。具有天然的分布式系统容错性。健壮性：无需中心节点，所有节点都是对等的，只要网络连通，任意节点可把消息散播到全网。 缺点消息延迟：节点随机向少数几个节点发送消息，消息最终是通过多个轮次的散播而到达全网；不可避免的造成消息延迟。消息冗余：节点会定期随机选择周围节点发送消息，而收到消息的节点也会重复该步骤，不可避免的引起同一节点消息多次接收，增加了消息处理压力。 需要说明的是，Gossip 协议适用于 AP 场景的数据一致性。 小结Gossip 协议基本思想是，一个节点想要分享一些信息给网络中的其他节点，会周期性的随机选择一些节点，并把信息传递给这些节点。这些收到信息的节点接下来会做同样的事情，即把这些信息传递给其他一些随机选择的节点。基于 Gossip 协议的一些系统，如 Apache Cassandra，Redis（Cluster模式），Consul等。","categories":[{"name":"分布式","slug":"分布式","permalink":"https://gentryhuang.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"Gossip","slug":"Gossip","permalink":"https://gentryhuang.com/tags/Gossip/"}]},{"title":"Raft 共识算法","slug":"architecture/Raft协议","date":"2021-04-23T11:28:56.000Z","updated":"2021-07-24T08:06:03.669Z","comments":false,"path":"posts/48468614/","link":"","permalink":"https://gentryhuang.com/posts/48468614/","excerpt":"","text":"概述Raft 是一个共识算法（consensus algorithm），也称作 Raft 协议。所谓共识就是多个节点就某个事情达成一致，即使是在部分节点故障、甚至网络分区的情况下也是可行的。在分布式系统中，共识算法更多用于提供系统的容错性。 Raft 算法是在兰伯特 Multi-Paxos 思想的基础上进行了简化和限制，目标就是容易理解。Raft 虽然增强了可理解性，但在性能、可靠性、可用性方面是不输于 Paxos 的。Raft 算法将共识的关键要素进行了拆分，以简化流程和提供算法的可理解性。 复制状态机共识算法的实现一般是基于复制状态机（Replicated state machines），即所有节点都是从同一个 state 出发，都经过同样的一些操作序列（log），最后到达同样的 state ，架构图如下： 这是一个共识系统的典型架构，其中涉及到三个组件： 状态机：处理来自 Log 的指令序列，将执行结果对外输出。状态机具有确定性，只要 Log 的指令序列相同，产生的结果也是相同的。 Log：保存了所有写操作记录。 共识模块：保证包含来自客户端的指令的 Log 的一致性，充当管理日志的角色。（这也是 Raft 算法核心内容） 复制状态机通常使用复制日志来实现。每个服务节点存储一个包含一系列命令的日志，日志会被其状态机所使用，用于计算其中的指令。注意，只要各个服务节点上的日志是相同的或者大多数节点日志相同，说明系统已经达成共识，这些具有相同日志的服务节点上的状态机就能以相同的顺序执行相同的命令，执行的结果也是相同的。不难看出，复制日志充当数据副本的角色。 保证复制日志的一致性是共识算法的工作。服务节点上的共识模块从客户端接收命令，并将其添加到其 Log 中，然后与其它服务节点的共识模块进行通信，以完成日志复制。正确复制指令后，每台服务节点将命令应用到状态机（状态机执行对应的指令）。 Raft 算法概览Raft 是一种用于管理复制日志的算法，它采用领导者模式，将共识问题分解为三个相对独立的子问题：Leader 选举、日志复制、安全（约定）。下面对 Raft 算法进行总体说明，并就关键特性进行列举。图中的相关元素会在后文具体说明。 算法简要状态数据结构 所有服务节点上的持久性状态（在响应RPC请求之前，已经更新到了稳定的存储设备） currentTerm: 服务节点已知最新任期（在服务节点首次启动时初始化为 0，该值是单调递增的） votedFor: 当前任期内收到选票的候选者id,如果没有投给任何候选者，则为空 log[]: 日志条目 所有服务节点上的易失性状态 commitIndex: 已知已提交的最高的日志条目的索引（初始值为 0，单调递增） lastApplied: 已经被应用到状态机的最高的日志条目的索引（初始值为 0，单调递增） 领导者（服务节点）上的易失性状态（选举后已经重新初始化） nextIndex[]: 对于每个服务节点，发送到该服务节点的下一个日志条目的索引（初始值为领导者最后的日志条目的索引+1） matchIndex[]: 对于每一台服务节点，已知的已经复制到该服务节点的最高日志条目的索引（初始值为0，单调递增） 选举 RPC 数据结构 由候选人负责调用，用来征集选票 term：候选人的任期编号 candidatedId: 请求选票的候选人的 id lastLogIndex: 候选人最后日志条目的索引值 lastLogTerm: 候选人最后日志条目的任期编号 返回值 term: 响应中的任期号，以便于候选人去更新自己的任期号（候选人任期号较小时） voteGranted: 候选人赢得了此张选票时为真 日志复制｜心跳 RPC 数据结构 领导者用于日志条目的复制 RPC 和 心跳 RPC term: 领导者任期 leaderId: 领导者Id，跟随者可以根据该值对客户端进行重定向 prevLogIndex: 上一个日志条目的索引 prevLogTerm: 上一个日志条目的任期 entries[]: 需要被保存的日志条目（如果是心跳 RPC，则为空；为了提高效率可能一次性发送多个） leaderCommit: 领导者的已知已提交的最高的日志条目的索引 需要特别说明的是，prevLogIndex 和 prevLogTerm 是动态变化的，不是很好理解。 结果 term: 响应中的任期，对于领导者而言，它会更新自己的任期（其它领导者任期更高） success: 如果跟随者所含有的条目和 prevLogIndex 以及 prevLogTerm 匹配上了，则结果为 true 接受者的实现 如果领导者的任期小于接收者的当前任期，则返回 false 如果接受者日志中不能找到一个和 prevlogIndex 以及 prevLogTerm 一样的索引和任期的日志条目，则返回 false 如果接受者的条目和新条目发生了冲突（索引相同，任期不同），那么就删除这个已存在的条目以及它之后的所有条目 服务节点规则 所有服务节点 如果commitIndex &gt; lastApplied，那么 lastApplied 加一，并把log[lastApplied]应用到状态机中。 如果接收到的 RPC 请求或响应中，任期号T &gt; currentTerm，那么就令 currentTerm 等于 T，并切换状态为跟随者 跟随者 响应来自候选人和领导者的请求 如果超过选举超时时间没有收到当前领导人（即该领导人的任期需与这个跟随者的当前任期相同）的心跳/附加日志，就自己变成候选者 候选者 节点在转变成候选者后就立即开始选举过程 如果接收到大多数服务节点的选票，那么就变成领导者 如果接收到来自新的领导者的 AppendEntries RPC，转变成跟随者 如果选举过程超时，再次发起一轮选举 领导人 选举后，向每个服务节点发送 AppendEntries RPC（心跳）；以一定的时间间隔不停的重复发送，以阻止跟随者超时 如果接收到来自客户端的请求：附加条目到本地日志中，在条目被应用到状态机后响应客户端 如果跟随者的最后一个日志条目的索引值大于等于 nextIndex ，则以 AppendEntries RPC 发送从 nextIndex 开始的所有日志条目 如果成功：更新相应跟随者的 nextIndex 和 matchIndex 如果因为日志不一致而失败，则递减 nextIndex 并进行重试 关键特性 Election Safety: 选举安全性。对于一个给定的任期号，最多只会有一个领导人被选举出来。 Leader Append-Only: 领导者只附加原则。领导人绝对不会删除或者覆盖自己的日志，只会增加。 Log Matching: 日志匹配原则。如果两个日志在相同的索引位置的日志条目的任期号相同，那么就可以认为这两个日志从头到这个索引位置之间全部完全相同。 Leader Completeness: 领导者完全特性。如果某个日志条目在某个任期中已经被提交，那么该条目必然出现在更大任期号的所有领导者中。 State Machine Safety: 状态机安全特性。如果一个领导者已经将给定的索引值位置的日志条目应用到状态机中，那么其它任何的服务节点在这个索引位置不会应用一个不同的日志。 Raft 在任何时候都保证以上的各个特性，这也是 Raft 实现共识算法的基础。 阶段状态（角色）在任何时候，每个服务节点都处于以下三种状态之一： 领导者（Leader）：处理所有客户端的交互以及日志复制，一个任期内只能有一个领导者。跟随者（Follower）：绝大多数服务节点在大多数时间都处于跟随者的状态，这些服务节点完全处于被动状态，它们不会发起任何 RPC 请求，仅仅对其它服务节点发起的 RPC 请求做出响应。候选者（Candidate）：处于领导者（Leader）与跟随者（Follower）之间的一种状态，只在选举新领导者的过程中临时出现，当系统处于稳定状态，只会有一个领导者，其他的服务节点都是跟随者。 下图展示了相关状态图，描述了三种状态以及变化情况。 领导者任期 每届领导者都会有一个任期 term，term 是随着任期数递增的，并且不会被重复使用。Raft 系统中的服务节点会持久化相关数据，其中包括当前任期 term 值。任期这个概念非常重要，Raft 可以根据该值判断过期信息。服务节点之间在通信时会交换当前任期号。如果一个服务节点的当前任期小于另一个服务节点，则它将其当前任期更新为较大的值。如果候选者或领导者发现其当前任期已过时，则将立即恢复为跟随者状态。如果服务节点收到带有过期任期的请求，则会拒绝该请求。 超时处理Raft 中有两个控制选举的超时设置，第一个是选举超时时间（election timeout），另一个是心跳超时时间（heartbeat timeout）。Leader 发送心跳消息是以心跳超时指定的时间间隔进行的，也就是根据 heartbeat timeout 发送心跳信息。Follower 会在 election timeout 内等待 RPC 消息，如果没有等到则会主动发起选举请求。 在 Raft 中定义了随机超时时间，巧妙地使用随机选举超时时间策略把超时时间都分散开来，在大多数情况下只有一个服务节点先发起选举，这样就能减少因选票瓜分导致选举失败的情况。 Raft 算法中，随机超时时间具有 2 种含义：可以定义为不一样 Follower 等待 Leader 心跳信息超时的时间间隔是随机的。 Candidate 在一个随机时间间隔内没有获得 majority 投票（含自己一票），那么选举无效，然后 Candidate 发起新一轮的选举。该过程的选举超时时间间隔是随机的。 在 Raft 算法中，选举超时时间随机分配在 [150ms,300ms] 区间中，当 Follower 收到 RPC 消息时（包括选举 RPC、AppendEntries RPC） 都会重置其选举超时时间。 通信Raft 服务节点使用远程过程调用（RPC）进行通信，其中主要包括以下两种类型的 RPC （Raft 在传输快照时使用的是第三种 RPC）。 RequestVote RPC 由候选人在选举期间发送的 RPC 请求，该 RPC 请求对应的数据结构可以参见前文的 选举 RPC 数据结构 。 AppendEntries RPC 领导者在发送心跳和复制日志条目时会发送该 RPC 请求，该 RPC 请求对应的数据结构可以参见前文的 日志复制｜心跳 RPC 数据结构 。需要注意的是，心跳 RPC 相比日志复制 RPC 缺少了日志条目。 注意：AppendEntries RPC 具有一致性检查的功能，它是实现各节点间日志的一致性（或者说副本数据）的重要机制。 领导者选举Raft 使用心跳超时机制触发领导者选举。前面已经介绍，如果存在 Follower 在 election timeout 内没有收到来自 Leader 的心跳，则会主动发起选举。没有收到 Leader 的心跳的原因可能是：此时还没有 Leader、Leader 挂了、网络故障。 选举 Leader下面我们以初始化状态下，集群中所有的节点都是跟随者的状态为例介绍选举过程。 设定，节点初始化状态都是 Follower 状态，任期为 0 ，各节点随机分配的 election timeout 如上图所示 。需要注意的是，节点都会对相关属性进行持久化，防止节点宕机后数据丢失。 等待超时 通过上图可知，集群中没有领导者，而节点 A 的选举超时时间最小（150ms），因此它会最先因为没有等到领导者的信息（不仅仅心跳信息）而发生超时，进而主动发起选举。 切换到 Candidate 状态 节点 A 增加自己的任期编号并推荐自己为候选者，先给自己投上一张票，然后向其它节点发送请求投票 RPC 消息，通常这些请求是并行发出的。注意此时 RPC 消息携带的信息。 响应投票请求 如果其它节点收到候选者 A 的投票请求，在任期编号为 1 的这一任期内还么没有进行过投票，那么就会把票投给节点 A 并将自己记录的任期替换成候选者的任期编号（投票 RPC 中会携带），此外节点的选举超时时间会被重置。投票请求对应的数据结构可参考前文。 切换到 Leader 状态 如果候选人在选举超时时间内获得 majority 投票，那么它就会成为本届任期内新的领导者。 发送心跳消息节点 A 当选领导者后，它会立刻向其它节点发送心跳消息（AppendEntries RPC），避免其它节点触发新的选举，以维护自己领导者的地位。注意心跳消息一致性检查的作用，通过这种机制，领导者在获得权力的时候就不需要任何特殊的操作来恢复一致性，只需要进行正常的操作，然后日志就能自动的在回复附加日志 RPC 的一致性检查失败的时候自动趋于一致。关于日志复制内容下文详细介绍。以上是正常流选举 Leader 的过程，下面对候选者选举的所有可能情况进行介绍。 选举结果第一、在选举超时时间内得到了 majority 投票，然后它会将自己的状态切换到 Leader 并立即向集群中其它服务节点发送心跳消息，以建立它的领导者地位并防止进行新的选举。注意，收到 Leader 的 RPC 消息后（包括日志复制消息和心跳消息），其它节点的心跳超时时间会重置。这也是前面介绍的正常流的过程。 第二、在等待投票结果时收到其它节点发送的 AppendEntries RPC 消息（以领导者身份），如果该领导者的任期（包括在此次 RPC 消息中）不小于候选者当前任期，则候选者转成 Follower 状态，并更新自己的任期，否则候选者拒绝该 RPC 请求并继续处于候选人的状态。 第三、没有任何服务节点获胜。可能存在有多个服务节点同时成为 Candidate 导致了分票，没有服务节点获得 majority 投票。发生这种情况时，每一个 Candidate 都等待选举超时，其中先超时的会增加其任期，然后进行一轮新的选举。注意这里选举超时时间的重要性，没有该机制的话，选票就可能会被无限地瓜分，那么就延长了系统不可用的时间（没有leader是不能处理客户端相关请求的）。 选举规则选举过程涉及的约定如下，其中包含了 Raft 安全约定中的部分内容。 Leader 会周期性地向所有 Follower 发送心跳请求（不包含日志项的 AppendEntries RPC）来维持自己的权威，以并行的方式执行，防止 Follower 发起新的选举。 如果在 Follower 的选举超时时间内没有收到来自领导者的消息（心跳或日志复制），那么就推荐自己为候选人，发起领导者选举。 选举中获得 majority 投票（含自己一票）的 Candidate 将晋升为 Leader 。 一个任期内只允许有一个领导者，除非领导者宕机、网络故障等发生，其它节点才会发起新一轮的选举。 每一个服务节点最多会对一个任期号投出一张选票，按照先来先服务的原则。 节点 C 的任期编号为 1，先收到一个来自节点 A 的包含任期编号为 2 的投票请求，接着又收到一个来自节点 B 的包含任期编号为 2 的投票请求。按照先来先服务的原则，C 会把唯一的一张票投给节点 A 并更新自己的任期编号，当再收到节点 B 的投票请求时，发现已经对任期编号为 2 的投票请求做出了响应，于是就拒绝节点 B 的投票请求。 日志完整性高的跟随者不会投票给日志完整性低的候选者，日志完整性高低依据节点最后一条日志条目对应的任期编号及索引号，任期编号更大、索引号更大完整性就越高。 上述涉及到的选票的安全性，会在 Raft 安全部分进行详细说明。 日志复制日志结构Log 具有持久化、保序的特点，是大多数分布式系统的基石。在 Raft 算法中，副本数据是以日志的形式存在的，Raft 中的日志结构如下图所示： 日志由有序序号标记的条目组成，每个日志条目包含了：索引（index）、任期编码（term）以及指令（command）。其中提交状态（ committed） 指日志条目被复制到大多数节点后日志条目的状态，applied 是指节点将日志条目应用到状态机。 索引：用来标识日志条目在日志中的位置，是一个连续的、单调递增的整数。任期编号：创建当前日志条目的领导者的任期编号。指令：一般由客户端请求指定的、状态机需要执行的指令，本质上是客户端指定的数据。 每个服务节点无论是领导者还是跟随者，都各自保存一个日志副本，日志条目格式如上图所示。每个服务节点都必须保证日志能在奔溃后还可以恢复，所以日志本身需要持久化。领导者将创建的日志条目复制到大多数的服务节点上的时候，该日志条目就会被提交（例如上图中的日志条目 7），同时该日志之前的所有日志条目也都会被提交，包括由其它领导者创建的日志条目。注意，领导者不能单独直接提交其它领导者创建的日志条目，只能在提交自己任期的日志时间接提交，这也是安全性规定的。 日志复制操作客户端将指令发送给领导者，领导者首先将命令封装成一个日志条目并写入自己的日志中，然后向所有其它的跟随者发送 AppendEntries 的远程调用，通常以并行的方式将调用的消息发送到所有服务节点，然后等待这些消息的响应。一旦领导者收到足够多的响应，该日志条目也就具备提交状态，那么领导者就会将该日志条目的指令应用到状态机并将执行结果返回给客户端，否则返回异常给客户端。需要注意的是，领导者将日志条目应用到它的状态机时并不需要直接通知跟随者应用日志条目，领导者会通过后续的 AppendEntries 远程调用通知其它的服务节点，最终每个跟随者都会知道该记录已提交，然后也将该日志条目应用到它的状态机。 领导者不直接发送消息通知其它节点应用指定的日志条目，是 Raft 的一个优化。通过前文的 AppendEntries RPC 的数据结构，我们知道领导者的日志复制 RPC 消息或心跳消息，包含了领导者已知已提交的最高的日志条目索引，所以通过日志复制 RPC 消息或心跳消息，跟随者就可以知道领导者的日志提交位置信息。因此，当其它节点接收到领导者的心跳消息或日志复制消息后，就会将该日志条目应用到它的状态机。这个优化降低了处理客户端请求的延迟。 下图展示了正常流程的日志复制过程： 接收到客户端请求后，领导者基于客户端请求中的指令会创建一个日志条目并添加到本地日志中。 领导者通过日志复制 RPC ，将新的日志条目复制到其它的服务节点上。 当领导者将日志条目成功复制到大多数的服务节点上的时候，领导者会将该日志条目应用到它的状态机中。 领导者将执行的结果返回给客户端。 当跟随者接收到心跳消息或者日志复制消息后，如果跟随者发现领导者已经提交了某个日志条目而自己还没有，那么跟随者就将这条日志条目应用到本地的状态机中。 以上是理想状态下的日志过程，在实际环境中可能会遇到进程奔溃、服务节点宕机等问题，这些问题会导致日志不一致。下面我们对日志复制过程进行讨论，主要讨论 Leader 在不同阶段宕机的情况。关于跟随者节点或候选者节点宕机比较容易处理，我们会在后文简单介绍。 客户端数据到达 Leader 节点之前，Leader 宕机了。 这种情况对数据的一致性没有影响。 客户端数据到达 Leader 节点，但未复制到 Follower 节点 该阶段 Leader 挂掉，数据属于未提交状态，客户端不会收到响应。Follower 节点上没有该数据，重新选举 Leader 后客户端重试重新提交可成功。原来的 Leader 节点恢复作为 Follower 加入集群重新从当前任期的新 Leader 同步数据，强制保持和 Leader 数据一致。 客户端数据到达 Leader 节点，成功复制到 Follower 所有节点，但还未向 Leader 响应接收 这个阶段 Leader 挂掉，虽然数据在 Follower 节点处于未提交状态，但是保持一致。重新选举出 Leader 后可完成数据提交。 客户端数据到达 Leader 节点，成功复制到 Follower 大多数节点，但还未向 Leader 响应接收 这个阶段 Leader 挂掉，数据在 Follower 节点处于未提交状态且不一致，Raft 协议要求投票只能投给拥有最新数据的节点。所以，拥有最新数据的节点会被选为 Leader ，然后再强制同步数据到 Follower ，数据不会丢失并最终一致。注意，如果是成功复制到少数 Follower ,那么数据就可能会丢失。 客户端数据到达 Leader 节点，成功复制到 Folloer 所有或多数节点，数据在 Leader 处于已提交状态，但在 Follower 处于未提交状态 这个阶段 Leader 挂掉，选出的新 Leader 拥有最新的数据，对于数据缺失的 Follower 节点，执行同步机制会保证最终一致。 网络分区导致脑裂，出现双 Leader 网络分区将原先的 Leader 节点和 Follower 节点分隔开，Follower 收不到 Leader 的心跳将发起选举产生新的 Leader。这时就产生了双 Leader，原先的 Leader 独自在一个区，向它提交数据不可能复制到多数节点所以永远提交不成功。向新的 Leader 提交数据可以提交成功，网络恢复后旧的 Leader 发现集群中有更新任期的 Leader（任期更大），则自动降级为 Follower 并更新任期且从新 Leader 同步数据达成集群数据一致。 通过上述穷举不难看出，Raft 能很好地应对一致性问题。此外，跟随者崩溃了或处于慢响应状态，领导者会反复重试这个调用，直到跟随者恢复后，领导者就能重试成功。但是领导者并不需要等待每个跟随者的响应，它只需要等到足够数量的响应，保证记录已被大多数服务节点存储即可。所以这样就能在一般情况下获得很好的性能提升。也就是说，在通常情况下，只需要获得大多数最快的服务器的应答，领导者就可以立即执行命令，并将结果返回至客户端。 任期更新出现网络分区时，可能使集群中出现两个 Leader，网络恢复时该如何处理两个 Leader 的问题呢？Raft 使用任期号来处理。每个 RPC 请求都包括发送者的任期号，接收者收到请求后会将其与自己的任期号相比较，如果不匹配，则会更新那些过期的记录。所以如果发送者的任期比接收者小，接收者会立即拒绝 RPC 请求，并将包括了接受者任期信息的响应发送回发送者，当发送者接收到响应时会发现自己的任期号是过期的，此时它就会停下并作为跟随者继续运行，同时更新自己的任期号。反之，如果接受者的任期号更小，它同样会更新自己的任期号。 选举过程也会导致任期号的更新。候选者发起投票请求时会将自己的任期号随着 RPC 请求发送出去，这样所有的接收者都会更新自己的任期号，与候选者保持一致。 日志的一致性在 Raft 算法中，领导者处理不一致日志是通过强制跟随者直接复制自己的日志来解决的。也就是说，Raft 是通过以领导者的日志为准来实现各节点日志的一致，这意味着在跟随者中的冲突的日志条目会被领导者的日志覆盖。 日志记录的索引以及任期编号可以唯一标识一条日志条目。Raft 维护着以下特性： 如果两条日志条目拥有相同的索引和任期号，那么它们存储的指令也是相同的。 如果两条日志条目拥有相同的索引和任期号，那么它们之前的所有日志条目也全部相同。 第一个特性来自领导者创建日志条目的原则，领导者最多在一个任期里在指定的日志索引位置创建一条日志条目，而且日志条目在日志中的位置不会改变。第二个特性由一致性检查来保证。此外，如果某条日志条目是已提交的，那么其所有前序的记录都应该处于已提交状态。 AppendEntries 一致性检查Raft 强制在 AppendEntries 远程（日志复制和心跳）调用时进行一致性检查，如果发现问题则需要修复跟随者日志。要使得跟随者的日志和领导者一致，领导者就必须找到最后两者达成一致的地方，然后删除从那个点之后的所有日志条目，发送自己的日志给跟随者。而这些操作都在进行 AppendEntries 的一致性检查时完成。 领导者会为每个跟随者维护一个状态变量 nextIndex ，这个变量存储下一个需要发送给跟随者的日志条目的下标位置索引。当一个服务节点成为领导者后，它会将 nextIndex 值统一设置为自己最后一条日志条目的 index 加 1 。领导者会根据 AppendEntries 调用发现一致性问题，因为当跟随者接收到 AppendEntries 调用时都会进行检查。当领导者与跟随者进行 AppendEntries 通信时，都会包括日志条目下标索引 index 以及任期号 term 作为请求参数，这里日志条目就是 log[nextIndex-1] 的值。当消息到达跟随者后，它会将接收到的下标位置索引与任期与自己的日志信息进行比较，如果不一致就会拒绝当前请求。在被跟随者拒绝之后，领导者就会减小 nextIndex 值并进行重试。最终 nextIndex 会在某个位置使得领导者和跟随者的日志达成一致。当这种情况发生，附加日志 RPC 就会成功，这时就会把跟随者冲突的日志条目全部删除并且加上领导人的日志。一旦附加日志 RPC 成功，那么跟随者的日志就会和领导人保持一致，并且在接下来的任期里一直继续保持。 一致性检查流程概括如下： Leader 初始化 nextIndex 为自己最后一个 log index + 1 AppendEntries 中的 prevLogTerm 、prevLogindex 来自 logs[nextIndex -1] Follower 会将接收到的下标索引与任期与自己的日志信息进行比较，如果一致则返回 true，否则返回 false。 Leader 收到 Follower 的回复，如果返回值是 false，则 nextIndex -= 1，回到第 2 步进行重试，否则同步 nextIndex 后的所有日志条目。 从一致性检查的过程不难发现，如果 Follower 和 Leader 的日志差异过大会造成 AppendEntries RPC 拒绝次数。但是在实践中，失败是很少发生的并且也不大可能会有这么多不一致的日志。如果一定要优化的话，那么可以采用：当 AppendEntries RPC 请求被拒绝的时候，跟随者可以包含冲突的条目的任期号和自己存储的那个任期的最早的下标索引。借助这些信息，领导者可以减小 nextIndex 越过所有那个任期冲突的所有日志条目，这样就变成每个任期需要一次 AppendEntries RPC 而不是每个条目一次。 一致性检查机制非常重要，如果一个跟随者接受了来自领导者的新记录，那么它的日志记录也与领导者的日志记录是完全匹配的。此外，领导者刚当选时不需要任何特殊的操作来恢复一致性，它只需要进行正常的操作，然后日志就能自动的在回复 AppendEntries RPC 的一致性检查失败的时候自动趋于一致。 日志压缩Raft 的日志在正常操作中不断增长，但在实际的系统中，不能让日志无限增长，否则系统重启时需要花很长的时间进行回放，从而影响系统的可用性。Raft 采用了快照技术进行日志压缩来解决日志过大问题。快照的缺点就是不是增量的，即使内存中某个值没有变，下次做快照的时候同样会被 dump 到磁盘。 快照结构 由快照结构可知，服务节点使用一个新的快照替换其日志中提交的日志条目（如上图中：索引1到索引5），快照只存储当前状态（如上图中的变量x和y）。并且快照包含一些元数据，其中 last included index、last included term 分别是快照覆盖的最后一条日志条目的索引以及任期号，这两个值用于 AppendEntries RPC 的一致性检查。此外，为了支持集群成员变更，快照中也保存了最新的配置信息。关于成员变更问题在下文中会有详细说明。 Raft 中每个节点独立的创建快照，只包括已经应用到状态机的日志条目。一旦节点完成一次快照，就可以删除最后索引位置之前的所有日志和快照了。 快照发送正常情况下，Leader 的日志和 Follower 保持一致，但并不是所有情况都处于正常情况之下，有时可能因为 Follower 的反应缓慢或宕机造成日志不一致的情况，这时就需要 Leader 进行日志复制。如果在复制的过程中，Leader 需要发给 Follower 的日志条目被丢失了（因为 Leader 做了快照），这时会通过 InstallSnapshot RPC 发送快照给 Follower，如果没有丢失则直接从日志中复制即可。 InstallSnapshot RPC 数据结构的关键字段如下： term: Leader 的任期 leaderId: Leader 的id，以便于跟随者重定向请求 lastIncludedIndex: 快照中包含的最后一条日志条目的索引值 lastIncludedTerm: 快照中包含的最后一条日志条目的任期号…… 当跟随者收到了 InstallSnapshot RPC 发来的快照，它会根据自身的日志进行处理： Follower 的日志信息不包括快照中的日志信息，或者包含与快照冲突的信息，这种情况直接使用快照内容替代自己的日志。 快照中的日志仅是 Follower 日志的子集（前缀）（由于网络重传或者错误），那么 Follower 中被快照包括的部分被代替，之后的部分仍然保留。 快照创建各节点独立创建快照的方式背离了 Raft 的强领导者原则，因为跟随者可以在不知道领导者的情况下创建快照。虽然快照创建背离 Raft 的领导者原则，但是本质上还是以领导者为中心，并且这种背离是值得的。领导者的存在是为了解决在达成一致性时的冲突，但是在创建快照时一致性已经达成，因为创建快照是基于已经提交的日志条目的，所以没有领导者也是可以的。数据依然是从领导者传给跟随者。 不使用基于领导者的快照方案，一方面减少网络带宽的使用，降低了快照处理的时间，另一方面降低了 Leader 设计的复杂性。 存在问题写入频率问题 快照不能创建的太频繁，否则会消耗大量磁盘带宽和其它资源。快照创建的频率太低，需要承受耗尽存储容量的风险，同时增加了回放日志的时间。解决上述问题一个简单策略就是设置一个阈值。 服务暂停问题 写入快照需要消耗显著的一段时间，并且我们不希望影响到正常的操作。可以通过 Copy-On-Write 技术解决该问题，如利用 Linux 上的 fork 指令复制父进程及所有内存中的状态，在子进程创建快照，父进程继续提供 Raft 基本服务。 安全性Raft 的安全性是为了保证每一个状态机会按照相同顺序执行相同的指令，即保证每个服务节点上的日志（数据副本）是一致的。如果没有安全性，数据的正确性和一致性就不能得到保证。例如，一个跟随者可能会进入不可用状态，同时领导者已经提交了一些日志条目，如果没有安全性，这个跟随者可能会被选举为领导者并且覆盖这些日志条目。前面的章节主要描述了 Raft 算法是如何选举和复制日志的，其中已经穿插了不少的安全机制，本章节对安全性进行补充。 选举限制 Raft 是一种强领导者模型的算法，只有从集群中选举出 Leader 才能处理客户端请求和协调 Raft 内部运行机制（如：心跳、日志复制，以及它们对应的一致性检查等）。 一个任期内只允许有一个领导者，这是由一个服务节点某一任期内最多只能投一票 和 只有获得 majority 投票的服务节点才会成为 Leader 这两个原则来保证的。为了实现这种机制，服务节点需要保证将自己的投票信息持久化，这样就能在服务节点崩溃之后也能恢复到之前的状态。否则就会出现服务节点已经作出投票，但在崩溃重启后在同一任期内将票又投给了另外一个不同服务节点的情况。 当一个候选者发起投票请求，它会包括自身的日志记录信息，索引 index、任期号 term 。当跟随者接收到请求，它会将候选者的日志信息与自己的日志信息进行比较，如果投票者的日志更完整，那么它会拒绝投票。Raft 是通过比较两份日志中最后一条日志条目的索引值和任期号定义哪个日志更新。如果两份日志最后的条目的任期号不同，那么任期号大的日志更新，如果两份日志最后的条目任期号相同，则索引值大的更新。 Raft 保证所有之前的任期号中已经提交的日志条目都会出现在新的领导者中，不需要传送这些日志条目给领导者。这意味着日志条目是单向传送的，只能从领导者传给跟随者，并且领导者从不会覆盖自身本地日志中已经存在的日志条目。 当前任期提交 只要日志条目被复制到大多数的服务节点上，领导者就可以提交当前任期内的这一日志条目。领导者不会根据大多数原则去提交一个之前任期内的日志条目，只会根据大多数提交当前任期的日志条目。一旦当前任期的日志条目被提交，那么根据日志匹配特性，之前的日志条目也都会被间接的提交。如果领导者被选举后迟迟收不到客户端的请求，也就是意味着该领导者还不能确认哪些日志条目被提交，基于这个问题 Raft 通过让每个 Leader 在其任期开始时向日志中提交一个空的没有任何操作的日志条目，立即尝试复制来处理这个问题。 状态机安全 Raft 中某个节点将某一位置的日志条目应用到状态机，那么其它节点在同一位置不能应用不同的日志，也就是说，所有节点在同一位置（index）必须应用同样的日志。 成员变更Raft 算法是强领导者模型，领导者选举建立在大多数的基础之上，当集群中的成员变更时就可能同时存在新旧配置的 2 个大多数，进而出现两个领导者，这会破坏 Raft 集群的领导者唯一性，影响了集群的运行。 尽管可以通过暂停整个集群，更新所有配置，然后重启整个集群的方式来解决因集群变更带来的问题，但是在更改的时候集群会不可用。Raft 通过单节点变更来解决成员变更问题。这里我们需要明确两个定义： 配置 这里的配置是对集群中节点的描述，包括每台服务节点的 ID 、网络地址等。比如：A、B、C 组成的集群，那么集群的配置就是 [A、B、C] 集合。这些信息都非常重要，因为我们需要用它们来决定多数票的具体数量，从而进行领导者选举或用来提交日志。 单节点变更 单节点变更是利用一次变更一个节点，不会同时存在旧配置和新配置 2 个 大多数的特性，实现成员变更。 节点奔溃前面的章节对领导者节点的奔溃进行不同场景的介绍，核心关注点在于领导者节点奔溃的时机，不同时机奔溃集群处理不同，但是关键一点是大多数共识的日志条目不会丢失。跟随者和候选者奔溃后的处理方式相对比较简单，并且它们处理的方式相同。如果跟随者或者候选者奔溃了，后续发送它们的 RPC 消息都会失败。Raft 中处理这种失败就是简单的通过无限重试，如果奔溃的节点恢复了，那么 RPC 消息就会成功。如果一个服务节点完成了一个 RPC 请求，但是还没有响应的时候奔溃了，那么恢复后就会再次收到同样的请求。Raft 的 RPC 都是幂等的，所以这样重试不会造成任何问题。 客户端协议请求领导者 Raft 中的客户端发送所有请求给领导者，当客户端请求的不是领导者时，那么该服务节点会拒绝客户端的请求并向客户端提供它最近接收到的领导者的信息（AppendEntries RPC包含了领导者的网络地址）。如果领导者已经崩溃了，那么客户端的请求就会超时，客户端之后会再次重试随机挑选服务节点。 线性语意 Raft 的目标是要实现线性语义（每一次操作立即执行，只执行一次），但 Raft 是可以执行同一条指令多次的，如领导者提交日志条目后宕机了，那么客户端会和新的领导者重试这条指令，导致这条指令被再次执行。解决方案就是客户端对于每一条指令都赋予一个唯一的序列号。然后，状态机跟踪每条指令最新的序列号和相应的响应。如果接收到一条指令，它的序列号已经被执行了，那么就立即返回结果，而不重新执行指令。 Raft 读取的是状态机运算后的数据。Raft 的读操作虽然直接从领导者节点读取，但是在网络分区的情况下可能会返回脏数据，而线性的读操作必须不能返回脏数据，Raft 使用两个额外的措施保证这一点。首先，领导者必须有关于被提交日志的最新信息，领导者完全特性保证了领导者一定拥有所有已经被提交的日志条目，但是在它任期开始的时候，可能还不知道哪些是已经被提交的，为了知道这些信息，它需要在它的任期里提交一条日志条目。Raft 中通过领导者在任期开始的时候提交一个空白的没有任何操作的日志条目到日志中去来实现。第二，领导者在处理只读的请求之前必须检查自己是否已经被废黜了（更新的领导者被选举出来）。Raft 中通过让领导人在响应只读请求之前，先和集群中的大多数节点交换一次心跳信息来处理这个问题。 小结Raft 算法本质上是通过复制日志来实现共识的，和客户端的交互依赖状态机执行日志条目的指令，集群内部通过选举、心跳、日志复制来协调。Raft 具体的做法是将共识问题分解为多个独立的子问题，高度概括为：先选举出领导者，由它完全负责 replicated log 的管理。此外，接受客户端写请求，然后复制到跟随者节点，并在 安全 的时候执行这些请求。","categories":[{"name":"分布式","slug":"分布式","permalink":"https://gentryhuang.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"Raft","slug":"Raft","permalink":"https://gentryhuang.com/tags/Raft/"},{"name":"共识算法","slug":"共识算法","permalink":"https://gentryhuang.com/tags/%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95/"}]},{"title":"Redis原理 - 链表","slug":"redis_theory/data_structure/链表","date":"2021-03-16T11:33:59.000Z","updated":"2021-04-06T08:37:27.429Z","comments":false,"path":"posts/2362a8ea/","link":"","permalink":"https://gentryhuang.com/posts/2362a8ea/","excerpt":"","text":"链表 redis中的链表 链表作为一种常用的数据结构，内置在很多高级编程语言中，因为redis使用c语言并没有内置这中数据结构，所以redis构建了自己的链表实现。 redis链表节点的结构 12345678typedef struct listNode&#123; // 前置节点 struct listNode *prev; // 后置节点 struct listNode *next; // 节点的值 (可用于保存各种不同类型的值) void *value&#125;listNode; redis链表结构 123456789101112131415161718192021typedef struct list &#123; // 表头节点 listNode *head; // 表尾节点 listNode *tail; // 节点值复制函数，用于复制链表节点所保存的值 void *(*dup)(void *ptr); // 节点值释放函数，用于释放链表节点所保存的值 void (*free)(void *ptr); // 节点值对比函数，用于对比链表节点所保存的值和其他值是否相等 int (*match)(void *ptr, void *key); // 链表所包含的节点数量 unsigned long len;&#125; list; redis链表的特点 12345- 双端：链表节点带有prev和next指针，获取某个节点的前置节点和后置节点的复杂度都是O(1)- 无环：表头节点的prev指针和表尾节点的next指针都指向NULL，对链表的访问以NULL为终点- 带表头和表尾指针：使用list结构的head指针和tail指针，程序获取链表的表头节点和表尾节点的复杂度为O(1)- 带链表长度计数器：程序使用list结构的len属性标记链表中节点的个数，程序获取链表中节点个数的复杂度为O(1)- 多态：链表可以保存各种不同类型的值 链表在redis中的应用 链表被广泛用于实现redis的各种功能，如：列表键、发布与订阅、慢查询、监视器，redis服务器本身还使用链表来保存多个客户端的状态信息，以及使用链表来构建客户端输出缓冲区。","categories":[{"name":"Redis","slug":"Redis","permalink":"https://gentryhuang.com/categories/Redis/"}],"tags":[{"name":"Redis数据结构","slug":"Redis数据结构","permalink":"https://gentryhuang.com/tags/Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"Redis原理 - 简单动态字符串","slug":"redis_theory/data_structure/简单动态字符串","date":"2021-03-13T11:00:50.000Z","updated":"2021-04-06T08:37:12.759Z","comments":false,"path":"posts/aa1d8127/","link":"","permalink":"https://gentryhuang.com/posts/aa1d8127/","excerpt":"","text":"简单动态字符串 初识动态字符串 redis没有直接使用C语言传统的字符串表示（以空字符结尾的字符数组），而是自己构建了一种名为简单动态字符串（simple dynamic string，SDS）的抽象类型，并将SDS作为redis的默认字符串表示。 在redis中，c字符串只会作为字符串字面量用在一些无须对字符串值进行修改的地方，比如日志。当Redis需要的不仅仅是一个字符串字面量，而是一个可以被修改的字符串值时，redis就会使用SDS来表示字符串值。 值的注意的是，对于redis中的key都是使用SDS来实现的。此外，SDS除了用来保存Redis数据库中的字符串值之外，SDS还被用作缓冲区（buffer）: AOF模块中的AOF缓冲区，以及客户端状态中的输入缓冲区。 sds的结构 12345678struct sdshdr&#123; // 记录buf数组中已使用字节的数量等价于sds所保存字符串的长度 int len; // 记录buf数组中未使用字节的数量 int free; // 字节数组，用于保存字符串 char buf[];&#125; 注意： sds遵循c字符串以空字符结尾的惯例，保存空字符的1字节空间不计算在sds的len属性中，并且为空字符分配额外的1字节空间，以及添加空字符到字符串末尾等操作，都是由sds函数自动完成的。遵循空字符结尾的好处是，sds可以直接使用一部分C字符串函数库里面的函数。 sds与c字符串的区别 c语言使用的简单字符串表示方式，并不能满足redis对字符串在安全性、效率以及功能方面的要求。 3.1 常数复杂度获取字符串长度 因为c字符串并不记录自身的长度信息，所以要获取长度就必须遍历整个字符串，故获取字符串长度的复杂度为O(N)。而redis的sds结构中通过len属性记录了sds的长度，故获取字符串长度的复杂度为O(1)。注意，设置和更新sds长度的工作是由sds的API在执行时自动完成的，使用sds无须进行任何手动修改长度的操作。 3.2 避免缓冲区溢出 c字符串不记录自身长度，很容易造成缓冲区溢出。与c字符串不同，sds的空间分配策略完全杜绝了发生缓冲区溢出的可能性，当sds api需要对sds进行修改时，api会先检查sds的空间是否满足需要，如果不满足的话，api会自动将sds的空间扩展至执行所需的大小，然后才执行实际的修改操作，因此使用sds既不需要手动修改sds的空间大小，也不会出现c字符串中可能出现的缓冲区溢出问题。 1234567891011121314151617sds sdscatlen(sds s, const void *t, size_t len) &#123; size_t curlen = sdslen(s); //追加时先进行扩容，后面详细说明 s = sdsMakeRoomFor(s,len); if (s == NULL) return NULL; //拼接字符串 memcpy(s+curlen, t, len); sdssetlen(s, curlen+len); s[curlen+len] = '\\0'; return s;&#125;// s:原数组 //strlen(t) 需拼接的目标数组的长度sds sdscat(sds s, const char *t) &#123; return sdscatlen(s, t, strlen(t));&#125;​ 3.3 内存分配与释放 因为c字符串的长度和底层数组的长度之间存在着关联性，所以每次增加或者缩短一个c字符串，程序都总要对保存这个c字符串的数字进行一次分配操作，但是内存分配操作涉及到复杂的算法，并且可能需要执行系统调用，所以通常是一个比较耗时的操作。redis作为数据库，经常被用于速度要求严苛、数据被频繁修改的场合，为了避免c字符串的这种缺陷，sds通过未使用空间解除了字符串长度和底层数组长度之间的关联，通过未使用空间，sds实现了空间预分配和惰性空间释放两种优化策略。 空间预分配 空间预分配用于优化sds的字符串增长操作：当sds的api对一个sds进行修改，并且需要对sds进行空间扩展的时候，程序不仅会为sds分配修改所必须要的空间，还会为sds分配额外的未使用空间。通过空间预分配策略，redis可以减少连续执行字符串增长操作所需的内存重新分配次数，在扩展sds空间之前，sds api 会先检查未使用空间是否足够，如果足够就直接使用未使用空间，而不需要执行内存重新分配。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// redis 扩容源码/* * 对 sds 中 buf 的长度进行扩展，确保在函数执行之后， * buf 至少会有 addlen + 1 长度的空余空间 * （额外的 1 字节是为 \\0 准备的） * * 返回值 * sds ：扩展成功返回扩展后的 sds * 扩展失败返回 NULL * * 复杂度 * T = O(N) */sds sdsMakeRoomFor(sds s, size_t addlen) &#123; struct sdshdr *sh, *newsh; // 获取 s 目前的空余空间长度 size_t free = sdsavail(s); size_t len, newlen; // s 目前的空余空间已经足够，无须再进行扩展，直接返回 if (free &gt;= addlen) return s; // 获取 s 目前已占用空间的长度 len = sdslen(s); sh = (void*) (s-(sizeof(struct sdshdr))); // s 最少需要的长度 newlen = (len+addlen); // 根据新长度，为 s 分配新空间所需的大小 if (newlen &lt; SDS_MAX_PREALLOC) // 如果新长度小于 SDS_MAX_PREALLOC // 那么为它分配两倍于所需长度的空间 newlen *= 2; else // 否则，分配长度为目前长度加上 SDS_MAX_PREALLOC newlen += SDS_MAX_PREALLOC; // T = O(N) newsh = zrealloc(sh, sizeof(struct sdshdr)+newlen+1); // 内存不足，分配失败，返回 if (newsh == NULL) return NULL; // 更新 sds 的空余长度 newsh-&gt;free = newlen - len; // 返回 sds return newsh-&gt;buf;&#125; 额外分配未使用空间数量的计算策略： 对sds修改后，sds的长度（即len属性的值）小于1MB，那么程序分配和len属性同样大小的未使用空间，这时sds的len属性的值将和free属性的值相同。例如：修改后sds的len变成10字节，那么程序也会分配10字节的未使用空间，sds的buf数组的实际长度：10 + 10 + 1 = 21字节 对sds修改后，sds的长度大于等于1MB，那么程序会分配1MB的未使用空间。例如：修改后sds的len变成30MB，那么程序会分配1MB的未使用空间，sds的buf数组的时间长度：30MB + 1MB + 1byte 惰性空间释放 惰性空间释放用于优化sds的字符串缩短操作：当sds的api需要缩短sds保存的字符串时，程序并不立即使用内存重分配来回收缩短后多来的字节，而是使用free属性将这些字节的数量纪录起来，用于将来对sds进行增长操作时，这些未使用空间可能就派上用场了。注意，sds也提供了相应的api，可以真正地释放sds的未使用空间，所以不用担心惰性空间释放策略会造成内存浪费。 3.4 二进制安全 c字符串中的字符必须符合某种编码，并且除了字符串的末尾之外，字符串里不能包含空字符，否则在读取的时候会被默认为结束字符，这些限制使得c字符串只能保存文本数据，不能保存图片、音视频、压缩文件这类的二进制数据。sds的api都是二进制安全的，所有的sds api都会以二进制的方式处理sds存放在buf数组里的数据,程序不会对其中的数据做任何限制、过滤，数据写入时是什么样，它被读取时就是什么样。这也是将sds的buf属性称为字节数组的原因，redis不是用这个数组来保存字符，而是用它来保存一系列二进制数据。 c字符串和sds之间的区别 123456 C字符串 SDS- 获取字符串长度的复杂度为O（n） 获取字符串长度的复杂度O（1）- API是不安全的，可能造成缓冲区溢出 API是安全的- 修改字符串长度N次，必然要执行N次内存重分配 修改字符长度N次，最多执行N次内存重分配- 只能保存文本数据 可以保存文本或者二进制数据- 可使用&lt;string.h&gt;库中的函数 可使用一部分&lt;string.h&gt;库中的函数 sds更多的api可参考源码","categories":[{"name":"Redis","slug":"Redis","permalink":"https://gentryhuang.com/categories/Redis/"}],"tags":[{"name":"Redis数据结构","slug":"Redis数据结构","permalink":"https://gentryhuang.com/tags/Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"Dubbo源码分析 - 异步改造","slug":"rpc/Dubbo异步改造","date":"2021-02-13T16:00:00.000Z","updated":"2021-04-06T08:30:21.668Z","comments":false,"path":"posts/c812f120/","link":"","permalink":"https://gentryhuang.com/posts/c812f120/","excerpt":"","text":"概述从 2.7.0 版本开始，Dubbo 的所有异步编程接口开始以 CompletableFuture 为基础，不仅支持了服务提供方的异步执行，而且对当前的异步调用功能进行了增强。异步改造引入了一些功能接口和实现，以及对部分逻辑进行了调整，但底层逻辑并没有改变，本篇文章将对 Dubbo 的异步演进进行介绍。 调用方式 Dubbo 的远程调用中大致可以分为以上 4 种调用方式： oneway: 客户端发送消息后，不需要接收响应。对于不需要关心服务响应结果的请求适合 oneway 通信。 sync: Dubbo 默认的通信方式，即同步调用。 async: 异步调用范畴，使用 Future 的方式获取结果。 future: 异步调用范畴，使用 CompletableFuture 获取结果，也支持通过 Future 的方式获取结果。 注意： Dubbo 中的调用方式可以分为两大类，oneway 和 twoway ，对于 Dubbo 协议来说，会对这两种方式做分别处理，对于非 Dubbo 协议不会特别区分。 Dubbo 2.6.x 异步实现Dubbo 2.6.x 的异步实现是针对消费端异步，只需指定调用方式为异步调用，并在需要结果的地方从 RpcContext 中取出 Future 获取结果即可。 实现方式 指定异步调用12&lt;!-- 设置 async = true，表示异步调用。默认是 false，同步调用 --&gt;&lt;dubbo:reference id=\"demoService\" check=\"false\" interface=\"com.alibaba.dubbo.demo.DemoService\" async=\"true\"/&gt; 通过上下文取出 Future123String hello = demoService.sayHello(\"world\"); // call remote methodFuture&lt;String&gt; future = RpcContext.getContext().getFuture();String result = future.get(); 具体调用实现可以参考 Dubbo异步调用 。 存在问题Dubbo 2.6.x 提供了一定的异步编程能力，但其异步方式存在以下问题： Future 获取方式不够直接，业务方需要从 RpcContext 中获取。如果同时进行多个异步调用，如果使用不当很容易造成上下文污染。 Future 接口无法实现自动回调，而且定义的 ResponseFure (2.7 已经废弃)虽然支持回调，但支持的异步场景有限，并且不支持 Future 间的相互协调。 不支持服务端异步。 Dubbo 2.7.x 异步实现Dubbo 2.7.x 异步改造是对 Dubbo 2.6.x 异步功能的增强，引入的 CompletableFuture 既支持 Future 又支持 Callback 的调用方式，使用方可以根据需要自行选择。 基础模型Dubbo 2.7.x 对异步实现进行了改造，引入了相关的接口和实现类，异步实现需要这些相关的基础模型配合完成。下面我们先对基础模型进行介绍。 ResultResult 相关的继承关系如下图所示： 在 Dubbo 2.6.x 中统一使用 RpcResult 表示调用结果，Dubbo 2.7.x 中废弃了 RpcResult ，采用以下三个对象表示结果状态。 AsyncRpcResult 表示的是一个异步的、未完成的RPC调用，是在调用链中实际传递的对象。 AppResponse 表示的是服务端返回的具体响应，相当于 Dubbo 2.6.x 中的 RpcResult 。其子类是 DecodeableRpcResult。 CompletableFuture 表示的是服务端返回的结果，由调用端创建，用于封装 AppResponse 对象。其中 DefaultFuture 继承该类。 三者关系：AppResponse -&gt; CompletableFuture -&gt; AsyncResult ，下面我们对其进行介绍。 AppResponse1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class AppResponse implements Result &#123; private static final long serialVersionUID = -6925924956850004727L; // 响应结果 private Object result; // 返回的异常信息 private Throwable exception; // 返回的附加信息 private Map&lt;String, Object&gt; attachments = new HashMap&lt;&gt;(); public AppResponse() &#123; &#125; public AppResponse(Object result) &#123; this.result = result; &#125; public AppResponse(Throwable exception) &#123; this.exception = exception; &#125; @Override public Object recreate() throws Throwable &#123; // 1 异常处理 if (exception != null) &#123; // fix issue#619 try &#123; // get Throwable class Class clazz = exception.getClass(); while (!clazz.getName().equals(Throwable.class.getName())) &#123; clazz = clazz.getSuperclass(); &#125; // get stackTrace value Field stackTraceField = clazz.getDeclaredField(\"stackTrace\"); stackTraceField.setAccessible(true); Object stackTrace = stackTraceField.get(exception); if (stackTrace == null) &#123; exception.setStackTrace(new StackTraceElement[0]); &#125; &#125; catch (Exception e) &#123; // ignore &#125; throw exception; &#125; // 2 结果 return result; &#125; // 省略其它方法 getter/setter 方法&#125; AppResponse 是调用的实际返回类型，相当于 Dubbo 2.6.x 中的 RpcResult ，理论上不需要实现 Result 接口，这样做是为了兼容。 DecodeableRpcResult属性123456789101112131415161718192021222324252627public class DecodeableRpcResult extends AppResponse implements Codec, Decodeable &#123; private static final Logger log = LoggerFactory.getLogger(DecodeableRpcResult.class); // 通道 private Channel channel; // 序列化类型 private byte serializationType; // 序列化相关的输入流 private InputStream inputStream; // 响应对象 private Response response; // 调用信息 private Invocation invocation; // 标志是否已经解码 private volatile boolean hasDecoded; public DecodeableRpcResult(Channel channel, Response response, InputStream is, Invocation invocation, byte id) &#123; Assert.notNull(channel, \"channel == null\"); Assert.notNull(response, \"response == null\"); Assert.notNull(is, \"inputStream == null\"); this.channel = channel; this.response = response; this.inputStream = is; this.invocation = invocation; this.serializationType = id; &#125;&#125; 解码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697+--- DecodeableRpcResult @Override public void decode() throws Exception &#123; // 没有解码，则进行解码 if (!hasDecoded &amp;&amp; channel != null &amp;&amp; inputStream != null) &#123; try &#123; // 解码 decode(channel, inputStream); &#125; catch (Throwable e) &#123; if (log.isWarnEnabled()) &#123; log.warn(\"Decode rpc result failed: \" + e.getMessage(), e); &#125; response.setStatus(Response.CLIENT_ERROR); response.setErrorMessage(StringUtils.toString(e)); &#125; finally &#123; hasDecoded = true; &#125; &#125; &#125;---@Override public Object decode(Channel channel, InputStream input) throws IOException &#123; if (log.isDebugEnabled()) &#123; Thread thread = Thread.currentThread(); log.debug(\"Decoding in thread -- [\" + thread.getName() + \"#\" + thread.getId() + \"]\"); &#125; // 1 确定序列化方式，用于反序列化 ObjectInput in = CodecSupport.getSerialization(channel.getUrl(), serializationType) .deserialize(channel.getUrl(), input); // 2 读取一个 byte 的标志位，其值可能有 6 种 byte flag = in.readByte(); // 3 根据标志位判断当前结果中包含的信息，并调用不同的方法进行处理 switch (flag) &#123; case DubboCodec.RESPONSE_NULL_VALUE: break; case DubboCodec.RESPONSE_VALUE: handleValue(in); break; case DubboCodec.RESPONSE_WITH_EXCEPTION: handleException(in); break; case DubboCodec.RESPONSE_NULL_VALUE_WITH_ATTACHMENTS: handleAttachment(in); break; case DubboCodec.RESPONSE_VALUE_WITH_ATTACHMENTS: // 根据 RpcInvocation 中记录的返回值类型读取返回结果，并设置到当前类的 result 字段 handleValue(in); // 读取附加信息并设置到当前类的 attachmetns 中 handleAttachment(in); break; case DubboCodec.RESPONSE_WITH_EXCEPTION_WITH_ATTACHMENTS: handleException(in); handleAttachment(in); break; default: throw new IOException(\"Unknown result flag, expect '0' '1' '2' '3' '4' '5', but received: \" + flag); &#125; if (in instanceof Cleanable) &#123; ((Cleanable) in).cleanup(); &#125; return this; &#125; ---/** * 处理结果 * * @param in * @throws IOException */ private void handleValue(ObjectInput in) throws IOException &#123; try &#123; // 1 返回结果类型 Type[] returnTypes; if (invocation instanceof RpcInvocation) &#123; returnTypes = ((RpcInvocation) invocation).getReturnTypes(); &#125; else &#123; returnTypes = RpcUtils.getReturnTypes(invocation); &#125; // 2 根据返回结果类型获取结果 Object value = null; if (ArrayUtils.isEmpty(returnTypes)) &#123; // This almost never happens? value = in.readObject(); &#125; else if (returnTypes.length == 1) &#123; value = in.readObject((Class&lt;?&gt;) returnTypes[0]); &#125; else &#123; value = in.readObject((Class&lt;?&gt;) returnTypes[0], returnTypes[1]); &#125; // 3 设置结果 result setValue(value); &#125; catch (ClassNotFoundException e) &#123; rethrow(e); &#125; &#125; DecodeableRpcResult 主要对响应结果进行解码，从字节流中获取数据对象。 CompletableFutureCompletableFuture 是 Java 8 提供的异步编程类，Dubbo 2.7.x 中的 DefaultFuture 继承了 CompletableFuture ，Dubbo 协议下对于 twoway 请求都会返回一个 DefaultFuutre 对象。此外，DefaultFuture 支持在请求的时候指定线程池，用来处理请求的响应，具体的我们会在下一篇文章中分析。 AsyncRpcResultAsyncRpcResult 是在调用链中实际传递的对象，表示一个异步的，未完成的RPC调用。注意，它并不是实际的调用结果，AppResponse 才是业务结果。 属性12345678910111213141516171819202122232425public class AsyncRpcResult implements Result &#123; private static final Logger logger = LoggerFactory.getLogger(AsyncRpcResult.class); // 当回调发生时，RpcContext 可能已经被更改。即执行 AsyncRpcResult 上添加的回调方法的线程可能先后处理过多个不同的 AsyncRpcResult 。 // 因此，我们应该保留当前RpcContext实例的引用，并在回调执行之前恢复它。 private RpcContext storedContext; private RpcContext storedServerContext; // 此次 RPC 调用关联的线程池 private Executor executor; // 此次 RPC 调用关联的 Invocation 对象 private Invocation invocation; // 请求返回的对象 （由调用端创建） private CompletableFuture&lt;AppResponse&gt; responseFuture; // 在构造方法中除了接收发送请求返回的 CompletableFuture&lt;AppResponse&gt; 对象，还会保存当前的 RPC 上下文 public AsyncRpcResult(CompletableFuture&lt;AppResponse&gt; future, Invocation invocation) &#123; this.responseFuture = future; this.invocation = invocation; this.storedContext = RpcContext.getContext(); this.storedServerContext = RpcContext.getServerContext(); &#125;&#125; 需要说明的是，responseFuture 属性不仅针对 Dubbo 协议，HTTP等协议调用返回结果也是 CompletableFuture 对象，都是由调用端创建。区别在于 Dubbo 协议一般返回的是 DefaultFuture 对象，而 HTTP 等协议会构造一个 CompletableFuture 对象，我们会在下面内容提到。 获取结果AsyncRpcResult 获取结果本质上需要先获取发送请求返回的 CompletableFuture ，也就是 responseFuture 属性，然后再从 responseFuture 中获取 AppResponse 对象，最后调用其对应的方法。 获取 CompletableFuture1234+--- AsyncRpcResult public CompletableFuture&lt;AppResponse&gt; getResponseFuture() &#123; return responseFuture; &#125; 获取 AppResponse123456789101112131415+--- AsyncRpcResult public Result getAppResponse() &#123; try &#123; // 如果完成，则获取 AppResponse if (responseFuture.isDone()) &#123; return responseFuture.get(); &#125; &#125; catch (Exception e) &#123; // This should not happen in normal request process; logger.error(\"Got exception when trying to fetch the underlying result from AsyncRpcResult.\"); throw new RpcException(e); &#125; // 获取默认的 AppResponse return createDefaultValue(invocation); &#125; 12345678910111213141516171819202122232425262728+--- AsyncRpcResult /** * 该方法将始终在最大 timeout 等待之后返回： * 1. 如果value在超时前返回，则正常返回。 * 2. 如果timeout之后没有返回值，则抛出TimeoutException。 * * @return * @throws InterruptedException * @throws ExecutionException */ @Override public Result get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; // 针对 ThreadlessExecutor 的特殊处理，这里调用 waitAndDrain() 等待响应 if (executor != null &amp;&amp; executor instanceof ThreadlessExecutor) &#123; ThreadlessExecutor threadlessExecutor = (ThreadlessExecutor) executor; threadlessExecutor.waitAndDrain(); &#125; return responseFuture.get(timeout, unit); &#125; @Override public Result get() throws InterruptedException, ExecutionException &#123; if (executor != null &amp;&amp; executor instanceof ThreadlessExecutor) &#123; ThreadlessExecutor threadlessExecutor = (ThreadlessExecutor) executor; threadlessExecutor.waitAndDrain(); &#125; return responseFuture.get(); &#125; 其中 ThreadlessExecutor 是一个特殊的线程池，主要用来解决同步调用模式下的响应，是对线程模型的优化，我们在下一篇文章中进行详细说明。 获取结果123456789101112+--- AsyncRpcResult @Override public Object recreate() throws Throwable &#123; RpcInvocation rpcInvocation = (RpcInvocation) invocation; // 1 如果是服务端的异步实现，则从上下文中取。 // 为什么？ 因为接口返回的结果是 CompletableFuture,属于异步范畴（服务端的异步），和消费端异步类似。 if (InvokeMode.FUTURE == rpcInvocation.getInvokeMode()) &#123; return RpcContext.getContext().getFuture(); &#125; // 2 获取 AppResponse 中的结果 return getAppResponse().recreate(); &#125; AsyncRpcResult.recreate() 方法是获取结果的方法，也就是从 AppResponse 中获取结果。 添加回调回调是 Dubbo 2.7.x 异步改造的重要角色，AsyncRpcResult 支持添加回调方法，而这个回调方法会被包装一层并注册到 responseFuture 上，具体实现如下： 12345678910111213+--- AsyncRpcResult public Result whenCompleteWithContext(BiConsumer&lt;Result, Throwable&gt; fn) &#123; // 在responseFuture之上注册回调 this.responseFuture = this.responseFuture.whenComplete((v, t) -&gt; &#123; // 将当前线程的 RpcContext 记录到临时属性中，然后将构造函数中存储的 RpcContext 设置到当前线程中，为后面的回调执行做准备 beforeContext.accept(v, t); // 执行回调 （使用的 RpcContext 是回调所属服务方法的调用线程的 RpcContext） fn.accept(v, t); // 恢复线程原有的 RpcContext afterContext.accept(v, t); &#125;); return this; &#125; 在添加回调时，需要使用 beforeContext 和 afterContext 来保证执行回调的线程的 RpcContext 是最初创建 AsyncRpcResult 对象的线程对应的 RpcContext，执行完回调后需要将执行回调的线程的 RpcContext 恢复到原有值。其中 beforeContext 用于保存执行回调线程的 RpcContext，并将最初创建 AsyncRpcResult 对象的线程的 RpcContext 临时设置到执行回调用线程中，为执行回调做准备。afterContext 用于恢复执行回调用的线程原有的 RpcContext 。具体实现如下： 12345678910111213141516171819+--- AsyncRpcResult private RpcContext tmpContext; private RpcContext tmpServerContext; private BiConsumer&lt;Result, Throwable&gt; beforeContext = (appResponse, t) -&gt; &#123; // 将当前线程的 RpcContext 记录到 tmpContext 中 tmpContext = RpcContext.getContext(); tmpServerContext = RpcContext.getServerContext(); // 将构造函数中存储的 RpcContext (也就是创建 AsyncRpcResult 线程的 RpcContext) 设置到当前线程中 RpcContext.restoreContext(storedContext); RpcContext.restoreServerContext(storedServerContext); &#125;; private BiConsumer&lt;Result, Throwable&gt; afterContext = (appResponse, t) -&gt; &#123; // 将当前线程的 RpcContext 恢复到原始值 RpcContext.restoreContext(tmpContext); RpcContext.restoreServerContext(tmpServerContext); &#125;; 如此一来，AsyncRpcResult 就可以随意添加回调，无需担心 RpcContext 被污染。 AsyncRpcResult 整个是为异步请求设计的，但是 Dubbo 中默认的请求方式是同步的，那么 Dubbo 又是如何支持同步调用的呢？Dubbo 进行服务引用时，在 AbstractProtocol.refer() 方法中，Dubbo 会将 AbstractProtocol.protocolBindingRefer() 方法实现返回的 Invoker 对象使用 AsyncToSyncInvoker 封装一层，该对象中的调用逻辑会对同步调用专门处理，我们在下面的内容中进行介绍。相比较而言，Dubbo 2.6.x 在 Dubbo 协议做了异步转同步处理，就是在调用时拿到 DefaultFuture 后立即阻塞等待结果。HTTP 协议就没有异步调用支持，而 Dubbo 2.7.x 使用了 AbstractInvoker 对 Future 功能进行统一支持，也就是 HTTP 协议也基本上支持了调用异步。 InvokerAsyncToSyncInvokerAsyncToSyncInvoker 描述了异步转同步的逻辑，是对 AsyncRpcResult 获取结果的补充，触发时机是在执行调用的时候。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class AsyncToSyncInvoker&lt;T&gt; implements Invoker&lt;T&gt; &#123; // 服务引用的 Invoker private Invoker&lt;T&gt; invoker; public AsyncToSyncInvoker(Invoker&lt;T&gt; invoker) &#123; this.invoker = invoker; &#125; @Override public Class&lt;T&gt; getInterface() &#123; return invoker.getInterface(); &#125; @Override public Result invoke(Invocation invocation) throws RpcException &#123; Result asyncResult = invoker.invoke(invocation); try &#123; // 如果是同步调用，则调用 get() 方法，阻塞等待响应返回。 // 调用的是 AsyncRpcResult.get 方法，其底层调用的是 CompletableFuture 的 get 方法 if (InvokeMode.SYNC == ((RpcInvocation) invocation).getInvokeMode()) &#123; /** * NOTICE! * must call &#123;@link java.util.concurrent.CompletableFuture#get(long, TimeUnit)&#125; because * &#123;@link java.util.concurrent.CompletableFuture#get()&#125; 被证明有严重的性能下降。 */ asyncResult.get(Integer.MAX_VALUE, TimeUnit.MILLISECONDS); &#125; &#125; catch (InterruptedException e) &#123; throw new RpcException(\"Interrupted unexpectedly while waiting for remote result to return! method: \" + invocation.getMethodName() + \", provider: \" + getUrl() + \", cause: \" + e.getMessage(), e); &#125; catch (ExecutionException e) &#123; Throwable t = e.getCause(); if (t instanceof TimeoutException) &#123; throw new RpcException(RpcException.TIMEOUT_EXCEPTION, \"Invoke remote method timeout. method: \" + invocation.getMethodName() + \", provider: \" + getUrl() + \", cause: \" + e.getMessage(), e); &#125; else if (t instanceof RemotingException) &#123; throw new RpcException(RpcException.NETWORK_EXCEPTION, \"Failed to invoke remote method: \" + invocation.getMethodName() + \", provider: \" + getUrl() + \", cause: \" + e.getMessage(), e); &#125; else &#123; throw new RpcException(RpcException.UNKNOWN_EXCEPTION, \"Fail to invoke remote method: \" + invocation.getMethodName() + \", provider: \" + getUrl() + \", cause: \" + e.getMessage(), e); &#125; &#125; catch (Throwable e) &#123; throw new RpcException(e.getMessage(), e); &#125; // 非同步调用直接返回调用结果 AsyncRpcResult return asyncResult; &#125; // 省略其它代码&#125; AsyncToSyncInvoker 是 Invoker 的装饰器，负责将异步调用转换成同步调用，也就是调用 AsyncRpcResult 中的 CompletableFuture.get 方法实现同步等待。相比 Dubbo 2.6.x 还是有很大区别的，Dubbo 2.6.x 使用 Future.get 功能阻塞等待，业务线程将处于阻塞等待状态，返回结果时需要消费端 Dubbo 线程池将结果写到 DefaultFuture 中，业务线程才能取出并返回。Dubbo 2.7.x 彻底优化了这种线程模型，关于优化的背景和实现会在下一篇文章中进行介绍，这里先了解即可。 AbstractProxyInvokerAbstractProxyInvoker 是 Dubbo 框架在服务暴露过程中创建的对象，由 ProxyFactory.getInvoker 创建，是对服务接口实现的封装。该过程对 Dubbo 中所有协议一致。 AbstractInvokerDubbo 在服务引用时会创建消费端的 Invoker，对于不同的协议创建的 Invoker 有所不同。下面我们对 Dubbo 协议 和 使用 HTTP 通信的协议 创建 Invoker 流程进行分析。其中每个协议创建的 Invoker 都会继承 AbstractInvoker 抽象类，该抽象类中定义了通用的执行逻辑，如调用模式的确定。 构造方法12345678910111213141516171819202122232425262728293031323334public abstract class AbstractInvoker&lt;T&gt; implements Invoker&lt;T&gt; &#123; protected final Logger logger = LoggerFactory.getLogger(getClass()); // 当前 Invoker 对象封装的业务接口类型 private final Class&lt;T&gt; type; // 当前 Invoker 关联的 URL 对象 private final URL url; // 当前 Invoker 关联的一些附加信息 private final Map&lt;String, Object&gt; attachment; // 标志 Invoker 的状态 private volatile boolean available = true; private AtomicBoolean destroyed = new AtomicBoolean(false); // 构造方法 public AbstractInvoker(Class&lt;T&gt; type, URL url) &#123; this(type, url, (Map&lt;String, Object&gt;) null); &#125; public AbstractInvoker(Class&lt;T&gt; type, URL url, String[] keys) &#123; this(type, url, convertAttachment(url, keys)); &#125; public AbstractInvoker(Class&lt;T&gt; type, URL url, Map&lt;String, Object&gt; attachment) &#123; if (type == null) &#123; throw new IllegalArgumentException(\"service type == null\"); &#125; if (url == null) &#123; throw new IllegalArgumentException(\"service url == null\"); &#125; this.type = type; this.url = url; this.attachment = attachment == null ? null : Collections.unmodifiableMap(attachment); &#125;&#125; invoke 方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364+--- AbstractInvoker @Override public Result invoke(Invocation inv) throws RpcException &#123; // if invoker is destroyed due to address refresh from registry, let's allow the current invoke to proceed if (destroyed.get()) &#123; logger.warn(\"Invoker for service \" + this + \" on consumer \" + NetUtils.getLocalHost() + \" is destroyed, \" + \", dubbo version is \" + Version.getVersion() + \", this invoker should not be used any longer\"); &#125; RpcInvocation invocation = (RpcInvocation) inv; invocation.setInvoker(this); if (CollectionUtils.isNotEmptyMap(attachment)) &#123; invocation.addObjectAttachmentsIfAbsent(attachment); &#125; // 1 从上下文中取出 附加信息 Map&lt;String, Object&gt; contextAttachments = RpcContext.getContext().getObjectAttachments(); if (CollectionUtils.isNotEmptyMap(contextAttachments)) &#123; invocation.addObjectAttachments(contextAttachments); &#125; // 2 设置调用模式 SYNC, ASYNC, FUTURE 。注意，oneway 调用方式 // 根据以下方式确定调用模式： // 1) 根据返回值类型是否是 CompletableFuture ，或方法名是 $invokeAsync，则是 FUTURE 模式。这个属于服务端异步。 // 2) 根据 async 属性，如果设置 async=true ，则是 ASYNC 模式 // 3) 默认是 SYNC 模式 invocation.setInvokeMode(RpcUtils.getInvokeMode(url, invocation)); // 3 如果是异步调用的模式，则给本次调用添加一个唯一id (FUTURE 模式不属于) RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation); AsyncRpcResult asyncResult; try &#123; // 4 调用子类实现的 doInvoker() 方法 asyncResult = (AsyncRpcResult) doInvoke(invocation); // 对调用异常的处理 // 4.1 创建 CompletableFuture 对象，使用该对象包装 AppResponse 对象 // 4.2 使用 AppResponse 对象包装异常信息 // 4.3 使用 AsyncRpcResult 最后包装 CompletableFuture 对象 &#125; catch (InvocationTargetException e) &#123; // biz exception Throwable te = e.getTargetException(); if (te == null) &#123; asyncResult = AsyncRpcResult.newDefaultAsyncResult(null, e, invocation); &#125; else &#123; if (te instanceof RpcException) &#123; ((RpcException) te).setCode(RpcException.BIZ_EXCEPTION); &#125; asyncResult = AsyncRpcResult.newDefaultAsyncResult(null, te, invocation); &#125; &#125; catch (RpcException e) &#123; if (e.isBiz()) &#123; asyncResult = AsyncRpcResult.newDefaultAsyncResult(null, e, invocation); &#125; else &#123; throw e; &#125; &#125; catch (Throwable e) &#123; asyncResult = AsyncRpcResult.newDefaultAsyncResult(null, e, invocation); &#125; // 5 使用 FutureContext 保存 FutureAdapter，FutureAdapter 中会封装 AsyncRpcResult 中的 CompletableFuture 对象 RpcContext.getContext().setFuture(new FutureAdapter(asyncResult.getResponseFuture())); return asyncResult; &#125; AbstractInvoker 的 invoke 方法是调用服务的模版方法，具体调用细节交给具体子类实现。 设置附加信息到调用信息 Invocation 中。 设置调用模式 FUTURE: 根据返回值类型是否是 CompletableFuture ，或方法名是否是 $invokeAsync，则是 FUTURE 模式。这个属于服务端异步。 ASYNC: 根据 async 属性，如果设置 async=true ，则是 ASYNC 模式。 SYNC: 默认调用模式。 异步调用时，给本地调用添加一个唯一id，并设置到附加属性中。 调用具体子类 Invoker 对象的 doInvoke 方法，不管是哪个子类实现，调用的结果都是 AsyncRpcResult 类型。 如果调用异常，则对异常进行处理。 使用上下文保存 FutureAdapter ，其中 FutureAdapter 中会封装 AsyncRpcResult 中的 CompletableFuture 对象。在后续的链路中可以使用 Future 的异步功能。 注意: 相比 Dubbo 2.6.x，AbstractInvoker 的模版方法中实现了异步逻辑，也就是任何协议的服务调用都支持 Future 的异步功能。在 Dubbo 2.6.x 中非 Dubbo 协议大都不支持异步调用特性。 Dubbo协议异步实现消费端DubboInvoker 是 Dubbo 协议在消费端创建的 Invoker 。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768+--- DubboInvoker @Override protected Result doInvoke(final Invocation invocation) throws Throwable &#123; RpcInvocation inv = (RpcInvocation) invocation; // 1 获取此次调用的方法名 final String methodName = RpcUtils.getMethodName(invocation); // 2 向 Invocation 中添加附加信息，这里将 URL 的 path 和 version 添加到附加信息中 inv.setAttachment(PATH_KEY, getUrl().getPath()); inv.setAttachment(VERSION_KEY, version); // 3 选择一个 ExchangeClient 实例 ExchangeClient currentClient; if (clients.length == 1) &#123; currentClient = clients[0]; &#125; else &#123; currentClient = clients[index.getAndIncrement() % clients.length]; &#125; try &#123; // 4 判断是否是 oneway 调用，不关心服务端的响应结果。调用后直接返回一个空 AsyncRpcResult boolean isOneway = RpcUtils.isOneway(getUrl(), invocation); // 根据调用方法名和配置，计算此次调用的超时时间 int timeout = calculateTimeout(invocation, methodName); // 5 request() 方法会相应创建 DefaultFuture 对象以及检测超时的定时任务，而 send() 方法则不会创建这些东西。 if (isOneway) &#123; // 是否等待底层 NIO 将请求发出，等待时间默认 1s，1s未发送则抛出异常 boolean isSent = getUrl().getMethodParameter(methodName, Constants.SENT_KEY, false); currentClient.send(inv, isSent); // 返回已完成状态的 AsynRpcResult 即 AsynRpcResult -&gt; CompletableFuture（已完成状态） -&gt; AppResponse（空结果） return AsyncRpcResult.newDefaultAsyncResult(invocation); // 需要关注返回值的请求 &#125; else &#123; // 5 获取处理响应的线程池 ExecutorService executor = getCallbackExecutor(getUrl(), inv); // 6 调用 ExchangeClient.request() 方法，将 Invocation 包装成 Request 请求发送出去，同时会创建相应的 DefaultFuture 返回。 CompletableFuture&lt;AppResponse&gt; appResponseFuture = // currentClient.request 返回的是 DefaultFuture，DefaultFuture 继承了 CompletableFuture 。 currentClient.request(inv, timeout, executor) // 增加了一个回调，取出其中的 AppResponse 对象。 // thenApply 是一个回调,obj 是 上一个任务的结果。返回的 AppResponse 表示的是 服务端返回的具体响应。 .thenApply(obj -&gt; (AppResponse) obj); // save for 2.6.x compatibility, for example, TraceFilter in Zipkin uses com.alibaba.xxx.FutureAdapter FutureContext.getContext().setCompatibleFuture(appResponseFuture); // 7 这里将 CompletableFuture （其实是 DefaultFuture） 封装成 AsyncRpcResult 并返回 AsyncRpcResult result = new AsyncRpcResult(appResponseFuture, inv); // 8 设置处理响应的线程池 result.setExecutor(executor); // 9 返回调用 return result; &#125; &#125; catch (TimeoutException e) &#123; throw new RpcException(RpcException.TIMEOUT_EXCEPTION, \"Invoke remote method timeout. method: \" + invocation.getMethodName() + \", provider: \" + getUrl() + \", cause: \" + e.getMessage(), e); &#125; catch (RemotingException e) &#123; throw new RpcException(RpcException.NETWORK_EXCEPTION, \"Failed to invoke remote method: \" + invocation.getMethodName() + \", provider: \" + getUrl() + \", cause: \" + e.getMessage(), e); &#125; &#125; DubboInvoker 进行远程调用时，会分别对 oneway 和 twoway 进行处理。 处理 oneway 调用方式 不需要响应结果，直接使用客户端的 send 方法即可，该方法不会返回服务端的响应。DubboInvoker 会返回一个空结果的 AsyncRpcResult 对象给业务方。 处理 twoway 调用方式 需要响应结果，使用客户端的 request 方法发送请求，该方法会创建并返回本次调用的 DefaultFuture 对象，当服务端响应时会更新 DefaultFuture 中的结果信息。此外，Dubbo 对线程模型进行了优化，可以指定处理响应的线程池，特别是同步调用的线程池，这个我们在下一篇文章中详细介绍。 相比较 Dubbo 2.6.x 中的 DefaultFuture，引入了 CompletableFuture 可以支持多异步场景，并且支持 Future 间的相互协调，此外提供了良好的回调方法，避免等待响应而阻塞。这是对 ExchangeClient 的改造，将 Dubbo 2.6.x 中异步编程接口都替换成了 CompletableFuture 。介绍完消费端的异步实现后，下面我们来看看服务端的异步实现。 服务端AbstractProxyInvoker 是 Dubbo 协议在服务端创建的 Invoker，它封装的是服务接口实现。Dubbo 协议下的服务暴露会使用 ProxyFactory#getInvoker 将服务接口实现封装成 AbstractProxyInvoker。当收到请求时，通道处理器链上的每个处理器都会对该请求进行各自逻辑的处理，其中 HeaderExchangeHandler#handleRequest 会将请求交给 DubboProtocol 中的 ExchangeHandler 处理，Dubbo 协议下的服务端异步实现处理逻辑就在这三者中。在分析源码之前，我们先看服务端异步实现的例子： 异步实现服务提供端异步执行将阻塞的业务从 Dubbo 内部线程池切换到业务自定义线程，在一定程度上避免 Dubbo 线程池的过度占用，有助于避免不同服务间的互相影响。 定义 CompletableFuture 签名接口 服务接口定义123public interface AsyncService &#123; CompletableFuture&lt;String&gt; sayHello(String name);&#125; 服务实现123456789101112131415public class AsyncServiceImpl implements AsyncService &#123; @Override public CompletableFuture&lt;String&gt; sayHello(String name) &#123; RpcContext savedContext = RpcContext.getContext(); // 建议为supplyAsync提供自定义线程池，避免使用JDK公用线程池 return CompletableFuture.supplyAsync(() -&gt; &#123; try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return \"async response from provider.\"; &#125;); &#125;&#125; 通过 return CompletableFuture.supplyAsync() ，业务执行已从 Dubbo 线程切换到业务线程，避免了对 Dubbo 线程池的阻塞。 服务消费方 CompletableFuture 签名接口是服务提供方的异步实现，消费端同普通消费一致，Dubbo 内部会根据调用的方法返回值类型等方式确定 调用模式，具体的在后面的源码部分介绍。 结果Dubbo 2.7 虽然支持了服务端的异步，但 Dubbo 的线程模型本身就是异步处理的方式，因此服务端的异步特性相对还是有点鸡肋的。 了解了服务端异步实现后，下面我们从代码层面分析，Dubbo 如何就 CompletableFuture 签名服务接口方法实现异步的。 HeaderExchangeHandler 处理请求123456789101112131415161718192021222324252627282930313233+--- HeaderExchangeHandler void handleRequest(final ExchangeChannel channel, Request req) throws RemotingException &#123; Response res = new Response(req.getId(), req.getVersion()); // 省略异常处理代码 Object msg = req.getData(); try &#123; // 1 使用上层通道处理器处理消息，其实就是 DubboProtocol 中的 ExchangeHandler CompletionStage&lt;Object&gt; future = handler.reply(channel, msg); // 2 请求处理完成回调，将结果发送到对端 future.whenComplete((appResult, t) -&gt; &#123; try &#123; if (t == null) &#123; res.setStatus(Response.OK); res.setResult(appResult); &#125; else &#123; res.setStatus(Response.SERVICE_ERROR); res.setErrorMessage(StringUtils.toString(t)); &#125; // 3 将处理后的结果发送到对端 channel.send(res); &#125; catch (RemotingException e) &#123; logger.warn(\"Send result to consumer failed, channel is \" + channel + \", msg is \" + e); &#125; &#125;); &#125; catch (Throwable e) &#123; res.setStatus(Response.SERVICE_ERROR); res.setErrorMessage(StringUtils.toString(e)); channel.send(res); &#125; &#125; 相比较与 Dubbo 2.6.x 中的处理请求逻辑，这里使用了 CompletableFuture 的完成回调，避免了阻塞等待请求完成。这得益于对通道处理 ExchangeHandler 的异步方法的改造，也就是 DubboProtocol 中的 ExchangeHandler 的实现。 DubboProtocol 的处理器1234567891011121314151617181920+--- DubboProtocolprivate ExchangeHandler requestHandler = new ExchangeHandlerAdapter() &#123; @Override public CompletableFuture&lt;Object&gt; reply(ExchangeChannel channel, Object message) throws RemotingException &#123; Invocation inv = (Invocation) message; // 获取暴露的 Invoker，这里是 AbstractProxyInvoker Invoker&lt;?&gt; invoker = getInvoker(channel, inv); RpcContext.getContext().setRemoteAddress(channel.getRemoteAddress()); // 如果服务端异步实现，这里返回的 result 是一个 AsyncRpcResult 类型对象，其中的 AppResonse 中的值并非 CompletableFuture 类型，而是 CompletableFuture 封装的 AppResponse Result result = invoker.invoke(inv); return result.thenApply(Function.identity()); &#125; // 省略其它代码&#125; DubboProtocol 中的 ExchangeHandler 的请求处理方法返回的是 CompletableFuture 对象，这同样是 Dubbo 2.7.x 中的改造，服务方法的结果统一包装成 CompletableFuture 类型，在服务端的 Invoker 的执行逻辑中就可以体现这一点，下面我们就来看 AbstractProxyInvoker 。 AbstractProxyInvoker服务端的 Invoker，直接封装服务接口实现。 123456789101112131415161718192021222324252627282930313233343536373839+--- AbstractProxyInvoker @Override public Result invoke(Invocation invocation) throws RpcException &#123; try &#123; // 1 执行服务方法，如 DemoService.sayHello Object value = doInvoke(proxy, invocation.getMethodName(), invocation.getParameterTypes(), invocation.getArguments()); // 2 将方法结果以 CompletableFuture 对象形式进行封装。 // 注意：如果服务方法返回类型是 CompletableFuture ，则无需再使用 CompletableFuture 包装。这个针对服务端的异步实现。 CompletableFuture&lt;Object&gt; future = wrapWithFuture(value); // 3 执行 future 逻辑 CompletableFuture&lt;AppResponse&gt; appResponseFuture = future.handle((obj, t) -&gt; &#123; // 4 使用 AppResponse 封装实际结果 AppResponse result = new AppResponse(); if (t != null) &#123; if (t instanceof CompletionException) &#123; result.setException(t.getCause()); &#125; else &#123; result.setException(t); &#125; &#125; else &#123; result.setValue(obj); &#125; return result; &#125;); // 5 统一包装成 AsyncRpcResult 对象 return new AsyncRpcResult(appResponseFuture, invocation); &#125; catch (InvocationTargetException e) &#123; if (RpcContext.getContext().isAsyncStarted() &amp;&amp; !RpcContext.getContext().stopAsync()) &#123; logger.error(\"Provider async started, but got an exception from the original method, cannot write the exception back to consumer because an async result may have returned the new thread.\", e); &#125; return AsyncRpcResult.newDefaultAsyncResult(null, e.getTargetException(), invocation); &#125; catch (Throwable e) &#123; throw new RpcException(\"Failed to invoke remote proxy method \" + invocation.getMethodName() + \" to \" + getUrl() + \", cause: \" + e.getMessage(), e); &#125; &#125; AbstractProxyInvoker 的执行逻辑主要有四点，下面进行总结： 执行服务接口实例方法，如 demoService.sayhello 方法。 将服务实例方法的调用结果包装成 CompletableFuture ，如果是服务端异步实现（服务接口方法返回类型是 CompletableFuture），则无需对结果进行包装，直接使用返回的 CompletableFuture 即可。 执行 CompletableFuture 的回调方法，将实际结果封装到 AppResponse 中。 将返回结果包装成 AsyncRpcResult 对象。 HTTP 协议实现消费端Dubbo 中的 HTTP 协议在消费端创建的 Invoker 是一个 AbstractInvoker 匿名对象。 1234567891011121314151617181920212223242526272829303132333435363738@Override+--- AbstractProxyProtocol protected &lt;T&gt; Invoker&lt;T&gt; protocolBindingRefer(final Class&lt;T&gt; type, final URL url) throws RpcException &#123; // 1 调用子类实现的 doRefer() 方法返回一个目标服务接口的代理对象 // 2 使用 ProxyFactory.getInvoker() 方法将服务接口的代理对象封装成一个 Invoker ，类型是 AbstractProxyInvoker。 final Invoker&lt;T&gt; target = proxyFactory.getInvoker(doRefer(type, url), type, url); // 3 创建 AbstractInvoker 的匿名对象 Invoker&lt;T&gt; invoker = new AbstractInvoker&lt;T&gt;(type, url) &#123; @Override protected Result doInvoke(Invocation invocation) throws Throwable &#123; try &#123; // 4 调用 AbstractProxyInvoker.invoke 方法，返回的结果是 AsyncRpcResult Result result = target.invoke(invocation); // FIXME result is an AsyncRpcResult instance. Throwable e = result.getException(); if (e != null) &#123; for (Class&lt;?&gt; rpcException : rpcExceptions) &#123; if (rpcException.isAssignableFrom(e.getClass())) &#123; throw getRpcException(type, url, invocation, e); &#125; &#125; &#125; return result; &#125; catch (RpcException e) &#123; if (e.getCode() == RpcException.UNKNOWN_EXCEPTION) &#123; e.setCode(getErrorCode(e.getCause())); &#125; throw e; &#125; catch (Throwable e) &#123; throw getRpcException(type, url, invocation, e); &#125; &#125; &#125;; invokers.add(invoker); return invoker; &#125; Dubbo 协议下的服务调用不仅引入 CompletableFuture ，还对方法等进行改造，如 HeaderExchangeClient.request 方法。HTTP 协议下的服务调用异步改造力度相对不大，异步实现主要依赖引入的 CompletableFuture ，以及在 AbstractInvoker 中统一的 Future 异步功能。 特别说明： 为什么将 doRefer 返回的代理对象通过 ProxyFactory.getInvoker 包装成 AbstractProxyInvoker 对象？因为此代理对象具备和远程服务通信的能力，原则上可以使用该代理对象调用服务接口方法，但是调用信息是存在 Invocation 中，将该代理对象包装成 AbstractProxyInvoker 可以根据 Invocation 中的信息动态选择目标服务方法。本质上和 DubboInvoker 类似，DubboInvoker 和远程服务通信需要使用 ExchangeClient，将调用信息 Invocation 交给它即可实现目标服务的调用，这里的代理对象就相当于 DubboInvoker 中的 ExchangeClient 。 服务端使用 JsonRpcServer 暴露服务，具体过程可参考：HTTP协议服务暴露 。 1234+--- HttpProtocol.doExport// 5 创建 JsonRpcServer，暴露服务JsonRpcServer skeleton = new JsonRpcServer(impl, type);JsonRpcServer genericServer = new JsonRpcServer(impl, GenericService.class); 其中的具有服务能力的 impl 是 ProxyFactory#getProxy(org.apache.dubbo.rpc.Invoker&lt;T&gt;, boolean) 创建的代理对象，具体逻辑如下： 12345678910111213141516171819202122232425262728293031+--- AbstractProxyProtocol // 省略无关代码 public &lt;T&gt; Exporter&lt;T&gt; export(final Invoker&lt;T&gt; invoker) throws RpcException &#123; final String uri = serviceKey(invoker.getUrl()); Exporter&lt;T&gt; exporter = (Exporter&lt;T&gt;) exporterMap.get(uri); if (exporter != null) &#123; // When modifying the configuration through override, you need to re-expose the newly modified service. if (Objects.equals(exporter.getInvoker().getUrl(), invoker.getUrl())) &#123; return exporter; &#125; &#125; // 其中的 invoker 是由 ProxyFactory#getInvoker 创建 final Runnable runnable = doExport(proxyFactory.getProxy(invoker, true), invoker.getInterface(), invoker.getUrl()); exporter = new AbstractExporter&lt;T&gt;(invoker) &#123; @Override public void unexport() &#123; super.unexport(); exporterMap.remove(uri); if (runnable != null) &#123; try &#123; runnable.run(); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; &#125; &#125; &#125;; exporterMap.put(uri, exporter); return exporter; &#125; 不难看出最终处理请求的还是上面方法传入的 invoker 对象，该对象中包含真正的服务实例。而传入的 invoker 对象是由 ProxyFactory#getInvoker 创建的，对象类型是 AbstractProxyInvoker ，下面以 JavassistProxyFactory 工厂为例。 1234567891011121314151617public class JavassistProxyFactory extends AbstractProxyFactory &#123; // 省略无关代码 @Override public &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) &#123; // TODO Wrapper cannot handle this scenario correctly: the classname contains '$' final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf('$') &lt; 0 ? proxy.getClass() : type); return new AbstractProxyInvoker&lt;T&gt;(proxy, type, url) &#123; @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable &#123; return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments); &#125; &#125;; &#125;&#125; 我们把前文的 AbstractProxyInvoker 的代码实现粘贴过来。 123456789101112131415161718192021222324252627282930313233343536373839+--- AbstractProxyInvoker @Override public Result invoke(Invocation invocation) throws RpcException &#123; try &#123; // 1 执行服务方法，如 DemoService.sayHello Object value = doInvoke(proxy, invocation.getMethodName(), invocation.getParameterTypes(), invocation.getArguments()); // 2 将方法结果以 CompletableFuture 对象形式进行封装。 // 注意：如果服务方法返回类型是 CompletableFuture ，则无需再使用 CompletableFuture 包装。这个针对服务端的异步实现。 CompletableFuture&lt;Object&gt; future = wrapWithFuture(value); // 3 执行 future 逻辑 CompletableFuture&lt;AppResponse&gt; appResponseFuture = future.handle((obj, t) -&gt; &#123; // 4 使用 AppResponse 封装实际结果 AppResponse result = new AppResponse(); if (t != null) &#123; if (t instanceof CompletionException) &#123; result.setException(t.getCause()); &#125; else &#123; result.setException(t); &#125; &#125; else &#123; result.setValue(obj); &#125; return result; &#125;); // 5 统一包装成 AsyncRpcResult 对象 return new AsyncRpcResult(appResponseFuture, invocation); &#125; catch (InvocationTargetException e) &#123; if (RpcContext.getContext().isAsyncStarted() &amp;&amp; !RpcContext.getContext().stopAsync()) &#123; logger.error(\"Provider async started, but got an exception from the original method, cannot write the exception back to consumer because an async result may have returned the new thread.\", e); &#125; return AsyncRpcResult.newDefaultAsyncResult(null, e.getTargetException(), invocation); &#125; catch (Throwable e) &#123; throw new RpcException(\"Failed to invoke remote proxy method \" + invocation.getMethodName() + \" to \" + getUrl() + \", cause: \" + e.getMessage(), e); &#125; &#125; 对于使用 HTTP 协议的服务实现，更多的是在形式上保持统一，和 Dubbo 协议的服务实现类似。 小结Dubbo 2.6.x 及之前版本中使用 Future 实现异步功能，并且不支持服务端的异步，这在功能设计上存在一些问题，Dubbo 2.7.x 基于 CompletableFuture 对异步功能进行了增强，弥补了功能设计上的一些问题。由于 CompletableFuture 实现了 CompletionStage 和 Future 接口，因此仍然支持 Dubbo 2.6 中通过 get() 或者 isDone() 方法轮询结果。但是，不建议使用 get() 这样阻塞的方式获取结果，因为这样做的的话就丢失了异步操作带来的性能提升。CompletableFuture 提供了良好的回调支持，如 whenComplete() 等方法可以在逻辑完成后，执行回调逻辑。同时 CompletableFuture 支持 Future 间的相互协调，如 thenApply() 等方法。正是由于 CompletableFuture 强大的功能，我们可以更加流畅地使用回调而无需等待响应而阻塞调用线程。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"Dubbo源码分析 - 线程模型改造","slug":"rpc/线程模型改造","date":"2021-02-05T16:00:00.000Z","updated":"2021-04-06T08:30:05.212Z","comments":false,"path":"posts/13d5a11a/","link":"","permalink":"https://gentryhuang.com/posts/13d5a11a/","excerpt":"","text":"前言在 异步改造 中对 Dubbo 2.7.x 中异步调用和异步实现进行了详细说明。其中 Dubbo 协议下，在对异步调用进行分析时，我们发现 ThreadlessExecutor 被多次使用，此外 ExchangeChannel#request 方法支持设置处理响应的线程池。本篇文章我们将对 Dubbo 线程池模型优化进行介绍，其中消费端线程池模型优化就是从这两个方面进行改造的。 概述Dubbo 协议下创建 NIO 服务器和客户端都会分别创建各自的线程池。2.7.x 之前版本的线程池的创建是由派发器 Dispatcher 创建的 WrappedChannelHandler 完成的。Dispatcher 和 WrappedChannelHandler 之间的关系可以参考 线程模型 。2.7.x 新增了 ExecutorRepository 用于创建和管理线程池。 WrappedChannelHandler 的子类实现了消息派发功能，即决定了 Dubbo 以哪种线程模型处理收到的消息和事件。因为 NIO 服务器端和客户端都会初始化线程池，这意味着服务端和客户端都可能使用自己的线程池来处理本端收到的消息和事件，具体的策略由 WrappedChannelHandler 的子类决定。 从 Issues 谈起点这里：消费者中建立了太多DubboClientHandler线程 描述 Dubbo Version: 2.5.3我有一个非常大的provider 集群（30个实例）。然后我们发现在客户端，为每一个实例，都准备了一个独立线程池，所以我们看到有30个线程池以去发起消费请求，这个从jstack堆栈上可以证明，因为里面很多线程组的名字是类似DubboClientHandler-IP1-XXX，其中ip都是不一样的。 问题 之所以我们提供如此大的服务集群，是因为我们希望最大化TPS，但现在集群是大了，但是消费者又因此导致巨大的线程消耗（高CPU）。我们能否通过配置改变这个线程的模型，例如用一个共享的线程池去处理所有的服务实例，这样最大的线程数便可控了。 待优化 对 2.7.5 版本之前的 Dubbo 应用，在 WrappedChannelHandler 中会为 每个客户端连接启动一个线程池，因为不会根据 URL 复用线程池，这意味着每个消费端都浪费着一定的资源。此外，对于同步调用，业务线程发起调用后要阻塞等待响应，服务端返回响应后需要消费端线程池将结果保存起来然后通知业务线程，这个过程业务线程处于空闲状态，而接收响应却是消费端线程池完成，被阻塞的业务线程没有被有效利用。当面临需要消费大量服务且并发数比较大的大流量场景时（典型如网关类场景），经常会出现消费端线程数分配过多的问题。 Dubbo 2.6.x 线程模型这里以 Netty 实现为例，Mina 等 NIO 组件类似。 服务端123456+--- NettyServer public NettyServer(URL url, ChannelHandler handler) throws RemotingException &#123; // ChannelHandlers.wrap方法，用来包装 ChannelHandler，实现Dubbo 线程模型的功能 // 线程名前缀 DubboServerHandler super(url, ChannelHandlers.wrap(handler, ExecutorUtil.setThreadName(url, SERVER_THREAD_POOL_NAME))); &#125; 在创建、启动 Netty 服务时会通过 ChannelHandlers.wrap 方法为传入的 ChannelHandler 依次包装 AllChannelHandler(默认)、HeartbeatHandler以及 MultiMessageHandler 。其中 AllChannelHanlder 是消息派发处理器，其父类 WrappedChannelHandler 会开启一个线程池，也就是每启动一个服务器就创建对应的一个线程池。 消费端12345678910111213+--- NettyClient public NettyClient(final URL url, final ChannelHandler handler) throws RemotingException &#123; // wrapChannelHandler方法，包装ChannelHandler，其中实现了 Dubbo 线程模型的功能。 super(url, wrapChannelHandler(url, handler)); &#125; protected static ChannelHandler wrapChannelHandler(URL url, ChannelHandler handler) &#123; // 1 设置线程名前缀，即URL.threadname=xxx ，默认：DubboClientHandler url = ExecutorUtil.setThreadName(url, CLIENT_THREAD_POOL_NAME); // 2 设置使用的线程池类型，即 URL.threadpool=xxx ，默认： cached。注意这个和Server的区别 url = url.addParameterIfAbsent(Constants.THREADPOOL_KEY, Constants.DEFAULT_CLIENT_THREADPOOL); // 3 包装通道处理器 return ChannelHandlers.wrap(handler, url); &#125; 在创建、启动 Netty 客户端时会通过 ChannelHandlers.wrap 方法为传入的 ChannelHandler 依次包装 AllChannelHandler(默认)、HeartbeatHandler以及 MultiMessageHandler 。其中 AllChannelHanlder 是消息派发处理器，其父类 WrappedChannelHandler 会开启一个线程池，也就是每创建一个连接就创建对应的一个线程池。 开启线程池123456789101112131415161718192021+--- WrappedChannelHandler public WrappedChannelHandler(ChannelHandler handler, URL url) &#123; this.handler = handler; this.url = url; // 1 基于SPI机制创建线程池 executor = (ExecutorService) ExtensionLoader.getExtensionLoader(ThreadPool.class).getAdaptiveExtension().getExecutor(url); String componentKey = Constants.EXECUTOR_SERVICE_COMPONENT_KEY; // 2 如果是消费端 if (Constants.CONSUMER_SIDE.equalsIgnoreCase(url.getParameter(Constants.SIDE_KEY))) &#123; componentKey = Constants.CONSUMER_SIDE; &#125; // 3 基于SPI机制创建线程池存储对象 DataStore dataStore = ExtensionLoader.getExtensionLoader(DataStore.class).getDefaultExtension(); // 4 添加线程池到 DataStore中 // 注意： AbstractClient 或 AbstractServer 从 DataStore 获得线程池 dataStore.put(componentKey, Integer.toString(url.getPort()), executor); &#125; 缓存线程池12345678910111213// DataStore 只有一个实现public class SimpleDataStore implements DataStore &#123; /** * 缓存已有的线程池 * key1: 表示线程池属于服务端侧还是消费端侧 * key2: 线程池关联服务的端口 * value: 线程池 */ private ConcurrentMap&lt;String, ConcurrentMap&lt;String, Object&gt;&gt; data = new ConcurrentHashMap&lt;String, ConcurrentMap&lt;String, Object&gt;&gt;(); // 省略其它代码&#125; 从源码层面上也说明了，在 WrappedChannelHandler 中会为每个连接启动一个线程池，并没有根据 URL 的信息对同一个线程池进行复用，而是直接通过 SPI 机制找到 ThreadPool 具体实现，然后创建线程池。注意，最终缓存的是最新的线程池。 线程池模型注意，创建 Dubbo 线程池都是强调消费端而没有强调服务端，因为一个节点部署 Dubbo 应用，一般只会创建一个 NIO 服务（以主机绑定的ip和port启动NIO服务），对应的线程池也只会初始化一个。 消费端同步请求的线程模型如下图所示： 请求-响应流程如下： 业务线程发出请求，拿到一个 Future 实例。 业务线程紧接着调用 Future.get 阻塞等待请求结果返回。 当响应返回之后，交由连接关联的 Consumer 端线程池进行反序列化等处理。 待处理完成之后，通过 Future.set 方法将业务结果置回，然后通知业务线程取结果。 当前版本的设计，消费端会维护一个线程池，而且线程池是按照连接隔离的 ，也就是每个连接独享一个线程池。此外，当面临需要消费大量服务且并发数比较大的场景时，如 网关类场景，可能会导致消费端的线程数不断增加，最终引发CPU飙升、内存溢出。 Dubbo 2.7.5 线程模型为了解决以上两个问题，Dubbo 2.7.5 对线程模型进行了改造，并且引入了 ThreadlessExecutor，以及 ExchangeChannel#request 方法支持设置处理响应的线程池，这样就可以通过 复用业务端被阻塞的线程，从而避免消费端线程池过度占用。 ExecutorRepositoryExecutorRepository 负责创建并管理 Dubbo 中的线程池，该扩展接口只有一个实现。在 Dubbo 2.6.x 中之所以没有复用同一个线程池，很大原因就是没有一个管理 Dubbo 线程池的工具，它仅有一个缓存 Dubbo 线程池的工具。下面我们看看是怎么管理线程池的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192public class DefaultExecutorRepository implements ExecutorRepository &#123; /** * 缓存已有的线程池 * key1: 表示线程池属于服务端侧还是消费端侧 * key2: 线程池关联服务的端口 * value: 线程池 */ private ConcurrentMap&lt;String, ConcurrentMap&lt;Integer, ExecutorService&gt;&gt; data = new ConcurrentHashMap&lt;&gt;(); /** * 当服务或客户端初始化时，根据 URL 参数创建相应的线程池并缓存在合适的位置 * * * @param url * @return */ public synchronized ExecutorService createExecutorIfAbsent(URL url) &#123; // 1 根据 URL 中的 side 参数值确定线程池缓存的第一层 key String componentKey = EXECUTOR_SERVICE_COMPONENT_KEY; if (CONSUMER_SIDE.equalsIgnoreCase(url.getParameter(SIDE_KEY))) &#123; componentKey = CONSUMER_SIDE; &#125; Map&lt;Integer, ExecutorService&gt; executors = data.computeIfAbsent(componentKey, k -&gt; new ConcurrentHashMap&lt;&gt;()); // 2 根据 URL 中的 port 值确定线程池缓存的第二层 key Integer portKey = url.getPort(); // 3 获取或创建线程池 ExecutorService executor = executors.computeIfAbsent(portKey, k -&gt; createExecutor(url)); // 4 如果缓存中相应的线程池已经关闭，则创建新的线程池，并替换掉缓存中已关闭的线程池 if (executor.isShutdown() || executor.isTerminated()) &#123; executors.remove(portKey); executor = createExecutor(url); executors.put(portKey, executor); &#125; return executor; &#125; /** * 获取线程池 * * @param url * @return */ public ExecutorService getExecutor(URL url) &#123; // 1 根据 URL 中的 side 参数值确定线程池缓存的第一层 key String componentKey = EXECUTOR_SERVICE_COMPONENT_KEY; if (CONSUMER_SIDE.equalsIgnoreCase(url.getParameter(SIDE_KEY))) &#123; componentKey = CONSUMER_SIDE; &#125; // 2 从缓存中获取线程池 Map&lt;Integer, ExecutorService&gt; executors = data.get(componentKey); /** * It's guaranteed that this method is called after &#123;@link #createExecutorIfAbsent(URL)&#125;, so data should already * have Executor instances generated and stored. */ if (executors == null) &#123; logger.warn(\"No available executors, this is not expected, framework should call createExecutorIfAbsent first \" + \"before coming to here.\"); return null; &#125; Integer portKey = url.getPort(); ExecutorService executor = executors.get(portKey); if (executor != null) &#123; if (executor.isShutdown() || executor.isTerminated()) &#123; executors.remove(portKey); executor = createExecutor(url); executors.put(portKey, executor); &#125; &#125; return executor; &#125; /** * 根据 URL 创建线程池 * * @param url * @return */ private ExecutorService createExecutor(URL url) &#123; // 通过 Dubbo SPI 查找 ThreadPool 接口的扩展实现，并调用 getExecutor() 方法创建线程池。默认使用 FixedThreadPool 扩展实现。 return (ExecutorService) ExtensionLoader.getExtensionLoader(ThreadPool.class).getAdaptiveExtension().getExecutor(url); &#125; // 省略无关代码&#125; ExecutorRepository 会根据 URL 复用同一个线程，这解决了每个连接（连接同一个节点上服务）都启动一个线程池问题。 创建线程池当服务端和客户端启动时会初始化线程池，遵循先缓存后创建的原则。相比 Dubbo 2.6.x ，WrappedChannelHandler 不会在初始化时创建线程池，而是封装了公共的获取线程池的方法。 获取线程池1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class WrappedChannelHandler implements ChannelHandlerDelegate &#123; protected static final Logger logger = LoggerFactory.getLogger(WrappedChannelHandler.class); protected final ChannelHandler handler; protected final URL url; public WrappedChannelHandler(ChannelHandler handler, URL url) &#123; this.handler = handler; this.url = url; &#125; // 省略无关代码 /** * 获取线程池，ThreadlessExecutor 或 共享线程池 * 1. 使用 ThreadlessExecutor ，将回调直接委托给发起调用的线程 * 2. 使用共享线程池执行回调 * * @param msg * @return */ public ExecutorService getPreferredExecutorService(Object msg) &#123; // 如果是响应，尝试从 DefaultFuture 中取出线程池，没有的话再获取共享线程池 if (msg instanceof Response) &#123; Response response = (Response) msg; DefaultFuture responseFuture = DefaultFuture.getFuture(response.getId()); if (responseFuture == null) &#123; return getSharedExecutorService(); &#125; else &#123; // 如果请求关联了线程池，则会获取相关的线程来处理响应 ExecutorService executor = responseFuture.getExecutor(); if (executor == null || executor.isShutdown()) &#123; executor = getSharedExecutorService(); &#125; return executor; &#125; // 非响应，则直接使用共享线程池 &#125; else &#123; return getSharedExecutorService(); &#125; &#125; /** * 获取当前服务器或客户端的共享线程池 * * @return */ public ExecutorService getSharedExecutorService() &#123; // 从 ExecutorRepository 中获取线程池 ExecutorRepository executorRepository = ExtensionLoader.getExtensionLoader(ExecutorRepository.class).getDefaultExtension(); ExecutorService executor = executorRepository.getExecutor(url); if (executor == null) &#123; executor = executorRepository.createExecutorIfAbsent(url); &#125; return executor; &#125; @Deprecated public ExecutorService getExecutorService() &#123; return getSharedExecutorService(); &#125;&#125; 需要注意的是 getPreferredExecutorService 方法，如果请求在发送的时候指定了关联的线程池，则收到响应时会优先根据请求 ID 从 DefaultFuture 中取出对应的线程池，可能是 ThreadlessExecutor线程池或共享线程池。 DefaultFuture构造方法123456789101112131415161718192021222324252627282930313233343536373839404142/** * 初始化 DefaultFuture * 1. 初始化 DefaultFuture * 2. 超时检查 * * @param channel channel * @param request the request * @param timeout timeout * @param executor 线程池 * @return a new DefaultFuture */public static DefaultFuture newFuture(Channel channel, Request request, int timeout, ExecutorService executor) &#123; final DefaultFuture future = new DefaultFuture(channel, request, timeout); future.setExecutor(executor); // ThreadlessExecutor 需要持有本次请求关联的 DefaultFuture，主要用于当调用出现异常时（如调用超时），ThreadlessExecutor 可以及时更新 DefaultFuture 的调用状态，避免业务方一直傻傻地等待 if (executor instanceof ThreadlessExecutor) &#123; ((ThreadlessExecutor) executor).setWaitingFuture(future); &#125; // 为每次请求创建一个超时检查任务 timeoutCheck(future); return future;&#125;private static void timeoutCheck(DefaultFuture future) &#123; // 1 创建超时任务 TimeoutCheckTask task = new TimeoutCheckTask(future.getId()); // 2 将超时任务加入时间轮，到了指定的超时时间触发任务 future.timeoutCheckTask = TIME_OUT_TIMER.newTimeout(task, future.getTimeout(), TimeUnit.MILLISECONDS);&#125;private DefaultFuture(Channel channel, Request request, int timeout) &#123; this.channel = channel; this.request = request; this.id = request.getId(); this.timeout = timeout &gt; 0 ? timeout : channel.getUrl().getPositiveParameter(TIMEOUT_KEY, DEFAULT_TIMEOUT); // put into waiting map. FUTURES.put(id, this); CHANNELS.put(id, channel);&#125; 需要说明的是，Dubbo 协议下 twoway 调用不仅会创建一个和本次调用的相关的 DefaultFuture 对象，还会为当前请求创建一个调用超时检测任务，该任务用于当调用超时时及时响应一个超时异常结果给调用方，尽可能减少业务方等待时间，不仅同步调用可以及时收到调用结果，异步调用也是，只是一般情况下异步调用不会立刻阻塞等待结果而已。Dubbo 2.6.x 没有使用时间轮，而是使用定时任务检测任务的超时，本质上是一样的。 超时任务1234567891011121314151617181920212223242526272829303132333435363738+--- DefaultFuture private static class TimeoutCheckTask implements TimerTask &#123; // 请求id private final Long requestID; TimeoutCheckTask(Long requestID) &#123; this.requestID = requestID; &#125; @Override public void run(Timeout timeout) &#123; // 根据请求id取出对应的 DefaultFuture DefaultFuture future = DefaultFuture.getFuture(requestID); // 判断 timeout 到了，结果是否返回，没有返回则请求超时了 if (future == null || future.isDone()) &#123; return; &#125; // 请求超时需要响应一个超时结果 if (future.getExecutor() != null) &#123; future.getExecutor().execute(() -&gt; notifyTimeout(future)); &#125; else &#123; notifyTimeout(future); &#125; &#125; private void notifyTimeout(DefaultFuture future) &#123; // 创建一个超时异常响应 Response timeoutResponse = new Response(future.getId()); // set timeout status. timeoutResponse.setStatus(future.isSent() ? Response.SERVER_TIMEOUT : Response.CLIENT_TIMEOUT); timeoutResponse.setErrorMessage(future.getTimeoutMessage(true)); // 处理响应 DefaultFuture.received(future.getChannel(), timeoutResponse, true); &#125; &#125; 处理响应123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051+--- DefaultFuture public static void received(Channel channel, Response response, boolean timeout) &#123; try &#123; DefaultFuture future = FUTURES.remove(response.getId()); if (future != null) &#123; Timeout t = future.timeoutCheckTask; // 请求没有超时，则取消超时任务 if (!timeout) &#123; // decrease Time t.cancel(); &#125; future.doReceived(response); &#125; else &#123; logger.warn(\"The timeout response finally returned at \" + (new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss.SSS\").format(new Date())) + \", response status is \" + response.getStatus() + (channel == null ? \"\" : \", channel: \" + channel.getLocalAddress() + \" -&gt; \" + channel.getRemoteAddress()) + \", please check provider side for detailed result.\"); &#125; &#125; finally &#123; CHANNELS.remove(response.getId()); &#125; &#125; private void doReceived(Response res) &#123; if (res == null) &#123; throw new IllegalStateException(\"response cannot be null\"); &#125; // 正常响应结果 if (res.getStatus() == Response.OK) &#123; this.complete(res.getResult()); // 超时异常 &#125; else if (res.getStatus() == Response.CLIENT_TIMEOUT || res.getStatus() == Response.SERVER_TIMEOUT) &#123; this.completeExceptionally(new TimeoutException(res.getStatus() == Response.SERVER_TIMEOUT, channel, res.getErrorMessage())); // 其它异常 &#125; else &#123; this.completeExceptionally(new RemotingException(channel, res.getErrorMessage())); &#125; // 已经有了请求结果，但可能是超时异常结果，这种情况下应该通知在 ThreadlessExecutor.queue 上等待的线程，避免其一直等待。 if (executor != null &amp;&amp; executor instanceof ThreadlessExecutor) &#123; ThreadlessExecutor threadlessExecutor = (ThreadlessExecutor) executor; // 通知在 ThreadlessExecutor.queue 上等待的线程返回 if (threadlessExecutor.isWaiting()) &#123; threadlessExecutor.notifyReturn(new IllegalStateException(\"The result has returned, but the biz thread is still waiting\" + \" which is not an expected state, interrupt the thread manually by returning an exception.\")); &#125; &#125; &#125; DefaultFuture 处理响应分为两种情况，一种是正常响应结果，另一种是异常响应结果。如果是异常结果，则还需要判断处理响应的线程池类型，如果是 ThreadlessExecutor 且其状态是等待状态，则需要通知阻塞的业务线程返回。此外，如果因为调用超时而返回异常结果时，也会将本次调用相关的 DefaultFuture 移除，当服务提供方返回响应（超时是针对消费端的，服务端不受影响）时是找不到对应的 DefaultFuture 对象的。 相比较 Dubbo 2.6.x , DefaultFuture 新维护了一个 ExecutorService 线程池，作为处理响应的线程池，可以参考 WrappedChannelHandler.getPreferredExecutorService 方法中的逻辑。 ThreadlessExecutorThreadlessExecutor 是一种特殊类型的线程池，它并不会管理任何线程，以线程池的身份作为一个中间容器使用。其中维护了一个阻塞队列 queue 和一个共享线程池 shareExecutor 。阻塞队列用来存储响应任务，最终会将响应任务交给等待的业务线程处理。共享线程池主要用于当业务线程不再等待响应时，会由该线程池处理任务。整个核心逻辑在 execute() 方法和 waitAndDrain() 方法。 属性123456789101112131415161718192021222324public class ThreadlessExecutor extends AbstractExecutorService &#123; private static final Logger logger = LoggerFactory.getLogger(ThreadlessExecutor.class.getName()); /** * 阻塞队列，用来在 IO线程和业务线程之间传递任务 */ private final BlockingQueue&lt;Runnable&gt; queue = new LinkedBlockingQueue&lt;&gt;(); /** * ThreadlessExecutor 底层关联的共享线程池。当业务线程已经不再等待响应时，会由该共享线程执行提交任务。 */ private ExecutorService sharedExecutor; /** * 指向请求对应的 DefaultFuture */ private CompletableFuture&lt;?&gt; waitingFuture; /** * finished 和 waiting 字段控制着等待任务的处理 */ private boolean finished = false; private volatile boolean waiting = true; private final Object lock = new Object();&#125; 任务通知1234567891011121314+--- ThreadlessExecutor @Override public void execute(Runnable runnable) &#123; synchronized (lock) &#123; // 判断业务线程是否还在等待响应，不等待则直接交给共享线程池处理 if (!waiting) &#123; sharedExecutor.execute(runnable); // 业务线程还在等待，则将任务写入队列，最终由业务线程自己执行（业务线程在 waitAndDrain 方法上等待任务） &#125; else &#123; queue.add(runnable); &#125; &#125; &#125; ThreadlessExecutor 重写了 execute(Runnable) 方法，通过该方法提交给这个执行器的任务不会被调度到特定的线程。如果业务线程在等待响应则将任务放入阻塞队列，最终业务线程自己执行。如果业务线程没有等待（可能业务线程已经执行了响应任务），则直接交给共享线程池处理。 任务等待12345678910111213141516171819202122232425262728293031+--- ThreadlessExecutorpublic void waitAndDrain() throws InterruptedException &#123; // 检测当前 ThreadlessExecutor 状态 if (finished) &#123; return; &#125; // 获取阻塞队列中的任务 Runnable runnable = queue.take(); synchronized (lock) &#123; // 修改waiting 状态 waiting = false; // 执行任务 runnable.run(); &#125; // 如果阻塞队列还有其它任务，则需要一起执行 runnable = queue.poll(); while (runnable != null) &#123; try &#123; runnable.run(); &#125; catch (Throwable t) &#123; logger.info(t); &#125; runnable = queue.poll(); &#125; // 标记 ThreadlessExecutor 是完成状态，无业务线程等待 finished = true; &#125; 该方法一般与一次 RPC 调用绑定，只会执行一次。存储在阻塞队列中的任务，只有当线程调用该方法时才会执行，执行任务的线程和调用该方法的线程是同一个线程。 关联 DefaultFuture123public void setWaitingFuture(CompletableFuture&lt;?&gt; waitingFuture) &#123; this.waitingFuture = waitingFuture;&#125; 为 ThreadlessExecutor 设置本次调用相关的 DefaultFuture 对象，主要用于同步调用异常（如超时异常）时，可以更新 DefaultFuture 的调用状态，即使用 notifyReturn 方法。 异常任务通知123456789/** * 通知阻塞 &#123;@link #waitAndDrain()&#125; 的线程返回，避免调用出现异常还傻傻地等待 */public void notifyReturn(Throwable t) &#123; // an empty runnable task. execute(() -&gt; &#123; waitingFuture.completeExceptionally(t); &#125;);&#125; 服务调用AsyncToSyncInvoker前面已经对该 Invoker 进行了介绍，在服务引用时会使用该类对消费端的 Invoker 进行包装，负责将异步调用转换成同步调用。 123456789101112131415161718192021@Override public Result invoke(Invocation invocation) throws RpcException &#123; Result asyncResult = invoker.invoke(invocation); try &#123; // 如果是同步调用，则调用 get() 方法，阻塞等待响应返回。 // 调用的是 AsyncRpcResult.get 方法，其底层调用的是 CompletableFuture 的 get 方法 if (InvokeMode.SYNC == ((RpcInvocation) invocation).getInvokeMode()) &#123; /** * NOTICE! * must call &#123;@link java.util.concurrent.CompletableFuture#get(long, TimeUnit)&#125; because * &#123;@link java.util.concurrent.CompletableFuture#get()&#125; 被证明有严重的性能下降。 */ asyncResult.get(Integer.MAX_VALUE, TimeUnit.MILLISECONDS); &#125; // 省略异常处理逻辑 &#125; catch (Throwable e) &#123; //... &#125; return asyncResult; &#125; 业务线程进行 Invoker 调用时，会执行到 AsyncToSyncInvoker.invoke 方法，执行完调用后会返回一个 AsyncRpcResult 对象，如果是 SYNC 同步调用模式，则会调用其 get 方法，本质上是调用 ThreadlessExecutor 的 waitAndDrain() 方法阻塞等待响应任务。 Dubbo 2.6.x 的异步转同步是通过 等待通知机制 实现的，使用的是 Lock 和 Condition 的组合。Dubbo 2.7.x 的异步转同步也是通过 等待通知机制 实现的，等待部分使用的是 LinkedBlockingQueue.take() 方法实现的，通知部分使用的是 LinkedBlockingQueue.add(Runnable) 实现的，由于 LinkedBlockingQueue 底层的实现机制也是基于 Lock 和 Condition 的组合，因此本质上实现机制是一致的。 AsyncRpcResult123456789+--- AsyncRpcResult @Override public Result get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; if (executor != null &amp;&amp; executor instanceof ThreadlessExecutor) &#123; ThreadlessExecutor threadlessExecutor = (ThreadlessExecutor) executor; threadlessExecutor.waitAndDrain(); &#125; return responseFuture.get(timeout, unit); &#125; 这里可能会有疑问，业务线程调用 threadlessExecutor.waitAndDrain() 方法阻塞等待结果时并没有时间限制，那怎么知道调用是否超时呢？这个就是前文介绍的，在创建请求相关的 DefaultFuture 时还会创建一个超时检测任务，当请求超时时会立即返回一个超时异常结果，并且会通知阻塞等待的业务线程。 DubboInvoker12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061+--- DubboInvoker@Override protected Result doInvoke(final Invocation invocation) throws Throwable &#123; RpcInvocation inv = (RpcInvocation) invocation; // 此次调用的方法名称 final String methodName = RpcUtils.getMethodName(invocation); // 向 Invocation 中添加附加信息，这里将 URL 的 path 和 version 添加到附加信息中 inv.setAttachment(PATH_KEY, getUrl().getPath()); inv.setAttachment(VERSION_KEY, version); // 选择一个 ExchangeClient 实例 ExchangeClient currentClient; if (clients.length == 1) &#123; currentClient = clients[0]; &#125; else &#123; currentClient = clients[index.getAndIncrement() % clients.length]; &#125; try &#123; // 是否是 oneway 调用 （不需要返回值） boolean isOneway = RpcUtils.isOneway(getUrl(), invocation); // 根据调用方法名和配置，计算此次调用的超时时间 int timeout = calculateTimeout(invocation, methodName); // 不需要关注返回值的请求 if (isOneway) &#123; // 省略调用逻辑 // 需要关注返回值的请求 &#125; else &#123; // 1 对于同步请求会使用 ThreadlessExecutor （SYNC 模式）， 对于异步请求，则会使用共享的线程池 （ASYNC 和 FUTURE 模式 ） ExecutorService executor = getCallbackExecutor(getUrl(), inv); // 2 使用上面选出的 ExchangeClient 执行 request() 方法将请求发出去，并传入线程池 executor。该线程池会作为处理响应的线程池，将保存到 DefaultFuture 中 CompletableFuture&lt;AppResponse&gt; appResponseFuture = // currentClient.request 返回的是 DefaultFuture，DefaultFuture 继承了 CompletableFuture 。 currentClient.request(inv, timeout, executor) // 增加了一个回调，取出其中的 AppResponse 对象。 // thenApply 是一个回调,obj 是 上一个任务的结果。返回的 AppResponse 表示的是 服务端返回的具体响应。 .thenApply(obj -&gt; (AppResponse) obj); // save for 2.6.x compatibility, for example, TraceFilter in Zipkin uses com.alibaba.xxx.FutureAdapter FutureContext.getContext().setCompatibleFuture(appResponseFuture); // 3 这里将 CompletableFuture （其实是 DefaultFuture） 封装成 AsyncRpcResult 并返回 AsyncRpcResult result = new AsyncRpcResult(appResponseFuture, inv); // 设置处理结果的线程池 result.setExecutor(executor); return result; &#125; &#125; catch (TimeoutException e) &#123; throw new RpcException(RpcException.TIMEOUT_EXCEPTION, \"Invoke remote method timeout. method: \" + invocation.getMethodName() + \", provider: \" + getUrl() + \", cause: \" + e.getMessage(), e); &#125; catch (RemotingException e) &#123; throw new RpcException(RpcException.NETWORK_EXCEPTION, \"Failed to invoke remote method: \" + invocation.getMethodName() + \", provider: \" + getUrl() + \", cause: \" + e.getMessage(), e); &#125; &#125; DubboInvoker 在发起调用之前，会先通过 getCallbackExecutor 方法根据调用模式获取不同的线程池实现，代码如下： 12345678910111213+--- AbstractInvoker protected ExecutorService getCallbackExecutor(URL url, Invocation inv) &#123; // 1 从 ExecutorRepository 中获取线程池 ExecutorService sharedExecutor = ExtensionLoader.getExtensionLoader(ExecutorRepository.class).getDefaultExtension().getExecutor(url); // 2 如果是同步请求，则使用 ThreadlessExecutor 线程池，它会对共享线程池进行封装 if (InvokeMode.SYNC == RpcUtils.getInvokeMode(getUrl(), inv)) &#123; return new ThreadlessExecutor(sharedExecutor); // 3 非同步请求，则使用共享线程池 &#125; else &#123; return sharedExecutor; &#125; &#125; 响应处理端点收到数据时（这里假设是响应数据）先由 IO 线程从二进制流中解码出响应，然后调用 WrappedChannelHandler.received 方法的实现，下面我们以 AllChannelHandler 为例： 123456789101112131415161718192021222324+--- AllChannelHandler /** * 当前端点收到数据 * * @param channel * @param message * @throws RemotingException */ @Override public void received(Channel channel, Object message) throws RemotingException &#123; // 1 获取线程池，如果是响应消息则优先获取发送请求时指定的关联线程池 ExecutorService executor = getPreferredExecutorService(message); try &#123; // 2 将消息封装成ChannelEventRunnable任务，提交到第 1 步获取的线程池中 executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message)); &#125; catch (Throwable t) &#123; // 3 如果线程池满了，请求会被拒绝，这里会根据请求配置决定是否返回一个说明性的响应 if (message instanceof Request &amp;&amp; t instanceof RejectedExecutionException) &#123; sendFeedback(channel, (Request) message, t); return; &#125; throw new ExecutionException(message, channel, getClass() + \" error when process received event .\", t); &#125; &#125; 符合以下条件 getPreferredExecutorService 方法获取的线程池就是 ThreadlessExecutor，否则一律使用共享线程池 收到的是响应消息。 响应对应的请求调用模式是 SYNC 同步调用。 ThreadlessExecutor 执行 execute 方法时，会将任务提交到阻塞队列中，处于阻塞的业务线程会从阻塞队列中获取任务并执行。 线程池模型通过复用业务端被阻塞的线程，解决了消费端线程池过度占用问题。同步调用优化后的线程模型如下： 业务线程发出请求后，拿到一个 Future 对象。 业务线程会调用 ThreadlessExecutor.waitAndDrain() 方法，该方法会使业务线程在阻塞队列上等待，直到队列中被加入任务。 当收到响应时，IO 线程会生成一个任务并放入 ThreadlessExecutor 阻塞队列中。 处于阻塞的业务线程将第 3 步添加的任务取出，并在本线程中执行。得到结果之后，调用 Future.set 方法进行设置，然后业务线程从 waitAndDrain() 方法返回。 业务线程继续执行，最后拿到结果值。 小结本篇文章主要对 Dubbo 的线程模型改造进行了介绍，首先解决了以连接维度的消费端线程池，根据 URL 复用线程池即合理地缓存线程池实现。接着解决了消费端线程池过度占用问题，通过引入 ThreadlessExecutor 复用业务端被阻塞的线程实现。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"集合 - CopyOnWriteArrayList","slug":"java-base/集合-CopyOnWriteArrayList","date":"2021-01-24T11:14:17.000Z","updated":"2021-08-21T09:35:51.858Z","comments":false,"path":"posts/bd5fd437/","link":"","permalink":"https://gentryhuang.com/posts/bd5fd437/","excerpt":"","text":"前言ArrayList 是一个非线程安全集合，需要使用方自行处理线程安全问题，或者使用 Collections.synchronizedList 包装。从 JDK 1.5 开始 JUC 中提供了使用写时复制机制实现的并发容器 CopyOnWriteArrayList。 概述CopyOnWriteArrayList 遵从 CopyOnWrite，顾名思义就是写时复制。简单来说就是当我们操作容器时并不直接操作当前容器，而是先根据当前容器复制出一个新的容器，然后在这个新的容器上操作，完成操作后再将原容器引用指向新容器。 源码解析CopyOnWriteArrayList 的类继承关系类图如下: 属性123456789101112131415public class CopyOnWriteArrayList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable &#123; private static final long serialVersionUID = 8673264195747942595L; /** * 保护所有更改操作的锁 */ final transient ReentrantLock lock = new ReentrantLock(); /** * 内部数组。 * 所有的读操作都是基于当前 array 进行的；所有的写操作都会复制一个新的 array，然后在新复制的数组上执行操作。 */ private transient volatile Object[] array;&#125; CopyOnWriteArrayList 核心属性就是以上两个。lock 用于保护所有更改操作，控制并发写操作。array 作为内部数组用于保存数据，读操作都是操作当前 array，写操作都是根据当前 array 复制一个新的 array，然后在这个新的数组中进行操作。 新增1234567891011121314151617181920212223242526public boolean add(E e) &#123; final ReentrantLock lock = this.lock; // 1 获得独占锁 lock.lock(); try &#123; // 2 获得 array 数组 Object[] elements = getArray(); // 3 获得 array 数组长度 int len = elements.length; // 4 根据当前 array 复制一个新的数组，长度 +1 Object[] newElements = Arrays.copyOf(elements, len + 1); // 5 将元素加入到新数组 newElements[len] = e; // 6 替换旧数组 setArray(newElements); return true; &#125; finally &#123; // 7 释放独占锁 lock.unlock(); &#125;&#125; 下面对上述代码流程进行说明： 使用 ReentrantLock 独占锁保证同时只有一个线程对集合进行写操作。 数据存储在 CopyOnWriteArrayList 的内部 array 数组中。 元素并不是直接存储到 array 数组中，而是复制出一个新的数组，并且复制出的数组的长度是旧数组长度+1，然后将元素加入到新数组中，最后再把旧的数组替换成新的数组。 查询12345678910111213 /** * &#123;@inheritDoc&#125; * * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */ public E get(int index) &#123; return get(getArray(), index); &#125; @SuppressWarnings(\"unchecked\") private E get(Object[] a, int index) &#123; return (E) a[index];&#125; 由于整个 get 方法是没有加锁的，而 CopyOnWriteArrayList 的写操作是通过复制出新的数组来完成操作的，这可能会导致读写的短暂不一致。 修改12345678910111213141516171819202122232425262728293031public E set(int index, E element) &#123; final ReentrantLock lock = this.lock; // 1 获得独占锁 lock.lock(); try &#123; // 2 获得当前 数组 array Object[] elements = getArray(); // 3 根据下标，获得旧的元素 E oldValue = get(elements, index); // 4 如果旧的元素不等于新的元素，等同于 add 方法，不过这里没有增加数组容量大小 if (oldValue != element) &#123; int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len); newElements[index] = element; setArray(newElements); // 5 为了保证 volatile 语义，即使元素没有改变也要替换成新的数组 &#125; else &#123; // Not quite a no-op; ensures volatile write semantics setArray(elements); &#125; return oldValue; &#125; finally &#123; // 6 释放独占锁 lock.unlock(); &#125; &#125; 和 add 方法类似，不同的是对要修改的元素进行判断。 删除1234567891011121314151617181920212223242526272829303132public E remove(int index) &#123; final ReentrantLock lock = this.lock; // 1 获取独占锁 lock.lock(); try &#123; // 2 获取对应下标元素 Object[] elements = getArray(); int len = elements.length; E oldValue = get(elements, index); // 3 确定调整位置，并根据该位置移动元素 int numMoved = len - index - 1; // 3.1 要删除的元素在末尾 if (numMoved == 0) setArray(Arrays.copyOf(elements, len - 1)); // 3.2 要删除的元素在数组中间 else &#123; Object[] newElements = new Object[len - 1]; System.arraycopy(elements, 0, newElements, 0, index); System.arraycopy(elements, index + 1, newElements, index, numMoved); setArray(newElements); &#125; return oldValue; &#125; finally &#123; // 4 释放锁 lock.unlock(); &#125; &#125; 删除方法和其它修改方法类似，先是获取独占锁来保证线程安全，接着判断要删除的元素是否是最后一个，如果是最后一个则复制出一个长度-1的新数组然后替换掉旧数组；如果要删除的元素不是最后一个，则分两次复制，随后替换旧数组。 迭代器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/** * 迭代器 * * @param &lt;E&gt; */ static final class COWIterator&lt;E&gt; implements ListIterator&lt;E&gt; &#123; /** * 数据快照 */ private final Object[] snapshot; /** * 遍历数组元素的游标 */ private int cursor; private COWIterator(Object[] elements, int initialCursor) &#123; cursor = initialCursor; snapshot = elements; &#125; /** * 判断是否还有下一个元素 * * @return */ public boolean hasNext() &#123; return cursor &lt; snapshot.length; &#125; /** * 判断是否有上一个元素 * * @return */ public boolean hasPrevious() &#123; return cursor &gt; 0; &#125; /** * 获取下个元素 * * @return */ @SuppressWarnings(\"unchecked\") public E next() &#123; if (!hasNext()) throw new NoSuchElementException(); return (E) snapshot[cursor++]; &#125; @SuppressWarnings(\"unchecked\") public E previous() &#123; if (!hasPrevious()) throw new NoSuchElementException(); return (E) snapshot[--cursor]; &#125; // 不支持写操作 public void remove() &#123; throw new UnsupportedOperationException(); &#125; public void set(E e) &#123; throw new UnsupportedOperationException(); &#125; public void add(E e) &#123; throw new UnsupportedOperationException(); &#125; &#125; 当获取迭代器时，内部会调用 COWIterator 的构造方法，该构造方法有两个参数，一个是 array 数组，另一个是下标 0 。构造方法中会把 array 数组赋值给 snapshot 变量，当其他线程进行了增删改的操作，旧的数组会被新的数组给替换掉，但是 snapshot 还是原来旧的数组的引用。当我们使用迭代器遍历 CopyOnWriteArrayList 的时候，不能保证拿到的数据是最新的，这是弱一致性问题。 设计特点CopyOnWriteArrayList 仅适用于写操作非常少的场景，而且能够容忍读写的短暂不一致。虽然采用了读写分离思想，但写操作时内存里会同时存在两个对象的内存，若这些对象占用内存较大，可能会带来系列问题，如造成频繁 GC。 小结CopyOnWriteArrayList 是 Java 并发包中相对比较简单的一个实现，它的核心思想是写时复制机制，支持并发读写，但带来的后果是内存 double 和数据一致性问题。","categories":[{"name":"JDK","slug":"JDK","permalink":"https://gentryhuang.com/categories/JDK/"}],"tags":[{"name":"CopyOnWrite","slug":"CopyOnWrite","permalink":"https://gentryhuang.com/tags/CopyOnWrite/"}]},{"title":"集合 - ConcurrentHashMap","slug":"java-base/集合-ConcurrentHashMap","date":"2021-01-18T12:30:35.000Z","updated":"2021-08-03T07:35:24.263Z","comments":false,"path":"posts/218dc61f/","link":"","permalink":"https://gentryhuang.com/posts/218dc61f/","excerpt":"","text":"","categories":[{"name":"JDK","slug":"JDK","permalink":"https://gentryhuang.com/categories/JDK/"}],"tags":[{"name":"ConcurrentHashMap","slug":"ConcurrentHashMap","permalink":"https://gentryhuang.com/tags/ConcurrentHashMap/"}]},{"title":"集合 - HashMap","slug":"java-base/集合-HashMap","date":"2021-01-10T12:30:35.000Z","updated":"2021-08-17T12:07:23.340Z","comments":false,"path":"posts/8c0fc113/","link":"","permalink":"https://gentryhuang.com/posts/8c0fc113/","excerpt":"","text":"前言HashMap 是基于哈希表实现的，外层是一个数组，数组中的每个元素封装了一个 key-value 及其他元数据信息，这些元数据信息是为了更好的管理数组中某个位置中的元素，如使用单链表或红黑树组织元素，元数据信息就是对应的指针等信息。对 HashMap 进行增、删、改、查都需要经历两个必须的步骤，先计算 key 的 hash 值，接着根据 hash 值计算出当前键值对位于数组的哪个位置。HashMap 虽然基础，但是其中的思想值得学习。本篇文章将分别对 JDK 7、8 版本下的 HashMap 进行介绍。 JDK 7 HashMap JDK 1.7 的 HashMap 结构如上图所示。内部存储结构是数组和链表的结合，在实例化 HashMap 时会创建一个长度为 Capacity 的 Entry 数组，这个长度被称为容量，数组中可以存放元素的位置我们称为桶（bucket），每个 bucket 都有自己的索引下标，系统可以根据索引下标快速查找 bucket 中的元素。每个 bucket 中存储一个元素，即一个 Entry 对象，但每一个 Entry 对象都可以通过指针链接下一个元素，因此，在一个 bucket 中就有可能生成一个 Entry 链。 关键属性12345678910111213141516171819202122232425262728293031//默认初始化化容量, 16 static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; //最大容量，即2的30次方 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; // 默认负载因子 static final float DEFAULT_LOAD_FACTOR = 0.75f; // HashMap内部的存储结构是一个数组，此处数组为空，即没有初始化之前的状态 static final Entry&lt;?,?&gt;[] EMPTY_TABLE = &#123;&#125;; // 空的存储实体 transient Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPTY_TABLE; //实际存储的 key-value 键值对的个数。注意和容量的区分。transient int size;// 扩容阈值，当table == &#123;&#125;时，该值为初始容量（初始容量默认为16）；当table被填充了，也就是为table分配内存空间后，threshold一般为 capacity*loadFactory。// HashMap在进行扩容时需要参考thresholdint threshold;//负载因子，代表了table的填充度有多少，默认是0.75。// 为什么是 0.75 ，是根据 泊松统计定义的final float loadFactor;//用于快速失败，由于HashMap非线程安全，在对HashMap进行迭代时，如果期间其他线程的参与导致HashMap的结构发生变化了（比如put，remove等操作），需要抛出异常ConcurrentModificationExceptiontransient int modCount;//默认的 threshold 值 static final int ALTERNATIVE_HASHING_THRESHOLD_DEFAULT = Integer.MAX_VALUE; 注意，HashMap 数组的每一个元素不止是一个 Entry 对象，也是一个链表的头节点。每一个 Entry 对象通过 next 指针指向它的下一个 Entry 节点。当新来的 Entry 映射到冲突的数组位置时，只需要插入到对应的链表中即可。 构造方法123456789101112131415161718192021222324252627282930313233343536// 通过初始容量和负载因子构造HashMap public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); // 分别赋值 负载因子 和 扩容阈值 this.loadFactor = loadFactor; // threshold 初始值为初始容量 threshold = initialCapacity; //init方法在HashMap中没有实际实现 init();&#125; // 通过扩容阈值构造 HashMap,容量是默认值 16 public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; // 负载因子取0.75，容量取16，构造HashMap public HashMap() &#123; this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR); &#125; // 通过其他 Map 来初始化HashMap,容量通过其他Map的size来计算，装载因子取0.75 public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this(Math.max((int) (m.size() / DEFAULT_LOAD_FACTOR) + 1, DEFAULT_INITIAL_CAPACITY), DEFAULT_LOAD_FACTOR); //初始化HashMap底层的数组结构 inflateTable(threshold); //添加m中的元素 putAllForCreate(m);&#125; Put方法原理1234567891011121314151617181920212223242526272829303132333435public V put(K key, V value) &#123; // 当插入第一个元素的时候，根据情况先初始化数组大小 if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; // 如果 key 为 null，最终会将这个 entry 放到 table[0] 中 if (key == null) return putForNullKey(value); // 1. 求 key 的 hash 值 // 对 key 的 hashcode 进一步计算，确保散列均匀 int hash = hash(key); // 2. 找到对应的数组下标 // i = h &amp; (table.length-1)，效果同取模运算 int i = indexFor(hash, table.length); // 3. 遍历一下对应下标处的链表，看是否有重复的 key 已经存在， 如果有，直接覆盖，put 方法返回旧值就结束了 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; // 保证并发访问时，若HashMap内部结构发生变化，快速响应失败 modCount++; // 4. 不存在重复的 key，新增一个 entry 并添加到链表中 addEntry(hash, key, value, i); return null;&#125; 通过上述方法可知，确定一个元素的存储位置需要以下步骤： 通过元素的 key 获取对应的 hash 值，其中使用到了 key 的 hashcode 值。 通过 hash 值和数组 length 信息计算得到存储的下标索引位置。 知道了对应的下标索引位置后就可以取出对应的元素了，如果该位置的元素有多个，那么需要遍历获取。 初始化数组1234567891011private void inflateTable(int toSize) &#123; // 1 保证数组大小一定是 2 的 n 次方，采用向上取整的策略。如 new HashMap(20)，那么处理成初始数组大小是 32 int capacity = roundUpToPowerOf2(toSize); // 2 计算扩容阈值：capacity * loadFactor threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); // 3 创建数组 table = new Entry[capacity]; initHashSeedAsNeeded(capacity); //ignore&#125; 保证数组大小一定是 2^n 是为了实现一个尽量均匀分布的 Hash 函数。HashMap 采用类似如下的公式计算元素对应的数组位置： 123&#x2F;&#x2F; HashCode 并不是 key 的直接 hashcode 值，而是对其处理后的值&#x2F;&#x2F; length 是 HashMap 的长度index &#x3D; HashCode(key) &amp; (lenght -1) 可以看到，HashMap 的作者采用了位运算的方式代替取模运算，只要数组大小是 2^n 就可以保证 length - 1 的值的二进制位全是 1，这种情况下，index 的结果等同于 HashCode 后几位的值。只要输入的 HashCode 本身分布均匀，Hash算法的结果就是均匀的。 添加节点到链表中12345678910111213141516171819202122232425262728void addEntry(int hash, K key, V value, int bucketIndex) &#123; // 1 如果当前 HashMap 大小已经达到了阈值，并且新键值对要插入的数组位置已经有元素了，那么要扩容 if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; // 1.1 扩容，后面会介绍一下 resize(2 * table.length); // 1.2 扩容以后，重新计算 hash 值 hash = (null != key) ? hash(key) : 0; // 1.3 重新计算扩容后的新的下标 bucketIndex = indexFor(hash, table.length); &#125; // 2 如果需要扩容，是先扩容再插入元素 createEntry(hash, key, value, bucketIndex);&#125;// 将新的键值对放到链表的表头，然后 size++void createEntry(int hash, K key, V value, int bucketIndex) &#123; // 获取待插入位置元素 Entry&lt;K,V&gt; e = table[bucketIndex]; // 这里执行链接操作，使得新插入的元素指向原有元素。这保证了新插入的元素总是在链表的头 // e 赋值给 Entry 中的 next table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); // 元素个数+1 size++;&#125; 在添加元素的过程中需要先判断是否需要扩容，扩容的标准是当前 HashMap 元素大小达到扩展阈值且要插入的位置已经有元素了。需要扩容的话先进行扩容，然后再将这个新的键值对插入到扩容后的数组的相应位置处的链表的表头。 注意，新的 Entry 节点插入链表时使用的是 头插法，作者认为后插入的 Entry 被查找的可能性更大。 Get方法原理相比较 put 过程，get 过程是非常简单的，主要过程如下： 根据 key 计算 hash 值 计算相应的数组下标： index = hash &amp; (length - 1) 遍历该数组位置处的链表，直到找到相同的 key 或为 null 123456789101112131415161718192021222324252627282930313233public V get(Object key) &#123; // key 为 null 的话，会被放到 table[0]，所以只要遍历下 table[0] 处的链表就可以了 if (key == null) return getForNullKey(); // 走查找流程 Entry&lt;K,V&gt; entry = getEntry(key); // 返回对应的值 return null == entry ? null : entry.getValue();&#125;final Entry&lt;K,V&gt; getEntry(Object key) &#123; if (size == 0) &#123; return null; &#125; // 1 通过 hash 函数计算 key 的 hash 值 int hash = (key == null) ? 0 : hash(key); // 2 确定数组下标，然后从头开始遍历链表，直到找到为止 for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; // 3 在对应的数组位置没有找到 return null;&#125; 扩容HashMap 的容量是有限的，当经过多次元素插入会使得 HashMap 达到一定饱和度时，key 映射位置发生冲突的几率会逐渐提高，这时 HashMap 需要进行扩容。在 put 的过程，如果当前 HashMap 元素个数 size 已经达到了阈值且要插入的数组位置上已经有元素了，那么就会触发扩容，扩容后数组大小是原来的 2 倍。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657void resize(int newCapacity) &#123; // 1 保存旧数组 Entry[] oldTable = table; // 2 保存旧容量 int oldCapacity = oldTable.length; // 3 如果旧容量已经是系统默认最大容量了，那么将阈值设置成整型的最大值，退出 if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; // 4 扩容，创建一个新的空数组，长度是原数组的 2 倍 Entry[] newTable = new Entry[newCapacity]; // 5 将原来数组中的键值对迁移到新的更大的数组中 transfer(newTable, initHashSeedAsNeeded(newCapacity)); // 6 扩容完毕后，用新的数组指向 table table = newTable; // 7 计算新的扩容阈值 threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);&#125;/* * 作用：将旧数组上的数据（键值对）转移到新 table 中，从而完成扩容。 */ void transfer(Entry[] newTable, boolean rehash) &#123; // 容量 int newCapacity = newTable.length; // 两层循环 // 外层 for 循环 用于遍历数组 // 内层 while 循环 用于遍历数组中对应位置的链表 for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; //如果是重新 Hash，则需要重新计算hash值 if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; // 计算元素 e 在新数组中的位置 int i = indexFor(e.hash, newCapacity); // 头插入，newTable[i]的值总是最新插入的值 e.next = newTable[i]; newTable[i] = e; // 继续下一个元素 e = next; &#125; &#125; &#125; 以上扩容代码相对还是比较直观的，整个扩容分为两个步骤：扩容和rehash。 我们知道，在多线程环境中 HashMap 是不安全的，其中一个很大的问题就是数组中某个位置的链表可能成环，这个问题就是发生在 rehash 过程。下面我们对该现象详细分析。 链表成环假设一个 HashMap 已经到了扩容的临界点，此时刚好有两个线程 A 和 B 在同一时刻对 HashMap 进行 put 操作，那么两个线程各自进行扩容： 接着两个线程都来到 transfer 方法中，其中线程 B 遍历到 Entry3 对象，刚执行完以下代码时就被挂起了。此时线程 B 的状态数据，e = Entry3，next = Entry2。 1Entry&lt;K,V&gt; next = e.next; 而在线程 B 被挂起期间，线程 A 成功完成了 rehash 过程，结果如下（图中的 e 和 next 分别代表线程 B 持有的两个 Entry 引用）。 第一轮 当线程 A 完成 rehash 后线程 B 恢复，继续执行属于它的 rehash 过程。接着执行以下代码，确认 e 对应的元素应该位于新数组哪个索引位置，毫无疑问地 i = 3，因为刚才线程 A 对 Entry3 的映射结果就是 3 。 12// 计算元素 e 在新数组中的位置int i = indexFor(e.hash, newCapacity); 接续执行后续的代码，如下： 123456// 头插入，newTable[i]的值总是最新插入的值e.next = newTable[i];newTable[i] = e; //继续下一个元素 e = next; 对应的情况如下图所示： 至此，第一轮执行完毕，此时线程 B 将 Entry3 rehash 到了自己的新数组中，且它的 e 和 next 指针同时指向 Entry2 。注意，线程 B 操作的 Entry 节点还是原来的节点，虽然原来的 Entry 节点被线程 A 进行了 rehash ，但是引用指向没有变。 第二轮 接着执行新的一轮，此时又执行到以下代码： 1Entry&lt;K,V&gt; next = e.next; 此时，e = Entry2，next = Entry3 ，整体情况如下图所示： 接着继续执行以下三行代码，采用头插法把 Entry2 插入到线程 B 的数组的头节点： 123456 // 头插入，newTable[i]的值总是最新插入的值 e.next = newTable[i]; newTable[i] = e; //继续下一个元素 e = next; 整体情况如下图所示： 至此，第二轮执行完毕，此时线程 B 将 Entry2 rehash 到了自己的新数组中，且它的 e 和 next 指针同时指向 Entry3 。 第三轮 接着执行新的一轮，此时又执行到以下代码： 1Entry&lt;K,V&gt; next = e.next; 此时，e = Entry3,next = null，接着继续执行以下代码，做头插法： 12// 头插入，newTable[i]的值总是最新插入的值e.next = newTable[i]; 此时，链表出现了环形。相关数据关系如下： 1234newTable[i] = Entry2e = Entry3Entry2.next = Entry3Entry3.next = Entry2 整体情况如下图所示： 最后，执行以下代码将新元素设为头，也就是将 Entry3 设置为头。 1newTable[i] = e; 至此，第三轮执行完毕，此时线程 B 将 Entry3 和 Entry2 互相使用 next 指针链接起来形成了一个环。由于 next = null ，因此在下一轮开始判断的时候不满足条件，结束数组当前位置数据的 rehash 。 此时，坑已经埋好了，就等调用 get 查找一个不存在的 key ，而这个 key 的 hash 结果映射到桶的位置恰好等于 3 时，由于位置 3 带有环形链表，因此程序会进入死循环。 值得说明的是，在一定程度上链表头插法会颠倒原来一个位置上链表的顺序。在并发的时候原来的顺序被线程 A 颠倒了，而被挂起的线程 B\b 恢复后拿到挂起前的节点和顺序继续完成 rehash，这个过程会将线程 A rehash 后的链表顺序重新排列，最终形成了环。JDK 1.8 之后就不再采用头插法了，而是直接插入链表尾部，因此不会形成环形链表形成死循环，但是在多线程的情况下仍然是不安全的，在put数据时如果出现两个线程同时操作，可能会发生数据覆盖，引发线程不安全。 JDK 8 HashMap JDK 1.8 的 HashMap 结构大体上如上图所示，具体细节并没有展示，比如红黑树中的链接指针没有全部显示。JDK 1.7 的 HashMap 采用 数组+链表 的方式在大部分情况下都能有不错的性能，但在极端的情况下可能会退化成一个链表，造成 HashMap 性能急剧下降。因此在 JDK 1.8 中采用了 数组+链表+红黑树的方式来组织数据，新增红黑树是为了解决哈希碰撞，避免过长链表效率低的问题。 关键属性123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class HashMap&lt;K, V&gt; extends AbstractMap&lt;K, V&gt; implements Map&lt;K, V&gt;, Cloneable, Serializable &#123; private static final long serialVersionUID = 362498820763181265L; /** * 默认容量大小 16，大小必须是 2^N */ static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 /** * 最大容量，当两个构造函数中任何一个带参数的函数隐式指定较大的值时使用。一定是2 &lt;= 1&lt;&lt;30的幂。 */ static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; /** * 默认负载因子 在构造函数中未指定时使用的负载因子 * 为什么是 0.75 ，是根据 泊松统计定义的 */ static final float DEFAULT_LOAD_FACTOR = 0.75f; /** * 桶的树化阈值： 使用红黑树时元素个数的阈值。在存储数据时，当链表长度 &gt;= 8时，则将链表转换成红黑树。 */ static final int TREEIFY_THRESHOLD = 8; /** * 桶的链表还原阈值：红黑树转链表阈值。 * 当在扩容时，在重新计算存储位置后，当原有的红黑树内数量 &lt;= 6时，则将 红黑树转换成链表 */ static final int UNTREEIFY_THRESHOLD = 6; /** * 最小树形化容量阈值：使用红黑树时最小的表容量。当 HashMap 中的容量 &gt; 该值时，才允许树化即将链表转成红黑树。 * 这样是为了减少形成很满的桶，因为桶的数量很少时，容易造成桶满 */ static final int MIN_TREEIFY_CAPACITY = 64; /* ---------------- Fields -------------- */ /** * 存储数据的 Node 数组，长度是 2 的幂。 */ transient Node&lt;K, V&gt;[] table; /** * table 容纳的元素个数 */ transient int size; /** * HashMap 被改变的次数 */ transient int modCount; // 扩容的阈值（当前 HashMap 所能容纳键值对数量的最大值，超过该值则需要扩容），等于 capacity * loadFactory int threshold; // 负载因子，默认为 0.75 final float loadFactor;&#125; TREEIFY_THRESHOLD 和 UNTREEIFY_THRESHOLD 两个参数是控制链表和红黑树相互转换的阈值，它们中间有个差值 7 可以有效防止链表和树频繁转换。其它属性和 JDK 1.7 版本中的类似。值得说明的是桶数组 table 被申明为 transient ，也就是不会被默认的序列化机制序列化。但 HashMap 通过实现 readObject/writeObject 两个方法自定义了序列化的内容，也就是将键值对序列化，后续可以根据键值对数据重建 HashMap。 这里不直接将 table 进行序列化是为了避免以下问题： table 多数情况下是无法被存满的，序列化未使用的部分，浪费空间 同一个键值对在不同 JVM 下所处的桶位置可能是不同的，这种情况下反序列化 table 可能会发生错误。 结构体123456789101112131415161718192021222324252627/** * HashMap 中元素项，用于链表的情况。 * * @param &lt;K&gt; * @param &lt;V&gt; */ static class Node&lt;K, V&gt; implements Map.Entry&lt;K, V&gt; &#123; // key 对应的 hash 值 final int hash; // key final K key; // value V value; // 下一个元素的指针 Node&lt;K, V&gt; next; &#125; /** * HashMap 中元素项，用于红黑树的情况。间接继承了 Node */ static final class TreeNode&lt;K, V&gt; extends LinkedHashMap.Entry&lt;K, V&gt; &#123; TreeNode&lt;K, V&gt; parent; // red-black tree links TreeNode&lt;K, V&gt; left; TreeNode&lt;K, V&gt; right; TreeNode&lt;K, V&gt; prev; // needed to unlink next upon deletion boolean red; &#125; 构造方法123456789101112131415161718192021222324252627282930313233343536373839/** * 指定容量大小和负载因子的构造函数，是最基础的构造函数 * @param initialCapacity * @param loadFactor */ public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); // HashMap的最大容量只能是MAXIMUM_CAPACITY if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); // 设置负载因子 this.loadFactor = loadFactor; // 取大于 cap 且最近的2的整数次幂的数作为扩容的阈值 this.threshold = tableSizeFor(initialCapacity); &#125; // 指定容量大小 public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; // 使用默认属性 public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted &#125; // 使用给定的数据源初始化 HashMap public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); &#125; 注意：在集合初始化时，推荐指定集合初始值大小，在一定程度上可以减少扩容带来的开销。 确定桶位置1tab[(n -1) &amp; hash] 计算方式和 JDK 1.7 HashMap 是一致的。HashMap 的数组长度 length 总是 2^n ，因此 (n - 1) &amp; hash 等价于对 length 取余，由于取余运算效率没有位运算高，这里做了一个优化。此外，length - 1 正好相当于一个低位掩码，&amp; 操作的结果就是 hash 值的高位全部归零，只保留对应的低位值，即定位数组桶的位置取决于 hash 值的低几位。 hash方法1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; 上述方法计算 hash 值没有直接使用 key 的 hashCode 方法生成的 hash 值，而是通过位运算重新计算出一个 hash 值。在 Java 中 hashCode 方法产生的 hash 是 int 类型，也就是 32 位。由于确定数组的桶位置是通过 (n - 1) &amp; hash 计算得到的，这就要求计算 hash 值的算法要具有随机性。因此，在计算 key 的 hashCode 时用其自身 hashCode 与其低 16 位做 ^ 操作，这让高位也参与到 hash 值的计算中来，进而降低了哈希冲突的风险又不会带来太大的性能问题。此外，重新计算 hash 的另一个好处是可以增加 hash 的复杂度。当我们覆写 hashCode 方法时，可能会写出分布性不佳的 hashCode 方法，进而导致 hash 的冲突率比较高。通过移位和异或运算，可以让 hash 变得更复杂，进而影响 hash 的分布性。计算过程如下： Get方法原理123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 根据 key 获取对应 value * * @param key * @return */ public V get(Object key) &#123; Node&lt;K, V&gt; e; // 根据 key 的 hashCode 计算得到 hash 值，然后利用 pos = （n-1）&amp; hash 计算其在数组中的位置 return (e = getNode(hash(key), key)) == null ? null : e.value; &#125; final Node&lt;K, V&gt; getNode(int hash, Object key) &#123; Node&lt;K, V&gt;[] tab; Node&lt;K, V&gt; first, e; int n; K k; // 1 如果 key 对应的数组位置有元素 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; // 1.1 先在头节点中找 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; // 1.2 头节点不是目标元素 if ((e = first.next) != null) &#123; // 1.2.1 如果是红黑树，则去红黑树中找 if (first instanceof TreeNode) return ((TreeNode&lt;K, V&gt;) first).getTreeNode(hash, key); // 1.2.2 如果不是红黑树，则说明是链表，那么就从链中找 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125; Get方法逻辑还是比较简单的。先定位键所在的桶的位置，然后再对链表或红黑树进行查找。 Put方法原理Put方法先定位要插入的键值对属于哪个桶，定位到桶后，再判断桶是否为空。如果为空，则将键值对存入即可。如果不为空，则需将键值对插入到链表最后一个位置或红黑树中，或者更新键值对。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103/** * 添加键值对 * * @param key * @param value * @return */ public V put(K key, V value) &#123; // 通过 hash(key) 计算 key 的 hash 值 return putVal(hash(key), key, value, false, true); &#125; /** * 尾插法 * * @param hash key 的 hash * @param key the key * @param value the value to put * @param onlyIfAbsent 如果为 true ，那么只有在不存在该 key 时才会进行 put 操作，默认是 false 即覆盖 * @param evict if false, the table is in creation mode. * @return previous value, or null if none */ final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K, V&gt;[] tab; Node&lt;K, V&gt; p; int n, i; // 初始化数组 table，table 被延迟到插入新数据时再进行初始化 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // key 映射的数组桶位置为空，则创建一个 Node 填充到对应位置即可 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); // key 映射的数组桶位置有数据 else &#123; Node&lt;K, V&gt; e; K k; // 在该位置的第一个数据的 key 和要插入 遇到相同的 key 了 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 在红黑树中插入节点 // a. 往红黑树中插入节点 b. 调整红黑树 else if (p instanceof TreeNode) e = ((TreeNode&lt;K, V&gt;) p).putTreeVal(this, tab, hash, key, value); // 在链表中插入节点 else &#123; // 对链表进行遍历，并统计链表长度 for (int binCount = 0; ; ++binCount) &#123; // 链表中不包含要插入的键值对节点，则插入到链表的最后，即尾插法 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); // 如果链表长度大于或等于树化阈值，则进行树化操作，也就是将链表转换为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; // 如果在链表中找到了相同的 key if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) // 此时 break，那么 e 为链表中与要插入的新值的 key 相同的 node break; // 用于遍历下一个 p = e; &#125; &#125; // 判断要插入的键值对是否存在 HashMap 中 // e != null 说明存在旧值的 key 与要插入的 key 相同 if (e != null) &#123; // existing mapping for key V oldValue = e.value; // onlyIfAbsent 表示是否仅在 oldValue 为 null 的情况下更新键值对的值 // key 相同进行值覆盖 if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); // 返回旧值 return oldValue; &#125; &#125; // 增加修改次数 ++modCount; // 如果 HashMap 由于新插入这个值导致 size 已经超过了阈值，需要进行扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; 下面对 Put逻辑进行小结： 当桶数组 table 为空时，通过扩容的方式初始化 table 查找要插入的键值对是否已经存在，存在的话根据条件判断是否用新值替换旧值 如果不存在，则将键值对插入红黑树或链表中，其中插入到链表的过程还会根据链表的长度决定是否将链表转为红黑树。具体转换会在下文进行介绍。 判断键值对数量是否大于阈值，大于的话则进行扩容操作 扩容机制在 HashMap 中，桶数组的长度均是 2^n ，当键值对数量超过扩容阈值时，需要进行扩容。HashMap 按当前桶数组长度的 2 倍进行扩容，扩容阈值也更新为原来的 2 倍。扩容之后，需要重新计算键值对的位置，并把它们移动到合适的位置上去。和 JDK 1.7 不同的是，JDK 1.7 是先判断是否需要扩容后插入新值，JDK 1.8 是先插入值再判断是否需要扩容，并且前者是头插法后者是尾插法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124/** * 初始化数组或数组扩容 * * @return the table */ final Node&lt;K, V&gt;[] resize() &#123; Node&lt;K, V&gt;[] oldTab = table; // table 旧的容量，最开始 table 为空 int oldCap = (oldTab == null) ? 0 : oldTab.length; // 扩容阈值 int oldThr = threshold; int newCap, newThr = 0; // oldCap &gt; 0 ，说明是对数组扩容 if (oldCap &gt; 0) &#123; // 超过最大容量，则使用 Integer.MAX_VALUE 的值，不再进行扩容 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; // 将 数组扩大一倍 &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) // 将 扩容阈值 也增大一倍 newThr = oldThr &lt;&lt; 1; // double threshold // 对应使用 new HashMap(int initialCapacity) 初始化后，第一次 put 的时候初始容量设置为 threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; // 对应使用 new HashMap() 初始化后，第一次 put 的时候初始容量使用默认值 else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; // 计算扩容阈值，为 12 newThr = (int) (DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // newThr 为 0 时，按阈值计算公式进行计算 if (newThr == 0) &#123; float ft = (float) newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float) MAXIMUM_CAPACITY ? (int) ft : Integer.MAX_VALUE); &#125; // 更新扩容阈值 threshold = newThr; // 用新的数组大小初始化新的数组 @SuppressWarnings(&#123;\"rawtypes\", \"unchecked\"&#125;) Node&lt;K, V&gt;[] newTab = (Node&lt;K, V&gt;[]) new Node[newCap]; // 如果非扩容而是初始化数组，执行到这里就结束了 table = newTab; // 扩容，进行数据迁移 if (oldTab != null) &#123; // 遍历原数组，将键值对映射到新的桶数组中 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K, V&gt; e; // 取出下标 j 的元素 if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; // 如果当前数组位置上只有一个 Node 元素，简单迁移即可 if (e.next == null) // 通过 hash 值计算出在新数组中所属的位置 newTab[e.hash &amp; (newCap - 1)] = e; // 如果是红黑树，需要对红黑树进行拆分 else if (e instanceof TreeNode) ((TreeNode&lt;K, V&gt;) e).split(this, newTab, j, oldCap); // 链表处理 else &#123; // preserve order // 将当前链表拆分成两个链表，放到新的数组中，并且保留原来的先后顺序 // loHead、loTail 对应一条链表，hiHead、hiTail 对应另一条链表 Node&lt;K, V&gt; loHead = null, loTail = null; Node&lt;K, V&gt; hiHead = null, hiTail = null; Node&lt;K, V&gt; next; // 遍历链表，并将链表节点按原顺序进行分组 do &#123; next = e.next; // 根据e的 hash 值和旧的容量做位与运算是否为 0 来拆分当前链表进行分组，注意之前是 e.hash &amp; (oldCap - 1) if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 将分组后的链表映射到新桶中 // 第一条链表 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 第二条链表的新的位置是 j + oldCap if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; 下面对上述代码流程进行总结： 计算新桶数组的容量 newCap 和新扩容阈值 newThr 根据计算出的 newCap 创建新的桶数组，桶数组 table 也是在这里进行初始化的 将遍历的桶数组的键值对节点重新映射到新的桶数组中。如果节点是 TreeNode 类型，则需要拆分红黑树进行分组然后映射；如果是普通节点，也就是链表，则同样需要分组然后映射。注意，以上分组的依据是根据节点的 hash 值和旧的容量做位与运算是否为 0 来限定的。 在 JDK 1.8 中，重新映射节点需要考虑节点类型。对于树形节点，需要先拆分分组然后映射；对于链表类型节点，也需要先拆分分组，然后映射。需要注意的是，分组后，组内节点相对位置保持不变。相对与 JDK 1.7 采用每个节点重新 hash 且头插入 ，JDK 1.8 采用尾插法且以分组的方式进行重新映射，避免了链表成环的问题。 树化、链化与拆分JDK 1.8 对 HashMap 实现进行了改进。最大的改进莫过于引入红黑树处理频繁的碰撞，同时也增加了代码实现的复杂度。本小结将对 HashMap 中 链表树化、红黑树链化以及红黑树拆分 进行说明。 链表树化12345678910111213141516171819202122232425262728293031323334353637final void treeifyBin(Node&lt;K, V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K, V&gt; e; // 数组容量小于 MIN_TREEIFY_CAPACITY，优先进行扩容而不是树化 // 尽可能避免树化，除非桶中元素碰撞严重 if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); // 取出数组对应位置的头节点 else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; // hd 为头节点(head)，tl 为尾节点（tail） TreeNode&lt;K, V&gt; hd = null, tl = null; do &#123; // 将普通节点替换成树形节点 TreeNode&lt;K, V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else &#123; p.prev = tl; tl.next = p; &#125; tl = p; // 将普通链表转成由树形节点链表 &#125; while ((e = e.next) != null); // 将树形链表转换成红黑树 // hd 是 index 对应桶的首节点 if ((tab[index] = hd) != null) hd.treeify(tab); &#125; &#125; // For treeifyBin TreeNode&lt;K, V&gt; replacementTreeNode(Node&lt;K, V&gt; p, Node&lt;K, V&gt; next) &#123; return new TreeNode&lt;&gt;(p.hash, p.key, p.value, next); &#125; 将链表转为红黑树需要满足以下两个条件： 链表长度大于等于 TREEIFY_THRESHOLD 8 桶数组容量大于等于 MIN_TREEIFY_CAPACITY 64 上述方法主要的过程是，先将链表转成由 TreeNode 类型节点组成的链表，并在最后调用 treeify 将该链表转为红黑树。TreeNode 继承自 Node ，所以 TreeNode 仍然包含 next 引用，原链表的节点顺序最终通过 next 引用被保存下来。 下面我们重点来介绍链表转红黑树的过程。 TreeNode 链表转红黑树将链表转为红黑树需要两个过程，第一个是通过 treeifyBin 方法将普通节点链表转成树形节点链表，也就是 TreeNode 链表；另一个则是 treeify 方法再将第一步得到的树形链表结构转成真正的红黑树。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778/** * 将树形链表转换成红黑树 */ final void treeify(HashMap.Node&lt;K, V&gt;[] tab) &#123; // 定义红黑树的根节点 HashMap.TreeNode&lt;K, V&gt; root = null; // 1 遍历树形链表节点，依次加入到红黑树中。 // x 指向当前节点，next 指向下一个节点 for (HashMap.TreeNode&lt;K, V&gt; x = this, next; x != null; x = next) &#123; // 记录 x 的下一个节点 next = (HashMap.TreeNode&lt;K, V&gt;) x.next; // 左右节点先确保干净 x.left = x.right = null; // 2 如果根节点为空，说明还没有开始构建红黑树，这里开始构建。即将当前节点作为根节点，颜色设为黑色 if (root == null) &#123; x.parent = null; x.red = false; root = x; // 3 红黑树已经存在，则往该树中添加节点 &#125; else &#123; // 记录当前遍历到的树形节点的 key 和 hash K k = x.key; int h = x.hash; Class&lt;?&gt; kc = null; // 3.1 从根节点遍历，为节点 x 找到空位置并插入 for (HashMap.TreeNode&lt;K, V&gt; p = root; ; ) &#123; // dir 表示方向（左边/右边），ph 表示 hash 值 int dir, ph; K pk = p.key; /* 比较大小，定位插入左边/右边*/ // 3.1.1 hash 判断 if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; // 3.1.2 根据比较器判断大小 else if ((kc == null &amp;&amp; // Comparable 接口判断 (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) // 3.1.3 通过 k 类名比较 dir = tieBreakOrder(k, pk); // 保存当前遍历的树节点 HashMap.TreeNode&lt;K, V&gt; xp = p; // 3.2.1 根据 dir 确定放入左边还是右边 // 如果根据 dir 确定了位置后，还要判断 p 是不是叶子节点（末节点），如果不是则继续往下找适合节点x插入的位置，也就是 x 节点的父节点 if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; // x 节点找到了父节点 x.parent = xp; // 将 x 节点挂到它的父节点 xp 下 if (dir &lt;= 0) xp.left = x; else xp.right = x; // 3.2.2 x 节点插入后，可能会导致红黑树不符合规则，因此需要尝试进行调整 root = balanceInsertion(root, x); break; &#125; &#125; &#125; &#125; // 确保根节点作为第一个节点 moveRootToFront(tab, root); &#125; 上面的方法做的只有一个工作，遍历 TreeNode 双向链表，将该链表中每个节点构建到红黑中。下面对流程进行分步说明： 遍历第一个节点时，此时红黑树不存在，以第一个节点作为红黑树根节点。 有了红黑树后，此后遍历链表的每个节点时，都要根据规则到红黑树中从根节点开始寻找要插入当前节点的位置，也就是找到一个父节点，将当前节点作为其左节点或右节点。 插入节点后，可能会导致红黑树特性被破坏，因此每次插入节点后要尝试重新调整红黑树。 上述方法完成了 TreeNode 链表中每个节点构建红黑树的过程，一个节点构建到红黑树后并没有结束，还要保证红黑树不能因为新增一个节点就被破坏，而保证的手段就是红黑树调整。 红黑树调整123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115static &lt;K, V&gt; HashMap.TreeNode&lt;K, V&gt; balanceInsertion(HashMap.TreeNode&lt;K, V&gt; root, HashMap.TreeNode&lt;K, V&gt; x) &#123; // 默认插入红色 x.red = true; // xp -&gt; 父节点 // xpp -&gt; 祖父节点 // xppl 是祖父节点的左节点（左叔叔节点） // xppr 是祖父节点的右节点（右叔叔节点） for (HashMap.TreeNode&lt;K, V&gt; xp, xpp, xppl, xppr; ; ) &#123; // 1 x 节点的父节点不存在，说明当前节点是根节点，只需变色为黑色即可 if ((xp = x.parent) == null) &#123; x.red = false; return x; // 2 x 节点的父节点是黑色，可以在下面直接添加红色节点，不需要调整；x 节点的祖父节点为空，说明 x 的父节点是根节点，可以在下面直接添加红色节点，也不许要调整 &#125; else if (!xp.red || (xpp = xp.parent) == null) return root; // 3 x 的父节点 xp 是红色且 x 祖父节点 xxp 不为空。这样就遇到了两个红色节点相连的情况。这种情况分两种可能 // 3.1 如果父节点 xp 是祖父节点的左节点 if (xp == (xppl = xpp.left)) &#123; // 3.1.1 如果祖父节点的右节点（右叔叔节点）不为空，同时是红色。则： // a. 将父节点和右叔叔节点变色 -&gt; 黑色 // b. 将祖父节点变色 -&gt; 红色 // c. 将祖父节点作为当前节点 x ，进行下一轮的调整（xxp 节点变成红色后可能与xpp的父节点发生冲突，也就是两个连续的红色节点） if ((xppr = xpp.right) != null &amp;&amp; xppr.red) &#123; xppr.red = false; xp.red = false; xpp.red = true; x = xpp; // 3.1.2 如果祖父节点的右节点（右叔叔节点）为空或是黑色。那么就可能对应以下两种情况： &#125; else &#123; // 3.1.2.1 xpp-&gt;xp(xxp的左节点)-&gt;x(xp的右节点) =&gt; LR 双红 if (x == xp.right) &#123; // 将 xp 节点左旋，调整成 LL 双红的情况 root = rotateLeft(root, x = xp); // 重置 xp，xxp // 左旋后得到的本来是： xpp-&gt;x(xxp的左节点)-&gt;xp(x的左节点) =&gt; LL 双红 // 但是由于 x = xp 了，因此恰巧从变量的角度看是这个样子：xpp-&gt;xp(xxp 的左节点)-&gt;x(xp的左节点) =&gt; LL 双红 xpp = (xp = x.parent) == null ? null : xp.parent; &#125; // 3.1.2.2 xpp-&gt;xp(xxp 的左节点)-&gt;x(xp的左节点) =&gt; LL 双红 if (xp != null) &#123; // 父节点 xp 变色 -&gt; 黑色 xp.red = false; // 存在祖父节点 if (xpp != null) &#123; // 祖父节点 xpp 变色 -&gt; 红色 xpp.red = true; // 右旋祖父节点 // 特别说明：上一步将祖父节点 xpp 变成红色，为啥这里直接旋转祖父节点 xpp 就可以结束了？因为 xp 变成了黑色，旋转后的结果是 xpp 挂到 xp 的右边成为 xp 的孩子节点， // xp 成为最开始 xpp 的父节点的孩子节点（如果 xpp 是根节点，那么此时 xp 就是新的根节点），因此这里不用考虑 xpp 变色后破坏红黑树特点。简单来说，对于 xpp 的父节点 // 而言只是将 xpp 这个孩子节点换成了 xp ，但是节点颜色相比之前是没有变的。 root = rotateRight(root, xpp); &#125; &#125; &#125; // 3.2 父节点 xp 是祖父节点的右节点。和上面的情况相反但操作类似，一个是左节点，另一个是右节点 &#125; else &#123; // 3.2.1 如果 x 节点的祖父节点的左节点（左叔叔节点）不为空，同时是红色。则： // a. 将父节点和左叔叔节点变色 -&gt; 黑色 // b. 将祖父节点变色 -&gt; 红色 // c. 将祖父节点作为当前节点 x ，进行下一轮的调整（xxp 节点变成红色后可能与xpp的父节点发生冲突，也就是两个连续的红色节点） if (xppl != null &amp;&amp; xppl.red) &#123; xppl.red = false; xp.red = false; xpp.red = true; x = xpp; // 3.2.2 如果祖父节点的左节点（左叔叔节点）为空或是黑色。那么就可能对应以下两种情况： &#125; else &#123; // 3.2.2.1 xpp-&gt;xp(xxp的右节点)-&gt;x(xp的左节点) =&gt; RL 双红 if (x == xp.left) &#123; // 将父节点 xp 右旋转，得到 RR 双红 root = rotateRight(root, x = xp); // 原因同 3.1.2.2 xpp = (xp = x.parent) == null ? null : xp.parent; &#125; // 3.2.2.2 xpp-&gt;xp(xxp的右节点)-&gt;x(xp的右节点) =&gt; RR 双红 if (xp != null) &#123; // 父节点变色 -&gt; 黑色 xp.red = false; // 存在祖父节点 if (xpp != null) &#123; // 祖父节点变色 -&gt; 红色 xpp.red = true; // 左旋祖父节点 // 特别说明：原因同上 root = rotateLeft(root, xpp); &#125; &#125; &#125; &#125; &#125; &#125; 左旋12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * 左旋： * 1 将节点 p 旋转为其右节点的左节点，即将节点 p 挂到其右节点的左边 * 2 其右节点的左节点成为节点p 的右节点 * * @param root * @param p * @param &lt;K&gt; * @param &lt;V&gt; * @return */ static &lt;K, V&gt; HashMap.TreeNode&lt;K, V&gt; rotateLeft(HashMap.TreeNode&lt;K, V&gt; root, HashMap.TreeNode&lt;K, V&gt; p) &#123; // r -&gt; 节点 p 的右节点 // rl -&gt; 节点 p 的右节点的左节点 // pp -&gt; 节点 p 的父节点，最后是 p 的右节点的父节点 HashMap.TreeNode&lt;K, V&gt; r, pp, rl; // p 不为空且右节点不为空 if (p != null &amp;&amp; (r = p.right) != null) &#123; // 1 将 p 的右节点的左节点挂到 p 的右节点，这有两个信息 // a. 断开 p 与其右节点 r 的连接 // b. 因为 p 要挂到其右节点 r 的左边，因此要把节点 r 原来的左节点挂到 p 的右边 if ((rl = p.right = r.left) != null) // r 节点的左节点的父节点重置为 p rl.parent = p; // 2 将 p 的父节点设置为 p 的右节点的父节点 if ((pp = r.parent = p.parent) == null) // 如果 p 为 root 节点，那么直接将其右节点设置为 root (root = r).red = false; // 3 确定 r 节点应该挂在 p 的父节点的左边还是右边。这个根据 p 的位置决定 else if (pp.left == p) pp.left = r; else pp.right = r; // 4 将 p 设置为其右节点的左边 r.left = p; // 5 将 p 的右节点指为其父节点 p.parent = r; &#125; // 返回根节点 return root; &#125; 右旋1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 右旋： * 1 将节点 p 旋转为其左节点的右节点，即将节点 p 挂到其左节点的右边 * 2 其左节点的右节点成为节点 p 的左节点 * * @param root * @param p * @param &lt;K&gt; * @param &lt;V&gt; * @return */ static &lt;K, V&gt; HashMap.TreeNode&lt;K, V&gt; rotateRight(HashMap.TreeNode&lt;K, V&gt; root, HashMap.TreeNode&lt;K, V&gt; p) &#123; // l -&gt; 节点 P 的左节点 // pp -&gt; 节点 p 的父节点 // lr -&gt; 节点 p 的左节点的右孩子 HashMap.TreeNode&lt;K, V&gt; l, pp, lr; // 节点 p 和 其左节点不为空 if (p != null &amp;&amp; (l = p.left) != null) &#123; // 1 将 p 的左节点的右孩子挂到 p 的左边 if ((lr = p.left = l.right) != null) // 将 p 指定为 lr 的父节点 lr.parent = p; // 2 将 p 的父节点指定为其右节点的父节点 if ((pp = l.parent = p.parent) == null) (root = l).red = false; // 2.1 确定 p 的右节点应该挂在 p的父节点左边还是右边 else if (pp.right == p) pp.right = l; else pp.left = l; // 3 调整 p 的关系： // a.将 p 设置为其左节点的右孩子 // b.将 p 的父节点指定为其左节点 l.right = p; p.parent = l; &#125; // 返回根节点 return root; &#125; 红黑树调整的过程完全是红黑树节点插入的过程，由于涉及的情况比较多，下面我们对上述过程分情况分析。再强调一遍，调整过程是红黑树的操作过程，并非 HashMap 自己搞的一套调整逻辑。 情况一红黑树为空树，插入的新节点 X 作为红黑树的根节点，这种情况下将节点 X 的颜色由红色变成黑色即可。 情况二插入的新节点 X 的父节点是黑色，这种情况下不需要调整。 情况三插入的新节点 X 的父节点是红色（节点 P 为红色，其父节点必然为黑色），叔叔节点 U 也是红色。由于 P 和 U 都是红色，不满足每个红色节点必须有两个黑色的子节点，也就是不能同时存在两个连续的红节点。这种情况下需要调整，先将 P 和 U 变为黑色，再将 PP 变为红色。但需要注意的是 PP 变为红色后，可能会和它的父节点形成连续的红色节点，此时需要递归向上调整，也就将 PP 看作新插入节点继续尝试调整。 情况四插入节点 X 的父节点为红色，叔叔节点不存在或为黑色（下面的所以情况以黑色为例进行说明）。这里需要根据插入节点 X 的父节点是祖父节点的左子树还是右子树进行讨论，不同的情况处理的逻辑不同。主要不同在于旋转的方向上不同。 父节点为祖父节点左子树 根据插入节点 X 是父节点的左子树还是右子树又可分为两类。 插入节点是父节点的右子树插入节点 X 的父节点 P 为红色，属于 LR 形。叔叔节点 U 为黑色。节点 X 是 P 的右子树，且节点 P 是 PP 的左子树。此时先对节点 P 进行左旋，调整节点 X 与 P 的位置，变为 LL 形。接下来按照 LL 形进行处理即可，也就是下面的 插入节点是父节点的左子树 情况。 插入节点是父节点的左子树插入节点 X 的父节点 P 为红色，属于 LL 形。叔叔节点 U 为黑色。节点 X 是 P 的左子树，且节点 P 是 PP 的左子树。此时先将 P 变成黑色，PP 变成红色；然后对 PP 进行右旋，调整 P 和 PP 的位置。 父节点为祖父节点右子树 根据插入节点 X 是父节点的左子树还是右子树又可分为两类。 插入节点是父节点的左子树插入节点 X 的父节点 P 为红色，属于 RL 形。叔叔节点 U 为黑色。节点 X 是 P 的左子树，且节点 P 是 PP 的右子树。此时先对节点 P 进行右旋，调整节点 X 与 P 的位置，变为 RR 形。接下来按照 RR 形进行处理即可，也就是下面的 插入节点是父节点的右子树 情况。 插入节点是父节点的右子树插入节点 X 的父节点 P 为红色，属于 RR 形。叔叔节点 U 为黑色。节点 X 是 P 的右子树，且节点 P 是 PP 的右子树。此时先将 P 变成黑色，PP 变成红色；然后对 PP 进行左旋，调整 P 和 PP 的位置。 以上四种情况覆盖了黑树调整的所有可能情况，对应了代码注释的 4 个分支。 红黑树拆分在扩容的过程，普通节点需要重新映射，红黑树节点同样也需要。在将普通链表转成红黑树时，HashMap 通过两个额外的引用 next 和 prev 保留了原链表的节点顺序。这样再对红黑树进行重新映射时，完全可以按照映射链表的方式进行，这样就避免了将红黑树转成链后再映射的过程，在一定程度上提高了效率。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859final void split(HashMap&lt;K, V&gt; map, HashMap.Node&lt;K, V&gt;[] tab, int index, int bit) &#123; HashMap.TreeNode&lt;K, V&gt; b = this; // 重新链接到 lo 和 hi 列表，保持顺序 HashMap.TreeNode&lt;K, V&gt; loHead = null, loTail = null; HashMap.TreeNode&lt;K, V&gt; hiHead = null, hiTail = null; int lc = 0, hc = 0; /** * 红黑树节点仍然保留了 next 引用，因此仍可以按链表方式遍历红黑树。下面的循环是对红黑树节点进行分组，与普通链表操作类似 */ for (HashMap.TreeNode&lt;K, V&gt; e = b, next; e != null; e = next) &#123; next = (HashMap.TreeNode&lt;K, V&gt;) e.next; e.next = null; if ((e.hash &amp; bit) == 0) &#123; if ((e.prev = loTail) == null) loHead = e; else loTail.next = e; loTail = e; ++lc; &#125; else &#123; if ((e.prev = hiTail) == null) hiHead = e; else hiTail.next = e; hiTail = e; ++hc; &#125; &#125; /* 两个 TreeNode 链表分组完毕 */ // 如果 loHead 不为空，且链表长度小于等于 6，则将红黑树转成链表 if (loHead != null) &#123; if (lc &lt;= UNTREEIFY_THRESHOLD) tab[index] = loHead.untreeify(map); else &#123; tab[index] = loHead; // hiHead == null 时，表明扩容后，所有节点仍在原位置，树结构不变，无需重新树化 // 否则，将 TreeNode 链表重新树化 if (hiHead != null) // (else is already treeified) loHead.treeify(tab); &#125; &#125; // 同上面逻辑 if (hiHead != null) &#123; if (hc &lt;= UNTREEIFY_THRESHOLD) tab[index + bit] = hiHead.untreeify(map); else &#123; tab[index + bit] = hiHead; if (loHead != null) hiHead.treeify(tab); &#125; &#125; &#125; 从上述代码中可以看到，重新映射红黑树的逻辑和重新映射链表的逻辑基本一致。不同的地方在于，重新映射后，会将红黑树拆分成两条由 TreeNode 组成的链表。如果链表长度小于等于 UNTREEIFY_THRESHOLD，则将链表转换成普通链表。否则根据条件重新将 TreeNode 链表树化。 红黑树链化红黑树中仍然保留了原链表节点顺序，有了这个基础再将红黑树转成链表就简单多了，仅需要将 TreeNode 链表转成 Node 类型的链表即可。 12345678910111213141516171819202122232425262728 /** * 红黑树中仍然保留了原链表节点顺序。有个这个特点，再将红黑树转成链表就简单多了，仅需将 TreeNode 链表转成 Node 类型的链表即可。 */ final HashMap.Node&lt;K, V&gt; untreeify(HashMap&lt;K, V&gt; map) &#123; // 用于组织链表的头、尾指针 HashMap.Node&lt;K, V&gt; hd = null, tl = null; // 遍历 TreeNode 链表，并用 Node 替换 for (HashMap.Node&lt;K, V&gt; q = this; q != null; q = q.next) &#123; /** * 替换节点类型 * Node&lt;K,V&gt; replacementNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) &#123; * return new Node&lt;&gt;(p.hash, p.key, p.value, next); * &#125; */ HashMap.Node&lt;K, V&gt; p = map.replacementNode(q, null); if (tl == null) hd = p; else tl.next = p; tl = p; &#125; return hd; &#125; Node&lt;K,V&gt; replacementNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) &#123; return new Node&lt;&gt;(p.hash, p.key, p.value, next);&#125; 小结感觉没什么可总结的，写的已经很详细了。 参考 什么是HashMap","categories":[{"name":"JDK","slug":"JDK","permalink":"https://gentryhuang.com/categories/JDK/"}],"tags":[{"name":"HashMap","slug":"HashMap","permalink":"https://gentryhuang.com/tags/HashMap/"}]},{"title":"Java基础 - JDK动态代理","slug":"java-base/jdk动态代理","date":"2021-01-03T12:30:35.000Z","updated":"2021-06-30T07:37:40.272Z","comments":false,"path":"posts/d38b32e5/","link":"","permalink":"https://gentryhuang.com/posts/d38b32e5/","excerpt":"","text":"概述Java 中代理分为两大类，一类是静态代理，另一类是动态代理。静态代理是针对需要被代理的类在编译之前就已经写好了对应的代理类，也就是说代理关系在编译之前就确立了。动态代理是针对目标类在程序运行期间自动生成的代理类，细分为有接口的代理类和无接口的代理类。JDK动态代理支持目标类有接口的情况，目标类没有接口无法为其生成代理类，能够为没有接口生成代理类的工具如 CGLIB 等。本篇文章将对JDK动态代理实现原理进行介绍。 示例接口12345678public interface IPrintf &#123; /** * 打印信息 * * @param message 信息 */ void print(String message);&#125; 实现类1234567public class PrintfImpl implements IPrintf &#123; @Override public void print(String message) &#123; System.out.println(\"print: \" + message); &#125;&#125; 代理对象1234567891011121314151617181920212223242526272829303132333435363738394041424344public class Client &#123; /** * 实例化对象 */ private static final IPrintf PRINTF = new PrintfImpl(); /** * JDK 生成代理对象 * * @return $Proxy0 */ public static IPrintf getProxy() &#123; // 返回代理对象 return (IPrintf) Proxy.newProxyInstance( // 类加载器，在程序运行时将生成的代理类加载到JVM中 PRINTF.getClass().getClassLoader(), // 被代理类的所有接口信息，用来确定生成的代理类可以具有哪些方法 PRINTF.getClass().getInterfaces(), // 调用处理器，每个代理对象都具有一个关联的调用处理器，用于指定动态生成的代理类需要完成的具体操作。 // 该接口中有一个 invoke 方法，代理对象调用任何目标接口的方法时都会调用该 invoke 方法，该方法中会通过反射调用目标方法。 new InvocationHandler() &#123; /** * * @param proxy 代理对象 * @param method 代理对象当前调用的方法 * @param args 方法参数 * @return 方法执行的结果（无返回值则为 null） * @throws Throwable 异常 */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; // 前置逻辑 System.out.println(\"before action ... \"); // 将方法派发给目标方法 Object result = method.invoke(PRINTF, args); // 后置逻辑 System.out.println(\"after action ... \"); return result; &#125; &#125; ); &#125;&#125; 测试12345678public class ProxyTest &#123; @Test public void test() &#123; IPrintf proxy = Client.getProxy(); proxy.print(\"hello world!\"); &#125;&#125; 打印结果 代理类通过阿里开源 Java 应用诊断工具 Arthas 反编译代理类，结果如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697/* * Decompiled with CFR. */package com.sun.proxy;import com.code.proxy.IPrintf;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.lang.reflect.UndeclaredThrowableException;public final class $Proxy4extends Proxyimplements IPrintf &#123; // 静态属性，每个属性对应接口中的一个方法 private static Method m1; private static Method m2; private static Method m0; private static Method m3; // 构造方法，入参类型为 InvocationHandler public $Proxy4(InvocationHandler invocationHandler) &#123; // 调用父类 Proxy 的构造方法 super(invocationHandler); &#125; // 静态代码块中通过反射初始化Method属性 static &#123; try &#123; // Object 中的三大方法 m1 = Class.forName(\"java.lang.Object\").getMethod(\"equals\", Class.forName(\"java.lang.Object\")); m2 = Class.forName(\"java.lang.Object\").getMethod(\"toString\", new Class[0]); m0 = Class.forName(\"java.lang.Object\").getMethod(\"hashCode\", new Class[0]); // 目标类的接口中的方法 m3 = Class.forName(\"com.code.proxy.IPrintf\").getMethod(\"print\", Class.forName(\"java.lang.String\")); return; &#125; // 异常处理 catch (NoSuchMethodException noSuchMethodException) &#123; throw new NoSuchMethodError(noSuchMethodException.getMessage()); &#125; catch (ClassNotFoundException classNotFoundException) &#123; throw new NoClassDefFoundError(classNotFoundException.getMessage()); &#125; &#125; public final boolean equals(Object object) &#123; try &#123; return (Boolean)this.h.invoke(this, m1, new Object[]&#123;object&#125;); &#125; catch (Error | RuntimeException throwable) &#123; throw throwable; &#125; catch (Throwable throwable) &#123; throw new UndeclaredThrowableException(throwable); &#125; &#125; public final String toString() &#123; try &#123; return (String)this.h.invoke(this, m2, null); &#125; catch (Error | RuntimeException throwable) &#123; throw throwable; &#125; catch (Throwable throwable) &#123; throw new UndeclaredThrowableException(throwable); &#125; &#125; public final int hashCode() &#123; try &#123; return (Integer)this.h.invoke(this, m0, null); &#125; catch (Error | RuntimeException throwable) &#123; throw throwable; &#125; catch (Throwable throwable) &#123; throw new UndeclaredThrowableException(throwable); &#125; &#125; // 目标类的打印方法 public final void print(String string) &#123; try &#123; // this.h 是 Proxy 中的属性，即调用 Proxy.newProxyInstance 方法传入的 InvocationHandler 对象 this.h.invoke(this, m3, new Object[]&#123;string&#125;); return; &#125; catch (Error | RuntimeException throwable) &#123; throw throwable; &#125; catch (Throwable throwable) &#123; throw new UndeclaredThrowableException(throwable); &#125; &#125;&#125; 通过上面反编译后的代理类代码不难看出，JDK 动态代理实现具有以下特点： 生成的代理类继承了 Proxy 类且实现了 目标类的接口，有参构造方法的参数类型是 InvocationHandler ，反射创建代理对象执行的就是该构造方法。 代理类通过反射为目标接口（接口列表）中的每个方法都映射一个 Method 对象。 代理类对接口中方法的实现逻辑都是通过 InvocationHandler.invoke 方法派发执行的，代理对象调用任何目标接口的方法时都会调用这个invoke方法，该方法中进行目标类的目标方法的调用，即每个方法执行逻辑都由第 2 步中的 Method 对象执行。 关于 JDK 动态代理使用就介绍完毕了，下面我们对底层实现原理进行说明。实现原理中的部分描述信息会引用到上述代码片段。 JDK 动态代理Java 中需要在运行期动态的生成一个类并创建其对象，一般需要使用字节码技术和反射机制。JDK 动态代理通过java.lang.reflect.Proxy提供了一种原生的动态代理模式，其底层通过对字节码的操作和反射的使用组装代理类，如前文中的 $Proxy4，最后通过反射创建代理对象。 JDK通过调用静态方法 Proxy.newProxyInstance() 创建动态代理，该方法需要三个参数： 类加载器通常可以从已经被加载的对象中获取其类加载器。 接口列表预期代理实现的接口列表。 InvocationHandler 接口的实现作为动态代理对象的调用处理器，即动态代理可以将所有调用派发到该调用处理器。因此，通常会向调用处理器的构造器中传入一个目标对象的引用，从而使得调用处理器在执行中介任务时可以将请求转发。 介绍完代理相关的概念和使用方式后，下面我们对 JDK 动态代理实现原理进行说明。 源码分析Proxy属性1234567891011121314151617181920212223242526272829303132333435363738+--- java.lang.reflect.Proxy /** * 构造方法参数类型，就是 InvocationHandler */ private static final Class&lt;?&gt;[] constructorParams = &#123;InvocationHandler.class&#125;; /** * 代理类的缓存 */ private static final WeakCache&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt; proxyClassCache = new WeakCache&lt;&gt;(new KeyFactory(), new ProxyClassFactory()); /** * 代理对象调用的处理器 * * @serial */ protected InvocationHandler h; /** * Prohibits instantiation. */ private Proxy() &#123; &#125; /** * 供生成的动态代理类调用，也就是 Proxy 的子类。 * * @param h 用于代理对象的调用处理器 * @throws NullPointerException */ protected Proxy(InvocationHandler h) &#123; Objects.requireNonNull(h); this.h = h; &#125; // 省略其它代码...&#125; Proxy 中有 3 个核心属性，下面简单介绍： constructorParamsProxy 中的有参构造器的参数，是个固定值即调用处理器 InvocationHandler，生成的代理类都会调用 Proxy 这个父类的构造方法。 proxyClassCache缓存生成的代理类，用于提高效率。需要注意的是，KeyFactory 和 ProxyClassFactory 都是 Proxy 的内部类，前者用于返回接口对应的弱引用，后者根据指定的类加载器和接口列表生成代理类。 h调用处理器，该处理器会将代理对象的方法调用派发给目标方法。 内部类 KeyFactory123456789101112131415161718192021222324private static final class KeyFactory implements BiFunction&lt;ClassLoader, Class&lt;?&gt;[], Object&gt; &#123; /** * 返回接口对应的弱引用信息。Key1、Key2 以及 KeyX 都持有 WeakReference * * @param classLoader * @param interfaces * @return */ @Override public Object apply(ClassLoader classLoader, Class&lt;?&gt;[] interfaces) &#123; switch (interfaces.length) &#123; case 1: return new Key1(interfaces[0]); // the most frequent case 2: return new Key2(interfaces[0], interfaces[1]); case 0: return key0; default: return new KeyX(interfaces); &#125; &#125;&#125; KeyFactory 就一个工作，返回接口对应的弱引用信息，KeyN 继承了 WeakReference 类。 内部类 ProxyClassFactory1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192private static final class ProxyClassFactory implements BiFunction&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt; &#123; // 代理类名称前缀，具体名称为： $Proxy + Num private static final String proxyClassNamePrefix = \"$Proxy\"; // 生成代理名称的序号，是自增原子类 private static final AtomicLong nextUniqueNumber = new AtomicLong(); /** * 生成代理类的逻辑 * * @param loader 类加载器 * @param interfaces 接口集合 * @return 代理类 */ @Override public Class&lt;?&gt; apply(ClassLoader loader, Class&lt;?&gt;[] interfaces) &#123; Map&lt;Class&lt;?&gt;, Boolean&gt; interfaceSet = new IdentityHashMap&lt;&gt;(interfaces.length); // 遍历接口集合 for (Class&lt;?&gt; intf : interfaces) &#123; // 1 验证类加载器是否将当前接口名称解析为相同的类对象 Class&lt;?&gt; interfaceClass = null; try &#123; interfaceClass = Class.forName(intf.getName(), false, loader); &#125; catch (ClassNotFoundException e) &#123; &#125; if (interfaceClass != intf) &#123; throw new IllegalArgumentException( intf + \" is not visible from class loader\"); &#125; // 2 判断是否是接口 if (!interfaceClass.isInterface()) &#123; throw new IllegalArgumentException( interfaceClass.getName() + \" is not an interface\"); &#125; // 3 验证接口是否重复加载 if (interfaceSet.put(interfaceClass, Boolean.TRUE) != null) &#123; throw new IllegalArgumentException( \"repeated interface: \" + interfaceClass.getName()); &#125; &#125; // 4 代理所在包的名称 String proxyPkg = null; int accessFlags = Modifier.PUBLIC | Modifier.FINAL; // 5 记录非public类型的接口，如果是非public类型的接口，则会将代理类定义在该对应的包中。当且仅当所有非public类型的接口都在一个包中才行，否则不合法 for (Class&lt;?&gt; intf : interfaces) &#123; int flags = intf.getModifiers(); if (!Modifier.isPublic(flags)) &#123; accessFlags = Modifier.FINAL; String name = intf.getName(); int n = name.lastIndexOf('.'); String pkg = ((n == -1) ? \"\" : name.substring(0, n + 1)); if (proxyPkg == null) &#123; proxyPkg = pkg; &#125; else if (!pkg.equals(proxyPkg)) &#123; throw new IllegalArgumentException( \"non-public interfaces from different packages\"); &#125; &#125; &#125; // 6 如果接口是public类型的，则使用固定的包名： com.sun.proxy if (proxyPkg == null) &#123; proxyPkg = ReflectUtil.PROXY_PACKAGE + \".\"; &#125; // 7 组装代理类名称，格式：proxyPkg + $Proxy + Num long num = nextUniqueNumber.getAndIncrement(); String proxyName = proxyPkg + proxyClassNamePrefix + num; // 8 根据代理类名和接口列表使用 ProxyGenerator 生成指定的代理类，可能返回null （配置了虚拟机参数，将代理类字节信息输出到文件） byte[] proxyClassFile = ProxyGenerator.generateProxyClass(proxyName, interfaces, accessFlags); try &#123; // 9 调用native方法，返回代理类 return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length); &#125; catch (ClassFormatError e) &#123; // 排除代理类生成代码中的bug，提供给代理类创建的参数存在其他问题(例如超出了虚拟机限制)。 throw new IllegalArgumentException(e.toString()); &#125; &#125; &#125; ProxyClassFactory 完成生成字节码的操作，是生成代理类的完整流程，具体工作如下： 根据目标类的接口类型确定生成代理类全路径名 执行 ProxyGenerator.generateProxyClass 方法，根据代理类名和接口生成代理类字节码数组或文件形式 调用 native 方法将代理类字节码数据转化为代理类 Class ProxyGeneratorProxyClassFactory.apply 通过调用 ProxyGenerator.generateProxyClass 方法组装代理类，对接口的 Class 对象、Method 对象进行拆解、封装进而生成字节码层面的方法、构造方法以及静态代码块。 属性1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556+--- ProxyGenerator // JVM参数，是否将生成的代理类保存到文件 private static final boolean saveGeneratedFiles = (Boolean) AccessController.doPrivileged(new GetBooleanAction(\"sun.misc.ProxyGenerator.saveGeneratedFiles\")); // Object 三大方法 private static Method hashCodeMethod; private static Method equalsMethod; private static Method toStringMethod; // 代理类全路径名 private String className; // 接口数组 private Class&lt;?&gt;[] interfaces; private int accessFlags; /** * ProxyGenerator 中的常量池 */ private ProxyGenerator.ConstantPool cp = new ProxyGenerator.ConstantPool(); /** * 记录方法标识，用于生成代理类中的方法的属性。 */ private List&lt;ProxyGenerator.FieldInfo&gt; fields = new ArrayList(); /** * 生成的方法信息集合，包括构造方法、静态代码块。 */ private List&lt;ProxyGenerator.MethodInfo&gt; methods = new ArrayList(); /** * 方法签名到方法代理对象的映射 */ private Map&lt;String, List&lt;ProxyGenerator.ProxyMethod&gt;&gt; proxyMethods = new HashMap(); private int proxyMethodCount = 0; static &#123; // 反射获取三大方法对象 try &#123; hashCodeMethod = Object.class.getMethod(\"hashCode\"); equalsMethod = Object.class.getMethod(\"equals\", Object.class); toStringMethod = Object.class.getMethod(\"toString\"); &#125; catch (NoSuchMethodException var1) &#123; throw new NoSuchMethodError(var1.getMessage()); &#125; &#125; /** * 构造方法 * * @param var1 代理类名称 * @param var2 目标类接口集合 * @param var3 */ private ProxyGenerator(String var1, Class&lt;?&gt;[] var2, int var3) &#123; this.className = var1; this.interfaces = var2; this.accessFlags = var3; &#125; JDK 动态代理涉及到的基础类先介绍到这里，下面我们从 Proxy.newProxyInstance 入口出发，根据调用链逐步分析源代码。 newProxyInstance123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566+--- Proxy /** * 创建代理对象。 * * @param loader 代理类的加载器 * @param interfaces 目标类的接口列表 * @param h 代理对象方法调用都会分派给该调用处理器 * @return 代理对象 * @throws IllegalArgumentException */ @CallerSensitive public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException &#123; // 调用处理器是必传参数 Objects.requireNonNull(h); // 接口列表 final Class&lt;?&gt;[] intfs = interfaces.clone(); final SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; checkProxyAccess(Reflection.getCallerClass(), loader, intfs); &#125; // 1. 查找或生成指定的代理类。 Class&lt;?&gt; cl = getProxyClass0(loader, intfs); try &#123; // 对生成的代理类进行安全检查 if (sm != null) &#123; checkNewProxyPermission(Reflection.getCallerClass(), cl); &#125; // 2. 获取代理类的指定构造方法，即参数类型为 InvocationHandler 的构造方法 final Constructor&lt;?&gt; cons = cl.getConstructor(constructorParams); final InvocationHandler ih = h; // 3. 保证代理类的构造方法 cons 具有访问权限，便于后续反射创建代理对象 if (!Modifier.isPublic(cl.getModifiers())) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; cons.setAccessible(true); return null; &#125; &#125;); &#125; // 4. 反射创建代理对象，注意参数为 InvocationHandler return cons.newInstance(new Object[]&#123;h&#125;); &#125; catch (IllegalAccessException | InstantiationException e) &#123; throw new InternalError(e.toString(), e); &#125; catch (InvocationTargetException e) &#123; Throwable t = e.getCause(); if (t instanceof RuntimeException) &#123; throw (RuntimeException) t; &#125; else &#123; throw new InternalError(t.toString(), t); &#125; &#125; catch (NoSuchMethodException e) &#123; throw new InternalError(e.toString(), e); &#125; &#125; Proxy.newProxyInstance 方法是生成代理对象的入口，下面对该方法的逻辑进行简单说明： 调用 getProxyClass0 方法根据指定的类加载器和接口列表获取代理类。这一步是整个代理逻辑的核心实现。 反射获取参数为 InvocationHandler的代理类的构造方法，并保证该构造方法是可访问的。 通过 newInstance 方法反射创建代理对象，参数类型为 InvocationHandler 。 第 2、3 步都很容易理解，下面我们重点来分析获取代理类的 getProxyClass0 方法。 getProxyClass0123456789101112131415161718+--- Proxy /** * 生成代理类。在调用此方法之前，必须调用checkProxyAccess方法来执行权限检查。 */ private static Class&lt;?&gt; getProxyClass0(ClassLoader loader, Class&lt;?&gt;... interfaces) &#123; if (interfaces.length &gt; 65535) &#123; throw new IllegalArgumentException(\"interface limit exceeded\"); &#125; /** * 获取代理类： * 1. 如果代理类存在则返回缓存的副本。 * 2. 不存在，则通过 ProxyClassFactory 创建代理类 */ return proxyClassCache.get(loader, interfaces); &#125; 前文中有提到代理类缓存属性 WeakCache proxyClassCache ，它的主要作用就是先查找对应的代理类缓存，没有的话就通过 java.lang.reflect.Proxy.ProxyClassFactory#apply 方法创建代理类，该方法在前文中已经详细说明。下面我们对 ProxyGenerator.generateProxyClass 根据代理类名和接口生成代理类字节码数组或文件形式 这一步骤进行说明。 generateProxyClass123456789101112131415161718192021222324252627282930313233343536373839404142434445+--- ProxyGenerator/** * 生成代理类-字节码形式 * * @param var0 代理类名称 * @param var1 目标类接口 * @param var2 * @return */ public static byte[] generateProxyClass(final String var0, Class&lt;?&gt;[] var1, int var2) &#123; ProxyGenerator var3 = new ProxyGenerator(var0, var1, var2); // 生成目标类的接口信息的字节码 final byte[] var4 = var3.generateClassFile(); // 添加JVM 参数 sun.misc.ProxyGenerator.saveGeneratedFiles ，则保存到文件 if (saveGeneratedFiles) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; try &#123; int var1 = var0.lastIndexOf(46); Path var2; if (var1 &gt; 0) &#123; // 创建目录 Path var3 = Paths.get(var0.substring(0, var1).replace('.', File.separatorChar)); Files.createDirectories(var3); var2 = var3.resolve(var0.substring(var1 + 1, var0.length()) + \".class\"); &#125; else &#123; var2 = Paths.get(var0 + \".class\"); &#125; // 保存到文件 Files.write(var2, var4, new OpenOption[0]); return null; &#125; catch (IOException var4x) &#123; throw new InternalError(\"I/O exception saving generated file: \" + var4x); &#125; &#125; &#125;); &#125; return var4; &#125; generateProxyClass 方法用于根据代理类名称和接口列表生成预期的代理类的字节码（数组）信息，最后通过 JDK 的本地方法转化为具体的代理类。该方法支持通过配置JVM参数将目标代理类输出到文件中。 在分析 ProxyGenerator.generateClassFile 方法之前，我们先对涉及的核心类和方法进行简单说明。注意该方法整个流程比较复杂，本文只对整体逻辑进行说明，具体细节可以参考源代码。 ProxyMethod方法代理类，用于拆解、封装 Method 的信息，作为后续方法字节码生成的数据来源。 属性1234567891011121314151617181920212223242526+--- ProxyGenerator private class ProxyMethod &#123; // 方法名 public String methodName; // 参数类型 public Class&lt;?&gt;[] parameterTypes; // 返回值类型 public Class&lt;?&gt; returnType; // 异常类型 public Class&lt;?&gt;[] exceptionTypes; // 方法所在接口 public Class&lt;?&gt; fromClass; // 当前方法对应的序列号，如 m0 public String methodFieldName; private ProxyMethod(String var2, Class&lt;?&gt;[] var3, Class&lt;?&gt; var4, Class&lt;?&gt;[] var5, Class&lt;?&gt; var6) &#123; this.methodName = var2; this.parameterTypes = var3; this.returnType = var4; this.exceptionTypes = var5; this.fromClass = var6; this.methodFieldName = \"m\" + ProxyGenerator.this.proxyMethodCount++; &#125; // 省略其它代码 &#125; generateMethod12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091+--- ProxyMethod private ProxyGenerator.MethodInfo generateMethod() throws IOException &#123; // 方法签名 如：toString 方法的描述信息 Ljava/lang/reflect/Method; void print(String message) 描述信息 (Ljava/lang/String;)V String var1 = ProxyGenerator.getMethodDescriptor(this.parameterTypes, this.returnType); // 创建 MethodInfo 对象，同时会初始化 ByteArrayOutputStream 对象 // 1. 方法名 + 方法签名 ProxyGenerator.MethodInfo var2 = ProxyGenerator.this.new MethodInfo(this.methodName, var1, 17); // 2. 方法参数 int[] var3 = new int[this.parameterTypes.length]; int var4 = 1; for (int var5 = 0; var5 &lt; var3.length; ++var5) &#123; var3[var5] = var4; var4 += ProxyGenerator.getWordsPerType(this.parameterTypes[var5]); &#125; byte var7 = 0; // 通过字节输出流 ByteArrayOutputStream 写入方法的二进制信息，即 MethodInfo 中的输出流中 DataOutputStream var9 = new DataOutputStream(var2.code); ProxyGenerator.this.code_aload(0, var9); // 3 写入接口方法的 InvocationHandler.invoke 处理逻辑 var9.writeByte(180); var9.writeShort(ProxyGenerator.this.cp.getFieldRef(\"java/lang/reflect/Proxy\", \"h\", \"Ljava/lang/reflect/InvocationHandler;\")); ProxyGenerator.this.code_aload(0, var9); var9.writeByte(178); var9.writeShort(ProxyGenerator.this.cp.getFieldRef(ProxyGenerator.dotToSlash(ProxyGenerator.this.className), this.methodFieldName, \"Ljava/lang/reflect/Method;\")); if (this.parameterTypes.length &gt; 0) &#123; ProxyGenerator.this.code_ipush(this.parameterTypes.length, var9); var9.writeByte(189); var9.writeShort(ProxyGenerator.this.cp.getClass(\"java/lang/Object\")); for (int var10 = 0; var10 &lt; this.parameterTypes.length; ++var10) &#123; var9.writeByte(89); ProxyGenerator.this.code_ipush(var10, var9); this.codeWrapArgument(this.parameterTypes[var10], var3[var10], var9); var9.writeByte(83); &#125; &#125; else &#123; var9.writeByte(1); &#125; var9.writeByte(185); var9.writeShort(ProxyGenerator.this.cp.getInterfaceMethodRef(\"java/lang/reflect/InvocationHandler\", \"invoke\", \"(Ljava/lang/Object;Ljava/lang/reflect/Method;[Ljava/lang/Object;)Ljava/lang/Object;\")); var9.writeByte(4); var9.writeByte(0); // 4 返回类型 if (this.returnType == Void.TYPE) &#123; var9.writeByte(87); var9.writeByte(177); &#125; else &#123; this.codeUnwrapReturnValue(this.returnType, var9); &#125; // 5 写入方法处理异常字节信息 short var6; short var8 = var6 = (short) var2.code.size(); List var13 = ProxyGenerator.computeUniqueCatchList(this.exceptionTypes); if (var13.size() &gt; 0) &#123; Iterator var11 = var13.iterator(); while (var11.hasNext()) &#123; Class var12 = (Class) var11.next(); var2.exceptionTable.add(new ProxyGenerator.ExceptionTableEntry(var7, var8, var6, ProxyGenerator.this.cp.getClass(ProxyGenerator.dotToSlash(var12.getName())))); &#125; var9.writeByte(191); var6 = (short) var2.code.size(); var2.exceptionTable.add(new ProxyGenerator.ExceptionTableEntry(var7, var8, var6, ProxyGenerator.this.cp.getClass(\"java/lang/Throwable\"))); ProxyGenerator.this.code_astore(var4, var9); var9.writeByte(187); var9.writeShort(ProxyGenerator.this.cp.getClass(\"java/lang/reflect/UndeclaredThrowableException\")); var9.writeByte(89); ProxyGenerator.this.code_aload(var4, var9); var9.writeByte(183); var9.writeShort(ProxyGenerator.this.cp.getMethodRef(\"java/lang/reflect/UndeclaredThrowableException\", \"&lt;init&gt;\", \"(Ljava/lang/Throwable;)V\")); var9.writeByte(191); &#125; if (var2.code.size() &gt; 65535) &#123; throw new IllegalArgumentException(\"code size limit exceeded\"); &#125; else &#123; var2.maxStack = 10; var2.maxLocals = (short) (var4 + 1); var2.declaredExceptions = new short[this.exceptionTypes.length]; for (int var14 = 0; var14 &lt; this.exceptionTypes.length; ++var14) &#123; var2.declaredExceptions[var14] = ProxyGenerator.this.cp.getClass(ProxyGenerator.dotToSlash(this.exceptionTypes[var14].getName())); &#125; return var2; &#125; &#125; generateMethod 方法根据 ProxyMethod 信息，按照方法的构造组装代表字节码信息的 MethodInfo，最终将该信息写入到输出流中。 MethodInfoProxyMethod 对象经过解析后会组装成 MethodInfo 对象，该对象封装了代理类中方法的字节码信息。 1234567891011121314151617181920212223242526+--- ProxyGenerator private class MethodInfo &#123; public int accessFlags; // 方法名 public String name; // 方法签名 public String descriptor; public short maxStack; public short maxLocals; // 输出流，方法字节码会写入到该流中 public ByteArrayOutputStream code = new ByteArrayOutputStream(); public List&lt;ProxyGenerator.ExceptionTableEntry&gt; exceptionTable = new ArrayList(); public short[] declaredExceptions; public MethodInfo(String var2, String var3, int var4) &#123; this.name = var2; this.descriptor = var3; this.accessFlags = var4; ProxyGenerator.this.cp.getUtf8(var2); ProxyGenerator.this.cp.getUtf8(var3); ProxyGenerator.this.cp.getUtf8(\"Code\"); ProxyGenerator.this.cp.getUtf8(\"Exceptions\"); &#125; // 省略写入输出流逻辑 &#125; FieldInfoFieldInfo 用于封装方法在代理类中的静态属性信息。 123456789101112131415161718192021222324+--- ProxyGenerator private class FieldInfo &#123; public int accessFlags; // m + N，方法在代理类中的字段名 public String name; // 固定值 Ljava/lang/reflect/Method; public String descriptor; public FieldInfo(String var2, String var3, int var4) &#123; this.name = var2; this.descriptor = var3; this.accessFlags = var4; ProxyGenerator.this.cp.getUtf8(var2); ProxyGenerator.this.cp.getUtf8(var3); &#125; // 写入输出流 public void write(DataOutputStream var1) throws IOException &#123; var1.writeShort(this.accessFlags); var1.writeShort(ProxyGenerator.this.cp.getUtf8(this.name)); var1.writeShort(ProxyGenerator.this.cp.getUtf8(this.descriptor)); var1.writeShort(0); &#125; &#125; 介绍完必要的前置概念和类信息后，我们回到 ProxyGenerator.generateClassFile 方法，继续接着流程往下分析。 generateClassFile123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138+--- ProxyGeneratorprivate byte[] generateClassFile() &#123; // 1. 将 Object 中的三大方法对象Method拆解，组装成 ProxyMethod 对象 this.addProxyMethod(hashCodeMethod, Object.class); this.addProxyMethod(equalsMethod, Object.class); this.addProxyMethod(toStringMethod, Object.class); // 2. 将目标类的接口中的方法对象Method拆解，组装成 ProxyMethod 对象 Class[] var1 = this.interfaces; int var2 = var1.length; int var3; Class var4; // 2.1 遍历接口 for (var3 = 0; var3 &lt; var2; ++var3) &#123; var4 = var1[var3]; // 2.3 获取接口中的方法列表 Method[] var5 = var4.getMethods(); int var6 = var5.length; // 2.4 遍历当前接口中的方法 for (int var7 = 0; var7 &lt; var6; ++var7) &#123; Method var8 = var5[var7]; // 2.5 对接口中的方法拆解、组装成 ProxyMethod 对象，然后加入缓存 proxyMethods 中 this.addProxyMethod(var8, var4); &#125; &#125; // 获取缓存的方法代理对象 ProxyMethod 集合 Iterator var11 = this.proxyMethods.values().iterator(); // 校验相同方法签名的返回类型 List var12; while (var11.hasNext()) &#123; var12 = (List) var11.next(); checkReturnTypes(var12); &#125; Iterator var15; try &#123; // 3. 生成构造方法字节码信息并加入到 methods 缓存起来 this.methods.add(this.generateConstructor()); // 4. 遍历方法代理对象列表，生成方法字节码信息并缓存到 methods 中 var11 = this.proxyMethods.values().iterator(); while (var11.hasNext()) &#123; var12 = (List) var11.next(); var15 = var12.iterator(); while (var15.hasNext()) &#123; ProxyGenerator.ProxyMethod var16 = (ProxyGenerator.ProxyMethod) var15.next(); // 4.1 生成方法的 FieldInfo 并加入到 fields 集合中，即代理类中方法Method的字段属性 this.fields.add(new ProxyGenerator.FieldInfo(var16.methodFieldName, \"Ljava/lang/reflect/Method;\", 10)); // 4.2 生成方法的 MethodInfo 并加入到 methods 集合中，注意 MethodInfo 中的 ByteArrayOutputStream this.methods.add(var16.generateMethod()); &#125; &#125; // 5. 生成静态代码块字节码信息（根据 proxyMethods 中的信息） this.methods.add(this.generateStaticInitializer()); &#125; catch (IOException var10) &#123; throw new InternalError(\"unexpected I/O Exception\", var10); &#125; // 6. 方法数量限制 if (this.methods.size() &gt; 65535) &#123; throw new IllegalArgumentException(\"method limit exceeded\"); &#125; else if (this.fields.size() &gt; 65535) &#123; throw new IllegalArgumentException(\"field limit exceeded\"); &#125; else &#123; // 7. 代理类字节码组装 // 7.1. 处理代理类 和 Proxy 的全路径类，并入放入常量池 cp 中 this.cp.getClass(dotToSlash(this.className)); this.cp.getClass(\"java/lang/reflect/Proxy\"); // 7.2. 处理代理类的接口，并放入常量池 cp 中 var1 = this.interfaces; var2 = var1.length; for (var3 = 0; var3 &lt; var2; ++var3) &#123; var4 = var1[var3]; this.cp.getClass(dotToSlash(var4.getName())); &#125; this.cp.setReadOnly(); // 7.3. 字节类型数据的输出流，内存操作流 ByteArrayOutputStream var13 = new ByteArrayOutputStream(); DataOutputStream var14 = new DataOutputStream(var13); try &#123; var14.writeInt(-889275714); var14.writeShort(0); var14.writeShort(49); this.cp.write(var14); var14.writeShort(this.accessFlags); // 7.3.1 写入代理类名称信息 var14.writeShort(this.cp.getClass(dotToSlash(this.className))); // 7.3.2 写入Proxy名称信息 var14.writeShort(this.cp.getClass(\"java/lang/reflect/Proxy\")); // 7.3.4 写入接口列表 var14.writeShort(this.interfaces.length); Class[] var17 = this.interfaces; int var18 = var17.length; // 遍历接口列表 for (int var19 = 0; var19 &lt; var18; ++var19) &#123; Class var22 = var17[var19]; // 写入接口信息 var14.writeShort(this.cp.getClass(dotToSlash(var22.getName()))); &#125; /// 7.3.5 写入字段信息，即接口方法的标识，如 m1、m2 var14.writeShort(this.fields.size()); var15 = this.fields.iterator(); while (var15.hasNext()) &#123; ProxyGenerator.FieldInfo var20 = (ProxyGenerator.FieldInfo) var15.next(); var20.write(var14); &#125; // 7.3.6 写入方法，包括构造方法、静态代码块 var14.writeShort(this.methods.size()); var15 = this.methods.iterator(); while (var15.hasNext()) &#123; ProxyGenerator.MethodInfo var21 = (ProxyGenerator.MethodInfo) var15.next(); var21.write(var14); &#125; var14.writeShort(0); // 4 返回字节数组信息 return var13.toByteArray(); &#125; catch (IOException var9) &#123; throw new InternalError(\"unexpected I/O Exception\", var9); &#125; &#125; &#125; generateClassFile 方法逻辑还是比较复杂的，下面对主要流程进行说明： 将 Object 中的三大方法对象解析、组装成 ProxyMethod 对象。 将目标类的接口中的方法对象解析、组装成 ProxyMethod 对象。 生成构造方法字节码信息并封装到 MethodInfo 对象中。 将第 1、2 步骤中组装的 ProxyMethod 对象进行解析，生成代表该方法字段标识的 FieldInfo 对象并缓存起来，解析为该方法的字节码信息的 MethodInfo 对象并缓存起来。 根据第 1、2 步骤中组装的 ProxyMethod 对象生成静态代码块字节码信息并封装到 MethodInfo 对象中并缓存起来。 对代理类中的方法数量做限制。 依次将代理类相关类路径、接口路径、代理类名、Proxy名、接口名、FieldInfo信息、MehodInfo信息写入到字节输出流中。 生成代理类字节码数组 整个过程介绍完毕，下面对该过程中涉及的核心方法进行说明。 addProxyMethod1234567891011121314151617181920212223242526272829303132333435363738394041424344+--- ProxyGenerator /** * 将方法对象拆解，组装成 ProxyMethod 对象 * * @param var1 方法对象 * @param var2 方法所在接口/类 */ private void addProxyMethod(Method var1, Class&lt;?&gt; var2) &#123; // 1 方法名 String var3 = var1.getName(); // 2 方法参数类型 Class[] var4 = var1.getParameterTypes(); // 3 方法返回类型 Class var5 = var1.getReturnType(); // 4 方法异常类型 Class[] var6 = var1.getExceptionTypes(); // 5 方法签名，如 hashCode()、equals(Ljava/lang/Object;)，最为缓存的 key String var7 = var3 + getParameterDescriptors(var4); Object var8 = (List) this.proxyMethods.get(var7); if (var8 != null) &#123; Iterator var9 = ((List) var8).iterator(); while (var9.hasNext()) &#123; ProxyGenerator.ProxyMethod var10 = (ProxyGenerator.ProxyMethod) var9.next(); if (var5 == var10.returnType) &#123; ArrayList var11 = new ArrayList(); collectCompatibleTypes(var6, var10.exceptionTypes, var11); collectCompatibleTypes(var10.exceptionTypes, var6, var11); var10.exceptionTypes = new Class[var11.size()]; var10.exceptionTypes = (Class[]) var11.toArray(var10.exceptionTypes); return; &#125; &#125; &#125; else &#123; var8 = new ArrayList(3); this.proxyMethods.put(var7, var8); &#125; // 创建 ProxyMethod 对象，并保存到 proxyMethods 中 ((List) var8).add(new ProxyGenerator.ProxyMethod(var3, var4, var5, var6, var2)); &#125; 上述方法用于将 Method 对象拆解、组装为 ProxyMethod 对象，为后续组装代理类的方法字节码做准备。 generateConstructor1234567891011121314151617+--- ProxyGenerator private ProxyGenerator.MethodInfo generateConstructor() throws IOException &#123; // 创建构造方法字节码的 MethodInfo ProxyGenerator.MethodInfo var1 = new ProxyGenerator.MethodInfo(\"&lt;init&gt;\", \"(Ljava/lang/reflect/InvocationHandler;)V\", 1); // 写入 MethodInfo 的输出流中 DataOutputStream var2 = new DataOutputStream(var1.code); this.code_aload(0, var2); this.code_aload(1, var2); var2.writeByte(183); var2.writeShort(this.cp.getMethodRef(\"java/lang/reflect/Proxy\", \"&lt;init&gt;\", \"(Ljava/lang/reflect/InvocationHandler;)V\")); var2.writeByte(177); var1.maxStack = 10; var1.maxLocals = 2; var1.declaredExceptions = new short[0]; return var1; &#125; generateConstructor 方法用于生成构造方法的字节码信息。 generateStaticInitializer123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657+--- ProxyGenerator private ProxyGenerator.MethodInfo generateStaticInitializer() throws IOException &#123; ProxyGenerator.MethodInfo var1 = new ProxyGenerator.MethodInfo(\"&lt;clinit&gt;\", \"()V\", 8); byte var2 = 1; byte var4 = 0; DataOutputStream var6 = new DataOutputStream(var1.code); // 获取方法列表 Iterator var7 = this.proxyMethods.values().iterator(); // 根据方法信息初始化对应的字段 while (var7.hasNext()) &#123; List var8 = (List) var7.next(); Iterator var9 = var8.iterator(); while (var9.hasNext()) &#123; ProxyGenerator.ProxyMethod var10 = (ProxyGenerator.ProxyMethod) var9.next(); // 方法字段初始化 var10.codeFieldInitialization(var6); &#125; &#125; // 异常处理 var6.writeByte(177); short var3; short var5 = var3 = (short) var1.code.size(); var1.exceptionTable.add(new ProxyGenerator.ExceptionTableEntry(var4, var5, var3, this.cp.getClass(\"java/lang/NoSuchMethodException\"))); this.code_astore(var2, var6); var6.writeByte(187); var6.writeShort(this.cp.getClass(\"java/lang/NoSuchMethodError\")); var6.writeByte(89); this.code_aload(var2, var6); var6.writeByte(182); var6.writeShort(this.cp.getMethodRef(\"java/lang/Throwable\", \"getMessage\", \"()Ljava/lang/String;\")); var6.writeByte(183); var6.writeShort(this.cp.getMethodRef(\"java/lang/NoSuchMethodError\", \"&lt;init&gt;\", \"(Ljava/lang/String;)V\")); var6.writeByte(191); var3 = (short) var1.code.size(); var1.exceptionTable.add(new ProxyGenerator.ExceptionTableEntry(var4, var5, var3, this.cp.getClass(\"java/lang/ClassNotFoundException\"))); this.code_astore(var2, var6); var6.writeByte(187); var6.writeShort(this.cp.getClass(\"java/lang/NoClassDefFoundError\")); var6.writeByte(89); this.code_aload(var2, var6); var6.writeByte(182); var6.writeShort(this.cp.getMethodRef(\"java/lang/Throwable\", \"getMessage\", \"()Ljava/lang/String;\")); var6.writeByte(183); var6.writeShort(this.cp.getMethodRef(\"java/lang/NoClassDefFoundError\", \"&lt;init&gt;\", \"(Ljava/lang/String;)V\")); var6.writeByte(191); if (var1.code.size() &gt; 65535) &#123; throw new IllegalArgumentException(\"code size limit exceeded\"); &#125; else &#123; var1.maxStack = 10; var1.maxLocals = (short) (var2 + 1); var1.declaredExceptions = new short[0]; return var1; &#125; &#125; generateStaticInitializer 方法用于生成代理类的静态代码块信息。 至此，JDK 动态代理的整个流程介绍完毕。 小结JDK 动态代理是针对接口做的代理，目标类没有实现接口是无法通过这个方式创建代理对象。通过拼接字节码生成类是十分灵活的，理论上不管是有接口的类还是普通类都是可以实现代理的，CGLIB 就是通过拼接字节码来实现非接口类的代理逻辑。","categories":[{"name":"JDK","slug":"JDK","permalink":"https://gentryhuang.com/categories/JDK/"}],"tags":[{"name":"代理","slug":"代理","permalink":"https://gentryhuang.com/tags/%E4%BB%A3%E7%90%86/"}]},{"title":"并发 - 线程池工具类","slug":"concurrent/线程池工具类","date":"2020-12-26T16:00:00.000Z","updated":"2021-08-13T04:55:36.740Z","comments":false,"path":"posts/9e3a7d05/","link":"","permalink":"https://gentryhuang.com/posts/9e3a7d05/","excerpt":"","text":"前言上一篇文章 线程池 对线程池的原理进行了说明，并对线程池的源码进行了深入分析，本篇文章对线程工具类 Executors 进行分析，需要说明的是 Executors 中除了并行计算的 WorkStealingPool 线程池，其它的都是直接基于 ThreadPoolExecutor 来实现的。本篇文章主要说明 Executors 基于 ThreadPoolExecutor 创建的线程池。 FixedThreadPoolFixedThreadPool 属于固定线程数的线程池，使用 Executors.newFixedThreadPool() 方法创建。 构造方法 指定线程数1234567891011/** * 创建固定数量的线程池 * * @param nThreads 核心线程数 = 最大线程数 * @return */public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 指定线程数和线程工厂12345678910111213/** * 创建固定数量的线程池 * * @param nThreads 核心线程数 = 最大线程数 * @param threadFactory 线程工厂 * @return */public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory);&#125; 特点核心线程数和最大线程数一致，并且使用的任务队列为无界队列。线程池中的线程数随着任务的提交会从 0 增加到核心线程数 nThreads，完成预热之后，线程池中的线程数将会保持 nThreads，之后的任务提交一律放入任务队列中，由空闲的核心线程从队列取出并执行。如果有工作线程退出，线程池将会创建新的工作线程以补足执行的数目 nThreads 。此外，由于使用的是无界队列，隐藏的默认拒绝策略是无效的，并且默认情况下线程池是不会回收核心线程数内的线程，keepAliveTime 同样是个无效参数。 运行示意图 适用场景适用于为了满足资源管理的需求，而需要限制线程数量的应用场景。 存在问题由于使用了无界的任务队列，当大量的任务提交到线程池，可能会造成任务堆积，而线程池的拒绝策略又处于失效状态，从而导致 OOM 。 SingleThreadExecutorSingleThreadExecutor 属于固定线程数的线程池，使用 Executors.newSingleThreadExecutor() 方法创建。 构造方法1234567891011121314151617181920212223/** * 创建单个线程的线程池 * * @return */ public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService(new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); &#125; /** * 创建单个线程的线程池 * * @param threadFactory 线程工厂 * @return */ public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) &#123; return new FinalizableDelegatedExecutorService(new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory)); &#125; 特点SingleThreadExecutor 和 FixedThreadPool 基本一致，区别在于前者的核心线程数和最大线程数固定为 1 ，并且是一个包装 ThreadPoolExecutor 的线程池，支持调用 finalize() 方法通知垃圾收集器时关闭线程池。 运行示意图 适用场景保证了所有任务都是被顺序执行，任意时间点最多会有一个任务处于活动状态。 存在问题和 FixedThreadPool 是一样的问题，使用了无界的任务队列，当大量的任务提交到线程池，可能会造成任务堆积，而线程池的拒绝策略又处于失效状态，从而导致 OOM 。 CachedThreadPoolCachedThreadPool 属于缓冲线程池，会根据需要创建新线程。使用 Executors.newCachedThreadPool() 方法创建。 构造方法1234567891011121314public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125;public static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;(), threadFactory);&#125; 特点核心线程数为 0 ，最大线程数为 Integer.MAX_VALUE，可以认为是无界的。使用的任务队列是没有容量的 SynchronousQueue ，即线程池使用这个队列意味着每次都要创建新的线程来处理任务。 keepAliveTime 被设置为 60L，单位为 TimeUnit.SECONDS ，意味着 CachedThreadPool 中的空闲线程等待任务的最大时长为 60s 。 CachedThreadPool 总体上有以下几个特点： 无核心线程数，且最大的线程数是 Integer.MAX_VALUE 。 任务队列并不会存储任务，如果有空闲线程则队列会把任务交给空闲线程执行，如果没有空闲线程则迫使线程池尝试创建一个新的线程执行任务。这个特点是任务队列 SynchronousQueue 提供的。 由于 keepAliveTime 被设置为 60L，因此会在该时间内缓存线程，被缓存的线程会等待 SynchronousQueue 队列中的任务。 线程池长时间闲置得话也不会消耗什么资源，因为线程池中的线程都是可回收的，和固定线程数的线程池不同，核心线程会不断轮询任务（不开启回收核心线程）。 SynchronousQueue一个比较特殊的阻塞队列，其本身不存储元素。每个插入操作必须等待另一个线程执行移除操作，反之亦然。如果使用该阻塞队列，只有当两个线程执行相反模式的操作才能配对成功，否则先执行的一方只能等待。下图是对线程池使用该队列处理任务过程的描述： 运行示意图 适用场景处理大量短时间任务，或者负载较轻的服务器。 存在问题由于允许创建线程数量为 Integer.MAX_VALUE，可能会创建大量的线程最终超过了操作系统的上限而无法创建新线程，容易导致 CPU 飙升和 OOM。 Executors 创建线程问题Executors 工具类创建的线程池都会存在一定的风险，相比较而言手动创建线程池更加合理，因为可以根据不同的场景对线程池进行定制，来提升程序的性能和减少资源消耗。 小结无论是使用 Executors 工具类还是定制线程池，都应该避免任务大量堆积，否则可能出现 OOM ；还应该避免过度创建新线程，否则可能由于创建大量线程导致系统崩溃。","categories":[{"name":"JDK","slug":"JDK","permalink":"https://gentryhuang.com/categories/JDK/"}],"tags":[{"name":"JUC","slug":"JUC","permalink":"https://gentryhuang.com/tags/JUC/"}]},{"title":"并发 - 线程池","slug":"concurrent/ThreadPool","date":"2020-12-16T16:00:00.000Z","updated":"2021-08-13T04:56:03.529Z","comments":false,"path":"posts/d7cef21d/","link":"","permalink":"https://gentryhuang.com/posts/d7cef21d/","excerpt":"","text":"前言最初的时候并没有线程池的概念，而是先有线程。每个任务都需要对应一个线程，任务少的情况没有太大问题，任务过多就出现了各种性能和资源开销问题，更重要的是可创建线程的数量是有上限的，不可能无限的创建。在并发环境下，系统不能够确定在某一时刻有多少任务需要执行，有多少资源需要投入。 针对上述问题，于是诞生了线程池，用来平衡线程与系统资源之间的关系。线程池解决问题思路如下： 对于反复创建线程开销问题，线程池采用固定数量的线程一直保持工作状态并能反复执行任务。 对于创建过多线程占用太多资源问题，线程池会根据需要创建线程，灵活地控制线程数量，避免使用过多资源。 概述线程池是一种管理线程和任务的工具，是应用场景最多的并发框架之一，几乎所有需要异步或并发执行任务的应用程序都可以使用线程池，合理地使用线程池可以带来可观得性能提升和响应速度。具体好处如下： 解耦：线程的创建与任务执行完全分开。 降低资源消耗：线程的复用降低了线程创建和销毁带来的资源消耗。 提高响应速度：大多情况下（线程池预热后），到达的任务可以不需要等待线程创建就能立即执行，消除了线程创建所带来的延迟，提升了响应速度。 便于线程管理：线程是稀缺资源，不能无限制地创建，使用线程池可以对线程进行统一分配、调优和监控。 关于线程池的概述就介绍这么多，本篇文章介绍的线程池核心是 JDK 中提供的 ThreadPoolExecutor 类，具体涉及的接口和实现类如下图所示： 需要说明的是，关于Scheduled类型的线程池继承体系本篇文章没有介绍到，它是基于本篇文章着重介绍的 ThreadPoolExecutor 的扩展实现，支持时间纬度执行任务。 总体设计线程池的设计没有办法直接采用一般意义上池化资源方案，而是采用生产者 - 消费者模式，将任务和线程解耦并不直接关联，从而良好的缓冲任务、复用线程，缓冲任务通过阻塞队列实现，工作线程从阻塞队列中获取任务以实现线程复用。线程池的使用方是生产者，线程池本身是消费者。至于为什么线程池没有采用一般意义上池化资源的设计方法，这个取决于线程对象的特殊性，线程有着特殊的生命周期，一旦一个线程启动执行任务就不能再次启动了。 任务执行任务的执行不一定非要通过开启新线程，任务在线程执行之前它也是一个实现类，也有对应的方法。因此我们可以定义出方法级别调用和线程级别调用。 线程级别调用123new Thread(() -&gt; &#123; //... &#125;).start(); 方法级别调用123((Runnable) () -&gt; &#123; //.. &#125;).run(); 线程池对任务的处理最终是通过方法级别调用的来完成，在后面分析源码的时候我们可以看到。 Executor 框架Executor 是一个异步任务的框架，根据一组执行策略进行调用、调度、执行和控制，目的是提供一种将任务提交和任务执行分离的机制。 两级调度模型最早 Java 的线程既是任务体也是执行机制，从 JDK5 开始，把任务体和执行机制进行了分离。任务体包括 Runnable 和 Callable，而执行机制由 Executor 框架提供，即 Executor是 Runnable 和 Callable 的调度容器。 Java 线程会被一对一映射为操作系统线程，在 Java 线程启动时创建对应的操作系统线程，同样地，当该 Java 线程终止时对应的操作系统线程也会被回收。操作系统会调度所有线程并将它们分配给可用的 CPU 。对于计算复杂的应用，我们通常会将其拆解为若干个任务并交给 Java 多个线程，这个动作是由用户级别的调度器 Executor 框架完成的，它会将这若干个任务映射为对应数量的线程。在底层，操作系统内核将这些线程映射到硬件处理器上。由此可见，创建一个线程远比创建一个对象要复杂得多，不仅要在 JVM 堆中分配内存，还需要调用操作系统内核 API 来为线程分配资源，因此应该避免频繁创建和销毁。 这个过程属于两级调度模型，对应的示意图如下： 从示意图可看出，应用程序通过 Executor 框架控制上层的调度。而下层的调度由操作系统内核控制，应用程序是无法控制的。 Executor 框架结构Executor 框架主要由三大部分组成，具体如下： 任务体包括 Runnable 接口和 Callable 接口及其实现。 任务的执行包括任务执行机制的核心接口 Executor，继承 Executor 的 ExecutorService 接口和它的实现们。 异步计算结果包括核心接口 Future 以及对应的实现们，特别是 FutureTask 实现类。是对具体 Runnable 或者 Callable 任务的执行结果进行取消、查询是否完成、获取结果、设置结果操作。 Executor 框架成员Executor 框架是线程池实现的基础，它的主要成员有 ThreadPoolExecutor、ScheduledThreadPoolExecutor、Executors、Runnable、Callable 以及 Future 。 下面正式进入到代码层面的介绍，定时任务实现类 ScheduledThreadPoolExecutor 继承自 ThreadPoolExecutor ，用于实现定时执行，本文暂不介绍它的实现。 Executor 接口1234567public interface Executor &#123; /** * @param Runable 接口 */ void execute(Runnable command);&#125; Executor 接口仅定义了一个方法，参数是 Runnable 类型，该方法的目的是将任务提交和任务执行细节解耦。用户无需关注如何创建线程，如何调度线程来执行任务，用户只需将任务提交到执行器 Executor 中，由执行器完成线程的调配和任务的执行。需要注意的是，该接口是没有返回值的，也就意味着无法判断提交的任务是否被线程池执行成功。 ExecutorService 接口ExecutorService 接口继承自 Executor 接口，一般我们自定义线程池时使用的就是这个接口，该接口中定义的方法加上继承过来的 execute 方法在很多场景中已经可以满足需求了。 该接口中的方法如下图所示： 上图中的方法大致分类如下： 向线程池提交任务方法 submit 方法和前文中的 Executor 接口中的 execute 方法有所不同，虽然也是向线程池提交任务，但是有返回值 Future ，并且参数类型不仅支持 Runnable 类型还支持 Callable 类型。 执行任务方法 invokeAll 方法用于执行多个任务，同时支持设置超时时间。invokeAny 方法用于执行多个方法中的一个即可，任务执行完成就可以返回，同样支持设置超时时间。这两类方法的底层需要依赖 execute 方法。 关闭线程池方法 shutdown 和 shutdownNow 方法用于关闭线程池。 判断线程池是否关闭 isShutdown 判断线程池是否已经开始了关闭工作，即是否执行了 shutdown 或者 shutdownNow 方法。注意，该方法返回 true 并不代表线程池此时已经彻底关闭了，仅说明线程池开始了关闭的流程，此时线程池中可能依然有线程在执行任务，队列中仍有等待被执行的任务。 判断线程池是否终止方法 isTerminated 和 awaitTermination 方法用于判断线程池是否终止。只有在调用关闭方法后才有调用的意义。 FutureFuture 的继承体系如下图所示： 由上图的UML可知，FutureTask 通过 RunnableFuture 间接实现了 Runnable 接口，因此 Executor.execute 方法支持将 FutureTask 提交到线程池。接下来介绍 AbstractExecutorService 抽象实现类就能很清晰看出 FutureTask 的作用。 AbstractExecutorService 实现AbstractExecutorService 抽象类实现自 ExecutorService 接口，在其基础上实现了几个常用的方法，这些方法供子类进行调用。将执行任务的流程串联起来，保证下层的实现（如 ThreadPoolExecutor）只需关注执行任务的方法即可。具体方法如下： 由于 invokeAll 方法和 invokeAny 方法更多的是执行将任务提交给线程池前的工作，它们并没有将任务提交给线程池，需要通过 Executor 中的 execute 方法实现，而 execute 方法最终要交给具体子类实现。因此，不再对这两类方法展开说明。下面重点介绍下 newTaskFor 方法和 submit 方法。 newTaskFor 方法123456789101112131415161718192021--- AbstractExecutorService /** * 将 Runnable 包装成 FutureTask * * @param runnable 任务 * @param value 任务执行成功的返回值 * @return Future */ protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; return new FutureTask&lt;T&gt;(runnable, value); &#125; /** * 将 Callable 包装成 FutureTask * * @param callable 任务 * @return Future */ protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) &#123; return new FutureTask&lt;T&gt;(callable); &#125; 从上面代码可以看出，newTaskFor 方法用于将 Runnable 和 Callable 类型的任务统一包装成 FutureTask ，FutureTask 又间接继承了 Runnable 接口。我们知道，Runnable 的 void run() 方法是没有返回值的， 而 Callable 的 V call() 方法是有返回值的，但 Executor 中的 void execute(Runnable command)方法是不关心返回结果的，它只负责处理 Runnable 类型的任务。综上，不难看出 newTaskFor 方法就是为了屏蔽不同类型任务的差异，以达到统一交给 Executor.execute 执行的目的。下面我们继续看提交任务的另外一种方式。 submit 提交任务123456789101112131415161718192021222324252627282930313233--- AbstractExecutorService /** * 提交 Runnable 任务，不需要返回结果。 */ public Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); execute(ftask); return ftask; &#125; /** * 提交 Runnable 任务，任务执行成功的返回结果为 result */ public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task, result); execute(ftask); return ftask; &#125; /** * 提交 Callable 任务，任务执行成功返回结果是Callable#call 方法返回值 * * @throws RejectedExecutionException &#123;@inheritDoc&#125; * @throws NullPointerException &#123;@inheritDoc&#125; */ public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task); execute(ftask); return ftask; &#125; Runnable 的 void run() 方法没有返回值，但是有的时候我们需要返回值，这个时候 submit 方法就可以实现，只需在该方法的第二个参数传入预期结果，当任务执行完成后会自动返回。 1&lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) 此外，我们可以看出 submit 方法提交任务的能力是通过 execute 方法实现的。定义于最上层接口 Executor 中的 void execute(Runnable command) 方法不会返回执行结果，想要执行结果就需要通过 FutureTask 包装任务，然后将包装后的任务 FutureTask 交给 Executor.execute 方法执行，执行后的结果也会保存到 FutureTask 中。关于 Future 的继承体系不展开分析，下面概述下 submit 提交任务的原理。 调用 newTaskFor 方法将 Runnable 和 Callable 类型的任务统一包装成 FutureTask 对象。12345678910111213141516171819202122232425262728293031// Callable public FutureTask(Callable&lt;V&gt; callable) &#123; if (callable == null) throw new NullPointerException(); this.callable = callable; this.state = NEW; &#125;// Runnable public FutureTask(Runnable runnable, V result) &#123; // 将 Runnable 适配成 Callable this.callable = Executors.callable(runnable, result); this.state = NEW; &#125; public static &lt;T&gt; Callable&lt;T&gt; callable(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); return new RunnableAdapter&lt;T&gt;(task, result); &#125; static final class RunnableAdapter&lt;T&gt; implements Callable&lt;T&gt; &#123; final Runnable task; final T result; RunnableAdapter(Runnable task, T result) &#123; this.task = task; this.result = result; &#125; // 任务执行还是调用 run 方法，返回结果是传入的预期值 public T call() &#123; task.run(); return result; &#125; &#125; 包装的本质是将任务统一适配为Callable类型，因为Callable类型任务可以通过call方法返回执行结果。 当任务执行的时候，FutureTask 中的 run 方法会执行，这个过程是最关键的一步。12345678910111213141516171819202122232425262728293031323334public void run() &#123; if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return; try &#123; Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; state == NEW) &#123; V result; boolean ran; try &#123; // 被适配的Runnable 和 Callable 方法级别调用 result = c.call(); ran = true; &#125; catch (Throwable ex) &#123; result = null; ran = false; setException(ex); &#125; if (ran) // 将执行结果保存到 FutureTask 中 set(result); &#125; &#125; finally &#123; // runner must be non-null until state is settled to // prevent concurrent calls to run() runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts int s = state; if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); &#125; &#125; 通过FutureTask#get方法从 FutureTask 中取出任务执行结果12345678910111213141516171819202122232425/** * @throws CancellationException &#123;@inheritDoc&#125; */ public V get() throws InterruptedException, ExecutionException &#123; int s = state; if (s &lt;= COMPLETING) s = awaitDone(false, 0L); // 从 FutureTask 中取出任务执行结果 return report(s); &#125; /** * @throws CancellationException &#123;@inheritDoc&#125; */ public V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; if (unit == null) throw new NullPointerException(); int s = state; if (s &lt;= COMPLETING &amp;&amp; (s = awaitDone(true, unit.toNanos(timeout))) &lt;= COMPLETING) throw new TimeoutException(); // 从 FutureTask 中取出任务执行结果 return report(s); &#125; 提交任务方式最上层接口 Executor 中的 void execute(Runnable) 不需要获取结果，不会使用 FutureTask 包装任务。抽象实现类 AbstractExecutorService 中的 Future&lt;?&gt; submit() 需要获取结果，因此使用了 FutureTask 包装任务。 需要获取任务结果用 submit 方法，不需要获取结果用 execute 方法。 运行机制 上图展示了线程池的运行机制，线程池运行机制主要分成两个部分，线程管理和任务管理。下面对线程池的主要处理流程进行说明： 主线程提交任务到线程池。 如果当前线程池中的线程少于核心线程数，则创建新的线程来执行任务。 如果线程池中的线程达到或超过核心线程数，则将任务加入到阻塞队列中。 如果在第 2 步中无法将任务加入阻塞队列，则依据最大线程数创建新的线程来处理任务。 如果在第 3 步创建新线程会使线程池中线程数超出最大线程数，任务将被拒绝并使用饱和策略处理（拒绝策略）。 处理完任务的线程会自旋获取新的任务去执行，当线程获取不到任务时，线程会被回收（一般针对非核心线程）。 其中第 1 步和第 3 步涉及到创建线程，该过程需要获取全局锁，因为关闭线程池也需要获取这个全局锁。当线程池完成了预热即核心线程数创建完毕，在一定程度上就不需要频繁创建线程，也就降低了获取全局锁的频次，对于线程池来说全局锁是一个严重的可伸缩瓶颈。关于流程中的概念下文会陆续说明。 ThreadPoolExecutor线程池核心实现就在 ThreadPoolExecutor 实现类中，该类实现了线程池所需的各个方法，包括最核心的 execute 方法。开发者可以基于该实现类来进行功能上的扩展，定时任务实现类 ScheduledThreadPoolExecutor 就是基于 ThreadPoolExecutor 扩展的功能。 在详细介绍 ThreadPoolExecutor 运行机制之前，我们先对其核心概念，属性、方法等进行简单介绍。 核心参数12345678 public ThreadPoolExecutor(int corePoolSize, // 核心线程数 int maximumPoolSize, // 最大线程数 long keepAliveTime, // 空闲线程存活时间 TimeUnit unit, // 空闲线程存活时间的单位 BlockingQueue&lt;Runnable&gt; workQueue, // 阻塞队列 ThreadFactory threadFactory, // 线程工厂 RejectedExecutionHandler handler // 饱和策略) &#123;//...&#125; corePoolSize 核心线程数，线程池的基本大小。当提交一个任务到线程池时，线程池会创建一个基本线程来执行任务，即使其它空闲的基本线程能够执行新任务也会创建线程，只有线程池预热完毕（线程池中线程数达到核心线程数）才不再创建核心线程。 特别说明： 核心线程并不是特指某一个或某几个线程，而是针对设置的核心线程数而言，任何一个线程都可以是核心线程。 corePoolSize 表示的是线程池的常驻线程数，如果设置为 0 则表示在没有任何任务时需要销毁线程池。如果大于 0 ，即使没有任务时也会保证线程池的线程数等于此值。 关于此值设置的合理性，如果设置的较小，则会频繁的创建和销毁线程（非核心线程）；设置过大，则会浪费资源。 maximumPoolSize 最大线程数，线程池允许创建的最大线程数，最大线程数 = 核心线程数 + 非核心线程数。此值只有在任务比较多且阻塞队列放不下时才会用到。 keepAliveTime 空闲线程存活时间，线程池中的线程空闲时间超过该值也没任务可做那么就需要回收销毁。如果设置为 0，表示一旦空闲立即回收。该参数一般只会对非核心线程起作用，核心线程不会因为空闲太长时间而被关闭，当最大线程数等于核心线程数时，那么线程池在空闲的时候也不会销毁任何线程。但是可通过调用 allowCoreThreadTimeOut(true) 方法使核心线程数内的线程也可以被回收。 unit 和 keepAliveTime 参数一起使用，是时间单位。如：天（DAYS）、小时（HOURS）、分钟（MINUTES）、毫秒（MILLISECONDS）等。 workQueue 用于存放等待执行的任务的阻塞队列，是 BlockingQueue 接口的实现。当线程池中的线程数大于等于核心线程数时才会用到该队列，注意和有没有空闲核心线程无关。 threadFactory 线程工厂，线程池中的线程就由它创建。如果没有设置就使用默认的线程工厂。 handler 饱和策略（拒绝策略），当阻塞队列和线程池都满了，说明线程池处于饱和状态，需要采取一种策略处理提交的新任务，默认是直接抛出异常。 通过配置不同的参数，就可以创建出行为不同的线程池，这也是线程池高度灵活性的基础。 核心属性123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164--- ThreadPoolExecutor //======= 约定使用32位表示线程池状态和数量，高3位表示状态 ，低29位表示数量 =============/ /** * 线程池初始化状态码，状态为 RUNNING，线程数为 0 */ private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); /** * COUNT_BITS 为 29 (0001 1101) */ private static final int COUNT_BITS = Integer.SIZE - 3; /** * 线程池允许最大线程池临界值，1 * 2^29 = 536870912 * 过程：（1）001 （2）左移29位得到001后跟29个0 -&gt; 0010 0000 0000 0000 0000 0000 0000 0000 （3）减去1得0001 1111 1111 1111 1111 1111 1111 1111 */ private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1; /** * 运行状态：111 00000000000000000000000000000 */ private static final int RUNNING = -1 &lt;&lt; COUNT_BITS; /** * 关闭状态：000 00000000000000000000000000000 */ private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS; /** * 停止状态：001 00000000000000000000000000000 */ private static final int STOP = 1 &lt;&lt; COUNT_BITS; /** * 整理状态：010 00000000000000000000000000000 */ private static final int TIDYING = 2 &lt;&lt; COUNT_BITS; /** * 终止状态：011 00000000000000000000000000000 */ private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; // 获取线程池的状态。将整数 c 的低 29 位置为 0 就得到了线程池的状态 private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125; // 用于计算线程池中线程数量。将整数 c 的高 3 位置为 0，就得到了线程池中的线程数 private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125; // 获取线程池状态码 private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; /** * 比较状态 * * @param c * @param s * @return */ private static boolean runStateLessThan(int c, int s) &#123; return c &lt; s; &#125; private static boolean runStateAtLeast(int c, int s) &#123; return c &gt;= s; &#125; /** * 当前线程池是否处于运行状态 * * @param c * @return */ private static boolean isRunning(int c) &#123; return c &lt; SHUTDOWN; &#125; /** * 增加线程池中的线程数量 */ private boolean compareAndIncrementWorkerCount(int expect) &#123; return ctl.compareAndSet(expect, expect + 1); &#125; /** * 减少线程池中的线程数量 * Attempts to CAS-decrement the workerCount field of ctl. */ private boolean compareAndDecrementWorkerCount(int expect) &#123; return ctl.compareAndSet(expect, expect - 1); &#125; private void decrementWorkerCount() &#123; do &#123; &#125; while (!compareAndDecrementWorkerCount(ctl.get())); &#125; /** * 线程池阻塞队列 */ private final BlockingQueue&lt;Runnable&gt; workQueue; /** * 线程池全局锁 */ private final ReentrantLock mainLock = new ReentrantLock(); /** * 1.用于保存和移除线程池创建的Worker，用来控制线程的生命周期。 * 2.对于垃圾回收来说，即使Worker中封装的thread完成了任务的执行（包括异常情况），但是如果Worker不被回收那么thread仍然被强引用着。 * 3.该Hash表是线程不安全的，操作时需要加全局锁 */ private final HashSet&lt;Worker&gt; workers = new HashSet&lt;&gt;(); /** * 全局锁条件 - 条件队列 */ private final Condition termination = mainLock.newCondition(); /** * 追踪线程池最大值，仅在获取到全局锁条件下执行 */ private int largestPoolSize; /** * 线程池完成任务数量 */ private long completedTaskCount; /** * 线程工厂 */ private volatile ThreadFactory threadFactory; /** * 饱和策略 */ private volatile RejectedExecutionHandler handler; /** * 保活时间，即最大允许空闲时间 */ private volatile long keepAliveTime; /** * 是否允许核心线程被回收 */ private volatile boolean allowCoreThreadTimeOut; /** * 核心线程池数，不会被回收，即 workers的最小值。除非设置 allowCoreThreadTimeOut 。 */ private volatile int corePoolSize; /** * 最大线程数 */ private volatile int maximumPoolSize; /** * 默认的饱和策略，直接抛出异常 */ private static final RejectedExecutionHandler defaultHandler = new AbortPolicy(); 上面的属性都很重要，其中还包含了部分属性的操作方法，这些都会在下面的源码分析中不断出现。 构造方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// Public constructors and methods 构造方法们 public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler); &#125; public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, defaultHandler); &#125; public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, // 当没有指定线程工厂时，使用默认的线程创建工厂 Executors.defaultThreadFactory(), handler); &#125; public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; &#125; 创建线程池时如果不指定线程工厂则会使用默认的线程工厂，默认线程工厂创建的线程都属于同一个线程组，拥有相同的优先级，并且都是非守护线程，具体代码实现如下： 12345678910111213141516171819202122232425262728293031--- Executors static class DefaultThreadFactory implements ThreadFactory &#123; private static final AtomicInteger poolNumber = new AtomicInteger(1); private final ThreadGroup group; private final AtomicInteger threadNumber = new AtomicInteger(1); private final String namePrefix; DefaultThreadFactory() &#123; SecurityManager s = System.getSecurityManager(); // 线程组 group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); namePrefix = \"pool-\" + poolNumber.getAndIncrement() + \"-thread-\"; &#125; public Thread newThread(Runnable r) &#123; // 创建线程 Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); // 设置为非守护线程 if (t.isDaemon()) t.setDaemon(false); // 设置优先级 if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; &#125; &#125; 生命周期设计思想线程池采用的是 Integer.SIZE 32 位的整数来存放线程池的状态和池中的线程数，其中高 3 位表示线程池状态即可以表示 7 种状态，低 29 位表示线程数即可以存放 5 亿多个线程。这种设计思想对整数赋予了双重角色，通过高低位的不同，既表示线程池状态，又表示工作线程数目，这是一个典型的高效优化。要知道用一个变量存储两个值，可以避免在做相关决策时出现不一致的情况，省去了占用锁资源去维护两个变量的一致性。这种方式在其它框架中也多有使用，如 Dubbo 协议就使用 16 个字节共 128 位，每一位用来表示不同意义的数值。 线程池状态线程池的状态表示如下图所示： 注意，线程池的状态并非用户显示配置（用户调用关闭方法除外），而是随着线程池的运行由内部自行维护，和线程的执行密切相关，下面分别说明线程池的状态及其状态流转。 RUNNING 状态说明线程池处于 RUNNING 状态允许接受新的任务，处理任务队列中的任务。 状态转换线程池一旦被创建就处于 RUNNING 状态，并且线程池中的线程数为 0 。 SHUTDOWN 状态说明线程池处于 SHUTDOWN 状态时，不再接收新任务，但能处理任务队列中的任务。 状态转换调用线程池的shutdown()方法时，线程池由RUNNING -&gt; SHUTDOWN 。 STOP 状态说明线程池处在 STOP 状态时，不能接收新任务，也不处理任务队列中的任务，并且会中断正在处理任务的线程。 状态转换调用线程池的shutdownNow()方法时，线程池由(RUNNING or SHUTDOWN ) -&gt; STOP 。 TIDYING 状态说明所有的任务已终止，线程池中线程数为 0 ，线程池会变为TIDYING状态（线程池内部自动更新状态）。当线程池变为TIDYING状态后，会紧接着执行钩子方法terminated()。若用户需要在线程池变为TIDYING时，进行相应的处理，可以通过重写terminated()方法来实现。 状态转换当线程池在 SHUTDOWN 状态下时，阻塞队列为空并且线程池中线程数为 0 时，就会由 SHUTDOWN -&gt; TIDYING。 当线程池在 STOP 状态下，线程池中线程数为 0 时，就会由STOP -&gt; TIDYING。 TERMINATED 状态说明线程池彻底终止，就变成 TERMINATED 状态。 状态转换线程池处在TIDYING状态时，执行完 terminated() 方法之后，就会由 TIDYING -&gt; TERMINATED。 下面进行小结，线程池状态及流转（线程池的生命周期）如下图所示： 任务执行机制任务调度任务调度是线程池的主要入口，所有任务的调度都是由execute方法完成的，当用户提交了一个任务后，任务调度阶段将决定如何执行该任务。 12345678910111213141516171819202122232425262728293031323334public void execute(Runnable command) &#123; // 任务体不允许为 null if (command == null) throw new NullPointerException(); // 获取线程池的状态码,该值包含了线程池的状态和线程数 int c = ctl.get(); // 1 如果当前线程数少于核心线程数，则创建一个 Worker 来执行任务，即创建一个线程并将 command 作为该线程的第一个任务 if (workerCountOf(c) &lt; corePoolSize) &#123; // 返回 false 说明线程池不允许创建线程，可能原因：（1）线程池关闭（2）当前线程数已经达到临界值 if (addWorker(command, true)) return; // 创建失败，重读线程池状态码 c = ctl.get(); &#125; // 2 如果线程池处于运行状态，则尝试将任务添加到阻塞队列 workQueue 中 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; // 再次获取线程池状态码 int recheck = ctl.get(); // 双重检查，再次判断线程池状态。如果线程状态变了（非运行状态）就需要从阻塞队列移除任务，同时执行拒绝策略。防止线程池关闭。 if (!isRunning(recheck) &amp;&amp; remove(command)) reject(command); // 如果线程池状态仍然是运行状态，并且线程池为空则创建一个非核心线程来执行任务，防止线程提交到阻塞队列后线程都关闭了。 // 一般这种情况是设置核心线程数为 0 else if (workerCountOf(recheck) == 0) addWorker(null, false); // 3 如果任务队列满了，则根据 maximumPoolSize 创建非核心线程。如果创建失败，说明当前线程数已经达到 maximumPoolSize 或线程池关闭，需要执行拒绝策略 &#125; else if (!addWorker(command, false)) reject(command); &#125; execute 方法逻辑体现了提交任务到线程池的流程，上面代码已经详细注释。需要强调的是，符合将任务加入阻塞队列中的情况，会进行双重检查线程池的状态，因为是直接将任务入队，和前后两种情况不一样，即使任务成功排队，也有可能出现线程池关闭或线程池为空的情况。 下面通过一张图进行阐述正常流（不考虑线程池关闭等情况）的流程： 任务缓冲任务缓冲是线程池管理任务的核心部分，通过一个阻塞队列来实现。线程池的本质是对任务和线程的管理，而做到这一点关键的思想是将任务和线程解耦，阻塞队列缓冲任务，工作线程自旋从阻塞队列中获取任务。 阻塞队列(BlockingQueue)是一个支持两个附加操作的队列。在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。 线程池中的阻塞队列参数非常重要，不同的阻塞队列对线程池有不同影响，下面对线程池常用的阻塞队列进行说明。 ArrayBlockingQueue基于数组结构的有界阻塞队列，该队列按照先进先出原则对元素进行排序。 LinkedBlockingQueue基于链表结构的无界阻塞队列，该队列按照先进先出规则对元素进行排序。此队列的默认长度为 Integer.MAX_VALUE，使用该队列作为任务队列有容量危险。 SynchronousQueue一个比较特殊的阻塞队列，其本身不存储元素。每个插入操作必须等待另一个线程执行移除操作，反之亦然。如果使用该阻塞队列，只有当两个线程执行相反模式的操作才能配对成功，否则先执行的一方只能等待。下图是对线程池使用该队列处理任务过程的描述： PriorityBlockingQueue支持优先级排序的无界阻塞队列，默认自然排序规则，不能保证同优先级元素的顺序。 DelayQueue一个实现 PriorityBlockingQueue 实现延迟获取的无界队列，在创建元素时可以指定多久才能从队列中移除，只有延时期满后才能从队列中获取元素。 LinkedBlockingDeque一个由链表结构构成的双向阻塞队列。队列头部和尾部都可以添加和移除元素。 任务申请任务执行有两种情况，一种是任务直接交给新创建的线程执行。另一种是线程执行 getTask 方法从任务队列中获取任务并执行，执行完任务的线程会继续尝试从任务队列中申请任务再去执行。第一种情况仅出现在用户提交任务到线程池，线程池为该任务创建线程的时候。第二种情况是线程执行任务最多的情况，包括线程池存在的线程执行任务，创建的非核心线程执行任务。 任务申请的核心方法 getTask 是配合 Worker线程 工作的，用于 Worker线程 拉取任务队列，下面对该方法进行分析。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657 /** * @return 返回null 表示可以对当前线程进行回收 */private Runnable getTask() &#123; boolean timedOut = false; // Did the last poll() time out? for (; ; ) &#123; // 获取线程池状态码 int c = ctl.get(); // 获取线程池状态 int rs = runStateOf(c); // 线程池状态为SHUTDOWN且队列为空 或 线程池状态为 STOP，应该回收线程。这个条件不仅可以回收非核心线程，也可以回收核心线程。todo 核心线程唯一回收条件 if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; // 减少线程池中的线程数 decrementWorkerCount(); return null; &#125; // 线程池中的线程数 int wc = workerCountOf(c); // 是否需要进行超时控制。即允许核心线程数内的线程回收，或线程池中的线程数超过了核心线程数，那么有可能发生超时关闭 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; // 控制线程池中线程数的关键 //1. wc &gt; maximumPoolSize ，可能是在此方法执行阶段同时执行 setMaximumPoolSize 方法修改了最大值。 //2. timed &amp;&amp; timedOut 如果为true，表示当前操作需要进行超时控制，且线程上一轮获取任务超时 //3. 结果：如果线程池中的线程数大于最大线程数或获取任务超时（不设置 allowCoreThreadTimeOut，核心线程没有超时概念），并且（线程数 &gt; 1 或 任务队列为空），则应该回收当前线程。 if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; // 减少工作线程数 if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; // 根据timed来判断： // 1. 如果为true，则通过阻塞队列的poll方法进行超时控制，如果在keepAliveTime时间内没有获取到任务则返回null // 2. 否则通过take方法获取任务，如果队列为空则take方法会阻塞直到队列不为空 Runnable r = timed ? // 超时获取任务，因为线程超时要被回收。如果线程在等待的过程发生了中断，会抛出中断异常 workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : // 不需要超时，如果线程在等待的过程发生了中断，会抛出中断异常 workQueue.take(); if (r != null) return r; // 如果 r == null ，说明获取任务超时 timedOut = true; &#125; catch (InterruptedException retry) &#123; // 获取任务时当前线程发生中断，重置超时标记并重试 timedOut = false; &#125; &#125; &#125; 上述方法用于从任务队列中不断拉取待执行的任务，具体执行流程如下图所示： 下面对主要逻辑进行说明： 该方法返回 null 时，表示当前线程可以被回收了，包括核心线程。这也是该方法多次判断的原因，控制线程池中线程数量，进而控制线程池的状态。 在没有设置 allowCoreThreadTimeOut 时，核心线程数的线程会阻塞等待任务，不会被回收。 超时回收，在 keepAliveTime 对应的具体时间内都没有任务，应该回收非核心线程。 以下情况需要返回 null，回收当前线程。 线程池处于 STOP 状态。 线程池处于 SHUTDOWN 状态，且阻塞队列为空。 线程池中的线程数大于最大线程数。 线程获取任务超时再次重试时，仍为可回收线程。 getTask 方法还是比较复杂的，整个逻辑中进行了多次判断，目的是控制线程的数量，进而维护线程池的状态。需要特殊说明的是，当线程获取任务超时时并没有立刻回收该线程，而是让线程重试，这么做是为了防止该线程可能会成为核心线程，避免误回收，如果误回收在后续流程中还需要重新创建线程，因此重试一次代价会小一些。 任务执行任务执行是 Worker线程 的工作，我们会在下面详细介绍。 任务拒绝拒绝策略线程池的拒绝策略属于一种限流保护机制，防止线程池崩溃。线程池拒绝任务的时机如下： 执行关闭方法后线程池处于关闭状态及以上状态 线程池处于运行状态，但是没有能力（阻塞队列已满，线程数达到最大值）处理新提交的任务了。 JDK 内置了 4 种拒绝策略，默认使用 AbortPolicy 策略。拒绝策略如下图所示： AbortPolicy12345678910111213141516171819/** * 丢弃任务并抛出异常（默认策略） */ public static class AbortPolicy implements RejectedExecutionHandler &#123; public AbortPolicy() &#123; &#125; /** * 直接抛出异常 * * @param r 任务 * @param e te */ public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; throw new RejectedExecutionException(\"Task \" + r.toString() + \" rejected from \" + e.toString()); &#125; &#125; AbortPolicy 策略是线程池默认的拒绝策略，在任务不能再提交到线程池时抛出异常，能够及时反馈程序的运行状态。对于比较核心的业务推荐使用此拒绝策略，因为当系统不能承载更大的并发流量时，业务方能够及时地通过异常发现。 CallerRunsPolicy123456789101112131415161718192021/** * 由提交任务的线程自己来执行任务 */ public static class CallerRunsPolicy implements RejectedExecutionHandler &#123; public CallerRunsPolicy() &#123; &#125; /** * 只要线程池没有被关闭，就由提交任务的线程自己来执行这个任务。 * * @param r * @param e */ public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; // 线程池没有关闭 if (!e.isShutdown()) &#123; // 方法级别调用 r.run(); &#125; &#125; &#125; CallerRunsPolicy 策略是由提交任务的线程处理任务，此策略适合让所有任务都执行完毕。 DiscardPolicy12345678910111213141516/** * 直接忽略任务 */ public static class DiscardPolicy implements RejectedExecutionHandler &#123; public DiscardPolicy() &#123; &#125; /** * 直接忽略 * * @param r * @param e */ public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; &#125; &#125; DiscardPolicy 策略会直接丢弃任务，并且不会抛出异常。此策略会导致业务方无法发现异常，不建议核心业务采用此策略。 DiscardOldestPolicy1234567891011121314151617181920/** * 将阻塞队列头的任务扔掉，然后将当前任务提交到线程池尝试执行。 */ public static class DiscardOldestPolicy implements RejectedExecutionHandler &#123; public DiscardOldestPolicy() &#123; &#125; /** * 将队列都任务移除，并将当前任务提交到线程池 * * @param r * @param e */ public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; e.getQueue().poll(); e.execute(r); &#125; &#125; &#125; DiscardOldestPolicy 策略会丢弃队列最前面的任务，然后重新提交被拒绝的任务。这种策略存在丢失任务的风险。 自定义拒绝策略只需要实现 RejectedExecutionHandler 接口，重写 rejectedExecution 方法即可。如果不自定义拒绝策略，线程池将使用默认的拒绝策略。 Worker线程管理前文在介绍任务执行机制的时候涉及到 Worker线程，线程池维护的线程模块其实就是一组 Worker对象 ，下面我们就来看看 ThreadPoolExecutor 的内部类 Worker 。 Worker线程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105private final class Worker extends AbstractQueuedSynchronizer implements Runnable &#123; /** * This class will never be serialized, but we provide a * serialVersionUID to suppress a javac warning. */ private static final long serialVersionUID = 6138294804551838833L; /** * Worker持有的线程，即任务执行的真正线程 */ final Thread thread; /** * 主线程提交任务到线程池，任务就会存放到这里。 */ Runnable firstTask; /** * 用于存放当前线程完成的任务数。注意和 completedTaskCount 的区别 */ volatile long completedTasks; /** * Worker 唯一的构造方法 * * @param firstTask 任务，可能为 null */ Worker(Runnable firstTask) &#123; // 设置状态值为 -1，防止在启动线程之前，线程就被中断。因为AQS中默认的 state 为 0，Worker中实现的 tryAcquire 方法内存值就是 0，修改值为 1 setState(-1); this.firstTask = firstTask; // 使用工厂创建线程，注意创建出来的线程的任务体就是 Worker 本身。这意味着当线程启动时，Worker#run方法就会执行 this.thread = getThreadFactory().newThread(this); &#125; /** * Worker 实现了 Runnable 接口，重写了run() 方法。 */ public void run() &#123; // 这里调用了外部类的 runWorker 方法 runWorker(this); &#125; // ------- Worker继承了AQS类，下面的核心方法是重写了AQS的方法，使用独占锁获得执行权，不支持锁的重入 -----------------/ protected boolean isHeldExclusively() &#123; return getState() != 0; &#125; /** * 独占式获取资源。AQS 中默认的 state 为 0。 * * @param unused * @return */ protected boolean tryAcquire(int unused) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; /** * 释放资源 * * @param unused * @return */ protected boolean tryRelease(int unused) &#123; setExclusiveOwnerThread(null); setState(0); return true; &#125; /** * lock */ public void lock() &#123; acquire(1); &#125; public boolean tryLock() &#123; return tryAcquire(1); &#125; /** * unlock */ public void unlock() &#123; release(1); &#125; public boolean isLocked() &#123; return isHeldExclusively(); &#125; /** * 中断线程 */ void interruptIfStarted() &#123; Thread t; if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; &#125; &#125;&#125; 线程池在创建线程时，会将线程封装成工作线程Worker，目的是管理线程的状态并维护线程的生命周期。 工作线程Worker 比较特别，下面对其关键点进行说明： 继承了 AQS ，实现了一套独占锁机制。 1.Worker 并没有直接使用可重入锁 ReentrantLock ，而是通过继承 AQS 实现了不可重入的独占锁，目的就是通过不可重入的特性判断 Worker 中封装线程的执行状态。2.在线程执行任务期间会加 Worker非重入锁，表示当前线程正在执行任务中，并不是处于空闲状态，不应该中断该线程。3.如果线程不是独占锁的状态则表明该线程处于空闲状态，可以对该线程进行中断 实现了 Runnable 接口，它是一个任务体并重写的 run 方法，该方法是线程池执行任务的关键。 在创建 Worker 成功后，紧接着就会启动 Worker 封装的真实 Thread ，启动成功后 Worker 中的 run 方法就会执行。 内部封装了实际执行任务的线程。 内部封装的线程是线程池的工厂创建出来的，它的使命就是执行 Worker 中的 run 方法中的任务。那业务任务谁来执行？ 同样地，也是该线程执行，只不过它使用的是方法级别的调用。 内部封装了初始化任务体 Worker 使用 firstTask 保存传入的第一个任务，该任务允许为null。如果该任务非空，那么线程就会在启动后优先执行这个任务，一般对应于核心线程的创建；如果该任务为空，对应于非核心线程的创建，用于去执行任务队列中的任务。 线程复用 一个 Worker 对应线程池中的一个线程，线程复用的逻辑实现是在 Worker 类中的 run 方法中执行 runWorker 方法。由上面的第 2、3 两个说明，很容易得出，当 Worker 中的线程启动后会执行 Worker 这个任务体的 run 方法，进而该线程就会执行 runWorker 方法，然后进入到 while 自旋，实现线程的复用。 线程回收 线程池管理着线程的生命周期，需要对长时间空闲的线程、启动失败的线程以及执行任务出现异常的线程进行回收。线程池使用了HashSet这个Hash表去持有Worker的引用，这样可以通过添加引用和移除引用的操作来控制线程的生命周期。 前文对线程池的任务执行机制进行了介绍，下图是 Worker 执行任务的模型： 新增线程如果说 execute 方法逻辑体现了提交任务到线程池的流程，那么 addWorker 方法则体现了线程池执行任务的开端，即接收任务、创建线程、启动线程。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128private boolean addWorker(Runnable firstTask, boolean core) &#123; //------------------------------- 1 创建线程前的检测工作 -------------------------------------/ // for 跳出标志 retry: for (; ; ) &#123; //------------------------- 1.1 创建线程前，对线程池状态和队列进行检查，判断是否还可以创建线程 ----------------------/ // 获取线程池状态码 int c = ctl.get(); // 获取线程池状态 int rs = runStateOf(c); /** * * 如果线程池状态范围是：[SHUTDOWN，TERMINATED]，出现下列任一种情况都不允许创建Worker: * 1 firstTask != null * 2 workQueue 为空 * *小结： * 1 线程池处于 SHUTDOWN 状态时，不允许提交任务，但是已经存在的任务需要继续执行。 * 1.1 当 firstTask == null 时且阻塞队列不为空，说明非提交任务创建线程，执行阻塞队列中的任务，允许创建 Worker * 1.2 当 firstTask == null 但阻塞队列为空，不能创建 Worker * 1.3 当 firstTask ！= null 时，不能创建 * 2 线程池状态大于 SHUTDOWN 状态时，不允许提交任务，且中断正在执行的任务。 */ if (rs &gt;= SHUTDOWN &amp;&amp; !(rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; !workQueue.isEmpty())) return false; //---------------------------- 2 创建线程前，对线程池中线程数检查，判断是否还可以创建线程 ---------------------/ for (; ; ) &#123; // 获取线程池线程数 int wc = workerCountOf(c); // 判断线程池线程数是否达到边界值：1 临界值 2 核心线程数或最大线程数 if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; // 增加线程池中线程数如果成功，则表示创建 Worker 前的校验工作完成，可以进行创建 Worker 流程了。 if (compareAndIncrementWorkerCount(c)) break retry; // 增加线程数失败，说明可能其它线程也在尝试创建Worker，就需要回到起点，重新校验。 //并发影响，需要重新获取线程池状态码 c = ctl.get(); //线程池状态是否改变，改变了则需要重头校验，否则只需要再次校验线程数即可 if (runStateOf(c) != rs) continue retry; &#125; &#125; //---------------------------------- 创建 Worker 流程 ------------------------------------/ // Worker 中的线程是否启动的标志 boolean workerStarted = false; // Worker 是否添加到 workers 集合中的标志 boolean workerAdded = false; Worker w = null; try &#123; // 创建 Worker，将任务传入。注意，如果是非提交任务创建Worker的话，firstTask 为null w = new Worker(firstTask); // 将创建的Worker中的线程临时保存到 t，这个是真正的线程，Worker 只是对线程进行了包装。 final Thread t = w.thread; // Worker 中的线程创建成功 if (t != null) &#123; // 加锁，注意这个锁的粒度是全局的。也就是说，当这里获取到锁，线程池不能关闭，因为线程池关闭也需要锁。 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 再次获取线程池状态 int rs = runStateOf(ctl.get()); // 如果线程池是运行状态，或者是关闭状态且传入的任务为null(不接收新任务，但是会继续执行任务队列中的任务)，符合条件。 // 此外都不符合条件，线程池不会维护当前创建的Worker线程，该Worker线程由于没有被引用最后会被JVM回收 if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; // 提前检查新创建的Worker中的线程是否是启动状态 if (t.isAlive()) throw new IllegalThreadStateException(); // 将新创建的 Worker 加入到 workers 集合，意味着线程池持有当前 Worker 的引用，当前 Worker 不会被 GC。 workers.add(w); // 更新 largestPoolSize 的值，该值用于追踪线程池中出现过的最大线程数量 int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; // 更新标记值 workerAdded = true; &#125; &#125; finally &#123; // 全局锁释放，注意全局锁释放的时机 mainLock.unlock(); &#125; // Worker线程只有添加到Worker集合后才能启动线程 if (workerAdded) &#123; // 启动Worker中的线程，这一步的意义重大 t.start(); // 标记线程启动成功 workerStarted = true; &#125; &#125; &#125; finally &#123; // 线程加入线程池失败或启动失败，需要清理工作 if (!workerStarted) addWorkerFailed(w); &#125; return workerStarted; &#125; 线程池通过上述方法增加线程，该方法仅完成创建线程并使它运行，最后返回是否成功。至于是哪种情况下增加线程，该方法并不关心。下图是新增Worker线程的流程图： 还需要强调一点，该方法只是创建并启动线程，线程还没有执行任务。再分析执行任务逻辑之前，先来看看创建 Worker 的异常流程，addWorkerFailed 方法。 12345678910111213141516171819private void addWorkerFailed(Worker w) &#123; // 获得全局锁 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; if (w != null) // 从 workers 缓存中移除启动失败的 Worker workers.remove(w); // 减少线程池中线程数，因为在此之前递增了 decrementWorkerCount(); // 尝试终止线程池 tryTerminate(); &#125; finally &#123; mainLock.unlock(); &#125;&#125; 方法名非常直观，就是执行 addWorker 失败的处理方法。该方法主要做了以下工作： 从 Worker 缓存集合中移除启动失败的 Worker 便于 GC 。 递减线程池中线程数，在校验是否允许创建 Worker 流程中递增了线程数，这里需要递减。 尝试终止线程池，新增线程失败的原因可能是线程池状态处于[SHUTDOWN,TERMINATED]，这种情况下要尝试更新线程池的状态为终止状态。 执行任务Worker 中的线程启动成功后，其 run 方法会调用 runWorker 方法： 1234567/** * Worker 实现了 Runnable 接口，重写了run() 方法。 */public void run() &#123; // 这里调用了外部类的 runWorker 方法 runWorker(this); &#125; runWorker 方法是执行提交任务和阻塞队列中等待任务的核心实现，接下来我们分析它的具体实现。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475final void runWorker(Worker w) &#123; // 当前线程，即 w 中的线程 Thread wt = Thread.currentThread(); // 获取该线程的第一个任务，可能没有。如果有的话，优先执行该任务。 Runnable task = w.firstTask; w.firstTask = null; // 将 state 值由由 -1 设置为 0，这样就可以允许中断了 。 w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; // 循环调用getTask() 方法从任务队列中获取任务并执行 while (task != null || (task = getTask()) != null) &#123; // 申请Worker非重入锁，标志着自己处于工作状态。 w.lock(); /** * 该if判断保证了：如果线程池正在停止，需要确保当前线程是中断状态，否则要保证当前线程不是中断状态。 * * 出现以下任何一种情况都需要中断线程： * 1 如果线程池状态大于等于 STOP，并且当前线程没有被中断 * 2 如果当前线程被中断了并且线程池状态大于等于 STOP 状态（恢复中断标识） * 使用interrupted()方法判断线程是否被中断，该方法会清除中断标志位，既确保了在线程RUNNING或者SHUTDOWN状态时线程是非中断状态的，又支持了线程池是STOP状态下的判断 */ if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) // 中断当前线程，进行中断标志复位 wt.interrupt(); try &#123; // ThreadPoolExecutor 的扩展方法 beforeExecute(wt, task); Throwable thrown = null; try &#123; // 执行目标任务,方法级别调用。 task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; // ThreadPoolExecutor 的扩展方法 afterExecute(task, thrown); &#125; &#125; finally &#123; // 置空 task,为下一个任务做准备 task = null; // 更新Worker线程完成任务数量 w.completedTasks++; // 释放 Worker非重入锁 w.unlock(); &#125; &#125; // while 循环没有出现异常，completedAbruptly 才会被设置为 false completedAbruptly = false; &#125; finally &#123; /** * 线程退出 while 循环后需要进行回收，可能情况如下： * 1 任务队列中已经没有要执行的任务了 * 2 任务执行过程出现异常 */ processWorkerExit(w, completedAbruptly); &#125; &#125; 线程执行任务的流程如下图所示： 执行任务逻辑已经详细注释，下面对该方法简要分析： 线程执行任务有两个途径，通过取 Worker 的 firstTask 或者调用 getTask 方法从任务队列中取出待执行的任务。 线程复用得益于对线程的封装，封装后的线程不再局限于执行当前任务，而是while循环不断地通过getTask()方法获取任务，然后执行任务，从而实现了线程的复用。 线程在执行任务前会先申请对应 Worker 独占锁，标志自己处于工作状态，不应该中断该线程，这是对线程封装的好处。 当线程池状态大于等于 STOP 状态，要保证当前线程是中断状态，否则要保证当前线程不是中断状态。 线程通过调用任务的 run 方法来执行对应的任务，而不是启动线程，这个正是前文特别说明的方法级别调用。 当 Worker 封装的线程退出循环后，执行 processWorkerExit() 方法对该线程进行回收。 可以通过重写 beforeExecute() 和 afterExecute() 方法来实现 ThreadPoolExecutor 的扩展功能。 再谈线程复用线程池会使用一定数量的线程去执行任务，通常线程数量远小于任务数量，针对这种情况线程池通过线程复用的方式让同一个线程去执行不同的任务。我们知道线程池是将线程和任务解耦，摆脱了一个任务必须一个线程的限制，这也是线程复用的必要条件。线程池使用Worker对线程的封装，也就是Worker线程，线程启动后会去执行一个循环任务，该任务可以执行线程的首个任务和轮询任务队列中的任务，线程通过调用任务的 run 方法实现任务的执行。 线程复用的逻辑主要在 runWorker 方法中，该方法是 Worker 类的 run 方法中的逻辑，Worker 中封装的线程启动后会执行 Worker 的 run 方法进而执行 runWorker 方法。整个逻辑简化后的代码如下： 12345678910111213runWorker(Worker w) &#123; // 线程首个任务 Runnable task = w.firstTask; // 轮询任务队列中的任务 while (task != null || (task = getTask()) != null) &#123; try &#123; // 线程执行任务的 run 方法，即方法级别的调用 task.run(); &#125; finally &#123; task = null; &#125; &#125;&#125; 线程回收线程池中线程的销毁依赖JVM自动回收，Worker 线程结束任务或异常退出后，Worker 会主动清除自身在线程池中的引用，这意味着线程池可以回收该线程了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; // 线程执行任务抛出了异常 if (completedAbruptly) // 减少线程池中线程数量 decrementWorkerCount(); // 获取全局锁 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 累计线程池完成的任务数量 completedTaskCount += w.completedTasks; // 将线程引用移出线程池 workers.remove(w); &#125; finally &#123; // 释放全局锁 mainLock.unlock(); &#125; // 尝试终止线程池 tryTerminate(); int c = ctl.get(); // 如果线程池状态小于 STOP 状态，说明还可以处理任务 if (runStateLessThan(c, STOP)) &#123; // 1. 当前线程处理任务没有出现异常 if (!completedAbruptly) &#123; // 获取核心线程数，如果设置了允许回收核心线程数，则返回 0，否则取核心线程数 int min = allowCoreThreadTimeOut ? 0 : corePoolSize; // 1.1 如果 allowCoreThreadTimeOut=true，并且任务队列中有任务，至少保留一个worker线程 if (min == 0 &amp;&amp; !workQueue.isEmpty()) min = 1; // 1.2 如果 allowCoreThreadTimeOut=false，线程池中线程数不能少于 corePoolSize // 线程池中线程数大于等于 min ，说明无需创建线程。 if (workerCountOf(c) &gt;= min) return; // replacement not needed &#125; // 执行到这里的可能情况： // 1 线程池中没有线程执行任务队列中的任务，需要创建线程取执行。（核心线程数设置为 0 或 允许回收核心线程） // 2 线程池中线程数小于核心线程数，需要创建线程补充核心线程数。（核心线程数 &gt; 0） // 3 当前线程执行任务过程出现异常，而且当前线程被回收了，为了确保有线程执行任务，这里需要创建线程。 addWorker(null, false); &#125; &#125; 线程回收流程如下图所示： 需要注意的是，线程销毁工作不是只有 processWorkerExit 方法才能完成，前文介绍的新增Worker线程逻辑中对异常流处理的 addWorkerFailed 方法也可以做到。这两者销毁线程的时机不同，前者是线程执行任务的逻辑中销毁，后者是创建线程后启动失败的处理。 上述 processWorkerExit 方法在将Worker线程移除线程池后也就完成了线程的回收工作，但由于执行该方法的原因很多，线程正常退出getTask方法或者执行任务异常都会执行该方法，因此在该方法中需要额外完成两个工作。一是使线程池自适应当前状态，另一个是根据需要创建线程。 至此，processWorkerExit 执行完之后Worker线程被销毁，该线程的整个生命周期结束。下面对整个过程使用流程图的形式进行总结，流程图如下： 关闭线程池调用线程池的 shutdown 或 shutdownNow 方法来关闭线程池，两者的原理有点差异，下面我们分别说明这两个方法。 shutdown12345678910111213141516171819public void shutdown() &#123; // 全局锁 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); // 设置线程池状态为 SHUTDOWN advanceRunState(SHUTDOWN); // 尝试中断线程池所有中闲置的线程 interruptIdleWorkers(); // hook onShutdown(); // hook for ScheduledThreadPoolExecutor &#125; finally &#123; mainLock.unlock(); &#125; // 尝试终止线程池 tryTerminate(); &#125; shutdown() 方法可以安全地关闭一个线程池，体现在下面几个方面： 只是将线程池的状态置为 SHUTDOWN ，这意味着线程池不能接收新的任务，再有新的任务被提交则根据拒绝策略进行处理。 会执行完正在执行的任务和队列中等待的任务，任务全部结束后才会彻底关闭线程池。 尝试中断线程池中所有闲置的线程。 调用tryTerminate尝试终止线程池，用于将线程池的状态更新为 TERMINATED 。 shutdownNow123456789101112131415161718192021public List&lt;Runnable&gt; shutdownNow() &#123; List&lt;Runnable&gt; tasks; // 全局锁 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); // 设置线程池状态为 STOP advanceRunState(STOP); // 尝试中断线程池中所有启动状态的线程 interruptWorkers(); // 将阻塞队列中正在等待的所有任务进行备份，然后清空阻塞队列并返回备份。有了这个备份，可以根据需要做补救措施。 tasks = drainQueue(); &#125; finally &#123; mainLock.unlock(); &#125; // 尝试终止线程池 tryTerminate(); return tasks; &#125; shutdownNow() 方法表示立即关闭线程池，工作如下： 将线程池状态置为 STOP 状态。 中断所有Worker线程，包括空闲和非空闲。 清空阻塞队列并返回等待执行的任务备份。 调用tryTerminate尝试终止线程池，用于将线程池的状态更新为 TERMINATED 。 tryTerminate()对于 tryTerminate() 方法的调用，前文中的新增线程失败逻辑、线程退出while逻辑以及两种关闭线程池的方法都会调用了该方法，下面我们来看看这个方法的具体逻辑。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152final void tryTerminate() &#123; for (; ; ) &#123; // 线程池状态码 int c = ctl.get(); // 以下几种情况不能终止线程池，直接返回（STOP 状态可不会直接返回） //1. 线程池是运行状态 RUNNING //2. 大于等于 TIDYING 状态，此时线程池中已经没有正在运行的线程了 //3. SHUTDOWN 状态且阻塞队列非空，这种情况需要执行完任务队列中的任务 if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN &amp;&amp; !workQueue.isEmpty())) return; // 执行到这里，说明已经具备终止线程池的条件，只差线程回收了。 // 线程池中线程数量不为 0，向任意空闲线程发出中断信号，所有被阻塞的线程（执行poll/take）最终都会被一个个唤醒，回收。 if (workerCountOf(c) != 0) &#123; // Eligible to terminate // 这里既不是中断所有线程，也不是中断所有空闲线程，而是中断任意一个空闲线程，原因如下： // 1. tryTerminate() 方法多处被调用，需要中断线程逻辑在上层已经进行了处理，如 shutdown 方法调用时会中断所有空闲线程 // 2. interruptIdleWorkers(ONLY_ONE) 方法用在 tryTerminate() 方法中主要为了唤醒 getTask()方法中存在执行workQueue.take()等待的线程，防止一直等待造成线程无法回收。 // 即使有多个线程阻塞等待，唤醒任意一个也足够了，被唤醒的线程在退出while循环后会再次调用tryTerminate()方法，继续中断阻塞等待线程。此外线程退出后进入到processWorkerExit()方法中 // 会要申请全局锁的，如果全部唤醒会出现竞争锁的情况。 interruptIdleWorkers(ONLY_ONE); return; &#125; // 全局锁 final ReentrantLock mainLock = this.mainLock; // 终止线程池时加全局锁，保证CAS执行成功，即线程池状态依次更新为 TIDYING 和 TERMINATED 。 // 这里可能发生并发问题，如两个线程都通过了 workerCountOf(c) != 0 条件，执行到这里就需要加锁。 mainLock.lock(); try &#123; // 设置线程池状态码为 TIDYING if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) &#123; try &#123; // 状态设置成功后执行 terminated() 钩子方法 terminated(); &#125; finally &#123; // 设置线程池状态码为 TERMINATED 终止状态 ctl.set(ctlOf(TERMINATED, 0)); termination.signalAll(); &#125; return; &#125; &#125; finally &#123; mainLock.unlock(); &#125; // else retry on failed CAS &#125; &#125; tryTerminate() 方法主要根据线程池状态判断是否终止线程池，下面进行简单总结： 判断线程池是否可以终止，原则是线程池处于关闭状态、队列中没有任务的情况下可以终止。 interruptIdleWorkers()方法的执行表示线程池具备终止条件，向任意空闲线程发送中断信号防止 getTask 方法中存在核心线程执行 workQueue.take()时一直阻塞，导致线程无法回收。 符合终止线程池的条件时，先获取全局锁，然后先将线程池状态置为 TIDYING 状态，设置成功后会执行 terminated() 钩子方法，最后将线程池状态设置为 TERMINATED 状态，完成线程池状态更新后释放全局锁。 下面我们来简单分析一下interruptIdleWorkers方法。 12345678910111213141516171819202122232425262728293031323334+--- ThreadPoolExecutor private void interruptIdleWorkers() &#123; interruptIdleWorkers(false); &#125; /** * 中断所有闲置的Worker * * @param onlyOne 是否仅中断一个 */ private void interruptIdleWorkers(boolean onlyOne) &#123; final ReentrantLock mainLock = this.mainLock; // 全局锁，涉及到 workers 操作线程池都会加该锁 mainLock.lock(); try &#123; // 遍历 workers ，对每个非中断线程进行中断操作。 for (Worker w : workers) &#123; Thread t = w.thread; // 如果线程非中断状态，且能 tryLock() 成功，说明该线程闲置，需要进行中断 if (!t.isInterrupted() &amp;&amp; w.tryLock()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; finally &#123; w.unlock(); &#125; &#125; if (onlyOne) break; &#125; &#125; finally &#123; mainLock.unlock(); &#125; &#125; 前文也进行了说明，Worker 继承了AQS，在Worker线程处理任务时会申请Worker独占锁，interruptIdleWorkers 在进行中断时会使用 tryLock() 来判断该Worker线程是否正在处理任务，如果 tryLock() 返回true，说明该Worker线程处于空闲状态，可以被中断。 注意事项： 线程池中多处执行 tryTerminate 方法的目的是将符合条件的线程池终止，前文也提到线程池的状态是内部自行维护的，并非人为设置。如用户执行 shutdown 和 shutdownNow 方法只是将线程池的状态设置为 SHUTDOWN 和 STOP ，后续的 TIDYING 和 TERMINATED 状态的设置就在于此。 tryTerminate 方法中的 interruptIdleWorkers(ONLY_ONE) 的作用是防止线程池在终止的过程中 getTask 方法中存在执行 workQueue.take() 阻塞的线程，因为此时线程池不允许再有新的任务添加到阻塞队列中，这样一来线程将一直阻塞下去，线程池永远都终止不了。 线程池中虽然多处使用中断来期望中断任务的执行，但由于 Java 中不推荐强行停止线程的机制的限制，因为强制的让一个线程被动的退出是很不安全的，内部的数据不一致会对程序造成不可预知的后果。即使调用了 shutdownNow 方法，如果被中断的线程对于中断信号不敏感，那么依然有可能导致任务不会停止。 线程池配置线程池太大或太小都会导致麻烦，选择一个合适的线程池是非常有必要的。调整线程池中的数量是为了充分并合理地使用 CPU 和内存资源，从而最大限度地提高程序性能。通常我们需要根据任务执行的性质来选择对应的策略。 CPU 密集型任务如果任务主要进行大量复杂的计算，例如加密、解密、压缩等，那么意味着 CPU 的处理能力是稀缺的资源，应当分配较少的线程，通常按照 CPU 核数 或者 CPU 核数 + 1 进行设置。 计算任务会占用大量的 CPU 资源，CPU 的每个核工作基本都是高负荷的，如果设置过多的线程，每个线程都会尝试抢占 CPU 资源，这就造成了不必要的上下文切换（CPU并没有太多空闲），性能反而由于线程数量过多导致性能下降。 IO 密集型任务I/O 操作比较多的任务，如数据库操作、文件读写、网络通信等，一般不会消耗太多 CPU 资源，但是普遍需要较长时间的等待，对于这类任务可以配置适当多的线程，如 CPU 核数 * 2 。由于 IO 读写速度相比于 CPU 的速度是比较慢的，设置过少的线程数是不能充分利用 CPU 资源。 合适线程数Brain Goetz 推荐的计算方法如下： 线程数 = CPU核数 × 目标CPU利用率 ×（1 + 平均等待时间/平均工作时间） 通过上面的公式可以大致计算出一个合理的线程数（核心线程数和最大线程数统称）。如果任务平均等待时间长则线程数就应该多，对应于 IO 密集型任务。如果平均工作时间长则线程数就应该少，对应于 CPU 密集型任务。 线程数太少可能会使得程序整体性能降低，线程数太多可能会消耗内存资源以及造成不必要的上下文切换。想用准确定制线程池需要做的工作很多，除了考虑线程数还可以合理使用线程池的阻塞队列实现任务的调度，还可以根据业务等纬度实现线程池隔离。 线程池监控线程池提供了一些用于获取属性的方法，这些属性可以用来对线程池进行监控。 线程池还提供了一些用于设置核心属性的方法，使用方可以通过这些方法动态设置线程池的核心策略，线程池内部会处理好当前状态并做到平滑修改。 动态设置核心线程数123456789101112131415161718192021222324252627+--- ThreadPoolExecutor public void setCorePoolSize(int corePoolSize) &#123; if (corePoolSize &lt; 0) throw new IllegalArgumentException(); // 计算核心线程数变化值 int delta = corePoolSize - this.corePoolSize; // 覆盖原来的corePoolSize this.corePoolSize = corePoolSize; //线程池的线程数大于变更的核心线程数，说明有多余的worker线程，此时会向空闲的worker线程发起中断请求以实现回收 if (workerCountOf(ctl.get()) &gt; corePoolSize) interruptIdleWorkers(); // 核心线程数大于原来值，尝试增加核心线程 else if (delta &gt; 0) &#123; // 取 任务数和 delta 两者的最小值 int k = Math.min(delta, workQueue.size()); // 预先创建足够多的新Worker以达到核心线程数，并处理队列中的任务。队列空了则停止 while (k-- &gt; 0 &amp;&amp; addWorker(null, true)) &#123; if (workQueue.isEmpty()) break; &#125; &#125; &#125; 动态设置最大线程数123456789101112+--- ThreadPoolExecutor public void setMaximumPoolSize(int maximumPoolSize) &#123; if (maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize) throw new IllegalArgumentException(); // 覆盖原来的 maximumPoolSize this.maximumPoolSize = maximumPoolSize; // 如果是设置小了的话，此时会向空闲的worker线程发起中断请求以实现回收 if (workerCountOf(ctl.get()) &gt; maximumPoolSize) interruptIdleWorkers(); &#125; 动态设置空闲时间1234567891011121314151617+--- ThreadPoolExecutor public void setKeepAliveTime(long time, TimeUnit unit) &#123; if (time &lt; 0) throw new IllegalArgumentException(); if (time == 0 &amp;&amp; allowsCoreThreadTimeOut()) throw new IllegalArgumentException(\"Core threads must have nonzero keep alive times\"); // 计算超时时间 long keepAliveTime = unit.toNanos(time); // 计算差值 long delta = keepAliveTime - this.keepAliveTime; // 覆盖原来的 keepAliveTime this.keepAliveTime = keepAliveTime; // 如果时间设置比原来小，则向空闲的worker线程发起中断请求以实现回收 if (delta &lt; 0) interruptIdleWorkers(); &#125; 允许核心线程超时回收12345678910111213+--- ThreadPoolExecutor public void allowCoreThreadTimeOut(boolean value) &#123; // 核心线程必须要有保活时间 if (value &amp;&amp; keepAliveTime &lt;= 0) throw new IllegalArgumentException(\"Core threads must have nonzero keep alive times\"); if (value != allowCoreThreadTimeOut) &#123; allowCoreThreadTimeOut = value; // 允许回收则立即中断空闲线程 if (value) interruptIdleWorkers(); &#125; &#125; 小结本篇文章对线程池核心点进行了详细分析，先是简单介绍了线程池产生的背景，接着说明了线程池的优势，最后对线程池源码进行了分析。从任务提交到线程池，到线程池创建线程并处理任务，到最后线程被回收，最后简单介绍了线程池的配置以及线程池的监控。","categories":[{"name":"JDK","slug":"JDK","permalink":"https://gentryhuang.com/categories/JDK/"}],"tags":[{"name":"JUC","slug":"JUC","permalink":"https://gentryhuang.com/tags/JUC/"}]},{"title":"并发 - ReentrantLock","slug":"concurrent/ReentrantLock","date":"2020-11-30T16:00:00.000Z","updated":"2021-08-21T09:38:25.057Z","comments":false,"path":"posts/dd0ffc6a/","link":"","permalink":"https://gentryhuang.com/posts/dd0ffc6a/","excerpt":"","text":"概述ReentrantLock 是一个可重入锁，指的是一个线程能够对临界资源重复加锁，它是基于 AQS 的独占模式实现的同步组件，用同步状态 state 记录某个线程获取独占锁的次数，初始值为 0 ，获取锁时+1，释放锁时-1，并且它支持公平和非公平模式。 特性说起 ReentrantLock ，就不得不提 synchronized 关键字，下面给出两者的对比关系： 特性 ReentrantLock synchronized 灵活性 支持响应中断、超时，尝试获取锁 不灵活 锁类型 公平锁或非公平锁 非公平锁 条件队列 可关联多个条件队列 关联一个条件队列 锁实现机制 依赖 AQS JVM 监视器模式 可重入性 可重入 可重入 释放锁 必须显示调用 unlock() 释放锁 自动释放 源码分析可重入锁 ReentrantLock 是基于 AQS 实现的独占模式的同步组件，既然是基于 AQS 实现，必然遵循使用 AQS 的固定步骤，在分析源码的过程会有所体现。由于可重入锁支持公平和非公平模式，并且实现方式有所区别，因此在分析源码过程中会按照这两种情况分别说明。下面我们就通过读源码的方式来了解 ReentrantLock 是如何通过公平锁和非公平锁与 AQS 关联起来的。 ReentrantLock 的类继承关系类图如下： 源码结构12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class ReentrantLock implements Lock, java.io.Serializable &#123; private static final long serialVersionUID = 7373984872572414699L; /** * 继承 AQS 的内部类 */ private final Sync sync; /** * ReentrantLock 通过在内部继承 AQS 来管理锁。真正获取锁和释放锁是由内部类 Sync 的实现类来控制的。 * 说明： * Sync 是一个抽象的内部类，它有两个实现，分别是 NonfairSync（非公平锁）和 FairSync（公平锁） */ abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = -5179523762034025860L; // 省略其它代码 &#125; /** * 默认创建非公平锁 */ public ReentrantLock() &#123; sync = new NonfairSync(); &#125; /** * 创建公平或非公平锁，根据传入参数决定 * * @param fair true: 公平 false: 非公平 */ public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync(); &#125; /** * 获取锁 */ public void lock() &#123; sync.lock(); &#125; /** * 解锁，不区分公平还是不公平 */ public void unlock() &#123; sync.release(1); &#125; // 省略其它代码&#125; ReentrantLock 基于 AQS 实现的独占模式的可重入锁步骤如下： 定义继承自 AQS 的静态内部类 Sync 由于 ReentrantLock 实现的是独占模式的锁功能，因此需要重写 tryAcquire 和 tryRelease 方法对 将 Sync 的实现组合在 ReentrantLock 的加锁（如 lock() 方法）和释放锁（如 unlock() 方法）的实现中 由于 ReentrantLock 支持公平和非公平锁，获取同步状态方法 tryAcquire 在两种实现中有所差异，因此该方法交给各自实现。静态内部类 Sync 实现了公平和非公平锁统一使用的释放同步状态的方法 tryRelease 。 了解了 ReentrantLock 实现独占模式的可重入锁的套路后，下面我们继续对支持锁功能的静态内部类 Sync 进行分析。 Sync123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101+--- ReentrantLock /** * ReentrantLock 通过在内部继承 AQS 来管理锁。真正获取锁和释放锁是由内部类 Sync 的实现类来控制的。 * 说明： * Sync 是一个抽象的内部类，它有两个实现，分别是 NonfairSync（非公平锁）和 FairSync（公平锁） */ abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = -5179523762034025860L; /** * 获取锁的方法，交给 公平锁和非公平锁 两个子类实现 */ abstract void lock(); /** * 非公平尝试获取同步状态。 * 用于：非公平锁的 tryAcquire 和 尝试获取锁的 tryLock */ final boolean nonfairTryAcquire(int acquires) &#123; // 1 获取当前线程 final Thread current = Thread.currentThread(); // 2 获取同步状态，也就是锁资源 int c = getState(); // 3 如果 state == 0 ，说明此时没有线程持有锁 if (c == 0) &#123; // 直接使用 CAS 尝试获取锁。 // 注意，相比较公平锁，这里没有对同步队列进行判断，因为是非公平锁 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; // 4 此时有线程持有锁，判断是否是重入的情况，根据占用锁的线程是否是当前线程 &#125; else if (current == getExclusiveOwnerThread()) &#123; // 4.1 重入的情况需要操作： state = state + 1 int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); // 4.2 修改 state setState(nextc); return true; &#125; // 5 获取锁失败 return false; &#125; /** * 可重入锁的释放锁，不区分是否为公平锁。 * * @param releases * @return */ protected final boolean tryRelease(int releases) &#123; // 释放同步状态 int c = getState() - releases; // 释放锁的操作只能是获取锁的线程，否则抛出异常 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); // 标记是否完全释放，因为 ReentrantLock 支持可重入 boolean free = false; // 如果释放后，同步状态为 0 ，说明是完全释放，那么重置独占锁的线程为 null if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; // 更新同步状态 setState(c); // 是否完全释放，完全释放才算释放成功 return free; &#125; /** * 判断当前线程是否正在占有独占锁 * * @return */ protected final boolean isHeldExclusively() &#123; // While we must in general read state before owner, // we don't need to do so to check if current thread is owner return getExclusiveOwnerThread() == Thread.currentThread(); &#125; /** * 创建当前 ReentrantLock 的 Condition 对象 * * @return */ final ConditionObject newCondition() &#123; return new ConditionObject(); &#125; // 省略其它方法 &#125; 继承自 AQS 的静态内部类 Sync 主要有 5 类方法： lock 抽象方法，供子类实现，完成获取锁的逻辑 nonfairTryAcquire 方法实现了非公平获取同步状态逻辑。没有定义在非公平锁实现类中是因为 ReentrantLock 中的其它方法也要使用，如 tryLock 方法 tryRelease 方法实现了释放同步状态的逻辑，释放同步状态逻辑不区分是否公平 isHeldExclusively 方法用于判断当前线程是否正在占有独占锁 newCondition 方法用于创建当前 Lock 的 Condition 对象 非公平锁12345678910111213141516171819202122232425262728293031323334353637+--- ReentrantLockstatic final class NonfairSync extends Sync &#123; private static final long serialVersionUID = 7316153563782823691L; /** * 实现 Sync 抽象类的 lock 方法，用于非公平获取锁 */ final void lock() &#123; // 1 调用 AQS 的设置通过状态的方法，尝试将同步状态由 0 设置为 1 if (compareAndSetState(0, 1)) // 1.1 将同步状态由 0 设置为 1 成功，表示获取锁成功。这里记录获取锁的线程 setExclusiveOwnerThread(Thread.currentThread()); // 2 调用 AQS 独占模式获取同步状态的方法。同步状态参数固定是 1 // acquire 方法会自动调用 tryAcquire 方法 else acquire(1); &#125; /** * 实现 AQS 的模版方法，尝试获取独占模式的同步状态。这里是获取锁 * * @param acquires * @return */ protected final boolean tryAcquire(int acquires) &#123; // 调用父类 Sync 中的方法 return nonfairTryAcquire(acquires); // 获取锁失败，回到外层调用方法： // public final void acquire(int arg) &#123; // if (!tryAcquire(arg) &amp;&amp; // // 线程入队及后续操作 // acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) // selfInterrupt(); // &#125; &#125; &#125; 非公平锁实现类 NonfairSync 继承了 Sync 类，实现了 Sync 中定义获取锁的 lock 方法（非公平获取锁），逻辑体现在 lock 方法和 tryAcquire 方法中；实现了AQS中定义的模版方法 tryAcquire，尝试以非公平方式获取独占模式的同步状态。 加锁lock 方法用于非公平获取锁，逻辑如下： 若通过 CAS 设置同步状态 state 成功则获取锁成功，然后将当前线程设置为独占线程即可。 若通过 CAS 设置同步状态 state 失败则获取锁失败，然后进入 acquire 方法进行后续处理（先通过调用实现的 tryAcquire 方法尝试再次获取锁，失败后则进入同步队列中） 加锁完整流程图 下面对加锁过程进行说明： 1 使用方通过 ReentrantLock 暴露出去的加锁方法 lock() 进行加锁操作。2 将加锁操作交给内部实现 NonfairSync 的加锁方法 lock() 完成。如果加锁成功则获取锁过程结束，否则执行 AQS 的 acquire 方法。3 AQS 的 acquire 方法会执行 tryAcquire 方法，该方法由 NonfairSync 实现用来非公平尝试获取同步状态。4 tryAcquire 是获取锁逻辑，获取失败后，会执行 AQS 框架的后续逻辑，跟 ReentrantLock 自定义同步组件无关。 关于 AQS 框架的逻辑就不再展开说明，感兴趣地可以参考 AQS原理分析 。 非公平锁123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/** * 公平锁实现 */static final class FairSync extends ReentrantLock.Sync &#123; private static final long serialVersionUID = -3000897897090466540L; /** * 实现 Sync 抽象类的 lock 方法，用于公平获取锁 */ final void lock() &#123; // 调用 AQS 的模版方法，会调用实现的 tryAcquire 方法。 // 注意，这里的同步状态固定为 1 acquire(1); &#125; /** * 实现 AQS 的模版方法。公平地尝试获取锁 * * @param acquires * @return true - 获取锁成功（1 没有线程在等待锁 2 重入锁的情况，线程本来就持有锁，当然可以再次拿到） */ protected final boolean tryAcquire(int acquires) &#123; // 1 获取当前线程 final Thread current = Thread.currentThread(); // 2 获取同步状态，也就是锁资源 int c = getState(); // 3 如果 state == 0 ，说明此时没有线程持有锁 if (c == 0) &#123; // 3.1 虽然此时没有线程持有锁，但是由于这是公平锁，要讲究先来后到，此时可能在同步队列中有等待的线程节点。 if (!hasQueuedPredecessors() &amp;&amp; // 3.2 如果同步队列中没有线程在等待，那么就使用 CAS 尝试获取锁。不成功的情况，说明就在刚刚几乎同一时刻有其它线程抢先了 compareAndSetState(0, acquires)) &#123; // 3.3 获取到锁就进行标记下，告知其它线程自己持有了锁 setExclusiveOwnerThread(current); return true; &#125; // 4 此时有线程持有锁，判断是否是重入的情况，根据占用锁的线程是否是当前线程 &#125; else if (current == getExclusiveOwnerThread()) &#123; // 4.1 重入的情况需要操作： state = state + 1 int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); // 4.2 修改 state setState(nextc); return true; &#125; // 5 获取锁失败 // 回到外层调用方法： // public final void acquire(int arg) &#123; // if (!tryAcquire(arg) &amp;&amp; // // 线程入队及后续操作 // acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) // selfInterrupt(); // &#125; return false; &#125;&#125; 公平锁实现类 FairSync 继承了 Sync 类，实现了 Sync 中定义获取锁的 lock 方法（公平获取锁），逻辑体现在 tryAcquire 方法中；实现了AQS中定义的模版方法 tryAcquire，尝试以公平方式获取独占模式的同步状态。 加锁lock 方法用于公平获取锁，是直接调用 AQS 模版方法 acquire 完成的，其获取锁的逻辑封装在实现的 tryAcquired 方法中。 加锁完整流程图 下面对加锁过程进行说明： 1 使用方通过 ReentrantLock 暴露出去的加锁方法 lock() 进行加锁操作。2 将加锁操作交给内部实现 FairSync 的加锁方法 lock() 完成，lock() 方法直接执行 AQS 的 acquire 方法。3 AQS 的 acquire 方法会执行 tryAcquire 方法，该方法由 FairSync 实现用来公平尝试获取同步状态。4 tryAcquire 是获取锁逻辑，获取失败后，会执行 AQS 框架的后续逻辑，跟 ReentrantLock 自定义同步组件无关。 公平锁的加锁逻辑几乎和非公平锁的加锁逻辑一致，唯一不同的地方在于，在获取锁时即使没有线程持有锁，对公平锁来说要讲究先来后到，此时可能在同步队列中有等待的线程节点，此时不能抢占获取锁。 释放锁对 ReentrantLock 来说，释放锁是不区分公平性的，因此释放锁的逻辑封装在了父类 Sync 中，实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849+--- ReentrantLock /** * 解锁，不区分公平还是不公平 */ public void unlock() &#123; // 同步状态固定为 1 sync.release(1); // 释放锁后回到外层方法 // public final boolean release(int arg) &#123; // if (tryRelease(arg)) &#123; // Node h = head; // if (h != null &amp;&amp; h.waitStatus != 0) // unparkSuccessor(h); // return true; // &#125; // return false; // &#125; &#125;+--- Sync /** * 可重入锁的释放锁，不区分是否为公平锁。 * * @param releases * @return */ protected final boolean tryRelease(int releases) &#123; // 释放同步状态 int c = getState() - releases; // 释放锁的操作只能是获取锁的线程，否则抛出异常 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); // 标记是否完全释放，因为 ReentrantLock 支持可重入 boolean free = false; // 如果释放后，同步状态为 0 ，说明是完全释放，那么重置独占锁的线程为 null if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; // 更新同步状态 setState(c); // 是否完全释放，完全释放才算释放成功 return free; &#125; 下面对 ReentrantLock 释放锁的操作进行简单概括： 使用方通过调用 ReentrantLock 的解锁方法 unlock() 进行解锁。 unlock() 方法会调用内部类 Sync 的 release 模版方法，该方法是 AQS 的方法。 release 中会调用 tryRelease 方法，tryRelease 需要自定义同步组件自行实现，该方法只在父类 Sync 中实现，因此可以看出，释放锁的过程并不区分是否公平。 释放锁成功后，所有处理由 AQS 框架完成，与自定义同步组件无关。 至此，可重入锁 ReentrantLock 的加锁和释放锁整个过程已经分析完毕。下面对整个流程进行简单总结，具体如下图所示： 其它1234567891011121314151617181920212223242526272829303132333435363738394041424344454647+--- ReentrantLock /** * 实现 Lock 接口方法 * &lt;p&gt; * 可中断获取锁 * * @throws InterruptedException */ public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1); &#125; /** * 实现 Lock 接口方法 * &lt;p&gt; * 尝试获取锁，获取不到也没关系，不会入队 * * @return */ public boolean tryLock() &#123; return sync.nonfairTryAcquire(1); &#125; /** * 实现 Lock 接口方法 * &lt;p&gt; * 尝试在指定的时间内获取锁 * * @param timeout * @param unit * @return * @throws InterruptedException */ public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout)); &#125; /** * 创建当前 ReentrantLock 的 Condition 对象。 * 使用 ReentrantLock 和 Condition 实现等待-通知机制 * * @return */ public Condition newCondition() &#123; return sync.newCondition(); &#125; ReentrantLock 除了我们就常用的加锁方法 lock() 和解锁方法 unlock 外，还提供了上述的系列方法。值得一说的是 newCondition 方法，该方法是使用 ReentrantLock 和 Condition 实现等待-通知机制的，具体的实现原理可参考 AQS 原理分析 - Condition实现原理 。 差异公平锁和非公平锁的差异如下： 非公平锁在调用 lock 后，首先会使用 CAS 尝试抢占锁，如果此时锁没有被占用，那么获取锁成功并返回。 非公平锁 CAS 尝试抢占锁失败后，和公平锁一样都会进入自己实现的 tryAcquire 方法，在该方法中如果发现同步状态 state == 0 ，非公平锁会直接 CAS 抢占锁，而公平锁会判断同步队列中是否有线程节点处于等待状态，如果有则不去抢占锁，进入排队流程。 相对来说，非公平锁会有更好的性能，因为它的吞吐量更大。但非公平锁让获取锁的时间变得更加不确定，可能会导致在阻塞队列中的线程长期处于饥饿状态。 小结ReentrantLock 基于 AQS 实现了锁的机制，支持公平和非公平模式。核心思想是使用同步状态 state 控制 ReentrantLock 可重入的情况，state 初始化的时候为0，表示没有任何线程持有锁。当有线程持有该锁时，值就会在原来的基础上+1，同一个线程允许多次获得锁，此时就会多次+1，这就是可重入的概念。解锁也是对这个字段-1，一直到0，此线程释放锁。拿不到锁就借助 AQS 的同步队列管理等待线程。","categories":[{"name":"JDK","slug":"JDK","permalink":"https://gentryhuang.com/categories/JDK/"}],"tags":[{"name":"JUC","slug":"JUC","permalink":"https://gentryhuang.com/tags/JUC/"},{"name":"AQS","slug":"AQS","permalink":"https://gentryhuang.com/tags/AQS/"},{"name":"Lock","slug":"Lock","permalink":"https://gentryhuang.com/tags/Lock/"}]},{"title":"并发 - Java并发工具类","slug":"concurrent/Java并发工具类","date":"2020-11-21T16:00:00.000Z","updated":"2021-08-13T04:42:49.123Z","comments":false,"path":"posts/37f29896/","link":"","permalink":"https://gentryhuang.com/posts/37f29896/","excerpt":"","text":"前言在 JDK 的并发包中提供了几个非常有用的并发工具类。 CountDownLatch、CyclicBarrier 和 Semaphore 工具类提供了并发流程控制的手段，它们都是对 AQS 共享模式的应用。本篇文章将介绍其简单使用以及内部原理。 工具类 作用 说明 Semaphore 信号量，通过控制 ‘许可证’ 的数量来协调各个线程，以保证合理的使用公共资源。 线程只有拿到 ‘许可证’ 才能继续运行 CyclicBarrier 循环栅栏，让一组线程到达一个栅栏（同步点）时被阻塞，直到最后一个线程到达栅栏时，被栅栏拦截的线程才会继续运行。 强调一组线程都到达同步点才会继续往下执行 CountDownLatch 门栓，等待多线程完成 强调一个或多个线程等待其它线程完成操作 CountDownLatch使用例子场景 加工厂生产产品，产品需要三道工序进行检测，只有三道工序检测通过才能进入下一个环节。 12345678910111213141516171819202122232425262728293031323334353637383940414243@Slf4jpublic class CountDownLatchDemo &#123; /** * 固定线程数线程池 */ public static ExecutorService service = Executors.newFixedThreadPool(5); /** * 产品质量检测 * * @param args * @throws InterruptedException */ public static void main(String[] args) throws InterruptedException &#123; // 需要3个工人进行检测，就用3来初始化一个 CountDownLatch CountDownLatch latch = new CountDownLatch(3); for (int i = 1; i &lt;= 3; i++) &#123; final int no = i; service.submit(() -&gt; &#123; try &#123; // 检测 Thread.sleep((long) (Math.random() * 10000)); log.info(\"No.\" + no + \" 完成检测。\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; // 调用 countDown() 代表完成。这里指某个员工完成检测任务 latch.countDown(); &#125; &#125; ); &#125; log.info(\"产品质量检测中.....\"); // 调用await() 代表线程阻塞等待其它线程完成，即同步状态 state 减为 0。这里指产品等待检测完成 latch.await(); log.info(\"产品质量检测完毕，进入下一个环节。\"); &#125;&#125; 打印结果 12345[main] INFO com.code.juc.tool.CountDownLatchDemo - 产品质量检测中.....[pool-1-thread-2] INFO com.code.juc.tool.CountDownLatchDemo - No.2 完成检测。[pool-1-thread-3] INFO com.code.juc.tool.CountDownLatchDemo - No.3 完成检测。[pool-1-thread-1] INFO com.code.juc.tool.CountDownLatchDemo - No.1 完成检测。[main] INFO com.code.juc.tool.CountDownLatchDemo - 产品质量检测完毕，进入下一个环节。 说明 以上例子中，main 线程调用了 latch.await() 进行阻塞等待，即它阻塞在门栓上（叫啥无所谓，中文是门栓、栅栏），只有当条件满足时（其它线程调用 latch.countDown() 递减 state 为0）它才能通过这个门栓。这个例子比较简单，只有一个线程调用 await 方法等待其它线程完成，这属于 一对多 关系。CountDownLatch 还可以实现复杂的 多对多 关系的场景，有 m 个线程在门栓上等待 n 个线程完成任务，直到 n 个线程都完成任务，这 m 个线程才能同时通过门栓。 源码分析根据 CountDownLatch 的使用例子分析源码，按照执行流程逐一分析。 属性123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384public class CountDownLatch &#123; /** * Synchronization control For CountDownLatch. // 继承AQS的内部类 * Uses AQS state to represent count. // 使用 AQS 的状态表示 数量 */ private static final class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = 4982264981922014374L; /** * 有参构造方法 * * @param count 数量 */ Sync(int count) &#123; // 调用父类方法，设置状态值 setState(count); &#125; /** * 获取数量 * * @return */ int getCount() &#123; // 调用父类方法，获取状态值 return getState(); &#125; /** * 覆写父类方法 （获取同步状态（这里表示数量） - 共享方式） * * @param acquires * @return */ @Override protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1; &#125; /** * 覆写父类方法（释放同步状态（这里表示数量） - 共享方式） * * @param releases 没有意义的参数，用不到 * @return */ @Override protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero for (; ; ) &#123; // 执行递减数量时，如果数量已经是 0 ，则直接返回 false，说明状态已经被其它线程递减为 0 了，当前线程无需唤醒 await() 阻塞的线程（们） int c = getState(); if (c == 0) &#123; return false; &#125; int nextc = c - 1; if (compareAndSetState(c, nextc)) &#123; return nextc == 0; &#125; &#125; &#125; &#125; /** * AQS 对象 */ private final Sync sync; /** * 构造方法，需要一个 &gt;= 0 的整数 * * @param count the number of times &#123;@link #countDown&#125; must be invoked * before threads can pass through &#123;@link #await&#125; * @throws IllegalArgumentException if &#123;@code count&#125; is negative */ public CountDownLatch(int count) &#123; if (count &lt; 0) &#123; throw new IllegalArgumentException(\"count &lt; 0\"); &#125; this.sync = new Sync(count); &#125; // $&#123;省略其它代码&#125; &#125; CountDownLatch 类是对 AQS 共享模式的使用。既然是使用 AQS 框架，那么就是一个固定的模式，AQS 已经处理好了同步状态的获取与释放以及阻塞与唤醒，自定义组件只需继承 AQS 以及根据同步状态获取方式（独占/共享）实现模版方法即可。前面也说了，AQS 准备好了一切，只需要条件触发就可以执行对应的任务，而实现的模版方法正是触发条件。 CountDownLatch 主要有两个核心方法，await 和 countDown 。countDown 方法每次调用都会将 state 减 1 ，直到 state 的值为 0。await 方法可以被多个线程调用，调用 await 方法的线程进入 AQS 的阻塞队列中并挂起，当且仅当 state 为 0 时，线程会从阻塞队列中依次被唤醒过来。 await 等待await 方法是一个阻塞方法，当且仅当同步状态 state 减至 0，该方法才会返回，否则调用该方法的线程将阻塞。 1234567891011121314151617--- CountDownLatch public void await() throws InterruptedException &#123; // 可中断获取同步状态 sync.acquireSharedInterruptibly(1); &#125;--- AbstractQueuedSynchronizer public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; // 中断则抛出中断异常 if (Thread.interrupted()) throw new InterruptedException(); // main 线程调用 await 时，state = 3，条件成立 if (tryAcquireShared(arg) &lt; 0) // 接下来就是 AQS 的工作了，共享方式可中断获取同步状态 doAcquireSharedInterruptibly(arg); &#125; CountDownLatch 的 await 方法简单，直接传入数量值为 1 尝试获取同步状态（其实传入值是没有意义的，用不到）。CountDownLatch 覆写了模版方法即条件，条件成立则 AQS 完成阻塞任务。 123456789101112131415161718192021222324252627282930313233343536--- AbstractQueuedSynchronizer /** * Acquires in shared interruptible mode. * @param arg the acquire argument */ private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; // 1 入队 ，即当前线程加入阻塞队列，共享方式 final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; // 尝试获取前驱节点 final Node p = node.predecessor(); if (p == head) &#123; // CountDownLatch 实现的条件，state != 0 时，返回 -1 int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; &#125; &#125; // 2 找大哥，找到大哥就挂起自己，然后等待大哥唤醒自己。没有找到则继续找，直到找到或其前驱节点是 head 节点，找到则挂起等待，是 head 则尝试获取同步状态。 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) // 线程被中断则抛出异常 throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; CountDownLatch 的 await 方法到此就结束了，下面总结下该方法的核心步骤。 main 线程没有获取到同步状态会进入阻塞队列main 线程对应的节点入队完成，如上图。需要注意的是，因为 main 线程对应节点入队时阻塞队列为空，因此需要构建阻塞队列，使用一个虚节点作为 head 。如果节点在入队时已经存在阻塞队列，那么直接挂到阻塞队列尾部即可。 尝试获取同步状态入队后进入for 循环，此时main线程对应的节点的前驱节点是 head，但 tryAcquireShared 返回 -1,此时进入 找大哥 的流程中。找大哥 就是将当前节点的有效前驱节点等待状态 waitStatus 设置为 -1。这里是将 main 线程对应节点的前驱节点 head 的 waitStatus 设置为 -1。 挂起，等待前置节点唤醒找到大哥后挂起自己，等待大哥（有效前置节点）唤醒自己。 以上是 main 线程获取同步状态失败后，进入阻塞队列等待唤醒的过程。需要说明的是，CountDownLatch 可以有多个线程等待其它线程完成，例子中只是使用一个线程等待而已。 countDown 唤醒countDown 方法每次调用都会将同步状态 state 减 1，直到减少至 0 。 1234567891011121314151617181920212223242526272829303132333435363738394041--- CountDownLatch public void countDown() &#123; // 释放同步状态 sync.releaseShared(1); &#125;--- AbstractQueuedSynchronizer public final boolean releaseShared(int arg) &#123; //只有当 state 减到 0 时， tryReleaseShared 方法才返回 true，否则仅是将 state 减 1 并返回 false if (tryReleaseShared(arg)) &#123; // state == 0 时，唤醒阻塞的线程。 注意，这里是 t1 线程唤醒阻塞的线程即 main 线程 doReleaseShared(); return true; &#125; return false; &#125; private void doReleaseShared() &#123; // t1 线程执行到这里，唤醒阻塞队列中等待的 main 线程 for (;;) &#123; // 将当前 head 保存起来，因为其它线程可能会占领它，此时是虚节点 Node h = head; if (h != null &amp;&amp; h != tail) &#123; // main 线程入队时已经把 head 当作大哥了，即 将 head 的 waitStatus 设置为 -1 (Node.SIGNAL) int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; // cas 将 head 的 waitStatus 设置 为 0。 if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases // 唤醒 head 下一个有效节点。这里是 main 线程对应的节点 unparkSuccessor(h); &#125;else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125; &#125; 上面代码只是正常情况下一个完整流程，即 main 线程加入阻塞队列并挂起后，t2、t3、t1 分别执行 countDown 方法递减 state 的值，到了 t1 调用该方法时，刚好 state 的值被减至 0 ，然后线程 t1 执行唤醒阻塞队列中的线程逻辑。下面对该过程进行总结。 至此，唤醒条件已经具备，即 state = 0 ，下面我们回到之前线程挂起的代码处，代码如下： 123456789101112131415161718192021222324252627282930313233343536--- AbstractQueuedSynchronizer /** * Acquires in shared interruptible mode. * @param arg the acquire argument */ private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; // 尝试获取前驱节点 final Node p = node.predecessor(); if (p == head) &#123; // CountDownLatch 实现的条件，state != 0 时，返回 -1 int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; // 2 main 占据 head 并继续唤醒后置阻塞的线程 setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; // 1 线程 t1 唤醒阻塞的 main 线程，该方法返回，即 main 线程继续执行尝试再次获取同步状态 parkAndCheckInterrupt()) // 如果线程被中断则抛出异常 throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; main 线程被唤醒后从 parkAndCheckInterrupt 方法返回，如果没有被中断，则继续尝试获取同步状态，此时可以获取到同步状态（r &gt;= 0 成立）。接下来 main 线程会进入到 setHeadAndPropagate 方法中。 123456789101112131415161718192021222324252627282930313233--- AbstractQueuedSynchronizer private void setHeadAndPropagate(Node node, int propagate) &#123; // 将当前 head 保存起来，因为其它线程可能会占领它 Node h = head; // Record old head for check below // node 节点占领 head，即 main 线程占领 head setHead(node); /* * 这里条件判断对应的场景比较多，毕竟是 AQS 统一处理方法，因此考虑的情况比较全面。对于 CountDownLatch ，就是唤醒 node 之后的有效节点。 */ if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; // 当前节点的后置节点 Node s = node.next; // 如果为 null 或者 是共享方式的节点 if (s == null || s.isShared()) // 接着唤醒阻塞线程 （共享式）。注意，这里是醒来的阻塞线程继续唤醒后置还在阻塞的线程。 doReleaseShared(); &#125; &#125; /** * 占领 head * Sets head of queue to be node, thus dequeuing. Called only by * acquire methods. Also nulls out unused fields for sake of GC * and to suppress unnecessary signals and traversals. * * @param node the node */ private void setHead(Node node) &#123; head = node; node.thread = null; node.prev = null; &#125; setHeadAndPropagate 方法主要做了两件事，node 占领 head 并唤醒 node 后置的有效节点。由于例子中只有 main 线程进入了阻塞队列，它后面没有等待唤醒的线程节点，但为了研究源码我们假设 main 线程对应节点后面还有一个 线程 t 节点等待唤醒，那么 main 线程会执行 doReleaseShared 方法来唤醒线程 t ，此时 head 是 main 线程对应的节点。 1234567891011121314151617181920212223242526272829private void doReleaseShared() &#123; for (;;) &#123; // 将当前 head 保存起来，因为其它线程可能会占领它 Node h = head; // h == null 说明阻塞队列为空，h == tail 说明头节已经是最后一个节点或者是刚刚初始化的节点，这对应 CountDownLatch 来说都应该结束。 // 按照例子走到这里，head 就 main线程对应的节点，同时 tail 也是 main 线程对应的节点。不过我们假设了 线程 t ，因此条件是成立的 if (h != null &amp;&amp; h != tail) &#123; // h 的状态，即 main 线程对应节点状态，由入队方法可知，t 线程对应节点会把 main 线程对应节点作为 大哥节点，即 waitStatus 设置为 -1（Node.SIGNAL) int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; // 可能会失败 if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases // 唤醒 h 的后置节点，也就是阻塞队列中的第一个节点。这里是线程 t 对应的节点 unparkSuccessor(h); &#125;else if (ws == 0 &amp;&amp; // todo 这里可能会失败 !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; // 线程执行到这里，如果唤醒的线程已经占领了 head，此时 h != head，当前线程继续循环。如果 h == head ，说明，唤醒的线程还没有占领 head，当前线程退出循环 // 这里可能 main 线程执行到这里时，main 线程唤醒的线程 t 已经占领了 head ,此时 h != head if (h == head) // loop if head changed break; &#125;&#125; setHeadAndPropagate 方法和 doReleaseShared 方法配合，依次唤醒阻塞的线程，即 执行 doReleaseShared 方法的线程唤醒它的后置阻塞线程，醒来的线程会再次尝试获取同步状态然后进入到 setHeadAndPropagate 方法中先占领 head，然后调用 doReleaseShared 方法继续唤醒它的后置阻塞节点。需要说明的是，AQS 的 doReleaseShared 方法极端场景还是挺多的，这里结合 CountDownLatch 来说明。 我们抛开给出的例子，根据以下场景分析几个特殊的情况 要进行体能测试，每组三个同学进行短跑，在体育老师发出起跑指令前，这三个同学都要在起跑线待着，当体育老师准备完毕后会发出开始跑的指令，那这三个同学就会一起跑向终点的测试仪。这里 CountDownLatch 的数量 为 1，即同步状态为 1 。 h != head 的情况当 t1 被唤醒后，唤醒 t1 的线程 t 执行到上图中的代码处，还没有退出循环，t1 已经占领了 head（此时图中的 head 要指向 t1 线程对应的节点，且 t1 线程节点 thread 置空，prev 置空。图中没有体现出来），此时 head != h ，线程 t 将会进行下一轮循环。 compareAndSetWaitStatus(h, Node.SIGNAL, 0) 失败线程 t 进行第二轮循环时，刚好被唤醒的线程 t1 也进入该循环，此时两个线程并发执行，假设线程 t CAS 操作成功，然后退出循环，线程 t1 失败，将会进行下一轮循环。注意，此时虚节点的 next 指针还存在，因为我们假设的是 t1 线程失败了，t 线程成功退出了，t 线程不属于阻塞队列中的线程，它不会维护阻塞队列节点关系，如果是 t1 线程成功并退出循环就会清除它上一个节点的 next ，这里就是虚节点。 执行 else if (ws == 0 &amp;&amp;..) 分支t1 线程第二次循环时，唤醒的 t2 线程还没有占领 head，此时的 head 还是 t1 线程对应的节点，但是 waitStatus 被之前的 t 线程通过 CAS 设置为 0 了，因此进入到 else if 分支，然后再次把节点 watiStatus 设置为 -3 。执行到 h == head 判断处时，假设 t2 还是没有占领 head ，此时 t1 退出循环，然后清除其前置节点的 next 指针，即虚节点。 compareAndSetWaitStatus(h, 0, Node.PROPAGATE) 失败进入这个方法的前提是 ws == 0，即 head 的 waitStatus 出现了 0，此时如果 CAS 失败，一般有两种可能，一种是线程并发执行 CAS 只有一个会成功，另一种是其它的线程把该节点的 waitStatus 值修改了，此时能改 head 的状态值的很可能是节点入队引起的修改，因为新节点要把有效的前驱节点状态值设置为 -1 。在 CountDownLatch 中一般不会发生第二种可能，因为一旦唤醒条件成立，就不会再有节点需要入队阻塞了。 剩下的 t2 线程、t3 线程依次会被唤醒，需要注意的是 t3 线程被唤醒占领头节点后也会进入到 doReleaseShared 方法的循环中，此时它对应的节点既是 head 又是 tail，就直接退出循环，结束整个流程了。 小结CountDownLatch 的构造函数需要一个 int 类型的参数作为数量（用来计数），如果想等待 N 个任务完成（N 个线程执行完任务），就需要传入 N 。CountDownLatch 的 countDown 方法用于将 N 减 1 ,await 方法会阻塞当前调用线程（阻塞在门栓上，门栓是一个同步点的概念），直到 N 减至 0 被阻塞的线程才会继续往下执行。此外，CountDownLatch 还提供了一个带有指定时间的 await 方法，用于等待超时的场景，超过等待时间就不会再等，被阻塞线程继续往下执行。这个方法很简单，就是在 await 方法的基础上增加了超时判断，下面粘贴下代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859--- CountDownLatch public boolean await(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout)); &#125;--- AbstractQueuedSynchronizer public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); return tryAcquireShared(arg) &gt;= 0 || doAcquireSharedNanos(arg, nanosTimeout); &#125; /** * Acquires in shared timed mode. * * @param arg the acquire argument * @param nanosTimeout max wait time * @return &#123;@code true&#125; if acquired */ private boolean doAcquireSharedNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (nanosTimeout &lt;= 0L) return false; // 计算出等待的最迟时间 final long deadline = System.nanoTime() + nanosTimeout; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return true; &#125; &#125; // 计算出等待剩余时间 nanosTimeout = deadline - System.nanoTime(); // 超过等待时间，则不再等待，直接返回 if (nanosTimeout &lt;= 0L) return false; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; // 执行挂起的最小时间粒度 nanosTimeout &gt; spinForTimeoutThreshold) // 挂起 nanosTimeout 时间后自动醒来 LockSupport.parkNanos(this, nanosTimeout); if (Thread.interrupted()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 需要注意，N 值必须 大于等于 0，如果 N 等于 0 ，调用 await 方法时当前线程不会被阻塞，此外 CountDownLatch 不支持重新初始化，也不支持修改数量的值。 CyclicBarrier使用例子场景 某个公司部门举办团建活动，需要员工自行拼车前往目的地，司机会在指定的地点等待拼车的 4 个人到齐后才发车。我们假设该部门某个团队有 8 个人，那么就需要拼 2 辆车前往目的地。 123456789101112131415161718192021222324252627282930313233@Slf4jpublic class CyclicBarrierDemo &#123; /** * 固定线程数线程池 */ public static ExecutorService service = Executors.newFixedThreadPool(8); public static void main(String[] args) &#123; // 要等待 4 个同学到齐，到齐后发车，因此这里初始化一个带有 Runnable 参数的 CyclicBarrier CyclicBarrier cyclicBarrier = new CyclicBarrier(4, () -&gt; log.info(\"4人已到齐，请系好安全带，现在出发赶往目的地 !\")); // 8个人，需要 2 辆车。这里会循环使用 CyclicBarrier for (int i = 0; i &lt; 8; i++) &#123; service.submit(() -&gt; &#123; try &#123; // 赶往拼车地点 Thread.sleep((long) (Math.random() * 10000)); log.info(\"到达指定拼车地点 !\"); cyclicBarrier.await(); // 一组人员全部到达后，才能出发。 即 一组线程全部到达栅栏后，被阻塞的线程才能继续执行 log.info(\"出发了 !\"); &#125; catch (InterruptedException | BrokenBarrierException exception) &#123; exception.printStackTrace(); &#125; &#125;); &#125; &#125;&#125; 打印结果 123456789101112131415161718[pool-1-thread-6] INFO com.code.juc.tool.CyclicBarrierDemo - 到达指定拼车地点 ![pool-1-thread-5] INFO com.code.juc.tool.CyclicBarrierDemo - 到达指定拼车地点 ![pool-1-thread-4] INFO com.code.juc.tool.CyclicBarrierDemo - 到达指定拼车地点 ![pool-1-thread-1] INFO com.code.juc.tool.CyclicBarrierDemo - 到达指定拼车地点 ![pool-1-thread-1] INFO com.code.juc.tool.CyclicBarrierDemo - 4人已到齐，请系好安全带，现在出发赶往目的地 ![pool-1-thread-1] INFO com.code.juc.tool.CyclicBarrierDemo - 出发了 ![pool-1-thread-6] INFO com.code.juc.tool.CyclicBarrierDemo - 出发了 ![pool-1-thread-5] INFO com.code.juc.tool.CyclicBarrierDemo - 出发了 ![pool-1-thread-4] INFO com.code.juc.tool.CyclicBarrierDemo - 出发了 ![pool-1-thread-8] INFO com.code.juc.tool.CyclicBarrierDemo - 到达指定拼车地点 ![pool-1-thread-2] INFO com.code.juc.tool.CyclicBarrierDemo - 到达指定拼车地点 ![pool-1-thread-3] INFO com.code.juc.tool.CyclicBarrierDemo - 到达指定拼车地点 ![pool-1-thread-7] INFO com.code.juc.tool.CyclicBarrierDemo - 到达指定拼车地点 ![pool-1-thread-7] INFO com.code.juc.tool.CyclicBarrierDemo - 4人已到齐，请系好安全带，现在出发赶往目的地 ![pool-1-thread-7] INFO com.code.juc.tool.CyclicBarrierDemo - 出发了 ![pool-1-thread-8] INFO com.code.juc.tool.CyclicBarrierDemo - 出发了 ![pool-1-thread-2] INFO com.code.juc.tool.CyclicBarrierDemo - 出发了 ![pool-1-thread-3] INFO com.code.juc.tool.CyclicBarrierDemo - 出发了 ! 说明 以上例子中，使用循环体和线程池模拟 8 个线程执行任务，其中每 4 个线程为一组，只有这 4 个线程都到达栅栏，例子中是到达指定拼车点，才能继续往下执行，否则都会阻塞在栅栏上等待其它线程到达栅栏。到达栅栏的定义是 线程调用 await 方法。一组线程都到达栅栏后，由最后到达的线程执行及时任务，没有任务则不执行。CyclicBarrier 是可循环使用的栅栏，当一组线程都到齐后，CyclicBarrier 进行下一个循环，下一组线程进行同样的操作。 源码分析CyclicBarrier 的字面意思是可循环使用的栅栏，因为它的栅栏可以重复使用（通过重置关键属性）。它要做的事情是，让一组线程到达一个栅栏（是一个同步点）时被阻塞，直到最后一个线程到达栅栏时，栅栏才会打开，所有被栅栏拦截的线程才能继续运行。它的功能是通过组合 ReentrantLock 和 Condition 来达到的。我们还是基于使用例子来分析源码。 属性123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class CyclicBarrier &#123; /** * 栅栏所处的代。栅栏上阻塞的线程被唤醒或者栅栏被重置，就开启新的一代 */ private static class Generation &#123; // 栅栏是否被打破，默认为 false boolean broken = false; &#125; /** * 锁 */ private final ReentrantLock lock = new ReentrantLock(); /** * 锁对应的条件，阻塞线程在栅栏或者唤醒阻塞在栅栏上的线程 */ private final Condition trip = lock.newCondition(); /** * 栅栏要拦截的线程数 */ private final int parties; /** * 一组线程都到达栅栏后优先执行的任务，即如果设置这个这个任务，那么被阻塞在栅栏上的线程要等这个任务结束后才能被唤醒。注意，这个任务是被最后到达的线程执行 */ private final Runnable barrierCommand; /** * 当前栅栏所处的代，如果第一次就是 1 代，如果第2次使用就是 2 代 */ private Generation generation = new Generation(); /** * 还要等待的线程数，即还没有到栅栏的线程数。这个初始值 是 parties 值，每个线程到栅栏就减 1 */ private int count; // CyclicBarrier 高级构造函数，支持优先执行任务 public CyclicBarrier(int parties, Runnable barrierAction) &#123; if (parties &lt;= 0) throw new IllegalArgumentException(); this.parties = parties; this.count = parties; this.barrierCommand = barrierAction; &#125; // CyclicBarrier 默认的构造方法 public CyclicBarrier(int parties) &#123; this(parties, null); &#125; // $&#123;省略其它代码&#125;&#125; CyclicBarrier 默认的构造方法的参数表示栅栏拦截的线程数，每个线程调用 await 方法都会告诉 CyclicBarrier 我已经到达栅栏，此时栅栏要把拦截的线程数减 1 ，然后阻塞当前线程，直到要拦截的线程都到达栅栏时，栅栏才会打开，即最后到达的线程唤醒阻塞在栅栏上的线程，然后这组线程都从 await 方法处继续往下执行。 CyclicBarrier 还提供一个高级构造函数，用于在最后一个线程到达栅栏时，优先执行的任务，便于处理复杂的业务场景。注意，执行优先任务先于唤醒阻塞线程 ，代码中所有体现。 下一代栅栏12345678910111213---CyclicBarrier /** * 开启下一代栅栏 * 1 唤醒阻塞在上一代栅栏上的线程 * 2 重置 count 和 generation */ private void nextGeneration() &#123; // signal completion of last generation trip.signalAll(); // set up next generation count = parties; generation = new Generation(); &#125; 开启下一代栅栏很好理解，因为要开启下一代栅栏了，当前代栅栏上阻塞的线程需要被唤醒，同时初始化好下一代栅栏。 打破栅栏123456789101112---CyclicBarrier /** * 打破栅栏 */ private void breakBarrier() &#123; // 设置栅栏已破标志 generation.broken = true; // 重置 count count = parties; // 唤醒阻塞在栅栏上的线程 trip.signalAll(); &#125; 打破栅栏需要标记当前代的栅栏不可用，并且要唤醒阻塞在这个不可用的栅栏上的线程，因为这里不进行唤醒的话，阻塞的线程将一直挂起。这里重制 count 不明白是干嘛的。 await12345678910111213141516171819--- CyclicBarrier // 不带超时机制的方法，例子中使用的就是这个 public int await() throws InterruptedException, BrokenBarrierException &#123; try &#123; // false , 0 return dowait(false, 0L); &#125; catch (TimeoutException toe) &#123; throw new Error(toe); // cannot happen &#125; &#125; // 带有超时机制的方法，如果超过等待时间，当前线程没有被唤醒则 抛出 TimeoutException public int await(long timeout, TimeUnit unit) throws InterruptedException, BrokenBarrierException, TimeoutException &#123; return dowait(true, unit.toNanos(timeout)); &#125; CyclicBarrier 提供了 await 两个重载方法，一个是不带超时机制的方法，另一个是带有超时机制的方法。下面我们分析 CyclicBarrier 核心代码 dowait 方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107--- CyclicBarrier private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException &#123; // 使用可重入锁 final ReentrantLock lock = this.lock; // 加锁 lock.lock(); try &#123; // 获取标志着当前栅栏的 代 final Generation g = generation; // 检查当前代的栅栏是否被打破，如果当前代的栅栏被打破需要 抛出 BrokenBarrierException 异常 if (g.broken) throw new BrokenBarrierException(); // 检查当前线程中断状态，如果被中断了，则要抛出 InterruptedException 异常，并且打破栅栏 if (Thread.interrupted()) &#123; breakBarrier(); throw new InterruptedException(); &#125; // 递减 count 的值 int index = --count; // 如果 count 递减后的值为 0 ，说明当前代的栅栏要拦截的最后一个线程也到达栅栏 if (index == 0) &#123; // tripped // 标志优先任务是否失败，默认是 false boolean ranAction = false; try &#123; // 如果指定了优先任务，就交给最后到达的线程执行 final Runnable command = barrierCommand; if (command != null) command.run(); // 设置标志 ranAction = true; // 唤醒当前代的栅栏上阻塞的任务，并开启下一代 （栅栏可以重复使用） nextGeneration(); return 0; &#125; finally &#123; // 如果执行优先任务失败，则打破栅栏 if (!ranAction) breakBarrier(); &#125; &#125; // ---------------------- 执行到这里的线程不是最后一个线程，因此需要阻塞，等待最后一个线程到来并唤醒自己 ---------------/ // loop until tripped, broken, interrupted, or timed out for (;;) &#123; try &#123; // 不带超时机制 if (!timed) // 释放锁，加入等待队列 (ConditionObject) trip.await(); // 带超时机制，并且超时时间 &gt; 0 else if (nanos &gt; 0L) // 释放锁，加入等待队列 (ConditionObject)，如果到时间还没有被唤醒则不再阻塞 nanos = trip.awaitNanos(nanos); // 执行到这里说明，线程进入等待队列后被中断了 &#125; catch (InterruptedException ie) &#123; // 栅栏仍是进入等待队列的前的栅栏，此时应该打破栅栏，并且抛出中断异常 if (g == generation &amp;&amp; ! g.broken) &#123; breakBarrier(); throw ie; &#125; else &#123; // 1 g != generation，说明新一代的栅栏生成了，即最后一个线程也到达了栅栏，此时只需复位被中断线程的中断标志 // 2 栅栏被打破了（一定要抛出异常），被打破异常交由后续逻辑处理，此时只需复位被中断线程的中断标志 Thread.currentThread().interrupt(); &#125; &#125; // 线程被唤醒后，还没从 await 方法返回栅栏就被打破了，直接抛出异常 if (g.broken) throw new BrokenBarrierException(); /** * 这个方法很重要，被唤醒后的线程正常逻辑都会从该方法返回出去 * 1 最后一个线程到达后会做三件事：执行优先任务、唤醒当前代的栅栏上阻塞的线程、开启栅栏的下一代 * 2 当前所在的方法是加了 ReentrantLock 锁的，因此我们要知道以下信息： * 1）最后一个到达线程在没有执行完三件事前，是不会释放锁的 * 2）唤醒的阻塞线程并不能马上从 await 方法返回，它需要先去竞争锁，获取锁后才能从 await 方法返回 * 3）即使最后一个线程开启了栅栏的下一代，在它没有释放锁前，其它组的线程也要阻塞，比如例子中的后四个线程 * 3 被最后一个线程唤醒的线程执行到这里时，新一代的栅栏一定已经存在了。注意，这里说的是被最后一个线程唤醒的线程，并不是由于超时机制醒来的线程 */ if (g != generation) return index; // 超时机制醒来的线程，如果发现已经超时了，则打破栅栏，抛出异常 if (timed &amp;&amp; nanos &lt;= 0L) &#123; breakBarrier(); throw new TimeoutException(); &#125; &#125; &#125; finally &#123; lock.unlock(); &#125; &#125; 涉及到的源码已经分析过了，下面结合使用例子简单分析下过程 CyclicBarrier 整个过程还是挺清晰的，没有使用 CAS 重试等机制，因为栅栏等待线程的 await 方法直接使用了ReentrantLock 锁，线程要到达栅栏必须拿到锁才行，整个过程是串行化的。分析完核心方法后，我们再看下其它几个方法。 12345678910111213141516171819202122232425262728293031323334--- CyclicBarrier // 重置栅栏 public void reset() &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; breakBarrier(); // break the current generation nextGeneration(); // start a new generation &#125; finally &#123; lock.unlock(); &#125; &#125; // 在栅栏上等待线程数 public int getNumberWaiting() &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; return parties - count; &#125; finally &#123; lock.unlock(); &#125; &#125; // 判断栅栏是否被打破 public boolean isBroken() &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; return generation.broken; &#125; finally &#123; lock.unlock(); &#125;&#125; 小结CyclicBarrier 和 CountDownLatch 还是有点像的，前者强调的是一组线程到达同步点即栅栏，后者强调的是阻塞在同步点的线程等待其它线程完成任务。具体区别如下： 作用不同CyclicBarrier 要等固定数量线程到达同步点，CountDownLatch 等待的不是线程而是同步状态state递减为 0。前者针对线程，后者针对事件/任务（根据需要调用 countDown 方法）。 重用性不同CyclicBarrier 可以重复使用，上一代使用完后自动初始化下一代，也可以调用 reset 方法重置。 CountDownLatch 只能使用一次，在同步状态减为 0 后门栓打开后，就不能再次使用，想要使用需要新建实例。 唤起任务数不同CyclicBarrier 只能唤醒一个任务，CountDownLatch 可以唤醒多个任务 Semaphore使用例子场景 有一些加工厂是对环境有很大污染的，如果要生产产品必须要有关机构申请生产许可证，拿到许可证后才可以生产，完成一定规模后需要归还许可证，便于其它工厂可以申请。 123456789101112131415161718192021222324252627282930313233343536@Slf4jpublic class SemaphoreDemo &#123; /** * 固定线程数线程池 */ public static ExecutorService service = Executors.newFixedThreadPool(10); public static void main(String[] args) &#123; // 有 3 个许可证书，每个加工厂公平获取。 Semaphore semaphore = new Semaphore(3, true); // 有 6 个加工厂想要获取 for (int i = 0; i &lt; 6; i++) &#123; service.submit(() -&gt; &#123; try &#123; // 获取许可证 semaphore.acquire(); log.info(\"拿到了许可证\"); // 处理任务 log.warn(\"凭借许可证处理任务...\"); Thread.sleep((long) (Math.random() * 10000)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; log.info(\"归还许可证\"); semaphore.release(); &#125; &#125;); &#125; &#125;&#125; 打印结果 123456789101112131415161718[pool-1-thread-1] INFO com.code.juc.tool.SemaphoreDemo - 拿到了许可证[pool-1-thread-1] WARN com.code.juc.tool.SemaphoreDemo - 凭借许可证处理任务...[pool-1-thread-2] INFO com.code.juc.tool.SemaphoreDemo - 拿到了许可证[pool-1-thread-2] WARN com.code.juc.tool.SemaphoreDemo - 凭借许可证处理任务...[pool-1-thread-3] INFO com.code.juc.tool.SemaphoreDemo - 拿到了许可证[pool-1-thread-3] WARN com.code.juc.tool.SemaphoreDemo - 凭借许可证处理任务...[pool-1-thread-3] INFO com.code.juc.tool.SemaphoreDemo - 归还许可证[pool-1-thread-4] INFO com.code.juc.tool.SemaphoreDemo - 拿到了许可证[pool-1-thread-4] WARN com.code.juc.tool.SemaphoreDemo - 凭借许可证处理任务...[pool-1-thread-1] INFO com.code.juc.tool.SemaphoreDemo - 归还许可证[pool-1-thread-5] INFO com.code.juc.tool.SemaphoreDemo - 拿到了许可证[pool-1-thread-5] WARN com.code.juc.tool.SemaphoreDemo - 凭借许可证处理任务...[pool-1-thread-4] INFO com.code.juc.tool.SemaphoreDemo - 归还许可证[pool-1-thread-6] INFO com.code.juc.tool.SemaphoreDemo - 拿到了许可证[pool-1-thread-6] WARN com.code.juc.tool.SemaphoreDemo - 凭借许可证处理任务...[pool-1-thread-2] INFO com.code.juc.tool.SemaphoreDemo - 归还许可证[pool-1-thread-6] INFO com.code.juc.tool.SemaphoreDemo - 归还许可证[pool-1-thread-5] INFO com.code.juc.tool.SemaphoreDemo - 归还许可证 说明 以上例子中，使用循环体和线程池模拟 6 个线程，即 6 个加工厂获取生产许可证。Semaphore 的许可证数量为 3，即监管部门目前只有 3 个生产许可证，此时 6 个工厂只能有其中三个可以获取到，另外 3 个工厂只能等待生产许可证的归还，如果不归还将一直等着。 源码分析Semaphore 是用来控制同时访问特定资源的线程数量，它通过协调各个线程来保证合理的使用有限的公共资源。Semaphore 也是对 AQS 共享模式的使用，因此套路也是一样的。它接收一个整形的数字 permits，也是 AQS 的 state，表示可用的许可证数量，即允许 permits 个线程获取许可证，也就是最大并发数是 permits。因为是共享模式的使用，因此需要重写对应的模版方法 tryAcquireShared 和 tryReleaseShared ，前者用来判断能否获取到许可证，后者用来判断能否归还许可整（总是返回true）。此外，Semaphore 在此基础上增加了公平和非公平获取同步状态的功能。Semaphore 的用法很简单，它的 acquire 方法获取许可证，release 方法归还许可证，获取不到许可证的线程就加入阻塞队列中，等待其它线程释放许可证。 类结构 前面也提到了，Semaphore 是对 AQS 共享模式的使用，并且支持公平和非公平的状态管理方式，即对同步状态 state 的操作。通过上图的 UML 类图更加清晰，Semaphore 既可以公平实现方式创建对象，又能以非公平方式创建对象。 Sync 内部类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class Semaphore implements java.io.Serializable &#123; private static final long serialVersionUID = -3222578661600680210L; /** * 继承 AQS 的内部类对象 */ private final Sync sync; /** * 信号量的同步实现。使用 AQS 的同步状态 state 表示许可证。分为 公平和非公平两种实现 */ abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = 1192457210091910933L; // 构造方法，设置 AQS 的同步状态 state。对于 Semaphore 来说表示许可证 Sync(int permits) &#123; setState(permits); &#125; // 获取同步状态，即许可证 final int getPermits() &#123; return getState(); &#125; // 非公平实现，共享式获取许可证。返回剩余许可证数量 final int nonfairTryAcquireShared(int acquires) &#123; for (; ; ) &#123; int available = getState(); // 减少 acquires 个许可证 int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125; &#125; // 重写 AQS 的共享式释放同步状态方法，即归还许可证。该方法总是返回 true protected final boolean tryReleaseShared(int releases) &#123; for (; ; ) &#123; int current = getState(); // 归还 releases 个许可证 (注意，如果不获取先释放的话，许可证会变多的) int next = current + releases; // 这里判断归还数量不能小于 0 if (next &lt; current) // overflow throw new Error(\"Maximum permit count exceeded\"); // CAS 更新 state （AQS 中的方法 ） if (compareAndSetState(current, next)) return true; &#125; &#125; // $&#123;省略其它代码&#125;&#125; Sync 内部类首先对同步状态 state 进行了初始化，先确定同步状态 state 的值，即表示的意义，这里指许可证。第二个是获取同步状态 - tryAcquireShared，这里指获取许可证，Sync 中没有进行实现而是交给了两个子类。第三个是释放同步状态 - tryReleaseShared，这里指归还许可证，Sync 中统一实现了这个逻辑。下面我们分别看下其子类实现。 NonfairSync 内部类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class Semaphore implements java.io.Serializable &#123; private static final long serialVersionUID = -3222578661600680210L; /** * 继承 AQS 的内部类对象 */ private final Sync sync; /** * 信号量的同步实现。使用 AQS 的同步状态 state 表示许可证。分为 公平和非公平两种实现 */ abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = 1192457210091910933L; // 构造方法，设置 AQS 的同步状态 state。对于 Semaphore 来说表示许可证 Sync(int permits) &#123; setState(permits); &#125; // 获取同步状态，即许可证 final int getPermits() &#123; return getState(); &#125; // 非公平实现要执行的方法，共享式获取许可证。返回剩余许可证数量 final int nonfairTryAcquireShared(int acquires) &#123; for (; ; ) &#123; int available = getState(); // 减少 acquires 个许可证 int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125; &#125; // 重写 AQS 的共享式释放同步状态方法，即归还许可证。该方法总是返回 true protected final boolean tryReleaseShared(int releases) &#123; for (; ; ) &#123; int current = getState(); // 归还 releases 个许可证 (注意，如果不获取先释放的话，许可证会变多的) int next = current + releases; // 这里判断归还数量不能小于 0 if (next &lt; current) // overflow throw new Error(\"Maximum permit count exceeded\"); // CAS 更新 state （AQS 中的方法 ） if (compareAndSetState(current, next)) return true; &#125; &#125; /** * 非公平实现 */ static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = -2694183684443567898L; // 构造方法 NonfairSync(int permits) &#123; super(permits); &#125; // 重写 AQS 的共享式获取同步状态的方法，这里是非公平方式获取许可证 protected int tryAcquireShared(int acquires) &#123; return nonfairTryAcquireShared(acquires); &#125; &#125; // $&#123;省略其它代码&#125;&#125; NonfairSync 内部类只做了一件事情，重写 AQS 的 tryAcquireShared 方法，需要注意它的非公平性，也就是不关心阻塞队列中有没有还在等待的线程，直接尝试获取许可证。 FairSync 内部类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101public class Semaphore implements java.io.Serializable &#123; private static final long serialVersionUID = -3222578661600680210L; /** * 继承 AQS 的内部类对象 */ private final Sync sync; /** * 信号量的同步实现。使用 AQS 的同步状态 state 表示许可证。分为 公平和非公平两种实现 */ abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = 1192457210091910933L; // 构造方法，设置 AQS 的同步状态 state。对于 Semaphore 来说表示许可证 Sync(int permits) &#123; setState(permits); &#125; // 获取同步状态，即许可证 final int getPermits() &#123; return getState(); &#125; // 非公平实现，共享式获取许可证。返回剩余许可证数量 final int nonfairTryAcquireShared(int acquires) &#123; for (; ; ) &#123; int available = getState(); // 减少 acquires 个许可证 int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125; &#125; // 重写 AQS 的共享式释放同步状态方法，即归还许可证。该方法总是返回 true protected final boolean tryReleaseShared(int releases) &#123; for (; ; ) &#123; int current = getState(); // 归还 releases 个许可证 (注意，如果不获取先释放的话，许可证会变多的) int next = current + releases; // 这里判断归还数量不能小于 0 if (next &lt; current) // overflow throw new Error(\"Maximum permit count exceeded\"); // CAS 更新 state （AQS 中的方法 ） if (compareAndSetState(current, next)) return true; &#125; &#125; /** * 非公平实现 */ static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = -2694183684443567898L; // 构造方法 NonfairSync(int permits) &#123; super(permits); &#125; // 重写 AQS 的共享式获取同步状态的方法，这里是非公平方式获取许可证 protected int tryAcquireShared(int acquires) &#123; return nonfairTryAcquireShared(acquires); &#125; &#125; /** * 公平实现 */ static final class FairSync extends Sync &#123; private static final long serialVersionUID = 2014338818796000944L; // 构造方法 FairSync(int permits) &#123; super(permits); &#125; // 重写 AQS 的共享式获取同步状态的方法， 这里是 公平方式获取许可证。返回剩余许可证数 protected int tryAcquireShared(int acquires) &#123; for (; ; ) &#123; // 是否有线程在排队等待许可证 if (hasQueuedPredecessors()) return -1; int available = getState(); // 减少 acquires 个许可证 int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125; &#125; &#125; // $&#123;省略其它代码&#125;&#125; FairSync 内部类同样只做了一件事情，重写 AQS 的 tryAcquireShared 方法，以公平的方式实现，也就是线程在获取许可证之前，先判断阻塞队列中是否还有等待的线程，有的话就直接返回 -1 进入阻塞队列中等待。 构造方法12345678910111213/** * 以非公平方式创建 Semaphore */ public Semaphore(int permits) &#123; sync = new NonfairSync(permits); &#125; /** * 可选择公平/非公平方式创建 Semaphore */ public Semaphore(int permits, boolean fair) &#123; sync = fair ? new FairSync(permits) : new NonfairSync(permits); &#125; 和 ReentrantLock 有点类似，实现了公平和非公平方式，默认使用非公平实现。 acquire 系列方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115--- Semaphore /** * 可响应中断地获取许可证（获取一个许可证） */ public void acquire() throws InterruptedException &#123; // AQS 的方法 sync.acquireSharedInterruptibly(1); &#125;--- AbstractQueuedSynchronizer public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); // Semaphore 实现的获取同步状态，公平还是不公平看Semaphore的具体实现 if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg); &#125; /** * Acquires in shared interruptible mode. * @param arg the acquire argument */ private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; // Semaphore 实现的获取同步状态，公平还是不公平看Semaphore的具体实现 setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125;--- Semaphore /** * 获取许可证（获取一个许可证），对中断不敏感 */ public void acquireUninterruptibly() &#123; // AQS 的方法 sync.acquireShared(1); &#125;--- AbstractQueuedSynchronizer public final void acquireShared(int arg) &#123; // Semaphore 实现的获取同步状态，公平还是不公平看Semaphore的具体实现 if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg); &#125; /** * Acquires in shared uninterruptible mode. * @param arg the acquire argument */ private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; // Semaphore 实现的获取同步状态，公平还是不公平看Semaphore的具体实现 int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; // 内部会调用 doReleaseShared 方法 setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125;--- Semaphore /** * 从 Semaphore 获取给定数量的许可证，不够就阻塞等待，对中断敏感 */ public void acquire(int permits) throws InterruptedException &#123; if (permits &lt; 0) throw new IllegalArgumentException(); sync.acquireSharedInterruptibly(permits); &#125; /** * 从 Semaphore 获取给定数量的许可证，不够就阻塞等待，对中断不敏感 */ public void acquireUninterruptibly(int permits) &#123; if (permits &lt; 0) throw new IllegalArgumentException(); sync.acquireShared(permits); &#125; 通过 acquire 方法也可以看出，AQS 框架在实现共享式获取同步状态时，当且仅当同步状态处理结果小于 0 时，线程才会走入队流程。因为都是共享式实现，AQS 底层处理是一样的，因此后续的入队、找有效前驱节点以及挂起操作和 CountDownLatch 是一样的，就不再分析了。继续看它的释放同步状态的方法。 release 系列方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546--- Semaphore /** * 归还许可证 */ public void release() &#123; // AQS 方法 sync.releaseShared(1); &#125; /** * 归还给定数量的许可证到 Semaphore */ public void release(int permits) &#123; if (permits &lt; 0) throw new IllegalArgumentException(); // AQS 方法 sync.releaseShared(permits); &#125;--- AbstractQueuedSynchronizer public final boolean releaseShared(int arg) &#123; // Semaphore 实现的释放同步状态方法 if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false; &#125; private void doReleaseShared() &#123; for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125; &#125; 通过 release 系列方法也可以看出，AQS 框架在实现共享式释放同步状态时，当且仅当同步状态处理结果为 true 时，才会唤醒阻塞队列的线程。因为都是共享式实现，AQS 底层处理是一样的，因此唤醒的流程和 CountDownLatch 是一样的。 例子流程 Semaphore 初始化 3 个 许可证同一个JVM进程中，某一时刻对 resource 访问的最大并发请求数为3 某一时刻t1、t2、t3获取到许可证，t4进入阻塞队列等待线程t1、t2、t3拿到许可证去访问资源，此时 Semaphore 中已经没有可用的许可证了，t4只能加入阻塞队列等待许可证的释放。这里 t4 要入队。 t3 访问资源后归还许可证，t4 获取到获取到许可证这个过程可能会有多种情况，如，t4 在没有挂起之前，t3 已经归还了许可证，此时 t4 直接就可以拿到。如果 t4 不太幸运的话，会挂起然后等待t3来唤醒。Semaphore 的一些特殊情况可以参考 CountDownLatch。 其它线程获取许可证依次类推 小结Semaphore 使用的注意事项： 获取和释放的许可证数量必须一致，否则随着许可证的获取和归还流程推进，最后会导致许可证数量不够，将出现程序卡死。 在初始化 Semaphore 的时候可以设置释放公平，这个可以根据情景选择，一般设置为 true 更合理，因为 Semaphore 本身就是限制同时请求量的，不针对某个请求的。 获取和释放许可证不一定非要同一个线程来完成，可以是 线程 A 获取，线程 B 释放，逻辑合理即可。 总结无论是 ReentrantLock，还是 CountDownLatch、CyclicBarrier、Semaphore 等 ，它们都是对 AQS 应用，至于是实现锁的功能，还是实现同步组件根据具体场景进行设计。本质上都离不开同步状态 state、独占方式 tryAcquire-tryRelease 获取与释放方法，共享方式 tryAcquireShared-tryReleaseShared 获取与释放方法，此外 AQS 也支持自定义同步组件同时实现独占和共享两种方式，以及公平和非公平实现，不同组件表示的意义是不同的。AQS 还提供了 等待队列 机制，ReentrantLock 就基于该机制实现了等待与唤醒机制。","categories":[{"name":"JDK","slug":"JDK","permalink":"https://gentryhuang.com/categories/JDK/"}],"tags":[{"name":"JUC","slug":"JUC","permalink":"https://gentryhuang.com/tags/JUC/"},{"name":"AQS","slug":"AQS","permalink":"https://gentryhuang.com/tags/AQS/"}]},{"title":"AQS 原理分析 - Condition实现原理","slug":"concurrent/aqs-condition","date":"2020-11-10T13:45:45.000Z","updated":"2021-08-13T04:41:20.070Z","comments":false,"path":"posts/40e44c1f/","link":"","permalink":"https://gentryhuang.com/posts/40e44c1f/","excerpt":"","text":"概述在 JUC 之前，Java 实现等待/通知模式是通过定义在 Object 中的一组监视器方法 wait方法、notify()以及 notifyAll() 与 synchronized 关键配合完成。在 JUC 中单独提供了一套等待/通知模式的实现方式，具体实现是 Condition 接口与 Lock 接口配合完成。 Condition 接口提供了类似 Object 的监视器方法，但该接口中定义的方法功能上更强大。比如，Condition 支持响应/不响应中断以及等待超时等接口。本篇文章是对 AQS 原理分析 的扩展，它是 AQS 中 ConditionObject 的相关实现。这样一来整个 AQS 就算完整了。 场景生产者-消费者是 Condition 其中的一个经典使用场景，代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;class BoundedBuffer &#123; /** * 锁 */ final Lock lock = new ReentrantLock(); /** * notFull Condition */ final Condition notFull = lock.newCondition(); /** * notEmpty Condition */ final Condition notEmpty = lock.newCondition(); /** * 数组，大小为 100 */ final Object[] items = new Object[100]; /** * 分别为添加的下标、移除的下标和数组当前数量 */ int putptr, takeptr, count; /** * 生产 * 如果数组满了，则添加线程进入等待状态，直到有空位才能生产 * * @param x item * @throws InterruptedException */ public void put(Object x) throws InterruptedException &#123; lock.lock(); try &#123; // 元素数量等于数组长度，线程等待 while (count == items.length) notFull.await(); // 添加元素 items[putptr] = x; // 添加下标 putptr 递增，和移除的下标 takeptr 对应。 if (++putptr == items.length) putptr = 0; // 数组元素个数递增 ++count; // 生产后通知消费 notEmpty.signal(); &#125; finally &#123; lock.unlock(); &#125; &#125; /** * 消费 * 如果数组为空，则消费线程进入等待状态，直到数组中有元素才能继续消费 * * @return item * @throws InterruptedException */ public Object take() throws InterruptedException &#123; lock.lock(); try &#123; // 数组为空，线程等待 while (count == 0) notEmpty.await(); // 取出元素 Object x = items[takeptr]; // 移除下标递增 if (++takeptr == items.length) takeptr = 0; // 数组元素个数递减 --count; // 消费后通知生产 notFull.signal(); return x; &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; 上述示例中，BoundedBuffer 实现了生产者-消费者模式，下面进行简单概述： 使用 Condition 时先获取相应的 Lock 锁，和 Object 类中的方法类似，需要先获取某个对象的监视器锁才能执行等待、通知方法。 生产和消费方法中判断数组状态使用的是 while 自旋而非 if 判断，目的是防止过早或意外的通知，当且仅当条件满足才能从 await() 返回。 实现原理Condition 结合 Lock 实现的等待通知机制包括两部分内容即等待和通知，分别依赖单向链表和双向链表。Condition 接口的实现类是 AQS 内部类 ConditionObject，它内部维护的队列称为条件队列，基于单向链表实现。Lock 是基于 AQS 实现的，它内部维护的队列称为同步队列，基于双向链表实现。Condition 对象是由 Lock 对象创建出来的，并且一个 Lock 对象可以创建多个 Condition 对象，每个 Condition 对象共享 Lock 这个外部资源。 获取到同步状态（锁）的线程调用 await 方法进行等待时，会先将自己打包成一个节点并加入到对应的条件队列中，加入成功后会完全释放同步状态，释放同步状态成功后会在该条件队列的尾部等待，于此同时该线程在同步队列中的节点也会被移除。在某个 Condition 上（条件队列）等待的线程节点被signal 或 signalAll 后，对应的线程节点会被转到外部类的同步队列中，这意味着该节点有了竞争同步状态的机会，线程需要获取到同步状态才能继续后续的逻辑。需要说明的是，一个锁对象可以同时创建 N 个 Condition 对象（对应 N 个条件队列），这表明获取到同步状态的线程可以有选择地加入条件队列并在该队列中等待，其它获取到同步状态的线程可以有选择地唤醒某个条件队列中的等待的线程。但不管有多少个条件队列，竞争同步状态的线程节点需要统一转到外部类的同步队列中，也就是 Lock 维护的双向链表，此后就是竞争同步状态的逻辑了。 下图简单描述了 Condition 的工作原理： 以上就是 Condition 实现的等待-通知机制。需要说明的是，上述描述没有涉及过多的细节，如异常流的处理。接下来我们通过对代码层面的解析来全面了解 Condition 的机制。 源码解析Condition Condition 接口中定义的方法和 Object 中的监视器方法类似，区别在于前者支持响应中断和超时等待。下面对该接口中定义的方法进行简单说明： void await() throws InterruptedException 方法 响应中断的等待方法，线程进入条件队列挂起，直到被通知或中断。 void awaitUninterruptibly() 方法 不响应中断的等待方法，不会抛出中断异常，仅仅复位中断标志，线程进入条件队列挂起，直到被通知或中断。 long awaitNanos(long nanosTimeout) throws InterruptedException 方法 在 await() 基础上增加了超时功能，线程进入条件队列挂起直到被通知、中断或超时，如果在 nanosTimeout 内返回，那么返回值就是 nanosTimeout - 实际耗时，如果返回值是 0 或者负数，表示超时了。 boolean awaitUntil(Date deadline) throws InterruptedException 方法 在 await() 基础上增加了超时功能，线程进入条件队列挂起直到被通知、中断或者到某个时间。如果没有到指定时间就通知，返回 true，否则表示超时。 boolean await(long time, TimeUnit unit) throws InterruptedException 方法 和 awaitUntil(Date deadline) 方法几乎一致，前者是绝对时间，后者是时间粒度。 void signal() 方法 将条件队列中的头节点转到同步队列中，以等待竞争同步状态。 void signalAll() 方法 将条件队列中的所有节点依次转到同步队列中，以等待竞争同步状态。此时条件队列进入下一个周期。 在 JUC 中 Condition 主要基于 ReentrantLock 和 ReentrantReadWriteLock 实现的，在语义中就是我们说的锁概念，而锁又是基于 AQS 实现的。总的来说，Condition 依赖 Lock，Lock 实现是基于 AQS 的。下面以 ReentrantLock 作为 Condition 的实现进行说明。 ConditionObjectConditionObject实现了 Condition 接口，同时作为AbstractQueuedSynchronizer的内部类，因为 Condition 的操作需要获取到同步状态，因此其实现类作为AbstractQueuedSynchronizer的内部类是比较合理的，这意味着ConditionObject可以访问外部资源。 12345678910111213141516171819+--- AbstractQueuedSynchronizer public class ConditionObject implements Condition, java.io.Serializable &#123; private static final long serialVersionUID = 1173984872572414699L; /** * 条件队列 - 头节点 */ private transient Node firstWaiter; /** * 条件队列 - 尾节点 */ private transient Node lastWaiter; /** * Creates a new &#123;@code ConditionObject&#125; instance. */ public ConditionObject() &#123; &#125; // $&#123;省略其它代码&#125;&#125; 每个 ConditionObject 对象内部维护了一个基于单向链表的条件队列，该队列是 Condition 实现等待-通知机制的关键。既然是链表，其中的节点定义是什么呢？ConditionObject 没有重新定义链表节点，而是直接使用外部类 AbstractQueuedSynchronizer 定义的 Node ，这也是合理的。下面我们简单看下该 Node 的定义。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647+--- AbstractQueuedSynchronizer static final class Node &#123; /** * 共享类型节点，表明节点在共享模式下等待 */ static final Node SHARED = new Node(); /** * 独占类型节点，表明节点在独占模式下等待 */ static final Node EXCLUSIVE = null; /** * 等待状态 - 取消（线程已经取消） */ static final int CANCELLED = 1; /** * 等待状态 - 通知（后继线程需要被唤醒） */ static final int SIGNAL = -1; /** * 等待状态 - 条件等待（线程在 Condition 上等待） */ static final int CONDITION = -2; /** * 等待状态 - 传播（无条件向后传播唤醒动作） */ static final int PROPAGATE = -3; /** * 等待状态，初始值为 0 */ volatile int waitStatus; /** * 同步队列中使用，前驱节点 */ volatile Node prev; /** * 同步队列中使用，后继节点 */ volatile Node next; /** * 节点中封装的线程 */ volatile Thread thread; /** * 条件队列中使用，后置节点 */ Node nextWaiter; &#125; 条件队列和同步队列共同使用上述的 Node 节点构建队列，区别在于前者底层数据结构是双向链表，节点的维护使用 prev 和 next 属性，后者底层数据结构是单向链表，节点维护使用 nextWaiter 属性，两者中的节点等待状态都是使用 waitStatus 属性。 ReentrantLock 对象和 ReentrantReadWriteLock 对象可以创建多个 ConditionObject 对象，代码如下： 123final ConditionObject newCondition() &#123; return new ConditionObject(); &#125; 下面对 ReentrantLock 和 ConditionObject 的关联关系进行说明： ConditionObject 维护的条件队列和 ReentrantLock 维护的同步队列的节点都是 Node 的实例，条件队列的线程节点需要移动到同步队列中以参与竞争同步状态。 ReentrantLock 对象与 ConditionObject 对象的比例关系为： 1 : N ，每个 ConditionObject 都能直接访问 ReentrantLock 这个外部类资源。 一个同步队列对应 N 个条件队列，同步队列中的线程（获取到同步状态）可以选择性地进入不同的条件队列进行等待，而多个条件队列中的线程节点要参与竞争同步状态就需要进入同一个同步队列。 接下来对等待和通知的核心代码进行分析，根据主要流程分别说明。 等待ConditionObject 中实现了几种不同功能的等待方法，在介绍 Condition 接口时已经详细说明，下面先对 await() 的方法实现进行分析。 当获取同步状态的线程调用 await() 方法时，相当于同步队列的头节点中的线程（获取了同步状态的节点）进入到 Condition 的条件队列中，完全释放同步状态后同步队列将会移除该线程对应的节点。需要说明的是，下图中的第 2 步中释放同步状态失败的情况是针对没有获取到同步状态就执行 await 方法的情况，获取到同步状态的线程在释放状态的时候一般是不会出释放同步状态失败的情况。值得一提的是，同步队列中头节点的线程是先释放同步状态然后才会占领头节点进而去唤醒后继等待的线程，也就是同步队列中的头节点就是供持有同步状态的线程占领，进而唤醒后继等待线程。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253+--- ConditionObject public final void await() throws InterruptedException &#123; // 响应中断 if (Thread.interrupted()) throw new InterruptedException(); //1. 将当前线程封装到节点中，并将节点加入到条件队列尾部 Node node = addConditionWaiter(); //2. 保存并完全释放同步状态，注意是完全释放，因为允许可重入锁。如果没有持锁会抛出异常，也就是释放同步状态失败 int savedState = fullyRelease(node); // 记录中断模式 int interruptMode = 0; /** *3. 判断上述加入到条件队列的线程节点是否被移动到了同步队列中，不在则挂起线程（曾经获取到锁的线程）。 * * 循环结束的条件： * 1. 其它线程调用 signal/signalAll 方法，将当前线程节点移动到同步队列中，节点对应的线程将会在竞争同步状态的过程被前驱节点唤醒。 * 2. 其它线程中断了当前线程，当前线程会自行尝试进入同步队列中。 */ while (!isOnSyncQueue(node)) &#123; // 挂起线程，直到被唤醒或被中断 LockSupport.park(this); /** * 检测中断模式： * 在线程从 park 中返回时，需要判断是被唤醒返回还是被中断返回。 * 1). 如果线程没有被中断，则返回 0，此时需要重试循环继续判断当前线程节点是否在同步队列中。 * 2). 如果线程被中断 * - 中断发生在被唤醒之前，当前线程（线程节点）会尝试自行进入同步队列并返回 THROW_IE，后续需要抛出中断异常。todo * - 中断发生在被唤醒之后，即当前线程（线程节点）尝试自行进入同步队列失败（说明其它线程调用过了 signal/signalAll 唤醒线程并尝试将线程节点转到同步队列）， * 返回 REINTERRUPT ，后续需要重新中断线程，向后传递中断标志。 */ if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; //4. 醒来后，被移动到同步队列的节点 node 重新尝试获取同步状态成功，且获取同步状态的过程中如果被中断，接着判断中断模式非 THROW_IE 的情况会更新为 REINTERRUPT if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; //5. 清理取消节点。正常情况下 signal/signalAll 将节点转到同步队列的同时会将节点的 nextWaiter 置空，这里主要对自行进入到同步队列中的节点进行处理。 // 1） 中断模式为 THROW_IE 的情况下 nextWaiter 不会被置空，且等待状态为 0 ，这种情况下节点应该从条件队列中移除。 // 2） fullyRelease 方法出现异常，nextWaiter 不会被置空，且等待状态为 CANCELLED，清理任务会由后继的节点完成。 if (node.nextWaiter != null) // clean up if cancelled // 清理条件队列中取消的节点（重组链表） unlinkCancelledWaiters(); //6. 如果线程发生过中断则根据 THROW_IE 或 REINTERRUPT 分别抛出异常或者重新中断。 todo 最终都要抛出异常还获取个球球的锁 if (interruptMode != 0) reportInterruptAfterWait(interruptMode); &#125; 下面对上述整个等待流程进行概述： 将获取到同步状态的线程封装到节点中并加入到条件队列。 完全释放同步状态，并记录获取到的同步状态，为后面重新竞争同步状态做准备。 在条件队列中等待被唤醒，或者被中断。 再次竞争挂起等待前的同步状态。 对中断情况的处理，抛出异常或重新中断线程以复位中断标志。 以上对整个等待流程进行了总体描述，需要注意的是，当线程从await()方法返回时，当前线程一定获取了Condition相关联的锁。下面对其中的分支流进行说明。 addConditionWaiter将当前线程封装到节点中，然后加入到当前 Condition 对象维护的条件队列的尾部。 1234567891011121314151617181920212223242526272829+--- ConditionObjectprivate Node addConditionWaiter() &#123; // 条件队列尾节点 Node t = lastWaiter; // 选出条件队列中有效尾节点。这里主要处理 fullyRelease 方法出现异常的情况。 if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; // 如果需要，清理条件队列中取消的节点（重组链表） unlinkCancelledWaiters(); // 重读尾节点，可能为 null t = lastWaiter; &#125; // 创建节点封装当前线程，节点状态为 CONDITION Node node = new Node(Thread.currentThread(), Node.CONDITION); // 初始化条件队列，firstWaiter 更新为当前节点 if (t == null) firstWaiter = node; // 将当前节点加入到条件队列尾 else t.nextWaiter = node; // 更新条件队列尾指针指向 lastWaiter = node; // 返回当前线程关联的节点 return node;&#125; 特别说明： addConditionWaiter() 方法不一定是线程安全的，没有获取到锁就调用 await 方法就是不安全操作。虽然没有获取到锁的线程执行 await 方法最终会抛出异常，遗留在条件队列的节点也会被后继节点清理，但是如果持锁和不持锁的两个线程同时调用 await 方法就可能会产生并发问题，使 ConditionObject 维护的条件队列中节点产生覆盖，这是一种破坏行为，最终会导致有些成功调用 await 方法的线程可能永远没有办法被唤醒(非正常唤醒除外，如中断)，更没有机会再次获取锁，因为条件队列中并没有记录它们，记录的是非法调用的线程节点。 上述过程涉及到清理无效节点的逻辑，该逻辑由 unlinkCancelledWaiters() 方法完成，下面我们来分析该方法。 unlinkCancelledWaiters1234567891011121314151617181920212223242526272829303132333435363738394041424344454647+--- ConditionObject private void unlinkCancelledWaiters() &#123; // 从首节点开始进行节点检测 Node t = firstWaiter; // 记录上一个非取消状态节点，参照节点是当前遍历节点 Node trail = null; // 遍历链表 while (t != null) &#123; // 保存当前节点的下一个节点，在当前节点处于取消状态时进行替换 Node next = t.nextWaiter; // 如果节点的等待状态不是 CONDITION，表明这个节点被取消了。 if (t.waitStatus != Node.CONDITION) &#123; // 取消状态的节点要断开和链表的关联 t.nextWaiter = null; /** * 重组链表，保证链条为空或者所有节点都是非取消状态 * * trail == null，表明 next 之前的节点的等待状态均为取消状态，此时更新 firstWaiter 引用指向 * trail != null，表明 next 之前有节点的等待状态为 CONDITION ，此时只需 trail.nextWaiter 指向 next 节点 * 注意： * 1 firstWaiter 一定指向链表第一个非取消节点，或者为 null * 2 trail 第一次赋值的话一定和 firstWaiter 一样的值 * 3 firstWaiter 一旦被赋予非 null 的值后就不会再变动，后续的节点连接就看 trail 的表演： * - 如果当前节点是取消节点，就 trail.nextWaiter 指向 next 节点 * - 如果当前节点是非取消节点，trail 跟着节点走 */ if (trail == null) firstWaiter = next; else trail.nextWaiter = next; // 当前节点没有后继则遍历结束，此时当前节点是无效节点，因此将 lastWaiter 回退即更新为上一个非取消节点 if (next == null) lastWaiter = trail; // 当前节点处于等待状态 &#125; else trail = t; // 下一个节点 t = next; &#125; &#125; unlinkCancelledWaiters() 方法用于清理取消节点，重新构造链表，主要处理因中断自行加入同步队列和释放同步状态异常的情况。取消节点的定义是线程节点挂起时被中断或释放同步状态失败。 线程节点加入到条件队列后就可以执行完全释放同步状态操作，下面我们看具体的逻辑。 fullyRelease1234567891011121314151617181920212223+--- AbstractQueuedSynchronizer final int fullyRelease(Node node) &#123; boolean failed = true; try &#123; // 获取同步状态（拿到同步状态的线程） int savedState = getState(); // 释放指定数量的同步状态 // java.util.concurrent.locks.ReentrantLock.Sync.tryRelease ，没有持有锁会抛出异常 if (release(savedState)) &#123; failed = false; // 返回同步状态，释放之前的值 return savedState; &#125; else &#123; throw new IllegalMonitorStateException(); &#125; &#125; finally &#123; // 释放同步状态失败，需要将节点状态设置为取消状态，后续会被清理 if (failed) node.waitStatus = Node.CANCELLED; &#125; &#125; 该方法用于完全释放同步状态，属于 AbstractQueuedSynchronizer 中定义的方法，上文也提到 ConditionObject 是 AbstractQueuedSynchronizer 的内部类，因此可以共享外部资源。注意，该方法是完全释放同步状态，一般情况下为了避免死锁的产生，锁的实现上一般支持重入功能。 需要特别说明的是，如果线程没有获取到同步状态就执行 await() 方法，该线程关联的节点能进入到条件队列中，但是进入条件队列后需要调用 fullyRelease 方法执行同步状态释放逻辑，由于没有获取到同步状态在执行到 ReentrantLock.tryRelease 方法时会抛出异常，进而 finally 块中将节点状态进行更新 node.waitStatus = Node.CANCELLED ，这个已经入队到条件队列的节点会被后续节点清理出去，也即执行 unlinkCancelledWaiters 方法。 释放持有的同步状态后会进入自旋等待逻辑，该过程会对通知和中断进行不同的处理。 等待转入同步队列12345678910111213141516171819+--- ConditionObject while (!isOnSyncQueue(node)) &#123; // 挂起线程，直到被唤醒或被中断 LockSupport.park(this); /** * 检测中断模式： * 在线程从 park 中返回时，需要判断是被唤醒返回还是被中断返回。 * 1. 如果线程没有被中断，则返回 0，此时需要重试循环继续判断当前线程节点是否在同步队列中。 * 2. 如果线程被中断 * - 中断发生在被唤醒之前，当前线程（线程节点）会尝试自行进入同步队列并返回 THROW_IE，后续需要抛出中断异常。 * - 中断发生在被唤醒之后，即当前线程（线程节点）尝试自行进入同步队列失败（说明其它线程调用过了 signal/signalAll 唤醒线程并尝试将线程节点转到同步队列）， * 返回 REINTERRUPT ，后续需要重新中断线程，向后传递中断标志，由后续代码去处理中断。 * */ if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; 以上自旋等待逻辑主要包括两部分工作，检查节点是否在同步队列中和处理中断。下面我们分别来看这两个逻辑。 isOnSyncQueue检查节点是否已经转到同步队列中。 12345678910111213141516171819202122232425262728293031323334353637383940+--- AbstractQueuedSynchronizer final boolean isOnSyncQueue(Node node) &#123; /** * 1 同步队列中的节点状态可能为 0、SIGNAL = -1、PROPAGATE = -3、CANCELLED = 1，但不会是 CONDITION = -2 * 2 node.prev 仅会在节点获取同步状态后，调用 setHead 方法将自己设为头结点时被设置为 null，所以只要节点在同步队列中，node.prev 一定不会为 null */ if (node.waitStatus == Node.CONDITION || node.prev == null) return false; /** * 1 条件队列中节点是使用 nextWaiter 指向后继节点，next 均为 null 。同步队列中节点是使用 next 指向后继节点。 * 2 node.next != null 代表当前节点 node 一定在同步队列中。 */ if (node.next != null) // If has successor, it must be on queue return true; /** * node.next == null 也不能说明节点 node 一定不在同步队列中，因为同步队列入队方法不是同步的而是自旋方式， * 是先设置 node.prev，后设置 node.next，CAS 失败时 node 可能已经在同步队列上了，所以这里还需要进一步查找。 */ return findNodeFromTail(node); &#125; /** * 从同步队列尾部开始搜索，查找是否存在 node 节点。 * 为什么不从头开始搜索？因为节点的 prev 可能会为 null * * @return true if present */ private boolean findNodeFromTail(Node node) &#123; Node t = tail; for (; ; ) &#123; if (t == node) return true; if (t == null) return false; t = t.prev; &#125; &#125; checkInterruptWhileWaiting检查在线程挂起期间是否发生中断，若发生中断则需要进行特殊处理，即尝试自行进入同步队列中。 123456+--- ConditionObject private int checkInterruptWhileWaiting(Node node) &#123; return Thread.interrupted() ? (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) : 0; &#125; 方法逻辑如下： 线程未被中断，则返回 0 线程被中断且自行入同步队列成功，则返回 THROW_IE，这种情况下后续需要抛出中断异常 线程被中断且未能自行入同步队列（其它线程已经执行 signal/signalAll 方法，节点状态已被更改），则返回 REINTERRUPT ，这种情况下后续需要重新中断线程以恢复中断标志 transferAfterCancelledWait取消等待（中断）后的转移节点操作，即线程被中断优先尝试自行加入同步队列，如果在中断之前已经执行过加入操作就等待加入同步队列完成。 注意： 由于中断尝试自行加入同步队列的线程节点并没有与条件队列断开连接，该节点会在后续的逻辑中进行清除。 即使发生了中断，节点依然会转到到同步队列中。 123456789101112131415161718192021+--- ConditionObject final boolean transferAfterCancelledWait(Node node) &#123; // 中断如果发生在 节点被转到同步队列前，应该尝试自行将节点转到同步队列中，并返回 true if (compareAndSetWaitStatus(node, Node.CONDITION, 0)) &#123; // 将节点转到同步队列中 enq(node); return true; &#125; /** * 1. 如果上面的CAS失败，则表明已经有线程调用 signal/signalAll 方法更新过节点状态（CONDITION -&gt; 0 ），并调用 enq 方法尝试将节点转到同步队列中。 * 2. 这里使用 while 进行判断节点是否已经在同步队列上的原因是，signal/signalAll 方法可能仅设置了等待状态，还没有完成将线程节点转到同步队列中，所以这里用自旋的 * 方式等待线程节点加入到同步队列，否则会影响后续重新获取同步状态（调用 acquireQueued() 方法，该方法需要线程节点入同步队列才能调用，否则会抛出np异常）。这种情况表明了中断发生在节点被转移到同步队列期间。 */ while (!isOnSyncQueue(node)) // 让出 CPU Thread.yield(); // 中断在节点被转到同步队列期间或之后发生，返回 false return false; &#125; 判断中断发生的时机： 中断在节点被转到同步队列前发生，此时返回 true 中断在节点被转到同步队列过程或之后发生，此时返回 false 通知在解析通知源码之前我们先回到线程挂起等待源码处，如下： 123456789+--- ConditionObject while (!isOnSyncQueue(node)) &#123; // 挂起线程，直到被唤醒或被中断 LockSupport.park(this); // 有中断情况，进进行处理 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; 线程释放同步状态成功后会挂起等待其它线程唤醒自己（同步队列中的线程节点），或者被其它线程中断。关于线程挂起等待时被中断的处理逻辑前文已经解析，主要是确保被中断的线程也能加入到同步队列中。下图对通知流程进行了简单地描述。 下面对通知流程进行说明： 将条件队列中头节点转到同步队列中。 根据情况决定是否唤醒对应的线程，不唤醒则在同步队列中等待，唤醒则准备竞争同步状态。 下面我们解析正常通知逻辑。 通知单个节点123456789101112131415161718192021222324252627282930+--- ConditionObject /** * 将条件队列中的头节点转到同步队列中 */ public final void signal() &#123; // 检查线程是否获取了独占锁，未获取独占锁调用 signal 方法是不合法的 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); // 条件队列的头节点 Node first = firstWaiter; // 将条件队列的头节点转到同步队列中 if (first != null) doSignal(first); &#125; private void doSignal(Node first) &#123; do &#123; // 因为条件队列的 firstWaiter 要出队转到同步队列中，因此使用 firstWaiter 后继节点占领 firstWaiter。 if ((firstWaiter = first.nextWaiter) == null) // 只有一个节点的话，尾节点指向设置为 null lastWaiter = null; // 断开 first 与条件队列的连接 first.nextWaiter = null; // 调用 transferForSignal 方法将节点移到同步队列中，如果转到同步队列失败，则对后面的节点进行操作，依次类推 &#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null); &#125; 通知所有节点1234567891011121314151617181920212223242526272829+--- ConditionObject public final void signalAll() &#123; // 检查线程是否获取了独占锁，未获取独占锁调用 signalAll 方法是不合法的 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); // 条件队列的头节点 Node first = firstWaiter; if (first != null) doSignalAll(first); &#125; private void doSignalAll(Node first) &#123; // 置空条件队列的头、尾指针，因为当前队列元素要全部出队，避免将新入队的节点误唤醒 lastWaiter = firstWaiter = null; // 将条件队列中所有的节点都转到同步队列中。 do &#123; Node next = first.nextWaiter; // 将节点从条件队列中移除 first.nextWaiter = null; // 将节点转到同步队列中 transferForSignal(first); first = next; &#125; while (first != null); &#125; 加入同步队列12345678910111213141516171819202122232425 final boolean transferForSignal(Node node) &#123; /** * 如果更新节点的等待状态由 CONDITION 到 0 失败，则说明该节点已经被取消（如被中断），也就不需要再转到同步队列中了。 * 由于整个 signal /signalAll 都需要拿到锁才能执行，因此这里不存在线程竞争的问题。 */ if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; // 调用 enq 方法将 node 加入到同步队列中尾，并返回 node 的前驱节点 Node p = enq(node); // 获取前驱节点的等待状态 int ws = p.waitStatus; /** * 1 如果前驱节点的等待状态 ws &gt; 0，说明前驱节点已经被取消了，此时应该唤醒 node 对应的线程去尝试获取同步状态，准确的应该是先找大哥，找大哥过程会剔除它的无效前驱节点。 * 注意，这里只是入队并没有执行剔除取消节点的逻辑，虽然AQS唤醒操作支持从尾节点向前寻找最前的有效节点并唤醒，但还是应该主动唤醒 node 对应的线程，以更新大哥节点。 * 2 如果前驱节点的等待状态 ws &lt;= 0 ，通过 CAS 操作将 node 的前驱节点 p 的等待状态设置为 SIGNAL，当节点 p 释放同步状态后会唤醒它的后继节点 node。 * 如果 CAS 设置失败（可能节点 p 在此期间被取消了），则应该立即唤醒 node 节点对应的线程，原因和 1 一致。 */ if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true;&#125; 加入同步队列主要逻辑如下： 由于执行 signal/signalAll 方法需要持有同步状态，因此 transferForSignal 方法是不存在并发问题的。 对条件队列中的非 CONDITION 状态的节点不执行转入同步队列操作。 将符合条件的节点加入到同步队列中，并返回前驱节点。 正常情况下不会执行 LockSupport.unpark(node.thread) 唤醒线程，而是节点进入同步队列然后方法返回 true，transferForSignal 方法结束。 同步队列中 node 的前驱节点取消等待，或者 CAS 等待状态失败，需要唤醒线程，这个属于异常流。 注意，执行 signal 或 signalAll 方法仅仅让线程节点具备竞争同步状态的机会，确切地说是将条件队列的节点移动到同步队列中，仅此而已。至于能不能获取到同步状态需要看具体竞争结果，要知道不仅条件队列中线程节点阻塞等待，同步队列中可能也有大量的线程节点在等待唤醒，况且条件队列中的线程节点需要移动到同步队列中才有资格参与同步状态的竞争。 通过下面的伪代码可以推演出多种可能情况： 1234567891011121314151617181920212223// 默认使用的是非公平锁，意味着即使同步队列中有等待唤醒的节点，锁还是有可能被其它线程获取。ReentrantLock lock = new ReentrantLock();Condition condition = lock.newCondition();public void await() throws InterruptedException &#123; lock.lock(); try &#123; // business condition.await(); &#125; finally &#123; lock.unlock(); &#125;&#125;public void signal() &#123; lock.lock(); try &#123; // business condition.signal(); &#125; finally &#123; lock.unlock(); &#125;&#125; 从等待中醒来线程节点移动到同步队列后被唤醒，线程从等待中醒来，继续从 LockSupport.park(this) 向后执行。 12345678+--- ConditionObject while (!isOnSyncQueue(node)) &#123; // 挂起线程，直到被唤醒或被中断 LockSupport.park(this); // 检测中断模式 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; 检查中断模式线程从挂起返回后会检查中断状态，检查中断逻辑前文已经说明，这里不再重复介绍。 以下情况会使 LockSupport.park(this) 返回： 线程节点被同步队列中其它节点唤醒，不仅仅是它的前驱节点，还可能是头节点（头节点线程进行 signal 时，线程节点的前驱节点取消了或更新前驱节点状态失败）。 线程在挂起时被中断。 虚假唤醒，和 Object.wait() 存在同样的问题，一般使用自旋避免。 竞争同步状态线程节点转入同步队列后，就可以尝试竞争同步状态了，注意预获取同步状态是之前释放锁前的值，代码如下： 123//醒来后，被移动到同步队列的节点 node 重新尝试获取同步状态成功，且获取同步状态的过程中如果被中断，接着判断中断模式非 THROW_IE 的情况会更新为 REINTERRUPTif (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; 这里回到了竞争同步状态的逻辑，获取到同步状态则继续向后执行，也意味着可以从 await 方法返回，没能获取到同步状态则继续在同步队列中等待。 处理中断1234567private void reportInterruptAfterWait(int interruptMode)throws InterruptedException &#123; if (interruptMode == THROW_IE) throw new InterruptedException(); else if (interruptMode == REINTERRUPT) // 中断线程，复位中断标志 selfInterrupt(); &#125; await() 方法返回之前会对中断进行处理，因为它支持响应中断，关于中断模式前文已经说明，会对被中断的线程进行特殊处理，保证被中断的线程也要转到同步队列中。 超时等待这里以超时时间粒度的等待方法为例简单介绍超时等待。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public final long awaitNanos(long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); // 加入条件队列 Node node = addConditionWaiter(); // 完全释放同步状态 int savedState = fullyRelease(node); // 过期时间 final long deadline = System.nanoTime() + nanosTimeout; // 中断模式 int interruptMode = 0; // 超时的话，自行转入到同步队列 while (!isOnSyncQueue(node)) &#123; // 超时时间到，跳出自旋等待 if (nanosTimeout &lt;= 0L) &#123; transferAfterCancelledWait(node); break; &#125; // 自旋还是挂起 if (nanosTimeout &gt;= spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); // 检查中断模式 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; // 计算超时时间 nanosTimeout = deadline - System.nanoTime(); &#125; // 竞争同步状态 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); return deadline - System.nanoTime();&#125; 超时等待是在 await() 方法的基础上增加了等待的超时时间，如果超过超时时间则不再等待其它线程唤醒，自行加入到同步队列中并退出自旋等待，然后尝试竞争同步状态。 忽略中断1234567891011121314151617181920public final void awaitUninterruptibly() &#123; // 加入条件队列 Node node = addConditionWaiter(); // 完全释放同步状态 int savedState = fullyRelease(node); // 中断模式 boolean interrupted = false; // 自旋等待 while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if (Thread.interrupted()) interrupted = true; &#125; // 竞争同步状态 if (acquireQueued(node, savedState) || interrupted) // 发生中断需要复位中断标志 selfInterrupt();&#125; 该方法和 await() 方法最大的区别是对中断不做特别处理，如果有中断发生复位中断标志即可，不会抛出中断异常。 其它和对象监视器的联系 Condition 定义的方法和对象监视器方法类似。 对象监视器方法需要和 synchronized 关键字一起使用，且必须先拿到锁才能执行监视器方法。Condition 对象需要和 Lock 对象绑定，同样需要先获取到锁才能执行 Condition 的方法。 和对象监视器的区别 Condition 接口中定义的方法功能更加完善，如忽略中断、等待超时。 Condition 是代码层面上的实现，对象监视器是JVM指令层面上的实现。 Condition 与 Lock 结合拥有一个同步队列和多个条件队列，而对象监视器模型上有一个同步队列和一个条件队列。 Condition 支持唤醒特定线程，对象监视器方法唤醒线程是随机的。","categories":[{"name":"JDK","slug":"JDK","permalink":"https://gentryhuang.com/categories/JDK/"}],"tags":[{"name":"JUC","slug":"JUC","permalink":"https://gentryhuang.com/tags/JUC/"},{"name":"AQS","slug":"AQS","permalink":"https://gentryhuang.com/tags/AQS/"}]},{"title":"AQS 原理分析","slug":"concurrent/aqs-base","date":"2020-10-28T11:10:01.000Z","updated":"2021-08-21T09:37:13.551Z","comments":false,"path":"posts/5144880e/","link":"","permalink":"https://gentryhuang.com/posts/5144880e/","excerpt":"","text":"前言Java 中的很多同步类，如 ReentrantLock、CountDownLatch 等都是基于 AbstractQueuedSynchronizer（简称为AQS）实现的。AQS 是一种提供原子式管理同步状态、阻塞和唤醒线程功能以及维护队列模型的抽象框架，用来构建锁或者其他同步组件。本篇文章将重点介绍 AQS 框架的实现原理，围绕独占模式和共享模式对同步状态的获取、释放，以及入队阻塞和唤醒出队流程展开说明。 概述AQS 框架的整体架构图如下图所示： AQS 框架大致分为上图中的五层，自上而下由浅入深，从 AQS 对外暴露的 API 到底层基础实现。AQS 设计基于模版方法模式，当需要自定义同步组件时，开发者只需要继承 AQS 并根据具体模式重写对应的 API 层方法，无需关注底层具体实现。当同步组件获取或释放同步状态时，AQS 模版方法会调用开发者重写的同步状态管理方法。 实现思路AQS 内部维护了一个双向链表作为同步队列来管理线程节点。线程会首先尝试获取同步状态，如果获取成功则将当前线程设置为有效的工作线程。如果获取失败则将当前线程以及等待状态等信息封装成一个线程节点加入到同步队列中。接着会不断循环尝试获取同步状态（当前节点是队列头节点直接后继节点才会尝试），如果失败则阻塞挂起自己，直至被唤醒或中断。当持有同步状态的线程完全释放同步状态时，会唤醒队列中的后继节点。 AQS 实现过程如下图所示： AQS 使用一个 volatitle 修饰的 int 类型的成员变量来表示同步状态，通过内部维护的同步队列来完成同步状态获取的排队工作。 主要工作AQS 框架主要的工作体现在 同步状态的管理、线程的阻塞和唤醒 以及 同步队列的维护 ，这三个任务都是基于同步状态的变化而流转的。 工作模式AQS 支持共享模式 SHARED 和独占模式 EXCLUSIVE，具体实现哪种模式需要根据具体的同步组件功能而定。AQS 的设计是基于模版方法模式的，共享模式和独占模式各有一套自己固有的流程，动态变化的是交给具体同步组件实现获取同步状态的出口方法逻辑，模版方法的好处就体现出来了，AQS 内部方法会根据执行步骤调用重写的入口方法。 同步状态 方法名 描述 protected final int getState() 获取 state的值 protected final void setState(int newState) 设置 state的值 protected final boolean compareAndSetState(int expect, int update) 使用 CAS 方式更新 state 基于 AQS 实现的同步组件，会实现它的出口方法来管理同步状态，每一种同步组件的同步状态 state 表示的语义是不一样的。而在出口方法中需要根据具体语义对同步状态进行更改，这时就需要使用 AQS 提供的以上三个方法。同步状态的变化影响着线程的阻塞入队和唤醒出队。需要注意的是，以上操作同步状态的方法都无法重写，只能内部使用。 出口方法AQS 提供了大量用于自定义同步组件的出口方法，也就是 AQS 模版中的勾子方法。自定义同步组件需要按需实现以下方法： 方法名 描述 protected boolean tryAcquire(int arg) 独占模式。尝试获取 arg 个同步状态，成功则返回 true ，失败则返回 false protected boolean tryRelease(int arg) 独占模式。尝试释放 arg 个同步状态，成功则返回 true ，失败则返回 false protected int tryAcquireShared(int arg) 共享模式。尝试获取 arg 个同步状态，负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源 protected boolean tryReleaseShared(int arg) 共享模式。尝试释放 arg 个同步状态，如果释放后允许唤醒后续等待结点返回True，否则返回False protected boolean isHeldExclusively() 当前线程是否正在独占资源，只有用到Condition才需要去实现它 一般来说，同步组件要么是独占模式，要么是共享模式，独占模式只需实现 tryAcquire-tryRelease，共享模式只需实现 tryAcquireShared-tryReleaseShared。当然 AQS 也支持同时实现独占和共享两种模式，如 ReentrantReadWriteLock 读写锁，而 ReentrantLock 是独占锁，因此需要实现 tryAcquire-tryRelease 。 模版方法AQS 内部将同步状态的管理以模版方法模式封装好了，前文介绍的出口方法是交给具体子类实现的钩子方法，下面列举的核心方法是模版中共用的方法。 方法名 描述 public final void acquire(int arg) 获取独占同步状态，忽略中断。会调用 tryAcquire(arg) 方法，如果未获取成功，则会进入同步队列等待 public final void acquireInterruptibly(int arg) 响应中断版本的 acquire public final boolean tryAcquireNanos(int arg, long nanosTimeout) 响应中断 + 超时版本的 acquire public final void acquireShared(int arg) 获取共享同步状态，忽略中断。会调用 tryAcquireShared 方法，如果获取失败，则会进入同步队列等待 public final void acquireSharedInterruptibly(int arg) 响应中断版本的 acquireShared public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout) 响应中断 + 超时版本的 acquireShared public final boolean release(int arg) 释放独占模式的同步状态 public final boolean releaseShared(int arg) 释放共享模式的同步状态 源码分析属性1234567891011121314151617181920212223242526272829303132333435363738394041public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable &#123; private static final long serialVersionUID = 7373984972572414691L; /** * Creates a new &#123;@code AbstractQueuedSynchronizer&#125; instance * with initial synchronization state of zero. */ protected AbstractQueuedSynchronizer() &#123; &#125; /** * 延迟初始化的同步队列头，除了初始化，它只能通过方法setHead进行修改。 * 注意： * 1 head 在逻辑上的含义是当前持有锁的线程，head 节点实际上是一个虚节点，本身并不会存储线程信息 * 2 如果head存在，它的waitStatus保证不会被CANCELLED。 */ private transient volatile Node head; /** * 同步队列的尾部，延迟初始化。仅通过方法enq修改以添加新的等待节点。 * 说明： * 当一个线程无法获取同步状态而需要被加入到同步队列时，会使用 CAS 来设置尾节点 tail 为当前线程对应的 Node 节点 */ private transient volatile Node tail; /** * 同步状态，在不同的同步组件中意义不一样 */ private volatile int state; /** * 继承自 AbstractOwnableSynchronizer 的属性，代表当前持有独占资源的线程。如： * 因为锁可以重入 reentrantLock.lock() 可以嵌套调用多次，所以每次用这个来判断当前线程是否已经拥有了锁， * if (currentThread == getExclusiveOwnerThread()) &#123;state++&#125; */ private transient Thread exclusiveOwnerThread; &#125; AQS 主要的属性就是以上四个，下面对其进行简要说明： 1 state 作为同步状态，不同的同步组件使用该属性表示不同的语义。如 ReentrantLock 中表示锁的语义；Semaphore 中表示许可证的语义；2 head 和 tail 连通整个同步队列，除了头部的虚节点，队列中的每个节点都封装了一个线程和对应的状态3 exclusiveOwnerThread 表示当前获取独占状态的线程 节点结构1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495/** * Wait queue node class. */ static final class Node &#123; /** * 共享类型节点，表明节点在共享模式下等待 */ static final Node SHARED = new Node(); /** * 独占类型节点，表明节点在独占模式下等待 */ static final Node EXCLUSIVE = null; /** * 等待状态 - 取消 * 当前线程因为超时或被中断取消，属于一个终结态 */ static final int CANCELLED = 1; /** * 等待状态 - 通知（后继线程需要被唤醒） * 获取同步状态的线程释放同步状态或者取消后需要唤醒后继线程；这个状态一般都是后继线程来设置前驱节点的。 */ static final int SIGNAL = -1; /** * 等待状态 - 条件等待（线程在 Condition 上等待） * 0 状态 和 CONDITION 都属于初始状态 */ static final int CONDITION = -2; /** * 等待状态 - 传播（无条件向后传播唤醒动作） * 用于将唤醒的后继线程传递下去，该状态的引入是为了完善和增强共享状态的唤醒机制。 * 特别说明： * 该状态的引入是为了解决共享同步状态并发释放导致的线程 hang 住问题 */ static final int PROPAGATE = -3; /** * 等待状态，初始值为 0，表示无状态 */ volatile int waitStatus; /** * 同步队列中使用，前驱节点 */ volatile Node prev; /** * 同步队列中使用，后继节点 */ volatile Node next; /** * 节点中封装的线程 */ volatile Thread thread; /** * 条件队列中使用，下一个节点 */ Node nextWaiter; /** * 判断当前节点是否处于共享模式等待 */ final boolean isShared() &#123; return nextWaiter == SHARED; &#125; /** * 获取前驱节点，如果为空的话抛出空指针异常 * * @return */ final Node predecessor() throws NullPointerException &#123; Node p = prev; if (p == null) throw new NullPointerException(); else return p; &#125; Node() &#123; // Used to establish initial head or SHARED marker &#125; /** * addWaiter会调用此构造函数 */ Node(Thread thread, Node mode) &#123; // Used by addWaiter this.nextWaiter = mode; this.thread = thread; &#125; /** * Condition会用到此构造函数 */ Node(Thread thread, int waitStatus) &#123; // Used by Condition this.waitStatus = waitStatus; this.thread = thread; &#125; &#125; 节点 Node 中的相关属性已经详细标注，就不再展开说明。考虑到 AQS 中有大量的状态判断与转换，下面简单梳理下 Node 的等待状态定义： 等待状态 waitStatus 描述 0 Node 被初始化时的默认值 CANCELLED (1) 线程获取同步状态的请求被取消，这是一个终结态 SIGNAL (-1) 这个状态一般都是后继节点来设置前驱节点的，本质上代表的不是自己的状态，而是后继节点的状态。后继线程节点已经准备好了，就等前驱节点同步状态释放。 CONDITION (-2) 表示节点在条件队列中，节点线程等待唤醒 PROPAGATE (-3) 用于将唤醒后继节点传播下去，该状态的引入是为了解决共享同步状态并发释放导致的线程 hang 住问题 独占模式获取同步状态独占模式下，获取同步状态的入口有三个，在前面的模版方法一节中有简单介绍。由于其他两个方法都是基于 acquire 的基础上附加的简单逻辑，因此我们以该方法作为入口对 AQS 的整个独占模式流程进行分析。 12345678910public final void acquire(int arg) &#123; // 1 调用具体同步器实现的 tryAcquire 方法获取同步状态 if (!tryAcquire(arg) &amp;&amp; // 2 获取同步状态失败，先调用 addWaiter 方法将当前线程封装成独占模式的 Node 插入到同步队列中，然后调用 acquireQueued 方法 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) // 3 执行到这里说明在等待期间线程被中断了，那么线程需要自我中断，用于复位中断标志 selfInterrupt();&#125; 通过 acquire 方法我们可以知道，获取同步状态的线程首先会调用 tryAcquire(arg) 方法尝试获取同步状态，而该方法是 AQS 交给独占模式的同步组件实现的方法，用来为同步状态 state 定义对应的语义。如果该方法返回 true ，则说明当前线程获取同步状态成功，就直接返回了；如果获取失败，就需要加入到同步队列中，检测创建的 Node 是否为 head 的直接后继节点，如果是会尝试获取同步状态。如果获取失败则通过 LockSupport 阻塞当前线程，直至被释放同步状态的线程唤醒或则被中断，随后再次尝试获取同步状态，如此反复。下面我们对以上流程进行分解。 tryAcquire123protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException(); &#125; 上述方法是 AQS 提供给子类实现的，子类可根据具体的场景定义对同步状态 state 的操作来表示获取的结果。 addWaiter获取同步状态失败后，会执行该方法将当前线程封装成独占模式的 Node 插入到同步队列尾部。具体实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071 /** * 在同步队列中新增一个节点 Node * * @param mode Node.EXCLUSIVE 类型是独占模式, Node.SHARED 类型是共享模式 * @return 返回新创建的节点 */ private Node addWaiter(Node mode) &#123; // 将当前线程和对应的模式 封装成一个 Node Node node = new Node(Thread.currentThread(), mode); // 将当前 node 设置为链表的尾部 Node pred = tail; // 链表不为空 if (pred != null) &#123; // 先设置当前节点的前驱，确保 node 前驱节点不为 null node.prev = pred; // 通过CAS将当前节点设置为 tail if (compareAndSetTail(pred, node)) &#123; // 上面的已经先处理 node.prev = pred ，再加上下面的 pred.next = node ，也就是实现了将当前节点 node 完整加入到链表中，也就是同步队列的末尾。 pred.next = node; // 入队后直接返回当前节点 return node; &#125; &#125; // 执行到这里说明队列为空(pred == null) 或者 CAS 加入尾部失败 enq(node); return node; &#125;/** * 通过自旋+CAS 在队列中成功插入一个节点后返回。 * 说明： * 该方法处理两种可能：等待队列为空，或者有线程竞争入队 * * @param node the node to insert * @return node's predecessor */ private Node enq(final Node node) &#123; for (; ; ) &#123; Node t = tail; // 队列为空处理 if (t == null) &#123; // Must initialize // head 和 tail 初始化的时候都是 null ，这里使用 CAS 为了处理多个线程同时进来的情况。 // 注意：这里只是设置了 tail = head，并没有返回，也就是接着自旋 if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; // 确保 node 前驱节点不为 null node.prev = t; // CAS 设置 tail 为 node，成功后把老的 tail也就是t连接到 node。 // 注意：这里也是 CAS 操作，就是将当前线程节点排到队尾，有线程竞争的话排不上重复排 if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125; &#125; 总的来说整个 addWaiter 方法就是在同步队列尾部（双向链表尾部）加入节点。以上的自旋和 CAS 操作都是为了保证节点正确加入到队列中。需要注意的是，节点在加入队列（双向链表）的过程中其实是有三步操作的，先是处理节点的前驱指针，接着将节点设置为尾节点，最后处理节点的后置指针。不难发现，如果在节点完整加入到队列前，其他线程通过后置指针访问队列可能获取的是 null ，但真实情况不应该是 null ，因此在 AQS 中涉及寻找节点的地方一般都是通过前驱指针查找，因为节点加入时前驱指针的处理是最先完成的。 此外，同步队列的头节点是一个虚节点，不存存储关键信息（如不存储线程信息）只是占位，在初始化时或滑动同步队列时该头节点对应的是获取同步状态的线程，真正的第一个有数据的节点是从第二开始的。下面以两个线程获取同步状态为例，线程 A 获取同步状态成功，线程 B 获取同步状态失败： 如果再有线程获取同步状态失败，则依次在同步队列中往后排队即可。 acquireQueued入队操作完成后，会将加入到队列的节点 node 作为参数进入到 acquireQueued 方法中，该方法可以对排队中的线程节点进行获取同步状态的操作，或者由于线程节点被中断而不再获取同步状态。 123456789101112131415161718192021222324252627282930313233343536373839final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (; ; ) &#123; // node 的前驱节点，如果为空会跑出 np 异常 final Node p = node.predecessor(); // 检测当前节点前驱是否 head，这是尝试获取同步状态的前提条件。注意，如果 p 是 head，说明当前节点在真实数据队列的首部，就尝试获取同步状态，头节点可是一个虚节点。 // 执行这一步一般有两种情况： // 1 线程因获取不到同步状态而入队，在进入等待之前再次尝试获取同步状态，可能此时它的前驱节点已经完全释放同步状态，尽量避免将线程挂起带来的开销 // 2 只能进入同步队列中等待，等醒来时继续尝试执行该方法 if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 当前节点占领 head，并将 p 从同步队列中移除，防止内存泄漏 setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; // 执行到这里，说明上面的 if 分支没有成功，要么当前 node 的前驱节点不是 head ，要么就是 tryAcquire 没有竞争过其他节点。 // 进入找“大哥：阶段，找到大哥后阻塞挂起自己。 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) // 如果阻塞过程中被中断，则设置 interrupted 为 true interrupted = true; &#125; &#125; finally &#123; // node.predecessor() 为空 或 tryAcquire 方法抛出异常的情况 if (failed) cancelAcquire(node); &#125; &#125; 上述方法非常重要，它实现了线程入队后的系列操作：先是判断是否有资格（直接前驱是 head）尝试获取同步状态，主要是为了尽可能避免线程被挂起，如果比较幸运在这一步就获取同步状态成功了，直接占领头节点等待后续线程将其移出队列即可（再强调一遍，头节点是个虚节点）；如果不那么幸运，就需要进入寻找有效前驱节点的流程，找到后挂起自己；最后，处在同步队列中的节点要么被它的前驱唤醒要么被中断而醒来，醒来后会继续自旋尝试获取同步状态，如此反复。 了解了上述方法的逻辑后，下面对关键步骤进行拆解分析。 setHead当获取同步状态成功后，当前线程节点会执行 setHead 方法占领同步队列头节点，即将自身节点设置为虚节点，也就是移除线程信息。注意，占领头节点并没有清除节点的等待状态信息。获取到同步状态的线程节点成为头节点后，等到该线程节点释放同步状态的时候会继续唤醒它的后继有效节点，如此反复。 1234567891011121314/** * 占领 head 节点，即将当前节点 node 设置为虚节点 head * 注意： * 1 头节点都是虚节点，它对应当前持有同步状态的节点。 * 2 先当前节点的线程信息抹除掉，且断开和前置节点的联系，便于 GC * 3 不修改 waitStatus，因为它是一直需要用的数据 * * @param node the node */private void setHead(Node node) &#123; head = node; node.thread = null; node.prev = null;&#125; shouldParkAfterFailedAcquire当线程节点没有资格获取同步状态或者获取同步状态失败，则会进入寻找有效前驱节点流程，因为挂起在同步队列中的线程节点需要依赖有效前驱节点唤醒的（不考虑被中断的情况）。 12345678910111213141516171819202122232425262728293031323334353637private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; // 前驱节点已经是 SIGNAL 状态，说明是有效的前驱，则后继节点（也就是当前节点）可以进入挂起模式等待它的前驱节点唤醒自己。 // 因为节点状态为 SIGNAL 在释放同步状态时会唤醒后继节点。 if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; // 前驱节点状态为 CANCELLED 状态，说明当前前驱节点取消了排队，是个无效的节点，需要把该节点剔除掉 // 因此需要向前找第一个非取消节点作为 node 的有效前驱（就靠这个大哥到时候唤醒自己），往前遍历总能找到一个大哥 if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; // 前驱节点状态为 0 或者 PROPAGATE ，则设置前驱节点状态为 SIGNAL，即将当前 pred 对应的节点作为大哥 &#125; else &#123; /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; // 返回 false ，那么最后会再走一次外部的 for 循环然后再次进入此方法 return false; &#125; 下面对上述方法的特殊点进行说明： 前驱节点的 waitStatus=-1 是依赖于后继节点设置的。也就是说，当还没给前驱设置-1 时返回 false，第二次进来的时候状态就是-1了。 进入同步队列中挂起的线程唤醒操作是由其有效前驱节点完成的。等着前驱节点获取到同步状态，然后释放同步状态时唤醒自己。也就是需要找到一个好“大哥”。 shouldParkAfterFailedAcquire 在读到前驱节点状态不为 SIGNAL 会给当前线程再一次获取同步状态的机会。 上述方法会顺带剔除取消排队的节点。 parkAndCheckInterrupt当入队的线程节点找到了有效的前驱节点后，就可以挂起自己了，等待它的大哥叫醒自己或者被中断。 12345678910111213/** * 挂起当前线程，返回当前线程的中断状态 * 备注： * 1 interrupt() 中断线程，给线程设置一个中断标志 * 2 interrupted() 判断当前线程是否被中断，返回一个boolean并清除中断状态，第二次再调用时中断状态已经被清除，将返回一个false。 * 3 isInterrupted() 判断线程是否被中断，不清除中断状态 * * @return &#123;@code true&#125; if interrupted */private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 至此，同步模式下的获取同步状态流程基本分析完毕。不过线程节点 node 进入同步队列后有个异常流需要被处理，也就是将 node 取消排队。下面我们重点对该流程进行分析。 cancelAcquire1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374/** * 取消 node 排队。 * 注意： * 取消的节点会在 shouldParkAfterFailedAcquire 中被踢掉 * * @param node the node */ private void cancelAcquire(Node node) &#123; // Ignore if node doesn't exist if (node == null) return; // 设置节点 node 不关联任何线程 node.thread = null; /* 寻找一个有效的前驱的节点作为 node 的前驱，下面在调整链表时会用到 */ // 获取 node 的前驱节点 Node pred = node.prev; // 跳过取消的节点，向前寻找第一个非取消节点作为 node 的前驱节点 while (pred.waitStatus &gt; 0) node.prev = pred = pred.prev; // 记录 node 的第一个有效前驱节点的后继节点，后续 CAS 会用到 Node predNext = pred.next; // 直接把当前节点 node 的等待状态置为取消,后继节点即便也在取消也可以跨越 node节点。 node.waitStatus = Node.CANCELLED; /* 根据当前取消节点 node 的位置，考虑以下三种情况： * 1 当前节点是尾节点 * 2 当前节点是 head 的后继节点 * 3 当前节点既不是 head 后继节点，也不是尾节点 */ // 1 如果 node 是尾节点，则使用 CAS 尝试将它的有效前驱节点 pred 设置为 tail if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123; // 这里的CAS更新 pre d的 next 即使失败了也没关系，说明被其它新入队线程或者其它取消线程更新掉了。 compareAndSetNext(pred, predNext, null); // 如果 node 不是尾节点，那么要做的事情就是将 node 有效前驱和后继节点连接起来 &#125; else &#123; // If successor needs signal, try to set pred's next-link // so it will get one. Otherwise wake it up to propagate. int ws; // 2 当前节点不是 head 的后继节点： // a 判断当前节点前驱节点是否为 -1 // b 如果不是，则把前驱节点设置为 SIGNAL 看是否成功 // c 如果 a 和 b 中有一个为true，再判断当前节点的线程是否不为null // 如果上述条件都满足，把当前节点的前驱节点的后继指针指向当前节点的后继节点。 if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) &#123; // 如果node的后继节点next非取消状态的话，则用CAS尝试把pred的后继置为node的后继节点 Node next = node.next; if (next != null &amp;&amp; next.waitStatus &lt;= 0) compareAndSetNext(pred, predNext, next); // 3 pred == head 或者 pred 状态取消或者 pred.thread == null ，这时为了保证队列的活跃性，会尝试唤醒一次后继线程。 &#125; else &#123; unparkSuccessor(node); &#125; // 将取消节点的 next 设置为自己而非 null，原因如下： // AQS 中 Condition部分的isOnSyncQueue 方法会根据 next 判断一个原先属于条件队列的节点是否转移到了同步队列。同步队列中节点会用到 next 域，取消节点的 next 也有值的话， // 可以判断该节点一定在同步队列上 node.next = node; // help GC &#125; &#125; 上述方法要做的就一件事，将节点 node 的状态标记为 CANCELLED ，取消排队。之所以处理得那么复杂，是要考虑到各种场景。但是我们可以看出，不管哪种场景都需要取消排队节点 node 的有效前驱，这个很好理解，为了重组链表，需要找到一个有效的前驱节点。根据当前取消节点 node 的位置会有三种情况，上述代码中已经详细标注，这里就不再说明。 上述方法的注意事项如下： 取消的节点 node 会被后续入队线程节点从同步队列中剔除掉。 当节点 node 不是尾节点时不会立即被剔除队列，只是设置等待状态为 CANCELLED ，需要后续线程节点去剔除。但需要将 node 的后继设置为自身，主要考虑到 Condition 的使用场景。 取消节点逻辑都是对后继指针 next 进行操作，而没有对 prev 指针进行操作。因为当前节点的前驱节点可能已经从队列中出去了，如果此时修改 prev 指针会不安全（np异常）。因此，在整个 AQS 中可以放心地根据 prev 指针查找，而不会出现断裂的情况。 了解了获取同步状态的方法后，下面对另外两种扩展进行介绍，它们分别是 可中断获取同步状态 和 超时获取同步状态 。 可中断获取同步状态1234567891011121314151617181920212223242526272829303132public final void acquireInterruptibly(int arg) throws InterruptedException &#123; // 如果线程被中断则直接抛出中断异常 if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) // 线程如果被中断过会抛出中断异常 doAcquireInterruptibly(arg);&#125; private void doAcquireInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (; ; ) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) // 发生中断，直接抛出异常 throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 相比较 acquire 方法，上述方法仅仅对中断进行了抛出异常处理，其他流程同 acquire 方法。 超时获取同步状态123456789101112131415161718192021222324252627282930313233343536373839404142434445 public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); return tryAcquire(arg) || // 获取同步状态失败，进入超时获取同步状态逻辑 doAcquireNanos(arg, nanosTimeout); &#125;private boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (nanosTimeout &lt;= 0L) return false; // 记录超时时间 final long deadline = System.nanoTime() + nanosTimeout; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (; ; ) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return true; &#125; // 获取同步状态等待时间 nanosTimeout = deadline - System.nanoTime(); // 超时则直接返回 if (nanosTimeout &lt;= 0L) return false; // 寻找有效的前驱节点，找到后挂起当前线程 nanosTimeout 时间，在这段时间内没有被唤醒也会自动醒来 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if (Thread.interrupted()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 相比较 acquire 方法，上述方法增加了对中断进行了抛出异常处理和超时等待同步状态逻辑，其他流程同 acquire 方法。 释放同步状态前面对独占模式下获取同步状态的流程进行了详细分析，接下来对独占模式下释放同步状态流程进行分析。释放同步状态逻辑相比获取同步状态的逻辑简单很多，它的入口只有一个， release 方法 。 12345678910111213141516public final boolean release(int arg) &#123; // 调用 tryRelease 方法释放 arg 个同步状态 if (tryRelease(arg)) &#123; // 当前线程获取 head 节点 Node h = head; // head 节点状态不会是 CANCELLED ，所以这里 h.waitStatus != 0 相当于 h.waitStatus &lt; 0 // 只有 head 存在且状态小于 0 的情况下唤醒 if (h != null &amp;&amp; h.waitStatus != 0) // 唤醒后继节点 unparkSuccessor(h); return true; &#125; return false; &#125; 独占模式下释放同步状态，首先调用 tryRelease 方法尝试获取同步状态，获取同步状态失败直接返回；获取同步状态成功后，会尝试唤醒同步队列中的后继线程节点。 需要特别说明的是唤醒的前置条件为什么是 h != null &amp;&amp; h.waitStatus != 0： h == null 说明同步队列还初始化，里面并没有需要唤醒的线程节点。 h != null &amp;&amp; h.waitStatus == 0 说明后继节点对应的线程仍在运行中，至少没有找到有效前驱节点，因此不需要唤醒。 h != null &amp;&amp; h.waitStatus &lt; 0 说明后继节点可能被阻塞了，需要唤醒。 上述方法中的 head 的可能性有很多，不一定是当前线程对应的节点： null ，AQS 的 head 延迟初始化 当前线程通过 tryRelease 方法完全释放掉同步状态，刚好此时有新的线程节点入队并在 acquireQueue 中获取到了同步状态并占领了 head。具体情况如下：1234567891011情况一： 时刻1:线程A通过acquireQueued，持锁成功，set了head 时刻2:线程B通过tryAcquire试图获取独占锁失败失败，进入acquiredQueued 时刻3:线程A通过tryRelease释放了独占锁 时刻4:线程B通过acquireQueued中的tryAcquire获取到了独占锁并调用setHead 时刻5:线程A读到了此时的head实际上是线程B对应的node 情况二： 时刻1:线程A通过tryAcquire直接持锁成功，head为null 时刻2:线程B通过tryAcquire试图获取独占锁失败失败，入队过程中初始化了head，进入acquiredQueued 时刻3:线程A通过tryRelease释放了独占锁，此时线程B还未开始tryAcquire 时刻4:线程A读到了此时的head实际上是线程B初始化出来的虚节点 head 下面仍然对释放同步状态的流程进行拆解分析。 tryRelease123protected boolean tryRelease(int arg) &#123; throw new UnsupportedOperationException();&#125; 上述方法是 AQS 提供给子类实现的，子类可根据具体的场景定义对同步状态 state 的操作来表示释放的结果。 unparkSuccessor当释放同步状态成功后，会根据当前头节点 head 的状态判断是否唤醒后继线程节点。 123456789101112131415161718192021222324252627282930313233/** * 唤醒后继节点（线程） * * @param node the node */ private void unparkSuccessor(Node node) &#123; // 尝试将 node 的等待状态设置为 0 ，这样的话后继竞争线程可以有机会再尝试获取一次同步状态 int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /** * 如果 node.next 存在且状态不为取消，则直接唤醒 s 即可。否则需要从 tail 开始向前找到 node 之后最近的非取消节点然后唤醒它，没有则无需唤醒。 * 注意：s == null ，不代表 node 就是 tail ，因为节点入队并不是原子操作。如 addWaiter 方法过程： * 1 某时刻 node 为 tail * 2 有新的线程通过 addWaiter 方法添加自己到同步队列 * 3 compareAndSetTail 成功，但此时 node.next 指针还没有更新完成，值仍为 null ，而此时 node 已经不是 tail，它有后继了 */ Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; // 从tail向前查找最接近 node 的非取消节点 (waitStatus==1) for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; // 唤醒节点 s 中的线程 if (s != null) LockSupport.unpark(s.thread); &#125; 上述方法的唯一工作就是尝试唤醒节点 node 的直接有效后继节点。需要注意，如果 node 的后继节点是 null 或取消节点，那么需要从同步队列尾部向前找距离 node 最近的有效节点并唤醒。 这里寻找有效后继节点的条件是 s == null || s.waitStatus &gt; 0 的原因如下： s == null ，对应的是线程节点入队并不是原子操作，next 的指针还没有来得及处理，因此需要从后往前遍历才能够遍历完全部的节点。 s.waitStatus &gt; 0 ，对应的是在产生 CANCELLED 状态节点的时候，处理的是 next 指针，prev 指针并未处理，因此也是需要从后往前遍历才能够遍历完全部的节点。 唤醒后续流程挂起在同步队列中的节点恢复，从以下方法返回。 12345678910111213/** * 挂起当前线程，返回当前线程的中断状态 * 备注： * 1 interrupt() 中断线程，给线程设置一个中断标志 * 2 interrupted() 判断当前线程是否被中断，返回一个boolean并清除中断状态，第二次再调用时中断状态已经被清除，将返回一个false。 * 3 isInterrupted() 判断线程是否被中断，不清除中断状态 * * @return &#123;@code true&#125; if interrupted */ private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted(); &#125; 线程节点醒来的原因可能是其他线程唤醒的，也可能是挂起的线程被中断了，因此这里需要判断线程在等待期间是否被中断过。线程醒来后会再回到 acquireQueued 方法中，当parkAndCheckInterrupt 返回 ture 或者 false 的时候，interrupted 的值不同，但都会执行下次循环尝试获取同步状态。如果获取同步状态成功，当前线程节点会占领头节点，并将原来的头节点移除队列，最后会把 interrupted 返回，然后回到 acquire 方法，如下： 12345678910public final void acquire(int arg) &#123; // 1 调用具体同步器实现的 tryAcquire 方法获取同步状态 if (!tryAcquire(arg) &amp;&amp; // 2 获取同步状态失败，先调用 addWaiter 方法将当前线程封装成独占模式的 Node 插入到同步队列中，然后调用 acquireQueued 方法 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) // 3 执行到这里说明在等待期间线程被中断了，那么线程需要自我中断，用于复位中断标志 selfInterrupt();&#125; 如果 acquireQueued 返回 true ，就会执行 selfInterrupt 方法。 123456/** * 中断当前线程，以复位中断标志 */static void selfInterrupt() &#123; Thread.currentThread().interrupt();&#125; 在 acquire 中执行 selfInterrupt 和在 acquireQueued 中执行 parkAndCheckInterrupt 是相互呼应的，是为了复位线程的中断标志。为什么搞这么麻烦，因为不明确线程醒来的原因，可能是释放同步状态的线程唤醒的，也可能是被中断了。 至此，整个唤醒流程结束。 独占模式流程图 共享模式获取同步状态共享模式下，获取同步状态的入口也有三个，在前面的模版方法一节中有简单介绍。由于其他两个方法都是基于 acquireShared 的基础上附加的简单逻辑，因此我们也以该方法作为入口对 AQS 的整个共享模式流程进行分析。需要注意的是，与独占模式区别关键在于共享模式允许多个线程持有同步状态。 1234567 public final void acquireShared(int arg) &#123; // 调用 tryAcquireShared 方法尝试获取同步状态 if (tryAcquireShared(arg) &lt; 0) // 获取失败 doAcquireShared(arg);&#125; 获取同步状态的线程首先会调用 tryAcquireShared(arg) 方法尝试获取同步状态，该方法是 AQS 交给共享模式的同步组件实现的方法，用来为同步状态 state 定义对应的语义。如果该方法返回值大于等于 0 ，说明当前线程获取同步状态成功，直接返回即可；如果获取失败，则执行 doAcquireShared(arg) 方法，类似独占模式下的 acquireQueued 方法，不过共享模式有自己独特的传播特性，而独占模式没有传播特性。下面依然分解过程分析。 tryAcquireShared123protected int tryAcquireShared(int arg) &#123; throw new UnsupportedOperationException();&#125; 上述方法是 AQS 提供给共享模式的子类组件实现的方法。在实现 tryAcquireShared 方法时需要注意，返回负数表示获取失败；返回 0 表示成功，但是后继竞争线程不会成功；返回正数表示获取成功，并且后继竞争线程也可能成功。 doAcquireShared获取同步状态失败后，会执行该方法。 123456789101112131415161718192021222324252627282930313233343536373839404142private void doAcquireShared(int arg) &#123; // 将当前线程以共享模式的方式加入到同步队列 final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; boolean interrupted = false; for (; ; ) &#123; // 获取前驱节点 final Node p = node.predecessor(); // 如果前驱节点为 head ，则尝试获取同步状态 if (p == head) &#123; int r = tryAcquireShared(arg); // 一旦获取共享同步状态成功，通过传播机制唤醒后继节点 if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); // 将旧的头节点从同步队列中移除 p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; // 进入找大哥流程 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; // 挂起线程 parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; // 取消节点 if (failed) cancelAcquire(node); &#125; &#125; 下面对共享模式下获取同步状态失败的流程进行简要总结： 将当前线程封装成共享模式的 Node 插入到同步队列的尾部。addWaiter 方法的流程见上文。 判断是否有资格（前驱节点是 head）尝试获取同步状态，同样是为了尽最大可能避免挂起线程。 如果获取同步状态成功，则占领头节点并通过传播机制唤醒尝试唤醒后继节点。注意，该过程是和独占模式不同的，根本原因在于共享模式允许同时有多个线程获取同步状态，传播机制是为了解决并发释放同步状态导致后续节点没有唤醒问题。 如果获取失败则进入寻找有效前驱节点流程，和独占模式一致。 对 node.predecessor() 为空 或 tryAcquireShared 方法抛出异常的处理，和独占模式一致。 了解了整个获取共享同步状态流程后，下面仍然进行拆解分析，前文已经分析过的方法就不再重复分析。其实可以看出，共享模式和独占模式唯一的区别在于 setHeadAndPropagate 方法。由于独占模式的特点，不需要传播唤醒特点。而共享模式允许多个线程同时持有同步状态，因此当获取后的同步状态仍然大于 0 那么可以继续唤醒后继线程，这就是共享模式下的传播特性。 setHeadAndPropagate再次获取同步状态成功后，会执行该方法。 1234567891011121314151617181920212223242526272829/** * 该方法主要做以下两件事： * 1. 在获取共享同步状态后，占领 head 节点 * 2. 根据情况唤醒后继线程 * * @param node the node * @param propagate the return value from a tryAcquireShared */private void setHeadAndPropagate(Node node, int propagate) &#123; // 记录 head Node h = head; // Record old head for check below // 占领 head setHead(node); /** * 1 propagate 是 tryAcquireShared 的返回值，这是决定是否传播唤醒的依据之一。 * 2 h.waitStatus 为 SIGNAL 或 PROPAGATE 时，根据 node 的下一个节点类型（共享模式）来决定是否传播唤醒 */ if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; // 注意 s == null 不代表 node 就是尾节点，可能它的后继节点取消了排队，这种情况已经继续尝试唤醒有效的后继节点 if (s == null || s.isShared()) doReleaseShared(); &#125;&#125; 通过前文的描述，不难看出上述方法的作用。除了占领头节点，还会根据需要继续唤醒后继节点，也就是传播唤醒。传播唤醒的前置条件 propagate &gt; 0 比较好理解，还有同步状态可获取，唤醒后继等待的线程节点即可。但是 h.waitStatus &lt; 0 条件就不太好理解了，为什么要多加这个条件呢？下面会详细分析。接下来继续看传播唤醒的方法 doReleaseShared() ，其实这个方法是释放同步状态方法公用的方法。我们在释放同步状态方法中再去分析该方法。 至此，共享模式下的获取同步状态流程分析完毕。同样地，下面简单地对另外两个获取同步状态的方法进行介绍，它们是基于 acquireShared 方法增强的功能，比较简单。 可中断获取同步状态123456789101112131415161718192021222324252627282930313233343536public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; // 中断处理 if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) // 线程如果被中断过会抛出中断异常 doAcquireSharedInterruptibly(arg);&#125;private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (; ; ) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) // 响应中断 throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 相比较 acquireShared 方法，上述方法仅仅对中断进行了抛出异常处理，其他流程同 acquireShared 方法。 超时获取同步状态123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout) throws InterruptedException &#123; // 中断处理 if (Thread.interrupted()) throw new InterruptedException(); return tryAcquireShared(arg) &gt;= 0 || // 获取同步状态失败，进入超时获取同步状态逻辑 doAcquireSharedNanos(arg, nanosTimeout);&#125;private boolean doAcquireSharedNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (nanosTimeout &lt;= 0L) return false; // 记录超时时间 final long deadline = System.nanoTime() + nanosTimeout; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (; ; ) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return true; &#125; &#125; // 获取同步状态等待时间 nanosTimeout = deadline - System.nanoTime(); // 超时则直接返回 false if (nanosTimeout &lt;= 0L) return false; // 寻找有效的前驱节点，找到后挂起当前线程 nanosTimeout 时间，在这段时间内没有被唤醒也会自动醒来 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if (Thread.interrupted()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 相比较 acquireShared 方法，上述方法增加了对中断进行了抛出异常处理和超时等待同步状态逻辑，其他流程同 acquireShared 方法。 释放同步状态12345678910111213141516171819/** * 释放共享同步状态 * 注意： * 共享锁的获取过程（执行传播）和释放都会涉及到 doReleaseShared 方法，也就是后继节点的唤醒 * * @param arg the release argument. This value is conveyed to * &#123;@link #tryReleaseShared&#125; but is otherwise uninterpreted * and can represent anything you like. * @return the value returned from &#123;@link #tryReleaseShared&#125; */public final boolean releaseShared(int arg) &#123; // 调用 tryReleaseShared 方法尝试释放同步状态 if (tryReleaseShared(arg)) &#123; // 进入唤醒后继节点逻辑 doReleaseShared(); return true; &#125; return false;&#125; 释放同步状态比较简单，先调用 tryReleaseShared 方法尝试释放同步状态，释放成功后调用 doReleaseShared 方法进入唤醒后继节点逻辑。 tryReleaseShared123protected boolean tryReleaseShared(int arg) &#123; throw new UnsupportedOperationException();&#125; 上述方法是 AQS 提供给共享模式的子类组件实现的方法，用于定义释放同步状态的。 doReleaseShared12345678910111213141516171819202122232425262728293031private void doReleaseShared() &#123; /** * 以下循环做的事情是，在队列存在后继节点时，唤醒后继节点；或者由于并发释放共享同步状态导致读到 head 节点等待状态为 0 ，虽然不能执行 unparkSuccessor ， * 但为了保证唤醒能够正确传递下去，设置节点状态为 PROPAGATE。这样的话获取同步状态的线程在执行 setHeadAndPropagate 时可以读到 PROPAGATE，从而由获取 * 同步状态的线程去释放后继等待节点。 */ for (; ; ) &#123; Node h = head; // 如果队列中存在后继节点 if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; // 如果 head 的状态为 SIGNAL ，则尝试将其设置为 0 并唤醒后继节点 if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases // 唤醒后继节点 unparkSuccessor(h); // 如果 head 节点的状态为 0 ,需要设置为 PROPAGATE 用以保证唤醒的传播，即通过 setHeadAndPropagate 方法唤醒此时由于并发导致的未能唤醒的后继节点 &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; // 检查h是否仍然是head，如果不是的话需要再进行循环。 if (h == head) // loop if head changed break; &#125; &#125; 上述方法是共享模式释放同步状态的核心方法，用来唤醒后继节点或设置设置头节点传播状态 PROPAGATE。 该方法可能会承受并发调用，一旦发生并发调用会存在线程设置头节点状态为 SIGNAL 失败，接着会自旋将头节点状态设置为 PROPAGATE 保证唤醒的传播。 共享模式流程图 PROPAGATE 状态AQS 中的 PROPAGATE 状态相比其它状态较难理解，它的引入是为了解决共享模式下并发释放同步状态导致的线程节点无法唤醒问题。下面从一个 bug 说起引入 PROPAGATE 的作用。 Bug12345678910111213141516171819202122232425262728293031323334353637383940import java.util.concurrent.Semaphore;public class TestSemaphore &#123; // 这里设置许可证为 0，意味着在释放许可证之前，所有获取许可证的线程都会挂起在同步队列中 private static Semaphore sem = new Semaphore(0); private static class Thread1 extends Thread &#123; @Override public void run() &#123; // 获取许可证 sem.acquireUninterruptibly(); &#125; &#125; private static class Thread2 extends Thread &#123; @Override public void run() &#123; // 释放许可证 sem.release(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; for (int i = 0; i &lt; 10000000; i++) &#123; Thread t1 = new Thread1(); Thread t2 = new Thread1(); Thread t3 = new Thread2(); Thread t4 = new Thread2(); t1.start(); t2.start(); t3.start(); t4.start(); t1.join(); t2.join(); t3.join(); t4.join(); System.out.println(i); &#125; &#125;&#125; 上述代码偶现线程挂起无法退出的情况。当然这个代码在新版的 JDK 中是不存在的，下面我们来看当时的版本涉及的相关方法。 相关方法获取同步状态 123456789101112131415161718192021222324252627private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 释放同步状态 12345678910 public final boolean releaseShared(int arg) &#123; // 并发执行可能读取的 h.waitStatus == 0，导致不能唤醒后继线程节点 if (tryReleaseShared(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 设置头并传播 123456789101112131415private void setHeadAndPropagate(Node node, int propagate) &#123; setHead(node); // 传播的条件，注意和新版 JDK 中的区别 // if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) if (propagate &gt; 0 &amp;&amp; node.waitStatus != 0) &#123; /* * Don't bother fully figuring out successor. If it * looks null, call unparkSuccessor anyway to be safe. */ Node s = node.next; if (s == null || s.isShared()) unparkSuccessor(node); &#125; &#125; 复现 Bug根据上面复现 Bug 的测试程序，走一遍源码，看看问题出现在哪个环节。 程序循环中做的事情就是创建 4 个线程，其中 2 个线程用于获取信号量，另外 2 个用于释放信号量。每次循环主线程会等待所有子线程执行完毕。出现 bug 的问题就在于两个获取信号量的线程有一个会没办法被唤醒，队列就死掉了。通过前文介绍可以知道，在共享模式下，如果一个线程被挂起，在不考虑线程中断和前驱节点取消的情况（持有同步状态的线程节点在释放同步状态后会尝试唤醒其后继节点，如果后继节点取消了那么会跳过取消节点，找到一个最近的有效后继节点并唤醒它），还有两种唤醒挂起线程的情况：一种是持有同步状态的线程释放同步状态后通过调用 unparkSuccessor 来唤醒挂起的线程；另一种是其它线程节点再次获取同步状态后通过传播机制唤醒后继节点。 某一时刻我们假定同步队列中的节点排队情况如下图所示： 接下来我们根据早期 JDK 中共享模式下释放同步状态源码流程简单走一遍： 时刻1：t3 调用 releaseShared，释放同步状态（许可证由 0 变为 1）成功，此时 h != null &amp;&amp; h.waitStatus != 0 条件成立，接着执行 unparkSuccessor(h) ，head 的 waitStatus 由 -1 变为 0 。 时刻2：t1 由于 t3 释放了同步状态被 t3 唤醒，t1 醒来后调用 Semaphore.NonfairSync的tryAcquireShared 获取同步状态（许可证），返回值为 0 （许可证由 1 减为 0）。 时刻3：t4 调用 releaseShared，释放同步状态（许可证由 0 变为 1）成功，但此时 t1 还没有占领头节点，头节点仍然是时刻1 的 head ，也就是 t3 占领的。由于 h.waitStatus == 0 ，不满足条件，因此 t4 不会执行唤醒后继线程的 unparkSuccessor(h) 。理论来说，t4 应该唤醒还挂在队列中的 t2，但是却没有。 时刻4：t1 获取同步状态成功后，接着调用 setHeadAndPropagate 占领头节点，然后尝试传播唤醒，但由于不满足 propagate &gt; 0（此时 propagate == 0，也就是时间2的结果），因此也不会传播唤醒后继节点。 最终的结果是，线程 t2 无法被唤醒，AQS 的同步队列死掉。 引入 PROPAGATE 后有两处地方调整。释放同步状态的 releaseShared 方法不再是简单粗暴地直接 unparkSuccessor ，而是将整个流程进行调整并抽成一个 doReleaseShared 方法，具体该方法见前文。该方法处理了并发释放同步状态的逻辑，虽然不能执行 unparkSuccessor ，但为了保证唤醒能够正确传递下去，设置读取到的 head 节点状态为 PROPAGATE。这样的话获取同步状态的线程在执行 setHeadAndPropagate 时可以读到 PROPAGATE，从而由获取同步状态的线程去释放后继等待节点；占领头节点并传播唤醒的 setHeadAndPropagate 方法增加了唤醒后继节点的条件，也就是我们的主角 PROPAGATE 状态，具体的方法见前文。 下面我们再看引入 PROPAGATE 等待状态是如何规避上述问题的： 时刻1：t3 调用 releaseShared，释放同步状态（许可证由 0 变为 1）成功，进入自旋逻辑将 head 的 waitStatus 由 -1 变为 0 ，接着执行 unparkSuccessor(h) 唤醒后继线程。 时刻2：t1 由于 t3 释放了同步状态被 t3 唤醒，t1 醒来后调用 Semaphore.NonfairSync的tryAcquireShared 获取同步状态（许可证），返回值为 0 （许可证由 1 减为 0）。 时刻3：t4 调用 releaseShared，释放同步状态（许可证由 0 变为 1）成功，进入自旋逻辑，此时 t1 还没有占领头节点，头节点仍然是时刻1 的 head ，也就是 t3 占领的。由于 h.waitStatus == 0 ，于是 t4 将读取到的头节点 head 的 waitStatus 设置为 PROPAGATE (-3) 。 时刻4：t1 获取同步状态成功后，接着调用 setHeadAndPropagate 占领头节点，然后尝试传播唤醒，虽然不满足 propagate &gt; 0（此时 propagate == 0，也就是时间2的结果），但是满足 h.waitStatus &lt; 0 条件，因此会传播唤醒后继节点，也就是线程 t2。 总结上述会产生线程无法唤醒的 Bug 的案例在引入 PROPAGATE 等待状态后可以被规避掉。在引入 PROPAGATE 之前之所以会出现线程 hang 住的情况，就是在于 releaseShared 有竞争的情况。线程 t3 释放同步状态后会唤醒同步队列中等待的线程 t1 ，t1 醒来后获取到了同步状态但还来得及占领头节点 head ，此时线程 t4 又来释放同步状态，但是读到的还是 t3 占领的头节点 head ，由于此时 head 的等待状态为 0 ，因此导致不会执行后续的唤醒后继节点流程。最终后一个挂起的线程既没有被释放同步状态线程（t4）唤醒，也没有被持有同步状态的线程（t1）唤醒。 综上所述，在共享模式下仅仅依靠 tryAcquireShared 的返回值来决定是否要将唤醒传递下去是不充分的。 独占模式 VS 共享模式获取同步状态独占模式和共享模式获取同步状态的核心方法如下图所示： 上述流程均按照线程获取同步状态失败入队等候，然后被唤醒。更完整的情况见前文。 释放同步状态独占模式和共享模式释放同步状态的核心方法如下图所示： 上述流程均按照线程释放同步状态然后唤醒后继线程节点，更完整的情况见前文。 公平与非公平12345678910111213141516+--- AbstractQueuedSynchronizer /** * 用于公平模式时判断同步队列中是否存在有效节点 * * @return true - 说明队列中存在有效节点，当前线程必须加入同步队列中等待；false - 说明当前线程可以竞争同步状态 */ public final boolean hasQueuedPredecessors() &#123; // The correctness of this depends on head being initialized // before tail and on head.next being accurate if the current // thread is first in queue. Node t = tail; // Read fields in reverse initialization order Node h = head; Node s; return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread()); &#125; AQS 支持公平与非公平模式，通过上述方法来判断是否公平。下面我们对判断条件进行说明： 同步队列中的第一个节点是一个虚节点，不存储线程信息只是占位，一般对应获取同步状态的线程。真正的第一个有效节点是从第二开始的。 (s = h.next) == null 说明此时同步队列有线程在进行初始化，此时队列中有元素，因此需要返回 ture 。 (s = h.next) != null 说明同步队列中至少有一个有效节点，如果此时 s.thread != Thread.currentThread() 说明同步队列中的第一个有效节点（head的直接后继节点）中的线程和当前线程相同，那么当前线程是可以获取同步状态的。如果 s.thread != Thread.currentThread()，说明同步队列的第一个有效节点中的线程与当前线程不同，当前线程必须加入进等待队列。 应用场景AQS 作为并发编程框架，在 JDK 的 JUC 中有很多的应用场景。下面列出 JUC 中几种常见的组件，后续会对这些组件源码进行分析。 同步组件 描述 ReentrantLock 使用 AQS 同步状态记录锁重复持有的次数。当一个线程获取锁时，会记录当前获得锁的线程标识，用于检测是否是重入，以及异常解锁判断 ReentrantReadWriteLock 使用 AQS 同步状态中的高 16 位保存写锁持有次数，低 16 位保存读锁持有次数 Semaphore 使用 AQS 同步状态作为许可证，获取的时候会减少许可证，释放的时候会增加许可证，许可证 &gt; 0 所有的 acquireShare 操作才可以通过 CountDownLatch 使用 AQS 同步状态表示计数，计数为0时，所有的 acquireShare 操作（CountDownLatch的await方法）才可以通过 ThreadPoolExecutor Worker 线程利用 AQS 同步状态实现对独占线程变量的设置，表明自己处于工作状态 自定义同步组件分析完 AQS 的基本原理后，借助 AQS 框架就能轻松实现目标同步组件。具体套路如下： 定义一个继承 AQS 的静态内部类，该内部类对象才是真正发挥 AQS 能力关键 根据具体场景选择对应的模式，是独占还是共享，是公平还是非公平，然后选择实现不同的入口方法对 将 AQS 实现组合在自定义同步组件的实现中 123456789101112131415161718192021222324252627282930/** * 借助 AQS 实现锁功能，不支持重入 */public class Mutex &#123; // 1 定义静态内部类 Sync 继承 AQS private static class Sync extends AbstractQueuedSynchronizer &#123; // 2 实现 tryAcquire-tryRelease @Override protected boolean tryAcquire(int arg) &#123; return compareAndSetState(0, 1); &#125; @Override protected boolean tryRelease(int arg) &#123; setState(0); return true; &#125; &#125; // 3 将 AQS 实现组合 Mutex 中 private Sync sync = new Sync(); public void lock() &#123; sync.acquire(1); &#125; public void unlock() &#123; sync.release(1); &#125;&#125; 小结本篇文章对 AbstractQueuedSynchronizer 进行了详细说明。先从它的实现思路出发，从全局对 AQS 进行介绍。有了实现思路后，接下来从源码层面对 AQS 进行拆解分析，分为两个部分，一个是独占模式，另一个是共享模式。使用 AQS 框架，是有固定模式的，AQS 已经处理好了同步状态的获取与释放以及阻塞与唤醒，自定义组件只需继承 AQS 以及根据同步状态获取方式（独占/共享）实现模版方法即可。如果还想实现公平或非公平组件，只需在模版方法中增加相应的逻辑即可，AQS 也提供了该逻辑。AQS 准备好了一切，只需要条件触发就可以执行对应的任务，而实现的模版方法正是触发条件。 参考：https://mp.weixin.qq.com/s/sA01gxC4EbgypCsQt5pVoghttps://www.cnblogs.com/micrari/p/6937995.htmlhttp://gee.cs.oswego.edu/dl/papers/aqs.pdf","categories":[{"name":"JDK","slug":"JDK","permalink":"https://gentryhuang.com/categories/JDK/"}],"tags":[{"name":"JUC","slug":"JUC","permalink":"https://gentryhuang.com/tags/JUC/"},{"name":"AQS","slug":"AQS","permalink":"https://gentryhuang.com/tags/AQS/"}]},{"title":"Dubbo源码分析 - 优雅停机","slug":"rpc/优雅停机","date":"2020-10-21T16:00:00.000Z","updated":"2021-04-06T08:35:47.211Z","comments":false,"path":"posts/ef4cfe7a/","link":"","permalink":"https://gentryhuang.com/posts/ef4cfe7a/","excerpt":"","text":"概述优雅停机仅存在于服务重启、下线这样的部署阶段，优雅停机是一个应用生命周期的一部分，它保障了应用的健壮性。dubbo是通过jdk的ShutdownHook来完成优雅停机的，所以如果用户使用 kill -9 pid 等强制关闭指令，是不会执行优雅停机的，只有通过 kill pid 即正常退出进程，才会执行。 基本要求 优雅停机的服务端有正在处理中的请求，不能被停机指令中断，除非超时 优雅停机的消费端不应该再发起新的请求 消费端不应该请求已经下线的服务提供者 意义应用的重新启动、停机等操作，避免了对业务的连续性造成影响，如：集群中的某个应用存在逻辑上的bug，需要修改程序，这时候就可以使用优雅停机平滑下线，不会造成调用方异常问题。 原理 dubbo中实现优雅停机主要包含以下步骤 收到kill 9 进程退出信号时，spring容器会触发容器销毁事件 (其实是spring注册的jvm钩子程序执行的，后面会看到) provider端会取消注册服务元数据信息 consumer端会收到最新地址列表（准备停机地址不在该地址列表中） dubbo协议会发送readonly事件报文通知consumer服务不可用 服务端等待已经执行的任务结束并不再处理新的请求 说明 上图中的流程是使用spring构建的dubbo应用 上图中的流程没有体现出优雅停机的消费端角色，该角色做的工作相对简单，主要是不再发起新的调用请求和等待响应返回，超时才会强制关闭 注册中心已经通知了最新服务列表，发送readonly事件主要考虑到注册中心推送服务有网络延迟以及客户端计算服务列表也需要时间。消费端收到后会设置对应的provider为不可用状态，下次负载均衡就不会调用这个下线的服务 方案dubbo对优雅停机的实现在不同的版本中有所差异，下面从2.5.x、2.6.x以及2.7.x这三个版本分别分析。 2.5.x的优雅停机注册shutdown hook 12345678910111213141516171819public abstract class AbstractConfig implements Serializable &#123; // 省略其它代码 static &#123; Runtime.getRuntime().addShutdownHook(new Thread(new Runnable() &#123; public void run() &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Run shutdown hook now.\"); &#125; /** * 销毁资源 * 1 注册中心数据销毁： 删除注册中心中本节点对应的提供者地址以及订阅数据 * 2 协议流程数据销毁： 取消该协议所有已经暴露和引用的服务，释放协议所占用的所有资源，比如连接和端口 */ ProtocolConfig.destroyAll(); &#125; &#125;, \"DubboShutdownHook\")); &#125; 说明 ProtocolConfig.destroyAll()方法是用来释放资源的，由于dubbo支持多注册中心和多协议，因此具体销毁实现细节取决于具体的注册中心和具体的协议，这里不再展开说明。 2.6.x的优雅停机 spring也依赖shutdown hook完成优雅停机，其注册jvm钩子的方法如下： 12345678910111213141516171819202122232425/** * Register a shutdown hook with the JVM runtime, closing this context * on JVM shutdown unless it has already been closed at that time. * &lt;p&gt;Delegates to &#123;@code doClose()&#125; for the actual closing procedure. * @see Runtime#addShutdownHook * @see #close() * @see #doClose() */@Overridepublic void registerShutdownHook() &#123; if (this.shutdownHook == null) &#123; // No shutdown hook registered yet. this.shutdownHook = new Thread() &#123; @Override public void run() &#123; synchronized (startupShutdownMonitor) &#123; doClose(); &#125; &#125; &#125;; // 注册jvm钩子 Runtime.getRuntime().addShutdownHook(this.shutdownHook); &#125;&#125; spring的shutdownhook具体任务如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * Actually performs context closing: publishes a ContextClosedEvent and * destroys the singletons in the bean factory of this application context. * &lt;p&gt;Called by both &#123;@code close()&#125; and a JVM shutdown hook, if any. * @see org.springframework.context.event.ContextClosedEvent * @see #destroyBeans() * @see #close() * @see #registerShutdownHook() */protected void doClose() &#123; if (this.active.get() &amp;&amp; this.closed.compareAndSet(false, true)) &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Closing \" + this); &#125; LiveBeansView.unregisterApplicationContext(this); try &#123; // Publish shutdown event // 注意容器关系事件的发布 publishEvent(new ContextClosedEvent(this)); &#125; catch (Throwable ex) &#123; logger.warn(\"Exception thrown from ApplicationListener handling ContextClosedEvent\", ex); &#125; // Stop all Lifecycle beans, to avoid delays during individual destruction. if (this.lifecycleProcessor != null) &#123; try &#123; this.lifecycleProcessor.onClose(); &#125; catch (Throwable ex) &#123; logger.warn(\"Exception thrown from LifecycleProcessor on context close\", ex); &#125; &#125; // Destroy all cached singletons in the context's BeanFactory. destroyBeans(); // Close the state of this context itself. closeBeanFactory(); // Let subclasses do some final clean-up if they wish... onClose(); this.active.set(false); &#125; &#125; dubbo2.6.x支持使用spring构建dubbo应用时，能够安全使用优雅停机。由于dubbo注册了jvm停止的钩子， spring可能 也注册了jvm停机的钩子，这种情况下两个并发执行的线程可能引用已经销毁的资源，导致优雅停机失效。比如，dubbo正在执行的任务需要引用spring中的bean，但此时spring钩子已经关闭spring上下文，导致访问spring资源都会报错。因此对于这种情况，dubbo在2.6.3中新增ShutdownHookListener 类用来解决并发问题，该类实现了ApplicationListener接口，当进程退出时jvm钩子会被触发，此时spring和dubbo注册的jvm钩子都会被回调，spring注册的jvm钩子程序中spring发出容器关闭事件，ShutdownHookListener接收到关闭事件后执行dubbo的jvm钩子程序进行资源的释放，这样就避免使用无效spring bean的问题，从而完成优雅停机。 ShutdownHookListener 1234567891011private static class ShutdownHookListener implements ApplicationListener &#123; @Override public void onApplicationEvent(ApplicationEvent event) &#123; if (event instanceof ContextClosedEvent) &#123; // 使用spring框架时也不应该删除dubbo shutdown hook，因为spring可能没有注册ContextClosed 事件 DubboShutdownHook shutdownHook = DubboShutdownHook.getDubboShutdownHook(); shutdownHook.destroyAll(); &#125; &#125;&#125; AbstractConfig中依然保留JVM停止钩子 12345678910111213141516171819202122232425public abstract class AbstractConfig implements Serializable &#123; // 省略无关代码... static &#123; legacyProperties.put(\"dubbo.protocol.name\", \"dubbo.service.protocol\"); legacyProperties.put(\"dubbo.protocol.host\", \"dubbo.service.server.host\"); legacyProperties.put(\"dubbo.protocol.port\", \"dubbo.service.server.port\"); legacyProperties.put(\"dubbo.protocol.threads\", \"dubbo.service.max.thread.pool.size\"); legacyProperties.put(\"dubbo.consumer.timeout\", \"dubbo.service.invoke.timeout\"); legacyProperties.put(\"dubbo.consumer.retries\", \"dubbo.service.max.retry.providers\"); legacyProperties.put(\"dubbo.consumer.check\", \"dubbo.service.allow.no.provider\"); legacyProperties.put(\"dubbo.service.url\", \"dubbo.service.address\"); // this is only for compatibility /** * Dubbo 的优雅停机 ShutdownHook 在 AstractConfig 的静态代码块中，这保证了ShutdownHook能够给被初始化。 * 说明： * 1 Dubbo 是 通过 JDK的ShutdownHook来完成优雅停机的 * 2 ShutdownHook本质上是一个线程，任务体在对应的run方法中 */ Runtime.getRuntime().addShutdownHook(DubboShutdownHook.getDubboShutdownHook()); &#125; &#125; DubboShutdownHook 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public class DubboShutdownHook extends Thread &#123; private static final Logger logger = LoggerFactory.getLogger(DubboShutdownHook.class); /** * ShutdownHook,类属性 */ private static final DubboShutdownHook dubboShutdownHook = new DubboShutdownHook(\"DubboShutdownHook\"); public static DubboShutdownHook getDubboShutdownHook() &#123; return dubboShutdownHook; &#125; /** * Has it already been destroyed or not? * &lt;p&gt; * 是否已经被销毁标识 */ private final AtomicBoolean destroyed; private DubboShutdownHook(String name) &#123; super(name); this.destroyed = new AtomicBoolean(false); &#125; /** * ShutdownHook的任务体 */ @Override public void run() &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Run shutdown hook now.\"); &#125; destroyAll(); &#125; /** * Destroy all the resources, including registries and protocols. * &lt;p&gt; * 销毁所有的资源，包括 Registry相关 和 Protocol相关 */ public void destroyAll() &#123; //如果已经销毁则忽略 if (!destroyed.compareAndSet(false, true)) &#123; return; &#125; // 销毁所有的 Registry,取消应用程序中的服务提供者和消费者的订阅与注册 AbstractRegistryFactory.destroyAll(); /** * 销毁所有的 Protocol * * 说明： * 这里的Protocol比较多，大体上可以分两类： * 1 和Registry相关的Protocol，RegistryProtocol关注服务的注册 * 2 具体协议，如 DubboProtocol、httpProtocol等,关注服务的暴露和引用 */ ExtensionLoader&lt;Protocol&gt; loader = ExtensionLoader.getExtensionLoader(Protocol.class); for (String protocolName : loader.getLoadedExtensions()) &#123; try &#123; Protocol protocol = loader.getLoadedExtension(protocolName); if (protocol != null) &#123; protocol.destroy(); &#125; &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; &#125; &#125;&#125; DubboShutdownHook与protocol、registry的关系图 图解(以dubbo协议和zookeeper注册中心为例) Registry相关 AbstractRegistryFactory#destroyAll方法，遍历所有的Registry并调用Registry#destroy方法。然后清空Registry缓存集合。 AbstractRegistry 实现了公用的销毁逻辑：取消注册和订阅。服务提供者和消费者都会执行注册和订阅，因此都需要进行取消。 FailbackRegistry实现销毁公用的重试任务 ZookeeperRegistry销毁其对应的客户端连接 Protocol相关 AbstractProtocol#destroy方法，销毁协议对应的服务消费者拥有的Invoker， 销毁协议对应的服务提供者的所有Exporter。 DubboProtocol销毁所有通信 ExchangeClient 和 ExchangeServer 小结 dubbo2.6.3在spring环境中注册两个钩子的情况，ShutdownHookListener解决了并发执行问题 使用ShutdownHookListener也不能移除调dubbo注册的jvm钩子，因为不能保证应用中一定会注册spring的shutdown hook 2.7.x优雅停机从dubbo的2.6.3版本开始，解决了使用spring构建的dubbo可能发生优雅停机并发执行shutdown hook的问题。但是还是存在一个问题，那就是如果在spring环境下没有注册spring的jvm钩子，虽然没有大问题，但是还是有不完整的。dubbo2.7.x进行显示地注册spring的jvm钩子，并且移除dubbo的jvm钩子，解决了当前问题。 12345678910111213141516171819202122232425262728293031public class SpringExtensionFactory implements ExtensionFactory &#123; // 省略其它代码... private static final Set&lt;ApplicationContext&gt; CONTEXTS = new ConcurrentHashSet&lt;ApplicationContext&gt;(); private static final ApplicationListener SHUTDOWN_HOOK_LISTENER = new ShutdownHookListener(); public static void addApplicationContext(ApplicationContext context) &#123; CONTEXTS.add(context); if (context instanceof ConfigurableApplicationContext) &#123; // 显示注册spring的jvm钩子 ((ConfigurableApplicationContext) context).registerShutdownHook(); // 显示移除dubbo的jvm钩子 DubboShutdownHook.getDubboShutdownHook().unregister(); &#125; BeanFactoryUtils.addApplicationListener(context, SHUTDOWN_HOOK_LISTENER); &#125; private static class ShutdownHookListener implements ApplicationListener &#123; @Override public void onApplicationEvent(ApplicationEvent event) &#123; if (event instanceof ContextClosedEvent) &#123; DubboShutdownHook shutdownHook = DubboShutdownHook.getDubboShutdownHook(); shutdownHook.doDestroy(); &#125; &#125; &#125;&#125; 说明 dubbo2.7.x优雅停机的实现，解决了spring环境下两个钩子并发的问题，并且显示注册spring的jvm钩子。 总结优雅停机并不是java中的概念，也不是只有dubbo框架进行了扩展实现，springboot、docker等都有涉及到优雅停机。dubbo中的优雅停机是不断优化的，2.5.x中的存在一定的问题，2.6.x在一般场景下是没有问题的，2.7.x是对之前版本的完善和优化。如果 ShutdownHook 不能生效，可以在需要的时机自行调用DubboShutdownHook.destroyAll()。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"Spring","slug":"Spring","permalink":"https://gentryhuang.com/tags/Spring/"}]},{"title":"Dubbo源码分析 - 本地暴露","slug":"rpc/本地导出","date":"2020-10-14T16:00:00.000Z","updated":"2021-04-06T08:35:09.855Z","comments":false,"path":"posts/751c0982/","link":"","permalink":"https://gentryhuang.com/posts/751c0982/","excerpt":"","text":"前言有了前面一系列文章铺垫，再来看服务暴露与服务引用就简单很多了。本地暴露需要配置、SPI、动态代理、协议等知识，其中协议部分会在后面的文章中着重分析。 配置承载无论是服务暴露还是服务引用，Dubbo 框架都会根据配置覆盖策略对配置项进行聚合处理，配置覆盖策略参见官网 。Dubbo 支持动态添加配置项即服务治理，其中不允许 Provider 端配置项透传到客户端的都会进行特殊处理. 服务暴露配置 仅本地暴露1&lt;dubbo:service scope=\"local\" /&gt; 仅远程暴露1&lt;dubbo:service scope=\"remote\" /&gt; 本暴露和远程暴露1在不配置 scope 的情况下，默认两种方式都暴露 不暴露1&lt;dubbo:service scope=\"none\" /&gt; 服务暴露机制Dubbo 服务暴露分为两部分，先将持有的服务信息（服务对象，服务接口，服务 URL信息）通过动态代理工厂转换成 Invoker ，再把 Invoker 通过具体的协议转成 Exporter（注意，这里涉及到多协议的知识后面文章会详细分析） 。Dubbo 框架在进行服务暴露时，无论是 API 配置、XML 配置还是注解配置，最终都会转成 ServiceBean，它继承自 ServiceConfig ，注意这里是指使用 Spring 环境时，如果仅使用 Dubbo API 配置的话，会转成 ServiceConfig 。因为 Spring 是主流，下面没有特别说明都是在 Spring 环境下。 服务暴露方式Dubbo 支持两种服务暴露方式，分为延迟暴露和立即暴露。延迟暴露的入口是 ServiceBean 的 afterPropertiesSet 方法，立即暴露的入口是 ServiceBean 的 onApplicationEvent 方法。 Spring支持的 Dubbo IOC1234567891011121314151617181920212223242526272829303132333435public class ServiceBean&lt;T&gt; extends ServiceConfig&lt;T&gt; implements InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener&lt;ContextRefreshedEvent&gt;, BeanNameAware, ApplicationEventPublisherAware &#123; @Override public void setApplicationContext(ApplicationContext applicationContext) &#123; this.applicationContext = applicationContext; // 为Spring拓展工厂注入上下文 ,用于Dubbo IOC SpringExtensionFactory.addApplicationContext(applicationContext); if (applicationContext != null) &#123; SPRING_CONTEXT = applicationContext; try &#123; Method method = applicationContext.getClass().getMethod(\"addApplicationListener\", new Class&lt;?&gt;[]&#123;ApplicationListener.class&#125;); // backward compatibility to spring 2.0.1 method.invoke(applicationContext, new Object[]&#123;this&#125;); // 当前Spring容器是否支持上下文监听 supportedApplicationListener = true; &#125; catch (Throwable t) &#123; if (applicationContext instanceof AbstractApplicationContext) &#123; try &#123; Method method = AbstractApplicationContext.class.getDeclaredMethod(\"addListener\", new Class&lt;?&gt;[]&#123;ApplicationListener.class&#125;); // backward compatibility to spring 2.0.1 if (!method.isAccessible()) &#123; method.setAccessible(true); &#125; method.invoke(applicationContext, new Object[]&#123;this&#125;); supportedApplicationListener = true; &#125; catch (Throwable t2) &#123; &#125; &#125; &#125; &#125; &#125; // $&#123;省略其它代码&#125;&#125; ServiceBean#setApplicationContext 方法用于将 Spring 的上下文设置设置到 SpringExtensionFactory 中，这样 Dubbo IOC 就可以使用 Spring 管理的对象了。 延迟暴露12345678910111213141516171819202122232425262728293031323334353637383940414243public class ServiceBean&lt;T&gt; extends ServiceConfig&lt;T&gt; implements InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener&lt;ContextRefreshedEvent&gt;, BeanNameAware, ApplicationEventPublisherAware &#123; /** * 服务暴露的入口，非延迟暴露 。收到 Spring 容器的刷新事件执行 * @param event */ @Override public void onApplicationEvent(ContextRefreshedEvent event) &#123; // 是否有延迟暴露 &amp;&amp; 是否已暴露 &amp;&amp; 是不是已被取消暴露 if (isDelay() &amp;&amp; !isExported() &amp;&amp; !isUnexported()) &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"The service ready on spring started. service: \" + getInterface()); &#125; export(); &#125; &#125; private boolean isDelay() &#123; // 获取 delay Integer delay = getDelay(); ProviderConfig provider = getProvider(); if (delay == null &amp;&amp; provider != null) &#123; // 如果前面获取的 delay 为空，这里继续获取 delay = provider.getDelay(); &#125; /** * 1 判断 delay 是否为空，或者等于 -1，当 delay 为空，或者等于-1时，该方法返回 true，而不是 false * 2 supportedApplicationListener 变量用于表示当前的 Spring 容器是否支持 ApplicationListener，这个值初始为 false。 * 在 Spring 容器将自己设置到 ServiceBean 中时，ServiceBean 的 setApplicationContext 方法会检测 Spring 容器是否支持 ApplicationListener,若支持，则将 supportedApplicationListener 置为 true */ return supportedApplicationListener &amp;&amp; (delay == null || delay == -1); &#125; public Integer getDelay() &#123; // 配置项 return delay; &#125; // $&#123;省略其它代码&#125;&#125; 注意，这里的 isDelay 方法，当方法返回 true 时，表示无需延迟导出。返回 false 时，表示需要延迟导出，与字面意思是相反的。 立即暴露123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145public class ServiceBean&lt;T&gt; extends ServiceConfig&lt;T&gt; implements InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener&lt;ContextRefreshedEvent&gt;, BeanNameAware, ApplicationEventPublisherAware &#123; /** * 服务暴露的入口，延迟暴露 * @throws Exception */ @Override @SuppressWarnings(&#123;\"unchecked\", \"deprecation\"&#125;) public void afterPropertiesSet() throws Exception &#123; if (getProvider() == null) &#123; Map&lt;String, ProviderConfig&gt; providerConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ProviderConfig.class, false, false); if (providerConfigMap != null &amp;&amp; providerConfigMap.size() &gt; 0) &#123; Map&lt;String, ProtocolConfig&gt; protocolConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ProtocolConfig.class, false, false); if ((protocolConfigMap == null || protocolConfigMap.size() == 0) &amp;&amp; providerConfigMap.size() &gt; 1) &#123; // backward compatibility List&lt;ProviderConfig&gt; providerConfigs = new ArrayList&lt;ProviderConfig&gt;(); for (ProviderConfig config : providerConfigMap.values()) &#123; if (config.isDefault() != null &amp;&amp; config.isDefault().booleanValue()) &#123; providerConfigs.add(config); &#125; &#125; if (!providerConfigs.isEmpty()) &#123; setProviders(providerConfigs); &#125; &#125; else &#123; ProviderConfig providerConfig = null; for (ProviderConfig config : providerConfigMap.values()) &#123; if (config.isDefault() == null || config.isDefault().booleanValue()) &#123; if (providerConfig != null) &#123; throw new IllegalStateException(\"Duplicate provider configs: \" + providerConfig + \" and \" + config); &#125; providerConfig = config; &#125; &#125; if (providerConfig != null) &#123; setProvider(providerConfig); &#125; &#125; &#125; &#125; if (getApplication() == null &amp;&amp; (getProvider() == null || getProvider().getApplication() == null)) &#123; Map&lt;String, ApplicationConfig&gt; applicationConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ApplicationConfig.class, false, false); if (applicationConfigMap != null &amp;&amp; applicationConfigMap.size() &gt; 0) &#123; ApplicationConfig applicationConfig = null; for (ApplicationConfig config : applicationConfigMap.values()) &#123; if (config.isDefault() == null || config.isDefault().booleanValue()) &#123; if (applicationConfig != null) &#123; throw new IllegalStateException(\"Duplicate application configs: \" + applicationConfig + \" and \" + config); &#125; applicationConfig = config; &#125; &#125; if (applicationConfig != null) &#123; setApplication(applicationConfig); &#125; &#125; &#125; if (getModule() == null &amp;&amp; (getProvider() == null || getProvider().getModule() == null)) &#123; Map&lt;String, ModuleConfig&gt; moduleConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ModuleConfig.class, false, false); if (moduleConfigMap != null &amp;&amp; moduleConfigMap.size() &gt; 0) &#123; ModuleConfig moduleConfig = null; for (ModuleConfig config : moduleConfigMap.values()) &#123; if (config.isDefault() == null || config.isDefault().booleanValue()) &#123; if (moduleConfig != null) &#123; throw new IllegalStateException(\"Duplicate module configs: \" + moduleConfig + \" and \" + config); &#125; moduleConfig = config; &#125; &#125; if (moduleConfig != null) &#123; setModule(moduleConfig); &#125; &#125; &#125; if ((getRegistries() == null || getRegistries().isEmpty()) &amp;&amp; (getProvider() == null || getProvider().getRegistries() == null || getProvider().getRegistries().isEmpty()) &amp;&amp; (getApplication() == null || getApplication().getRegistries() == null || getApplication().getRegistries().isEmpty())) &#123; Map&lt;String, RegistryConfig&gt; registryConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, RegistryConfig.class, false, false); if (registryConfigMap != null &amp;&amp; registryConfigMap.size() &gt; 0) &#123; List&lt;RegistryConfig&gt; registryConfigs = new ArrayList&lt;RegistryConfig&gt;(); for (RegistryConfig config : registryConfigMap.values()) &#123; if (config.isDefault() == null || config.isDefault().booleanValue()) &#123; registryConfigs.add(config); &#125; &#125; if (registryConfigs != null &amp;&amp; !registryConfigs.isEmpty()) &#123; super.setRegistries(registryConfigs); &#125; &#125; &#125; if (getMonitor() == null &amp;&amp; (getProvider() == null || getProvider().getMonitor() == null) &amp;&amp; (getApplication() == null || getApplication().getMonitor() == null)) &#123; Map&lt;String, MonitorConfig&gt; monitorConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, MonitorConfig.class, false, false); if (monitorConfigMap != null &amp;&amp; monitorConfigMap.size() &gt; 0) &#123; MonitorConfig monitorConfig = null; for (MonitorConfig config : monitorConfigMap.values()) &#123; if (config.isDefault() == null || config.isDefault().booleanValue()) &#123; if (monitorConfig != null) &#123; throw new IllegalStateException(\"Duplicate monitor configs: \" + monitorConfig + \" and \" + config); &#125; monitorConfig = config; &#125; &#125; if (monitorConfig != null) &#123; setMonitor(monitorConfig); &#125; &#125; &#125; if ((getProtocols() == null || getProtocols().isEmpty()) &amp;&amp; (getProvider() == null || getProvider().getProtocols() == null || getProvider().getProtocols().isEmpty())) &#123; Map&lt;String, ProtocolConfig&gt; protocolConfigMap = applicationContext == null ? null : BeanFactoryUtils.beansOfTypeIncludingAncestors(applicationContext, ProtocolConfig.class, false, false); if (protocolConfigMap != null &amp;&amp; protocolConfigMap.size() &gt; 0) &#123; List&lt;ProtocolConfig&gt; protocolConfigs = new ArrayList&lt;ProtocolConfig&gt;(); for (ProtocolConfig config : protocolConfigMap.values()) &#123; if (config.isDefault() == null || config.isDefault().booleanValue()) &#123; protocolConfigs.add(config); &#125; &#125; if (protocolConfigs != null &amp;&amp; !protocolConfigs.isEmpty()) &#123; super.setProtocols(protocolConfigs); &#125; &#125; &#125; if (getPath() == null || getPath().length() == 0) &#123; if (beanName != null &amp;&amp; beanName.length() &gt; 0 &amp;&amp; getInterface() != null &amp;&amp; getInterface().length() &gt; 0 &amp;&amp; beanName.startsWith(getInterface())) &#123; setPath(beanName); &#125; &#125; // 延迟暴露 if (!isDelay()) &#123; export(); &#125; &#125; // $&#123;省略其它代码&#125;&#125; ServiceBean#afterPropertiesSet 的方法不仅支持延迟暴露，还会在 Spring 生命周期内把 Dubbo 的核心配置承载对象设置到 ServiceBean 中（或其父类中）。ServiceBean 配置继承关系如下： 123456- AbstractConfig - AbstractMethodConfig - AbstractInterfaceConfig - AbstractServiceConfig - ServiceConfig - ServiceBean 关于配置在之前的文章中应详细介绍，可以参考 API和属性配置 。 服务暴露过程 上图是服务本地暴露的主要流程，配置检查和初始化完成后，生成 URL，然后将服务导出到 JVM 中。配置加载及配置承载对象的初始对应的三种方式在前面的文章中已经详细分析过，可以参考 API和属性配置 、XML配置 、注解配置 。下面分析具体源码。 源码分析以延迟暴露的方式进行分析，默认情况下就是延迟暴露的方式。ServiceBean 是 Dubbo 框架与 Spring 框架进行整合的关键，可以看做是两个框架之间的桥梁。ReferenceBean 具有同样的作用。 1234567891011121314151617181920public class ServiceBean&lt;T&gt; extends ServiceConfig&lt;T&gt; implements InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener&lt;ContextRefreshedEvent&gt;, BeanNameAware, ApplicationEventPublisherAware &#123; @Override public void export() &#123; // 调用父类 ServiceConfig 的 export 方法进行服务暴露 super.export(); // 发布服务暴露完成的事件 publishExportEvent(); &#125; private void publishExportEvent() &#123; ServiceBeanExportedEvent exportEvent = new ServiceBeanExportedEvent(this); applicationEventPublisher.publishEvent(exportEvent); &#125; // $&#123;省略其它代码&#125;&#125; ServiceBean 中的属性 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class ServiceBean&lt;T&gt; extends ServiceConfig&lt;T&gt; implements InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener&lt;ContextRefreshedEvent&gt;, BeanNameAware, ApplicationEventPublisherAware &#123; private static final long serialVersionUID = 213195494150089726L; /** * Spring 上下文 */ private static transient ApplicationContext SPRING_CONTEXT; /** * Dubbo 服务注解 */ private final transient Service service; /** * Spring 上下文 */ private transient ApplicationContext applicationContext; /** * 服务名 */ private transient String beanName; /** * 是否支持 Spring 上下文监听器 */ private transient boolean supportedApplicationListener; /** * Spring 事件发布对象 */ private ApplicationEventPublisher applicationEventPublisher; /** * 无参构造方法 */ public ServiceBean() &#123; super(); this.service = null; &#125; public ServiceBean(Service service) &#123; super(service); this.service = service; &#125; public static ApplicationContext getSpringContext() &#123; return SPRING_CONTEXT; &#125; /** * 注入事件发布对象 * * @param applicationEventPublisher * @since 2.6.5 */ @Override public void setApplicationEventPublisher(ApplicationEventPublisher applicationEventPublisher) &#123; this.applicationEventPublisher = applicationEventPublisher; &#125; // $&#123;省略其它代码&#125;&#125; 准备工作在服务暴露之前，Dubbo 需要检查配置，或者补充缺省配置。配置检查完毕后，会根据配置组装 URL 。在 Dubbo 中，URL 十分重要，详细参见 URL统一模型 。 检查配置我们继续从入口看起，ServiceBean 的父类 ServiceConfig 类，下面我们先看下这个类中的属性。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public class ServiceConfig&lt;T&gt; extends AbstractServiceConfig &#123; private static final long serialVersionUID = 3033787999037024738L; /** * 自适应 Protocol 实现对象 */ private static final Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension(); /** * 自适应 ProxyFactory 实现对象 */ private static final ProxyFactory proxyFactory = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension(); /** * 随机端口 */ private static final Map&lt;String, Integer&gt; RANDOM_PORT_MAP = new HashMap&lt;String, Integer&gt;(); /** * 延时暴露线程池 */ private static final ScheduledExecutorService delayExportExecutor = Executors.newSingleThreadScheduledExecutor(new NamedThreadFactory(\"DubboServiceDelayExporter\", true)); /** * 服务URL集合 */ private final List&lt;URL&gt; urls = new ArrayList&lt;URL&gt;(); /** * 服务配置暴露的Exporter: * URL: Exporter 不一定是 1:1 的关系，需要看scope的值： * 1 scope 未设置时，会暴露Local + Remote两个，也就是URL : Exporter = 1:2 * 2 scope设置为空时，不会暴露，也就是URL:Exporter = 1:0 * 3 scope甚至为local 或 Remote 任一个时，会暴露对应的，也就是URL:Exporter = 1:1 */ private final List&lt;Exporter&lt;?&gt;&gt; exporters = new ArrayList&lt;Exporter&lt;?&gt;&gt;(); /** * 接口名 */ private String interfaceName; /** * 非配置，通过interfaceName 通过反射获得 */ private Class&lt;?&gt; interfaceClass; /** * 服务接口的实现对象 */ private T ref; /** * 服务名 */ private String path; /** * 方法配置对象集合 */ private List&lt;MethodConfig&gt; methods; /** * 提供者配置对象 */ private ProviderConfig provider; /** * 是否已经暴露 */ private transient volatile boolean exported; /** * 是否未暴露 */ private transient volatile boolean unexported; /** * 泛化 */ private volatile String generic; public ServiceConfig() &#123; &#125; public ServiceConfig(Service service) &#123; appendAnnotation(Service.class, service); &#125; // $&#123;省略其它代码&#125;&#125; 下面我们从 ServiceConfig#export 方法继续进行分析，如下： 123456789101112131415161718192021222324252627282930/** * 暴露服务入口，加jvm锁 */ public synchronized void export() &#123; // 当export 或者 delay 未配置时，从ProviderConfig对象读取 if (provider != null) &#123; if (export == null) &#123; export = provider.getExport(); &#125; if (delay == null) &#123; delay = provider.getDelay(); &#125; &#125; // 不暴露服务(export = false),则不进行暴露服务逻辑 if (export != null &amp;&amp; !export) &#123; return; &#125; // 延迟暴露的话，就是使用任务线程池ScheduledExecutorService处理 if (delay != null &amp;&amp; delay &gt; 0) &#123; delayExportExecutor.schedule(new Runnable() &#123; @Override public void run() &#123; doExport(); &#125; &#125;, delay, TimeUnit.MILLISECONDS); &#125; else &#123; doExport(); &#125; &#125; 需要注意的是，如果我们只是想本地启动服务进行一些调试工作，这个时候我们并不希望把本地启动的服务暴露出去，此时，我们就可以通过配置 export 禁止服务暴露，如： &lt;dubbo:provider export=”false” /&gt; 我们继续跟进 doExport 方法，该方法主要进行配置的处理。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152/** * 服务暴露，jvm锁 */ protected synchronized void doExport() &#123; // 检查是否可以暴露，若可以，标记已经暴露然后执行服务暴露逻辑 if (unexported) &#123; throw new IllegalStateException(\"Already unexported!\"); &#125; // 如果已经暴露了直接返回 if (exported) &#123; return; &#125; // 标记已经暴露过了 exported = true; // 校验interfaceName 是否合法，即接口名非空 if (interfaceName == null || interfaceName.length() == 0) &#123; throw new IllegalStateException(\"&lt;dubbo:service interface=\\\"\\\" /&gt; interface not allow null!\"); &#125; // 校验provider是否为空(为空则新建一个)并拼接属性配置（环境变量 + .properties文件中的 属性）到ProviderConfig对象 checkDefault(); // 检测application，module等核心配置类对象是否为空，若为空则尝试从其他配置类对象中获取对应的实例。即： 从ProviderConfig 对象中，读取application,module,registries,monitor,protocols配置对象 if (provider != null) &#123; if (application == null) &#123; application = provider.getApplication(); &#125; if (module == null) &#123; module = provider.getModule(); &#125; if (registries == null) &#123; registries = provider.getRegistries(); &#125; if (monitor == null) &#123; monitor = provider.getMonitor(); &#125; if (protocols == null) &#123; protocols = provider.getProtocols(); &#125; &#125; // 从ModuleConfig 对象中，读取registries,monitor配置对象 if (module != null) &#123; if (registries == null) &#123; registries = module.getRegistries(); &#125; if (monitor == null) &#123; monitor = module.getMonitor(); &#125; &#125; // 从ApplicationConfig 对象中，读取registries,monitor配置对象 if (application != null) &#123; if (registries == null) &#123; registries = application.getRegistries(); &#125; if (monitor == null) &#123; monitor = application.getMonitor(); &#125; &#125; // 检测ref是否泛化接口的实现 if (ref instanceof GenericService) &#123; // 设置 interfaceClass 为 GenericService.class interfaceClass = GenericService.class; if (StringUtils.isEmpty(generic)) &#123; // 设置 generic = \"true\" generic = Boolean.TRUE.toString(); &#125; // 普通接口的实现 &#125; else &#123; try &#123; // 通过反射获取对应的接口的Class interfaceClass = Class.forName(interfaceName, true, Thread.currentThread() .getContextClassLoader()); &#125; catch (ClassNotFoundException e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; // 检验接口和方法 （接口非空，方法都在接口中定义） checkInterfaceAndMethods(interfaceClass, methods); // 校验引用ref是否实现了当前接口 checkRef(); // 标记为非泛化实现 generic = Boolean.FALSE.toString(); &#125; /** 处理服务接口客户端本地代理,即本地存根。目前已经废弃，此处主要用于兼容，使用stub属性. todo 服务端没有意义 &#123;@link StubProxyFactoryWrapper#getInvoker(java.lang.Object, java.lang.Class, com.alibaba.dubbo.common.URL)&#125; */ if (local != null) &#123; // 如果local属性设置为ture，表示使用缺省代理类名，即：接口名 + Local 后缀 if (\"true\".equals(local)) &#123; local = interfaceName + \"Local\"; &#125; Class&lt;?&gt; localClass; try &#123; // 获取本地存根类 localClass = ClassHelper.forNameWithThreadContextClassLoader(local); &#125; catch (ClassNotFoundException e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; // 检测本地存根类是否可赋值给接口类，若不可赋值则会抛出异常，提醒使用者本地存根类类型不合法 if (!interfaceClass.isAssignableFrom(localClass)) &#123; throw new IllegalStateException(\"The local implementation class \" + localClass.getName() + \" not implement interface \" + interfaceName); &#125; &#125; /** 处理服务接口客户端本地代理(stub 属性)相关，即本地存根。目的：想在客户端【服务消费方】执行需要的逻辑，不局限服务提供的逻辑。本地存根类编写方式是固定。todo 服务端没有意义 &#123;@link StubProxyFactoryWrapper#getInvoker(java.lang.Object, java.lang.Class, com.alibaba.dubbo.common.URL)&#125;*/ if (stub != null) &#123; // 如果stub属性设置为ture，表示使用缺省代理类名，即：接口名 + Stub 后缀 if (\"true\".equals(stub)) &#123; stub = interfaceName + \"Stub\"; &#125; Class&lt;?&gt; stubClass; try &#123; // 获取本地存根类 stubClass = ClassHelper.forNameWithThreadContextClassLoader(stub); &#125; catch (ClassNotFoundException e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; // 判断interfaceClass 是否是 stubClass 的接口，即 检测本地存根类是否可赋值给接口类，若不可赋值则会抛出异常，提醒使用者本地存根类类型不合法 if (!interfaceClass.isAssignableFrom(stubClass)) &#123; throw new IllegalStateException(\"The stub implementation class \" + stubClass.getName() + \" not implement interface \" + interfaceName); &#125; &#125; // 校验ApplicationConfig配置 checkApplication(); // 校验RegistryConfig配置 checkRegistry(); // 校验ProtocolConfig配置数组 checkProtocol(); // 读取环境变量和properties配置到ServiceConfig对象（自己） appendProperties(this); // 校验Stub和Mock相关的配置 checkStubAndMock(interfaceClass); // 服务路径，缺省是接口名 if (path == null || path.length() == 0) &#123; path = interfaceName; &#125; // 暴露服务 doExportUrls(); /** * 1 ProviderModel 表示服务提供者模型，此对象中存储了和服务提供者相关的信息，比如服务的配置信息，服务实例等。每个被导出的服务对应一个 ProviderModel * 2 ApplicationModel 持有所有的 ProviderModel */ ProviderModel providerModel = new ProviderModel(getUniqueServiceName(), this, ref); ApplicationModel.initProviderModel(getUniqueServiceName(), providerModel); &#125; 以上就是配置检查的相关分析，下面对配置检查的主要逻辑进行简单的总结，如下： 检测 dubbo:service 标签的 interface 属性合法性，不合法则抛出异常 检测 ProviderConfig、ApplicationConfig 等核心配置类对象是否为空，若为空，则尝试创建或从其他配置类对象中获取相应的实例。 检测并处理泛化服务和普通服务类 检测本地存根配置，并进行相应的处理 对 ApplicationConfig、RegistryConfig 等配置类进行检测，并读取环境变量和properties配置到配置承载对象中 设置配置到配置承载对象在之前的文章中详细说明了，可以参见 API和属性配置 。 多协议多注册中心暴露Dubbo 允许使用不同的协议暴露服务，也支持向多个注册中心注册服务，Dubbo 在 ServiceConifg#doExportUrls 中对多协议，多注册中心进行了支持，代码如下： 12345678private void doExportUrls() &#123; // 加载注册中心URL 数组 【协议已经处理过，不再是配置的注册中心协议 如：zookeeper ,而是统一替换成了registry】 List&lt;URL&gt; registryURLs = loadRegistries(true); // 遍历协议集合，支持多协议暴露。 for (ProtocolConfig protocolConfig : protocols) &#123; doExportUrlsFor1Protocol(protocolConfig, registryURLs); &#125; &#125; 上面代码比较简单，首先是通过 loadRegistries 加载注册中心URL，然后再遍历 ProtocolConfig 集合使用具体的协议导出每个服务。并在导出服务的过程中，将服务注册到注册中心。下面，我们先来看一下 loadRegistries 方法的逻辑。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217/** * 加载注册中心URL数组 * * @param provider 是否是服务提供者 * @return URL数组 */ protected List&lt;URL&gt; loadRegistries(boolean provider) &#123; // 校验RegistryConfig 配置数组，不存在会抛出异常，并且该方法会初始化RegistryConfig的配置属性【见API与属性配置】 checkRegistry(); // 创建注册中心URL数组 List&lt;URL&gt; registryList = new ArrayList&lt;URL&gt;(); if (registries != null &amp;&amp; !registries.isEmpty()) &#123; // 遍历RegistryConfig 数组 for (RegistryConfig config : registries) &#123; // 获取注册中心的地址 String address = config.getAddress(); // 地址为空就使用 0.0.0.0 任意地址 if (address == null || address.length() == 0) &#123; address = Constants.ANYHOST_VALUE; &#125; // 如果配置了启动参数的注册中心地址，它的优先级最高，就进行覆盖 String sysaddress = System.getProperty(\"dubbo.registry.address\"); if (sysaddress != null &amp;&amp; sysaddress.length() &gt; 0) &#123; address = sysaddress; &#125; // 选择有效的注册中心地址 if (address.length() &gt; 0 &amp;&amp; !RegistryConfig.NO_AVAILABLE.equalsIgnoreCase(address)) &#123; // 创建参数集合map,用于 URL的构建 Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); // 将应用配置对象和注册中心配置对象的属性添加到参数集合map中 appendParameters(map, application); /** * 需要注意的是：RegistryConfig 的 getAddress方法上使用了 @Parameter(excluded = true)注解，因此它的address属性不会加入到参数集合map中 * @Parameter(excluded = true) * public String getAddress() &#123;return address;&#125; */ appendParameters(map, config); // 添加 path,dubbo,timestamp,pid 到参数集合map中 map.put(\"path\", RegistryService.class.getName()); // 这里的path要和服务暴露逻辑中的path区分，注册中心的URL中的path为RegistryService的全路径名 map.put(\"dubbo\", Version.getProtocolVersion()); map.put(Constants.TIMESTAMP_KEY, String.valueOf(System.currentTimeMillis())); if (ConfigUtils.getPid() &gt; 0) &#123; map.put(Constants.PID_KEY, String.valueOf(ConfigUtils.getPid())); &#125; // 参数集合map中不存在 protocol 参数【以上配置对象的属性中没有有效的协议protocol参数】，就默认 使用 dubbo 作为 协议protocol的值 if (!map.containsKey(\"protocol\")) &#123; // todo remote扩展实现已经不存在了，不需考虑这种情况 if (ExtensionLoader.getExtensionLoader(RegistryFactory.class).hasExtension(\"remote\")) &#123; map.put(\"protocol\", \"remote\"); &#125; else &#123; map.put(\"protocol\", \"dubbo\"); &#125; &#125; // 解析地址，创建 URL数组，注意address可能包含多个注册中心ip, 【数组大小可能为一】 List&lt;URL&gt; urls = UrlUtils.parseURLs(address, map); // 循环 dubbo Register url for (URL url : urls) &#123; // 设置 registry=$&#123;protocol&#125;参数,设置到注册中心的 URL的参数部分的位置上，并且是追加式的添加 url = url.addParameter(Constants.REGISTRY_KEY, url.getProtocol()); // 重置 URL中的 protocol属性为 'registry',即将URL的协议头设置为'registry' url = url.setProtocol(Constants.REGISTRY_PROTOCOL); /** * 通过判断条件，决定是否添加url到registryList中，条件如下： * 1 如果是服务提供者,是否只订阅不注册，如果是就不添加到注册中心URL数组中 * 2 如果是服务消费者，是否是只注册不订阅，如果是就不添加到注册中心URL数组中 */ if ((provider &amp;&amp; url.getParameter(Constants.REGISTER_KEY, true)) || (!provider &amp;&amp; url.getParameter(Constants.SUBSCRIBE_KEY, true))) &#123; registryList.add(url); &#125; &#125; &#125; &#125; &#125; return registryList; &#125; /** * 解析注册中心地址，创建 URL数组 * * @param address * @param defaults * @return */ public static List&lt;URL&gt; parseURLs(String address, Map&lt;String, String&gt; defaults) &#123; // 判断注册中心地址的有效性 if (address == null || address.length() == 0) &#123; return null; &#125; // 注册中心地址address 可以使用\"|\"或\";\"作为分割符，设置多个注册中心分组。注意：一个注册中心集群是一个分组而不是多个。 String[] addresses = Constants.REGISTRY_SPLIT_PATTERN.split(address); if (addresses == null || addresses.length == 0) &#123; return null; //here won't be empty &#125; List&lt;URL&gt; registries = new ArrayList&lt;URL&gt;(); // 遍历注册中心分组 for (String addr : addresses) &#123; registries.add(parseURL(addr, defaults)); &#125; return registries; &#125; /** * 解析单个 URL，将defaults属性集合 里的参数合并到 注册中心地址address中，合并逻辑： * 使用 defaults 集合对注册中心urL的属性 进行 '查漏补缺', 即 将defaults集合中不在 注册中心url上的属性 设置到url上，存在则忽略 * * @param address 注册中心地址 * @param defaults 参数集合 * @return Dubbo URL */ public static URL parseURL(String address, Map&lt;String, String&gt; defaults) &#123; if (address == null || address.length() == 0) &#123; return null; &#125; String url; if (address.indexOf(\"://\") &gt;= 0) &#123; url = address; &#125; else &#123; String[] addresses = Constants.COMMA_SPLIT_PATTERN.split(address); url = addresses[0]; if (addresses.length &gt; 1) &#123; StringBuilder backup = new StringBuilder(); for (int i = 1; i &lt; addresses.length; i++) &#123; if (i &gt; 1) &#123; backup.append(\",\"); &#125; backup.append(addresses[i]); &#125; url += \"?\" + Constants.BACKUP_KEY + \"=\" + backup.toString(); &#125; &#125; String defaultProtocol = defaults == null ? null : defaults.get(\"protocol\"); if (defaultProtocol == null || defaultProtocol.length() == 0) &#123; defaultProtocol = \"dubbo\"; &#125; String defaultUsername = defaults == null ? null : defaults.get(\"username\"); String defaultPassword = defaults == null ? null : defaults.get(\"password\"); int defaultPort = StringUtils.parseInteger(defaults == null ? null : defaults.get(\"port\")); String defaultPath = defaults == null ? null : defaults.get(\"path\"); Map&lt;String, String&gt; defaultParameters = defaults == null ? null : new HashMap&lt;String, String&gt;(defaults); if (defaultParameters != null) &#123; defaultParameters.remove(\"protocol\"); defaultParameters.remove(\"username\"); defaultParameters.remove(\"password\"); defaultParameters.remove(\"host\"); defaultParameters.remove(\"port\"); defaultParameters.remove(\"path\"); &#125; // 分离url中的各个参数，然后根据各个参数构建标准的Dubbo URL -&gt; protocol://username:password@host:port/path?key=value&amp;key=value... URL u = URL.valueOf(url); boolean changed = false; String protocol = u.getProtocol(); String username = u.getUsername(); String password = u.getPassword(); String host = u.getHost(); int port = u.getPort(); String path = u.getPath(); Map&lt;String, String&gt; parameters = new HashMap&lt;String, String&gt;(u.getParameters()); if ((protocol == null || protocol.length() == 0) &amp;&amp; defaultProtocol != null &amp;&amp; defaultProtocol.length() &gt; 0) &#123; changed = true; protocol = defaultProtocol; &#125; if ((username == null || username.length() == 0) &amp;&amp; defaultUsername != null &amp;&amp; defaultUsername.length() &gt; 0) &#123; changed = true; username = defaultUsername; &#125; if ((password == null || password.length() == 0) &amp;&amp; defaultPassword != null &amp;&amp; defaultPassword.length() &gt; 0) &#123; changed = true; password = defaultPassword; &#125; if (port &lt;= 0) &#123; if (defaultPort &gt; 0) &#123; changed = true; port = defaultPort; &#125; else &#123; changed = true; port = 9090; &#125; &#125; if (path == null || path.length() == 0) &#123; if (defaultPath != null &amp;&amp; defaultPath.length() &gt; 0) &#123; changed = true; path = defaultPath; &#125; &#125; if (defaultParameters != null &amp;&amp; defaultParameters.size() &gt; 0) &#123; for (Map.Entry&lt;String, String&gt; entry : defaultParameters.entrySet()) &#123; String key = entry.getKey(); String defaultValue = entry.getValue(); if (defaultValue != null &amp;&amp; defaultValue.length() &gt; 0) &#123; String value = parameters.get(key); if (value == null || value.length() == 0) &#123; changed = true; parameters.put(key, defaultValue); &#125; &#125; &#125; &#125; // 根据标准构建的Ddubbo URL中的参数的值是否有效，会重新构建Dubbo URL，区别在于之前无效的参数都是用默认值替换 if (changed) &#123; u = new URL(protocol, username, password, host, port, path, parameters); &#125; return u; &#125; 需要说明的是，本文主要分析 Dubbo 的本地暴露，本地暴露不会向注册中心注册服务，因为仅用于 JVM 内部调用，相关信息放在内存中。在下一篇远程暴露时会用到，这里为了完整就提前分析了。 加载注册中心URL代码还是挺复杂的，主要逻辑如下： 检测是否存在注册中心配置类，不存在则抛出异常。存在则初始化RegistryConfig的配置属性。 组装参数集合，应用于注册中心URL的属性 ‘查漏补缺’。 构建注册中心URL列表 有关注册中心URL构建还有一个数据流向操作，上面代码中也注释了，比较简单，因为会在远程暴露时用到，这里简单介绍下，以 Redis 注册中心为例进行说明，更常用 Zookeeper 作为注册中心。 组装 URL123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177/** * 使用不同的协议，逐个向注册中心分组暴露服务。该方法中包含了本地和远程两种暴露方式 * * @param protocolConfig 协议配置对象 * @param registryURLs 处理过的注册中心分组集合【已经添加了ApplicationConfig和RegistryConfig的参数】 */ private void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List&lt;URL&gt; registryURLs) &#123; // 协议名 String name = protocolConfig.getName(); // 协议名为空时，缺省设置为 dubbo if (name == null || name.length() == 0) &#123; name = \"dubbo\"; &#125; // 创建参数集合map，用于Dubbo URL 的构建（服务提供者URL） Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); // 将side,dubbo,timestamp,pid参数，添加到map集合中 map.put(Constants.SIDE_KEY, Constants.PROVIDER_SIDE); map.put(Constants.DUBBO_VERSION_KEY, Version.getProtocolVersion()); map.put(Constants.TIMESTAMP_KEY, String.valueOf(System.currentTimeMillis())); if (ConfigUtils.getPid() &gt; 0) &#123; map.put(Constants.PID_KEY, String.valueOf(ConfigUtils.getPid())); &#125; // 通过反射将各种配置对象中的属性添加到map集合中，map用于URL的构建【注意属性覆盖问题】 appendParameters(map, application); appendParameters(map, module); appendParameters(map, provider, Constants.DEFAULT_KEY); appendParameters(map, protocolConfig); appendParameters(map, this); // 将MethodConfig 对象数组添加到 map 集合中。就是将每个MethodConfig和其对应的ArgumentConfig对象数组添加到map中【处理方法相关的属性到map】 if (methods != null &amp;&amp; !methods.isEmpty()) &#123; // methods 为 MethodConfig 集合，MethodConfig 中存储了 &lt;dubbo:method&gt; 标签的配置信息 for (MethodConfig method : methods) &#123; /** * 将MethodConfig对象的属性添加到map集合中，其中属性键 = 方法名.属性名。如： * &lt;dubbo:method name=\"sleep\" retries=\"2\"&gt;&lt;/dubbo:method&gt;对应的MethodConfig，属性到map的格式：&#123;\"sleep.retries\":2&#125; */ appendParameters(map, method, method.getName()); // 当配置了 MehodConfig.retry = false 时，强制禁用重试 String retryKey = method.getName() + \".retry\"; if (map.containsKey(retryKey)) &#123; String retryValue = map.remove(retryKey); // 检测 MethodConfig retry 是否为 false，若是，则设置重试次数为0 if (\"false\".equals(retryValue)) &#123; map.put(method.getName() + \".retries\", \"0\"); &#125; &#125; // 将MethodConfig下的ArgumentConfig 对象数组即&lt;dubbo:argument&gt; 标签中的配置信息，添加到 map 集合中 List&lt;ArgumentConfig&gt; arguments = method.getArguments(); if (arguments != null &amp;&amp; !arguments.isEmpty()) &#123; for (ArgumentConfig argument : arguments) &#123; // 检测type 属性是否为空 if (argument.getType() != null &amp;&amp; argument.getType().length() &gt; 0) &#123; // 通过反射取出接口的方法列表 Method[] methods = interfaceClass.getMethods(); // 遍历接口中的方法列表 if (methods != null &amp;&amp; methods.length &gt; 0) &#123; for (int i = 0; i &lt; methods.length; i++) &#123; String methodName = methods[i].getName(); // 比对方法名，查找目标方法 if (methodName.equals(method.getName())) &#123; // 通过反射取出目标方法的参数类型列表 Class&lt;?&gt;[] argtypes = methods[i].getParameterTypes(); // 若果配置index配置项，且值不为-1 if (argument.getIndex() != -1) &#123; // 从argtypes数组中获取下标index处的元素argType，并检测ArgumentConfig中的type属性与argType名称是否一致，不一致则抛出异常 if (argtypes[argument.getIndex()].getName().equals(argument.getType())) &#123; // 将ArgumentConfig对象的属性添加到map集合中，键前缀=方法名.index，如：map = &#123;\"sleep.2\":true&#125; appendParameters(map, argument, method.getName() + \".\" + argument.getIndex()); &#125; else &#123; throw new IllegalArgumentException(\"argument config error : the index attribute and type attribute not match :index :\" + argument.getIndex() + \", type:\" + argument.getType()); &#125; &#125; else &#123; // 遍历参数类型数组argtypes，查找argument.type类型的参数 for (int j = 0; j &lt; argtypes.length; j++) &#123; Class&lt;?&gt; argclazz = argtypes[j]; // 从参数类型列表中查找类型名称为argument.type的参数 if (argclazz.getName().equals(argument.getType())) &#123; // 将ArgumentConfig对象的属性添加到map集合中 appendParameters(map, argument, method.getName() + \".\" + j); if (argument.getIndex() != -1 &amp;&amp; argument.getIndex() != j) &#123; throw new IllegalArgumentException(\"argument config error : the index attribute and type attribute not match :index :\" + argument.getIndex() + \", type:\" + argument.getType()); &#125; &#125; &#125; &#125; &#125; &#125; &#125; // 用户未配置 type 属性，但配置了index属性，且index != -1 &#125; else if (argument.getIndex() != -1) &#123; // 指定单个参数的位置 // 将ArgumentConfig对象的属性添加到map集合中 appendParameters(map, argument, method.getName() + \".\" + argument.getIndex()); &#125; else &#123; throw new IllegalArgumentException(\"argument config must set index or type attribute.eg: &lt;dubbo:argument index='0' .../&gt; or &lt;dubbo:argument type=xxx .../&gt;\"); &#125; &#125; &#125; &#125; // end of methods for &#125; //--- 检测 generic 是否 为 true ,并根据检测结果向map中添加不同的信息 ---/ // 将 generic,methods,revision 加入到数组 if (ProtocolUtils.isGeneric(generic)) &#123; map.put(Constants.GENERIC_KEY, generic); map.put(Constants.METHODS_KEY, Constants.ANY_VALUE); &#125; else &#123; // 先从MAINFEST.MF 中获取版本号，若获取不到，再从jar包命名中可能带的版本号作为结果，如 2.6.5.RELEASE。若都不存在，返回默认版本号【源码运行可能会没有】 String revision = Version.getVersion(interfaceClass, version); if (revision != null &amp;&amp; revision.length() &gt; 0) &#123; map.put(\"revision\", revision); // 修订号 &#125; // 为接口生成包裹类 Wrapper，Wrapper 中包含了接口的详细信息，如接口方法，字段信息等 String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames(); // 添加方法名到 map 中，如果包含多个方法名，则用逗号隔开，比如：method=a,b if (methods.length == 0) &#123; logger.warn(\"NO method found in service interface \" + interfaceClass.getName()); // 没有方法名就添加 method=* map.put(Constants.METHODS_KEY, Constants.ANY_VALUE); &#125; else &#123; // 将逗号作为分隔符连接方法名，并将连接后的字符串放入 map 中 map.put(Constants.METHODS_KEY, StringUtils.join(new HashSet&lt;String&gt;(Arrays.asList(methods)), \",\")); &#125; &#125; // token 【使暴露出去的服务更安全，使用token做安全校验】 if (!ConfigUtils.isEmpty(token)) &#123; if (ConfigUtils.isDefault(token)) &#123; map.put(Constants.TOKEN_KEY, UUID.randomUUID().toString()); &#125; else &#123; map.put(Constants.TOKEN_KEY, token); &#125; &#125; // 协议为injvm时，不注册，不通知 if (Constants.LOCAL_PROTOCOL.equals(protocolConfig.getName())) &#123; protocolConfig.setRegister(false); map.put(\"notify\", \"false\"); &#125; // 获得基础路径 String contextPath = protocolConfig.getContextpath(); if ((contextPath == null || contextPath.length() == 0) &amp;&amp; provider != null) &#123; contextPath = provider.getContextpath(); &#125; // ---------------------------- 主机绑定 -------------------------------------/ // 获得注册到注册中心的服务提供者host，并为map设置bind.ip , anyhost 两个key String host = this.findConfigedHosts(protocolConfig, registryURLs, map); // 获取端口，并为map设置bing.port key Integer port = this.findConfigedPorts(protocolConfig, name, map); /** * 创建Dubbo URL对象 【注意这里的 path 的值】 * 1 name: 协议名 * 2 host: 主机名 * 3 port: 端口 * 4 path: 【基础路径】/path * 5 parameters: 属性集合map */ URL url = new URL(name, host, port, (contextPath == null || contextPath.length() == 0 ? \"\" : contextPath + \"/\") + path, map); // $&#123;省略其它代码&#125;&#125; 上面的代码比较复杂，不过总体上是将配置承载对象中的属性添加到参数集合中用于构建 Dubbo URL 。其中涉及到的将配置对象的属性添加到参数集合的 appendParameters 方法可以参见 API和属性配置 。 服务暴露服务暴露的准备工作完成后，接下来就可以执行服务暴露工作了。服务暴露，分为本地暴露和远程暴露。我们先不研究细节，先从宏观层面上看一下服务暴露逻辑。如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788/** * 使用不同的协议，逐个向注册中心分组暴露服务。该方法中包含了本地和远程两种暴露方式 * * @param protocolConfig 协议配置对象 * @param registryURLs 处理过的注册中心分组集合【已经添加了ApplicationConfig和RegistryConfig的参数】 */ private void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List&lt;URL&gt; registryURLs) &#123; // $&#123;省略其它代码&#125; // 如果存在当前协议对应的 ConfiguratorFactory 扩展实现，就创建配置规则器 Configurator，将配置规则应用到url todo 这里应该不会存在把？ if (ExtensionLoader.getExtensionLoader(ConfiguratorFactory.class).hasExtension(url.getProtocol())) &#123; // 加载ConfiguratorFactory ，并生成Configurator，将配置规则应用到url中 url = ExtensionLoader.getExtensionLoader(ConfiguratorFactory.class).getExtension(url.getProtocol()).getConfigurator(url).configure(url); &#125; // 从URL中获取暴露方式 String scope = url.getParameter(Constants.SCOPE_KEY); // 如果 scope = none，则不进行暴露，直接结束 if (!Constants.SCOPE_NONE.equalsIgnoreCase(scope)) &#123; // scope != remote，本地暴露 if (!Constants.SCOPE_REMOTE.equalsIgnoreCase(scope)) &#123; exportLocal(url); &#125; // scope != local，远程暴露，包含了服务暴露和服务注册两个过程 if (!Constants.SCOPE_LOCAL.equalsIgnoreCase(scope)) &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Export dubbo service \" + interfaceClass.getName() + \" to url \" + url); &#125; if (registryURLs != null &amp;&amp; !registryURLs.isEmpty()) &#123; // 遍历注册中心URL数组 for (URL registryURL : registryURLs) &#123; // dynamic属性：服务是否动态注册，如果设为false,注册后将显示disable状态，需要人工启用，并且服务提供者停止时，也不会自动下线，需要人工禁用 url = url.addParameterIfAbsent(Constants.DYNAMIC_KEY, registryURL.getParameter(Constants.DYNAMIC_KEY)); // 获取监控中心URL URL monitorUrl = loadMonitor(registryURL); if (monitorUrl != null) &#123; // 监控URL不能空，就将监控中心的URL作为monitor参数添加到服务提供者的URL中，并且需要编码。通过这样方式，服务提供者的URL中就包含了监控中心的配置 url = url.addParameterAndEncoded(Constants.MONITOR_KEY, monitorUrl.toFullString()); &#125; if (logger.isInfoEnabled()) &#123; logger.info(\"Register dubbo service \" + interfaceClass.getName() + \" url \" + url + \" to registry \" + registryURL); &#125; // 获取配置的动态代理的生成方式 &lt;dubbo:service proxy=\"\"/&gt;,可选jdk/javassist,默认使用javassist String proxy = url.getParameter(Constants.PROXY_KEY); if (StringUtils.isNotEmpty(proxy)) &#123; registryURL = registryURL.addParameter(Constants.PROXY_KEY, proxy); &#125; // 使用ProxyFactory 创建 AbstractProxyInvoker 对象 Invoker&lt;?&gt; invoker = proxyFactory.getInvoker( ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(Constants.EXPORT_KEY, url.toFullString()) ); // 创建 DelegateProviderMetaDataInvoker 对象，在Invoker对象基础上，增加了当前服务提供者ServiceConfig对象，即把Invoker和ServiceConfig结合在了一起 DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this); // 暴露服务，生成Exporter: Exporter&lt;?&gt; exporter = protocol.export(wrapperInvoker); // 添加到 Exporter 集合 exporters.add(exporter); &#125; &#125; else &#123; // 无效注册中心，仅暴露服务 // 使用ProxyFactory 创建 Invoker 对象 Invoker&lt;?&gt; invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, url); // 创建 DelegateProviderMetaDataInvoker 对象 DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this); // 使用Protocol 暴露Invoker 对象 Exporter&lt;?&gt; exporter = protocol.export(wrapperInvoker); // 添加到 Exporter 集合 exporters.add(exporter); &#125; &#125; &#125; this.urls.add(url);&#125; 从宏观层面上看，服务暴露的方式取决于 scope 参数，该参数值在文章前面有具体说明。 创建 Invoker不管是本地暴露，还是远程暴露，进行服务暴露之前，都需要先创建 Invoker ，这一点非常重要。在 Dubbo 中，Invoker 是一个非常重要的模型，无论是在服务提供端，还是服务消费端均会出现 Invoker。Dubbo 官方文档中对 Invoker 进行了说明。 Invoker 是实体域，它是 Dubbo 的核心模型，其它模型都向它靠扰，或转换成它，它代表一个可执行体，可向它发起 invoke 调用，它有可能是一个本地的实现，也可能是一个远程的实现，也可能一个集群实现。 Invoker 是由 ProxyFactory 创建的，Dubbo 默认的 ProxyFactory 实现类是 JavassistProxyFactory ，在 Javassist动态代理 中进行了详细的说明。 本地暴露1234567891011121314151617181920212223242526272829303132/** * 本地暴露 * * @param url */ @SuppressWarnings(&#123;\"unchecked\", \"rawtypes\"&#125;) private void exportLocal(URL url) &#123; /** * 1 若果URl的协议头是injvm，说明已经暴露到本地了，无需再次暴露 * 2 非injvm协议就基于原有的URL构建协议为injvm，主机地址 127.0.0.1，端口为0 的新的 URL */ if (!Constants.LOCAL_PROTOCOL.equalsIgnoreCase(url.getProtocol())) &#123; URL local = URL.valueOf(url.toFullString()) .setProtocol(Constants.LOCAL_PROTOCOL) .setHost(LOCALHOST) .setPort(0); // 添加服务接口的实现类【仅用于RestProtocol协议】到线程变量中 ServiceClassHolder.getInstance().pushServiceClass(getServiceClass(ref)); // 创建 Invoker，这里 proxyFactory 会在运行时执行 JavassistProxyFactory 的 getInvoker 方法 （默认情况，也可通过参数指定） Invoker invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, local); // 这里的 protocol 会在运行时调用 InjvmProtocol 的 export 方法 Exporter&lt;?&gt; exporter = protocol.export(invoker); // 添加到Exporter集合中 exporters.add(exporter); logger.info(\"Export dubbo service \" + interfaceClass.getName() + \" to local registry\"); &#125; &#125; 本地暴露的代码比较简单，下面总结下流程： 根据 URL 协议头决定是否暴露服务，如果需要暴露就创建 injvm 协议的 URL 然后通过 SPI 机制分别获取运行时的 proxyFactory 和 protocol 扩展实现，这就是 Dubbo SPI 自适应的好处 使用proxyFactory创建 Invoker(AbstractProxyInvoker) 使用protocol进行服务暴露 以上流程的前 3 步已经分析过，下面对第 4 步进行分析。 Protocol本地暴露涉及的 Protocol 类图如下： 由上图的 UML 类图可知，Protocol 有两个 Wrapper 类，由 Dubbo SPI 机制我们知道执行 Protocol#export 方法的顺序： Protocol$Adaptive =&gt; ProtocolListenerWrapper ==&gt; ProtocolFilterWrapper =&gt; InjvmProtocol 下面对执行链进行分析，其中 Protocol 自适应扩展对象原理在 自适应扩展 中已经详细分析。这里说明下，上图的 UML 类图中其它的先不做分析，只关注本地暴露相关的， Dubbo 中的多协议部分会单独作为一个模块分析。 ProtocolListenerWrapper实现 Protocol 接口，是 Protocol 的 Wrapper 类，在服务暴露时用于给 Exporter 添加监听器，监听 Exporter 暴露和取消。 1234567891011121314151617181920212223242526272829303132333435363738394041public class ProtocolListenerWrapper implements Protocol &#123; private final Protocol protocol; public ProtocolListenerWrapper(Protocol protocol) &#123; if (protocol == null) &#123; throw new IllegalArgumentException(\"protocol == null\"); &#125; this.protocol = protocol; &#125; /** * * @param invoker Service invoker * @param &lt;T&gt; * @return * @throws RpcException */ @Override public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; // registry协议开头的服务暴露逻辑，则跳过 if (Constants.REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) &#123; return protocol.export(invoker); &#125; // 服务暴露，创建 Exporter Exporter&lt;T&gt; export = protocol.export(invoker); // 获取 ExporterListener List&lt;ExporterListener&gt; exporterListeners = Collections.unmodifiableList(ExtensionLoader.getExtensionLoader(ExporterListener.class) .getActivateExtension(invoker.getUrl(), Constants.EXPORTER_LISTENER_KEY)); // 使用 ListenerExporterWrapper 包装 Exporter，为 Exporter邦定监听器 return new ListenerExporterWrapper&lt;T&gt;(export, exporterListeners); &#125; // $&#123;省略其它代码&#125;&#125; ProtocolListenerWrapper 在服务暴露流程中的逻辑如下： 判断当前Invoker对应的URL协议是否为 registry，远程暴露时需要用到注册中心，执行到这里时协议会为 registry，这种情况就无需绑定监听器。 使用具体协议暴露服务，创建 Exporter 获取ExporterListener，用户可以自行实现监听器。注意，实现的监听器是自动激活类型 将获取的监听器绑定到服务暴露生成的Exporter ExporterExporter 是 Invoker 服务在 Protocol 上的对象。更多可以参考 Dubbo项目结构总览 。本地暴露涉及到的 UML 类图如下： InjvmExporter实现 AbstractExporter 抽象类，Injvm Exporter 实现类，代码如下： 1234567891011121314151617181920212223242526272829303132333435363738class InjvmExporter&lt;T&gt; extends AbstractExporter&lt;T&gt; &#123; /** * 服务键 */ private final String key; /** * Exporter 集合 * key : 服务键 * 该值实际就是 &#123;@link com.alibaba.dubbo.rpc.protocol.AbstractProtocol#exporterMap&#125; */ private final Map&lt;String, Exporter&lt;?&gt;&gt; exporterMap; /** * 构造方法，发起暴露 * * @param invoker invoker * @param key 服务键 * @param exporterMap AbstractExporter的缓存 */ InjvmExporter(Invoker&lt;T&gt; invoker, String key, Map&lt;String, Exporter&lt;?&gt;&gt; exporterMap) &#123; super(invoker); this.key = key; this.exporterMap = exporterMap; // 加入到Exporter集合[会把自己加入到AbstractProtocol中的Map中] exporterMap.put(key, this); &#125; /** * 取消暴露 */ @Override public void unexport() &#123; super.unexport(); // 移除 key对应的Exporter exporterMap.remove(key); &#125;&#125; InjvmExporter 会将自身的对象放入到其父类 AbstractExporter 和自身的缓存中，这也是本地暴露的本质。 ListenerExporterWrapper实现 Exporter 接口，具有监听器功能的 Exporter 的 Wrapper 类，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778/** * ListenerExporter * &lt;p&gt; * 实现 Exporter接口，具有监听器功能的Exporter包装器 */public class ListenerExporterWrapper&lt;T&gt; implements Exporter&lt;T&gt; &#123; private static final Logger logger = LoggerFactory.getLogger(ListenerExporterWrapper.class); /** * 真实的Exporter 对象 */ private final Exporter&lt;T&gt; exporter; /** * Exporter 监听器数组 */ private final List&lt;ExporterListener&gt; listeners; public ListenerExporterWrapper(Exporter&lt;T&gt; exporter, List&lt;ExporterListener&gt; listeners) &#123; if (exporter == null) &#123; throw new IllegalArgumentException(\"exporter == null\"); &#125; this.exporter = exporter; this.listeners = listeners; // 执行监听器 if (listeners != null &amp;&amp; !listeners.isEmpty()) &#123; RuntimeException exception = null; for (ExporterListener listener : listeners) &#123; if (listener != null) &#123; try &#123; // 事件触发【服务导出后】回调，可以进行自定义实现ExporterListener，重新该方法 listener.exported(this); &#125; catch (RuntimeException t) &#123; logger.error(t.getMessage(), t); exception = t; &#125; &#125; &#125; if (exception != null) &#123; throw exception; &#125; &#125; &#125; @Override public Invoker&lt;T&gt; getInvoker() &#123; return exporter.getInvoker(); &#125; /** * 取消服务暴露 */ @Override public void unexport() &#123; try &#123; exporter.unexport(); &#125; finally &#123; // 执行监听器 if (listeners != null &amp;&amp; !listeners.isEmpty()) &#123; RuntimeException exception = null; for (ExporterListener listener : listeners) &#123; if (listener != null) &#123; try &#123; listener.unexported(this); &#125; catch (RuntimeException t) &#123; logger.error(t.getMessage(), t); exception = t; &#125; &#125; &#125; if (exception != null) &#123; throw exception; &#125; &#125; &#125; &#125;&#125; ListenerExporterWrapper是一个 Wrapper 类，是用来给 Exporter 绑定 ExporterListener 监听器的。 ExporterListener1234567891011121314151617181920212223242526@SPIpublic interface ExporterListener &#123; /** * The exporter exported. * * 当服务暴露完成 * * @param exporter * @throws RpcException * @see com.alibaba.dubbo.rpc.Protocol#export(Invoker) */ void exported(Exporter&lt;?&gt; exporter) throws RpcException; /** * The exporter unexported. * * 当服务取消完成 * * @param exporter * @throws RpcException * @see com.alibaba.dubbo.rpc.Exporter#unexport() */ void unexported(Exporter&lt;?&gt; exporter);&#125; Exporter 的监听器，是一个扩展点。用户可以自定义实现，用来监听服务暴露。 ProtocolFilterWrapper实现 Protocol 接口，是 Protocol 的 Wrapper 类，用于给 Invoker 增加过滤链。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102public class ProtocolFilterWrapper implements Protocol &#123; private final Protocol protocol; public ProtocolFilterWrapper(Protocol protocol) &#123; if (protocol == null) &#123; throw new IllegalArgumentException(\"protocol == null\"); &#125; this.protocol = protocol; &#125; /** * 创建带Filter链的Invoker 对象 * * @param invoker Invoker对象 * @param key URL中参数名 【如：用于获得ServiceConfig或ReferenceConfig配置的自定义过滤器】 * @param group 分组 【暴露服务时：group=provider; 引用服务时：group=consumer】 * @param &lt;T&gt; * @return 在执行的时候执行Filter */ private static &lt;T&gt; Invoker&lt;T&gt; buildInvokerChain(final Invoker&lt;T&gt; invoker, String key, String group) &#123; Invoker&lt;T&gt; last = invoker; // 获取所有的过滤器，包括类上带有@Active注解的和在XML中配置的 List&lt;Filter&gt; filters = ExtensionLoader.getExtensionLoader(Filter.class).getActivateExtension(invoker.getUrl(), key, group); // 倒序循环 Filter，递归包装Invoker，就是一个链表结构： Xx1Filter-&gt;Xx2Filter-&gt;Xx3Filter-&gt;...-&gt;Invoker if (!filters.isEmpty()) &#123; for (int i = filters.size() - 1; i &gt;= 0; i--) &#123; final Filter filter = filters.get(i); final Invoker&lt;T&gt; next = last; // 创建新的Invoker 对象， 用于包装 next last = new Invoker&lt;T&gt;() &#123; @Override public Class&lt;T&gt; getInterface() &#123; return invoker.getInterface(); &#125; @Override public URL getUrl() &#123; return invoker.getUrl(); &#125; @Override public boolean isAvailable() &#123; return invoker.isAvailable(); &#125; /** * 调用Invoker的invoke方法的时候会执行 * 1 调用Filter#invoke(invoker,invocation)方法，不断执行过滤器逻辑 * 2 在Filter中会调用Invoker#invoker(invocation)方法，最后会执行到Invoker【如：InjvmInvoker,DubboInvoker等】的invoke方法 * * @param invocation * @return * @throws RpcException */ @Override public Result invoke(Invocation invocation) throws RpcException &#123; return filter.invoke(next, invocation); &#125; @Override public void destroy() &#123; invoker.destroy(); &#125; @Override public String toString() &#123; return invoker.toString(); &#125; &#125;; &#125; &#125; return last; &#125; @Override public int getDefaultPort() &#123; return protocol.getDefaultPort(); &#125; @Override public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; // 如果 Invoker的URL中 protocol=registry,说明是注册中心的协议，这种情况无需创建Filter过滤器。 if (Constants.REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) &#123; return protocol.export(invoker); &#125; // 建立带有Filter 过滤链的 Invoker，再暴露服务 return protocol.export(buildInvokerChain(invoker, Constants.SERVICE_FILTER_KEY, Constants.PROVIDER)); &#125; // $&#123;省略其它代码&#125;&#125; ProtocolFilterWrapper 在服务暴露时就做了一件事，为 Invoker 增加过滤链。其中key和group参数是用来获取自定义过滤器的，具体规则参见 Dubbo SPI 。过滤器链如下，包含 Dubbo 自带过滤器和用户自定义过滤器。 EchoFilter - 回声探测过滤器ClassLoaderFilter - 类加载器切换过滤器GenericFilter - 服务提供者的泛化调用过滤器ContextFilter - 服务提供者的上下文过滤器TraceFilter - 追踪过滤器TimeoutFilter - 服务提供者的超时过滤器MonitorFilter - 监控过滤器ExceptionFilter - 加工异常过滤器XxxFilter - 自定义过滤器 构建 Invoker 的过器滤链过程如下： 需要注意的是，返回的 Invoker 是一个匿名内部类对象，该对象的 invoke 方法没有其它逻辑，仅用来执行 Filter.invoke 方法。当向该 Invoker 发起调用时，会先执行过滤器链，只有当过滤器链执行完毕后，才会执行真正的 Invoker 的逻辑。 InjvmProtocol实现 AbstractProtocol 抽象类，Injvm 协议实现类。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * InjvmProtocol */public class InjvmProtocol extends AbstractProtocol implements Protocol &#123; /** * 协议名 */ public static final String NAME = Constants.LOCAL_PROTOCOL; /** * 端口 */ public static final int DEFAULT_PORT = 0; /** * 单例：在Dubbo SPI中，被初始化有且仅有一次 */ private static InjvmProtocol INSTANCE; public InjvmProtocol() &#123; INSTANCE = this; &#125; /** * 获得单例子 * * @return */ public static InjvmProtocol getInjvmProtocol() &#123; if (INSTANCE == null) &#123; ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(InjvmProtocol.NAME); &#125; return INSTANCE; &#125; @Override public int getDefaultPort() &#123; return DEFAULT_PORT; &#125; /** * 进行服务暴露，创建InjvmExporter[并把自己-&gt;Exporter存入到父类的 &#123;@link #exporterMap&#125; 属性中，key:当前服务键，value:Exporter] * * @param invoker Service invoker * @param &lt;T&gt; * @return * @throws RpcException */ @Override public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; // 创建Exporter，并且把自己添加到 exporterMap 中，exporterMap 是父类属性 return new InjvmExporter&lt;T&gt;(invoker, invoker.getUrl().getServiceKey(), exporterMap); &#125; injvm 协议暴露服务比较简单，直接创建 InjvmExporter 对象，然后放入内存中即可，没有其它逻辑。 小结本篇文章详细分析了 Dubbo 本地服务导出过程，包括配置检测，URL 组装，Invoker 创建过程等，下一篇文章将分析远程暴露。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"Dubbo源码分析 - 领域模型扩展","slug":"rpc/Invoker扩展","date":"2020-10-11T16:00:00.000Z","updated":"2021-04-06T08:28:59.091Z","comments":false,"path":"posts/946483bd/","link":"","permalink":"https://gentryhuang.com/posts/946483bd/","excerpt":"","text":"概述常见的领域模型在之前的文章中有所介绍，如：AbstractExpoter、AbstractInvoker、DubboExpoter、DubboInvoker、InjvmExpoter、InjvmInvoker 等，关于集群容错中涉及的领域模型将在介绍集群容错篇章进行介绍。本篇文章将对领域模型相关的扩展进行介绍，涉及的类图如下： 上图描述的是 服务暴露的监听、服务引用的监听 以及 过滤器链的构建 关系。 ProtocolListenerWrapperProtocolListenerWrapper 本身是 Protocol 扩展点的 Wrapper类， 在服务暴露和服务引用时以 Dubbo AOP 的能力分别将具有监听功能的 ExporterListener 和 InvokerListener 绑定到流程中，便于用户在 Dubbo 服务暴露和服务引用后添加自定义的业务逻辑。 Dubbo SPI12# com.alibaba.dubbo.rpc.Protocollistener&#x3D;com.alibaba.dubbo.rpc.protocol.ProtocolListenerWrapper 作为 Protocol 扩展点的 Wrapper 实现。 构造方法12345678910111213141516public class ProtocolListenerWrapper implements Protocol &#123; // 扩展点 private final Protocol protocol; // Wrapper 的格式 public ProtocolListenerWrapper(Protocol protocol) &#123; if (protocol == null) &#123; throw new IllegalArgumentException(\"protocol == null\"); &#125; this.protocol = protocol; &#125; @Override public int getDefaultPort() &#123; return protocol.getDefaultPort(); &#125;&#125; 服务暴露12345678910111213141516171819+--- ProtocolListenerWrapper @Override public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; // 1 registry协议开头的服务暴露逻辑直接返回 // 因为 RegistryProtocol 并非 Dubbo 中的具体协议，它的逻辑是在执行具体协议之前处理前置工作 if (Constants.REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) &#123; return protocol.export(invoker); &#125; // 2 暴露服务 Exporter&lt;T&gt; export = protocol.export(invoker); // 3 获得ExporterListener的激活扩展实现。可以自定义 ExporterListener 实现，并配置 @Activate注解或者xml中listener属性 List&lt;ExporterListener&gt; exporterListeners = Collections.unmodifiableList(ExtensionLoader.getExtensionLoader(ExporterListener.class) .getActivateExtension(invoker.getUrl(), Constants.EXPORTER_LISTENER_KEY)); // 4 创建带 ExporterListener的ListenerExporterWrapper，用来监控服务暴露完毕后的回调操作。 return new ListenerExporterWrapper&lt;T&gt;(export, exporterListeners); &#125; ProtocolListenerWrapper.export 用于具体协议暴露服务后增加监听器，用于监听服务暴露完成和服务取消暴露事件。使用 ListenerExporterWrapper 对 ExporterListener 进行封装。 ExporterListener1234567891011121314151617181920@SPIpublic interface ExporterListener &#123; /** * 监听服务暴露事件 * * @param exporter * @throws RpcException * @see com.alibaba.dubbo.rpc.Protocol#export(Invoker) */ void exported(Exporter&lt;?&gt; exporter) throws RpcException; /** * 监听取消暴露事件 * * @param exporter * @throws RpcException * @see com.alibaba.dubbo.rpc.Exporter#unexport() */ void unexported(Exporter&lt;?&gt; exporter);&#125; ExporterListener 是 Dubbo 的一个扩展点，其扩展实现类可以通过实现 exported() 方法和 unexported() 方法监听服务暴露事件以及取消暴露事件。ExporterListenerAdapter 是该扩展点的适配器抽象类，使用方在使用该扩展点进行功能定制时可以直接通过继承该抽象实现类即可。 ListenerExporterWrapper在 ProtocolListenerWrapper 的 export() 方法中会在原有的 Exporter 之上用 ListenerExporterWrapper 进行一层封装，ListenerExporterWrapper 的构造方法中会循环调用全部 ExporterListener.exported() 方法，通知其服务暴露的事件，核心逻辑如下所示： 1234567891011121314151617181920212223242526272829303132+--- ListenerExporterWrapper /** * 构造方法 * @param exporter 暴露的 Expoter * @param listeners 自定义的 ExporterListener */ public ListenerExporterWrapper(Exporter&lt;T&gt; exporter, List&lt;ExporterListener&gt; listeners) &#123; if (exporter == null) &#123; throw new IllegalArgumentException(\"exporter == null\"); &#125; this.exporter = exporter; this.listeners = listeners; // 在服务暴露过程中触发全部ExpoterListener监听器 if (listeners != null &amp;&amp; !listeners.isEmpty()) &#123; RuntimeException exception = null; for (ExporterListener listener : listeners) &#123; if (listener != null) &#123; try &#123; // 事件触发【服务暴露后】回调 listener.exported(this); &#125; catch (RuntimeException t) &#123; logger.error(t.getMessage(), t); exception = t; &#125; &#125; &#125; if (exception != null) &#123; throw exception; &#125; &#125; &#125; ListenerExporterWrapper.unexported() 方法的逻辑与上述 exported() 方法的实现基本类似，代码实现如下： 12345678910111213141516171819202122232425262728+--- ListenerExporterWrapper /** * 取消服务暴露 */ @Override public void unexport() &#123; try &#123; exporter.unexport(); &#125; finally &#123; // 执行监听器 if (listeners != null &amp;&amp; !listeners.isEmpty()) &#123; RuntimeException exception = null; for (ExporterListener listener : listeners) &#123; if (listener != null) &#123; try &#123; listener.unexported(this); &#125; catch (RuntimeException t) &#123; logger.error(t.getMessage(), t); exception = t; &#125; &#125; &#125; if (exception != null) &#123; throw exception; &#125; &#125; &#125; &#125; 在服务暴露时返回的就是 ListenerExporterWrapper 对象，执行取消服务暴露则会调用上述 unexport() 方法。 UML关系图 服务引用1234567891011121314151617+--- ProtocolListenerWrapper @Override public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; // 1 如果是注册中心协议，直接进入 ProtocolFilterWrapper#refer方法 if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; return protocol.refer(type, url); &#125; // 2 引用服务 Invoker&lt;T&gt; invoker = protocol.refer(type, url); // 3 获得 InvokerListener 的激活扩展实现，可以自定义 InvokerListener 实现，并配置 @Activate注解或者xml中listener属性 List&lt;InvokerListener&gt; listeners = Collections.unmodifiableList(ExtensionLoader.getExtensionLoader(InvokerListener.class) .getActivateExtension(url, Constants.INVOKER_LISTENER_KEY)); // 4 创建带 InvokerListener的 ListenerInvokerWrapper对象，用来监控服务引用后的回调操作 return new ListenerInvokerWrapper&lt;T&gt;(invoker, listeners); &#125; ProtocolListenerWrapper.refer 用于具体协议引用服务后增加监听器，用于监听服务引用完成和服务销毁事件。使用 ListenerInvokerWrapper 对 InvokerListener 进行封装。 InvokerListener1234567891011121314151617181920@SPIpublic interface InvokerListener &#123; /** * 监听服务引用事件 * * @param invoker * @throws RpcException * @see com.alibaba.dubbo.rpc.Protocol#refer(Class, com.alibaba.dubbo.common.URL) */ void referred(Invoker&lt;?&gt; invoker) throws RpcException; /** * 监听销毁引用事件 * * @param invoker * @see com.alibaba.dubbo.rpc.Invoker#destroy() */ void destroyed(Invoker&lt;?&gt; invoker);&#125; 同样地，InvokerListener 是 Dubbo 的一个扩展点，起扩展实现类可以通过实现 referred() 方法和 destroyed() 方法监听服务引用和销毁引用事件。InvokerListenerAdapter 是该扩展点的适配器抽象类，使用方在使用该扩展点进行功能定制时可以直接通过继承该抽象实现类即可。 ListenerInvokerWrapper在 ProtocolListenerWrapper 的 refer() 方法中会在原有的 Invoker 之上用 ListenerInvokerWrapper 进行一层封装，在构造方法内部会遍历整个 InvokerListener 列表，并调用每个 InvokerListener.referred() 方法，通知它们 Invoker 被引用的事件。 123456789101112131415161718192021222324+--- ListenerInvokerWrapper public ListenerInvokerWrapper(Invoker&lt;T&gt; invoker, List&lt;InvokerListener&gt; listeners) &#123; if (invoker == null) &#123; throw new IllegalArgumentException(\"invoker == null\"); &#125; // 被修饰的 Invoker 对象 this.invoker = invoker; // 监听器集合 this.listeners = listeners; // 执行监听器 if (listeners != null &amp;&amp; !listeners.isEmpty()) &#123; for (InvokerListener listener : listeners) &#123; // 在服务引用过程中触发全部InvokerListener监听器 if (listener != null) &#123; try &#123; // 当服务引用完成时会被调用 listener.referred(invoker); &#125; catch (Throwable t) &#123; logger.error(t.getMessage(), t); &#125; &#125; &#125; &#125; &#125; ListenerInvokerWrapper.destroy 方法的逻辑与上述方法基本类似，代码实现如下： 123456789101112131415161718192021+--- ListenerInvokerWrapper @Override public void destroy() &#123; try &#123; // 销毁引用 invoker.destroy(); &#125; finally &#123; // 执行监听器 if (listeners != null &amp;&amp; !listeners.isEmpty()) &#123; for (InvokerListener listener : listeners) &#123; if (listener != null) &#123; try &#123; listener.destroyed(invoker); &#125; catch (Throwable t) &#123; logger.error(t.getMessage(), t); &#125; &#125; &#125; &#125; &#125; &#125; 服务引用返回的就是 ListenerInvokerWrapper 对象，当进行引用销毁时会调用上述方法。 UML关系图 ProtocolFilterWrapperProtocolFilterWrapper 同样也是 Protocol 扩展点的 Wrapper类， 在服务暴露和服务引用时以 Dubbo AOP 的能力分别构建过滤器链。 Dubbo SPI12# com.alibaba.dubbo.rpc.Protocolfilter&#x3D;com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper 作为 Protocol 扩展点的 Wrapper 实现。 构造方法123456789101112131415public class ProtocolFilterWrapper implements Protocol &#123; // 扩展点 private final Protocol protocol; // Wrapper 的格式 public ProtocolFilterWrapper(Protocol protocol) &#123; if (protocol == null) &#123; throw new IllegalArgumentException(\"protocol == null\"); &#125; this.protocol = protocol; &#125; @Override public int getDefaultPort() &#123; return protocol.getDefaultPort(); &#125;&#125; 服务暴露1234567891011+--- ProtocolFilterWrapper @Override public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; // 1 如果是注册中心协议，无需创建Filter过滤器。 if (Constants.REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) &#123; return protocol.export(invoker); &#125; // 2 建立带有Filter 过滤链的 Invoker，暴露服务。 // Constants.PROVIDER 标识自己是服务提供者类型的调用链 return protocol.export(buildInvokerChain(invoker, Constants.SERVICE_FILTER_KEY, Constants.PROVIDER)); &#125; ProtocolFilterWrapper.export 方法会在 Invoker 的基础上创建带有 Filter 过滤器的 Invoker ，然后将处理后的 Invoker 暴露出去。 服务引用1234567891011121314+--- ProtocolFilterWrapper @Override public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; // 1 如果是注册中心协议，无需创建Filter过滤器。 if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; return protocol.refer(type, url); &#125; /** * 1 引用服务，返回 Invoker 对象 * 2 引用服务完成后，调用 buildInvokerChain(invoker,key,group)方法，创建带有Filter过滤器的Invoker对象。和服务暴露区别在group的值上， * Constants.CONSUMER 标识自己是消费类型的调用链 */ return buildInvokerChain(protocol.refer(type, url), Constants.REFERENCE_FILTER_KEY, Constants.CONSUMER); &#125; ProtocolFilterWrapper.refer 方法会将引用的 Invoker 对象包装成带有 Filter 过滤器的 Invoker 。 关于过滤器链可以参考：过滤器链 小结本篇文章介绍了服务暴露和服务引用的事件监听，触发时机是在服务暴露完成、服务引用完成，触发方式是利用 Protocol 扩展点的 Wrapper 功能，在服务暴露和服务引用的方法执行时执行自定义的监听器 ExporterListener 和 InvokerListener 的扩展实现，以完成指定功能。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"集群容错 - Mock","slug":"rpc/集群容错之Mock","date":"2020-10-05T16:00:00.000Z","updated":"2021-04-20T10:55:04.668Z","comments":false,"path":"posts/542117c1/","link":"","permalink":"https://gentryhuang.com/posts/542117c1/","excerpt":"","text":"概述Mock 机制是 RPC 框架中非常常见且有用的功能，不仅可以用来实现服务降级，还可以用来在测试中模拟返回结果以及调用的各种异常情况。Dubbo 中的 Mock 机制也叫做本地伪装，是在服务消费方实现的，具体来说就是在 Cluster 这一层实现的。Mock 机制相关的 UML 类图如下： Mock 涉及的接口比较多，整个流程贯穿 Cluster 和 Protocol 层，还可能会涉及到 Proxy 层。在介绍 Mock 机制之前，我们先简单对配置方式进行介绍。 配置Dubbo 的 Mock 机制是应用在消费端侧，而不是服务端侧。虽然服务端侧也提供了 mock 配置项，但是消费端更清楚所需的 Mock 机制。 基本使用 显示指定 Mock 类12&lt;!-- mock 指定 Mock 实现的全路径名，BarServiceMock 必须实现 BarService 接口，具体名称不重要 --&gt;&lt;dubbo:reference interface=\"com.foo.BarService\" mock=\"com.foo.BarServiceMock\" /&gt; 映射拼接到自定义 Mock 类，形式：接口 + Mock123456&lt;!-- 1 mock = true/default/fail/force 2 要求 Mock 实现所在的包名必须和服务接口的包名一致，因为使用：接口.getName() + \"Mock\" 作为 Mock 实现类的全路径名，然后利用反射获取对应的 Mock 实现类 3 这种用法不够灵活 --&gt;&lt;dubbo:reference interface=\"com.foo.BarService\" mock=\"true\" /&gt; 进阶使用return使用 return 来返回一个字符串，它表示的对象作为 Mock 的返回值。合法的字符串可以是： empty: 代表空，如果接口方法返回类型是基本类型，则是默认值；如果是集合类型，则是空值 null: null true: true false: false JSON 格式：代表反序列化 JSON 所得到的对象 1234&lt;!-- 使用 return 什么都不指定，默认返回 null --&gt;&lt;dubbo:reference interface=\"com.foo.BarService\" mock=\"return\" /&gt;&lt;!-- 以返回 null 为例--&gt;&lt;dubbo:reference interface=\"com.foo.BarService\" mock=\"return null\" /&gt; throw使用 throw 来返回一个 Exception 对象作为 Mock 的返回值。当没有指定具体异常对象时，调用出错会抛出一个默认的 RpcException 异常。当指定了具体的异常时，调用出错会抛出指定的具体异常。 1234&lt;!-- 当调用出错时，抛出一个默认的 RpcException --&gt;&lt;dubbo:reference interface=\"com.foo.BarService\" mock=\"throw\"/&gt;&lt;!-- 当调用出错时，抛出指定的 Exception --&gt;&lt;dubbo:reference interface=\"com.foo.BarService\" mock=\"throw com.foo.MockException\" /&gt; force 和 fail在 Dubbo 2.6.6 以上的版本支持配置 fail: 和 force: ，之下的版本不支持配置，否则在 Mock 的配置校验逻辑会抛出异常。如果要在 Dubbo 2.6.6 之下使用只能通过配置规则的方式。force: 代表强制使用 Mock 行为，在这种情况下是不会走远程调用的。fail: 与默认行为一致，只有当远程调用发生错误时才使用 Mock 行为。force: 和 fail: 不仅可以单独使用，还支持与 return 或 throw 组合使用。 123456789&lt;!-- 单独使用--&gt;&lt;dubbo:reference interface=\"com.foo.BarService\" mock=\"force:true\"/&gt;&lt;dubbo:reference interface=\"com.foo.BarService\" mock=\"force:com.foo.BarServiceMock\"/&gt;&lt;!-- 组合使用，以 force: 为例 --&gt;&lt;dubbo:reference interface=\"com.foo.BarService\" mock=\"force:return\"/&gt;&lt;dubbo:reference interface=\"com.foo.BarService\" mock=\"force:return null\"/&gt;&lt;dubbo:reference interface=\"com.foo.BarService\" mock=\"force:throw\"/&gt;&lt;dubbo:reference interface=\"com.foo.BarService\" mock=\"force:throw com.foo.MockException\"/&gt; 注意，无论是 force: 还是 fail: 都只是前缀，仅具有语意，它后面的内容才是 mock 配置项真正的内容，这两个前缀仅用于 MockClusterInvoker 的 Mock 判断逻辑。因此，在使用的时候按照 mock 内容来设置即可。 方法级别 MockMock 可以在方法级别上指定，即以参数的形式进行配置。假定 com.foo.BarService 上有好几个方法，我们可以单独为 sayHello 方法指定 Mock 行为。本例中只要 sayHello 被调用，则强制返回 null，不会走远程调用，具体配置如下： 123&lt;dubbo:reference id=\"demoService\" check=\"false\" interface=\"com.foo.BarService\"&gt; &lt;dubbo:parameter key=\"sayHello.mock\" value=\"force:return fake\"/&gt;&lt;/dubbo:reference&gt; 应用在 Dubbo 中可以利用本地伪装实现服务降级。我们可以通过 动态配置 以及 在消费方配置 mock 来实现 Mock 机制，通常使用动态配置规则进行服务降级。向注册中心的提供者目录下写入 Mock URL 用于引用 MockInvoker，这个是在 MockProtocol 中完成的。 MockClusterWrapper123456789101112131415161718192021public class MockClusterWrapper implements Cluster &#123; /** * 真正的 Cluster 对象 */ private Cluster cluster; /** * Wrapper 类都要有一个参数类型为扩展点的构造函数 * * @param cluster */ public MockClusterWrapper(Cluster cluster) &#123; this.cluster = cluster; &#125; @Override public &lt;T&gt; Invoker&lt;T&gt; join(Directory&lt;T&gt; directory) throws RpcException &#123; // 使用 MockClusterInvoker 进行包装 return new MockClusterInvoker&lt;T&gt;(directory, this.cluster.join(directory)); &#125;&#125; MockClusterWrapper 是 Cluster 包装类，包装类会被自动注入合适的扩展点实现，这里就是注入合适的 Cluster 扩展实现。该 Wrapper 主要用于包装 Cluster Invoker 对象，以此实现 Mock 机制。即创建 MockClusterInvoker 对象，封装服务目录和 Cluster Invoker 。 MockClusterWrapper 作为 Cluster 的 Wrapper 实现，无论哪个 Cluster 的扩展实现合并 Invoker 列表都会被封装成一个 MockClusterInvoker 对象。不难看出 MockClusterWrapper 作为 Mock 机制触发的入口，真正实现逻辑是交给 MockClusterInvoker 完成的。下面我们就接着从 MockClusterInvoker 分析。 MockClusterInvokerMockClusterInvoker 是 Dubbo Mock 机制的核心，它和其它的 Cluster Invoker 一样，在 invoke() 方法中完成了主要的逻辑。 属性12345678910111213141516171819202122public class MockClusterInvoker&lt;T&gt; implements Invoker&lt;T&gt; &#123; private static final Logger logger = LoggerFactory.getLogger(MockClusterInvoker.class); /** * 服务目录 */ private final Directory&lt;T&gt; directory; /** * 真正的 Invoker 对象 */ private final Invoker&lt;T&gt; invoker; /** * @param directory 服务目录 * @param invoker ClusterInvoker */ public MockClusterInvoker(Directory&lt;T&gt; directory, Invoker&lt;T&gt; invoker) &#123; this.directory = directory; this.invoker = invoker; &#125;&#125; invoke 方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253+--- MockClusterInvoker @Override public Result invoke(Invocation invocation) throws RpcException &#123; Result result = null; // 1 获取 mock 配置项的值，默认是 false （getUrl() 是提供方URL合并处理的值，其中提供方的参数配置项优先级最低） String value = getUrl().getMethodParameter(invocation.getMethodName(), MOCK_KEY, Boolean.FALSE.toString()).trim(); // 2 mock 配置项未设置或设置为 false ，则不会开启 Mock 机制，直接调用底层的 ClusterInvoker if (value.length() == 0 || \"false\".equalsIgnoreCase(value)) &#123; //no mock result = this.invoker.invoke(invocation); // 3 mock 配置项为 force，表示强制 Mock，直接调用 doMockInvoke() 方法执行 Mock 机制 &#125; else if (value.startsWith(\"force\")) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"force-mock: \" + invocation.getMethodName() + \" force-mock enabled , url : \" + getUrl()); &#125; //force:direct mock result = doMockInvoke(invocation, null); // 4 如果 mock 配置项配置的不是 force，表示先调用 Invoker ，调用失败再调用 doMockInvoke() 方法 &#125; else &#123; //fail-mock try &#123; result = this.invoker.invoke(invocation); //fix:#4585 if (result.getException() != null &amp;&amp; result.getException() instanceof RpcException) &#123; RpcException rpcException = (RpcException) result.getException(); // 如果是业务异常，则直接抛出 if (rpcException.isBiz()) &#123; throw rpcException; // 如果是非业务异常，则调用 doMockInvoke() 方法返执行 Mock 机制 &#125; else &#123; result = doMockInvoke(invocation, rpcException); &#125; &#125; &#125; catch (RpcException e) &#123; if (e.isBiz()) &#123; throw e; &#125; if (logger.isWarnEnabled()) &#123; logger.warn(\"fail-mock: \" + invocation.getMethodName() + \" fail-mock enabled , url : \" + getUrl(), e); &#125; result = doMockInvoke(invocation, e); &#125; &#125; return result; &#125; MockClusterInvoker 的 invoke 方法主要是根据 mock 配置项的值分以下 3 种情况处理： 没有配置 mock 或 mock 的值为 false ，则直接调用 ClusterInvoker 的 invoke 方法发起 RPC 调用，不会进行 Mock 逻辑。 mock 的值以 force 开头，表示强制 Mock，进入 doMockInvoker 逻辑。 mock 的值不是以上两种情况，则表示失败后才会 Mock，进入 doMockInvoker 逻辑。 通过以上逻辑可以看出，MockClusterInvoker 主要处理无 Mock、强制 Mock 以及失败后返回 Mock 结果等逻辑，具体的 Mock 逻辑被封装到了 doMockInvoke 方法中了。 doMockInvoke1234567891011121314151617181920212223242526272829303132333435+--- MockClusterInvoker@SuppressWarnings(&#123;\"unchecked\", \"rawtypes\"&#125;) private Result doMockInvoke(Invocation invocation, RpcException e) &#123; Result result = null; Invoker&lt;T&gt; minvoker; // 1 调用 selectMockInvoker() 方法过滤得到的 MockInvoker，即使用路由 MockInvokersSelector 匹配 MockInvoker List&lt;Invoker&lt;T&gt;&gt; mockInvokers = selectMockInvoker(invocation); // 2 如果 selectMockInvoker() 方法未返回 MockInvoker 对象，则创建一个 MockInvoker // 通过 selectMockInvoker 方法获取的是 MockProtocol 协议引用的 Invoker，也就是通过向注册中心的 providers 目录写入 Mock URL 的情况 if (CollectionUtils.isEmpty(mockInvokers)) &#123; minvoker = (Invoker&lt;T&gt;) new MockInvoker(getUrl(), directory.getInterface()); &#125; else &#123; // 存在则选择第一个 MockInvoker minvoker = mockInvokers.get(0); &#125; try &#123; // 3 调用 MockInvoker.invoke() 方法进行 Mock 逻辑 result = minvoker.invoke(invocation); &#125; catch (RpcException me) &#123; // 如果是业务异常，则在 Result 中设置该异常 if (me.isBiz()) &#123; result = AsyncRpcResult.newDefaultAsyncResult(me.getCause(), invocation); &#125; else &#123; throw new RpcException(me.getCode(), getMockExceptionMessage(e, me), me.getCause()); &#125; &#125; catch (Throwable me) &#123; throw new RpcException(getMockExceptionMessage(e, me), me.getCause()); &#125; // 4 返回 Mock 结果 return result; &#125; 执行到了 doMockInvoke 方法，说明需要 Mock 机制，该方法的主要逻辑是获取或创建 MockInvoker 对象，然后调用其 invoke 方法。其中 selectMockInvoker 方法用于从服务目录中过滤得到 MockInvoker 列表，一般这种情况得到的 Invoker 是通过 MockProtocol 引用完成的。 selectMockInvoker123456789101112131415161718192021222324+--- MockClusterInvoker private List&lt;Invoker&lt;T&gt;&gt; selectMockInvoker(Invocation invocation) &#123; List&lt;Invoker&lt;T&gt;&gt; invokers = null; //TODO generic invoker？ if (invocation instanceof RpcInvocation) &#123; // 1 将Invocation附属信息中的invocation.need.mock属性设置为true，然后交给 Directory 中的 Router 集合进行过滤处理 //Note the implicit contract (although the description is added to the interface declaration, but extensibility is a problem. The practice placed in the attachment needs to be improved) ((RpcInvocation) invocation).setAttachment(INVOCATION_NEED_MOCK, Boolean.TRUE.toString()); // 2 Directory 根据 invocation 中 attachment 是否有 vocation.need.mock 来判断是否是 MockInvoker //directory will return a list of normal invokers if Constants.INVOCATION_NEED_MOCK is present in invocation, otherwise, a list of mock invokers will return. try &#123; invokers = directory.list(invocation); &#125; catch (RpcException e) &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Exception when try to invoke mock. Get mock invokers error for service:\" + getUrl().getServiceInterface() + \", method:\" + invocation.getMethodName() + \", will construct a new mock with 'new MockInvoker()'.\", e); &#125; &#125; &#125; return invokers; &#125; selectMockInvoker 方法会在调用信息 Invocation 的隐式参数中设置 invocation.need.mock=true 的标识，这样的情况下，从服务目录中获取 Invoker 列表时，MockInvokersSelector 路由如果检测到标识则过滤出 MockInvoker 。其中 MockInvokersSelector 实现了 Router 接口，具有服务路由的功能。 MockInvokersSelectorMockInvokersSelector 是 Dubbo Mock 机制相关的 Router 实现，通过 MockRouterFactory 创建，会在 RouterChain 初始化时被加载，因此每次 Directory.list 的过程中都会执行该路由逻辑。注意，这里是 Dubbo 2.7.x 版本实现，和 集群容错 - Router 一文中的版本不一致，代码有些变化，但是整体逻辑是不变的。 123456789101112131415161718+--- RouterChain private RouterChain(URL url) &#123; // 获取激活的 RouterFactory // ServiceRouterFactory , TagRouterFactory,MockRouterFactory,AppRouterFactory 目前这四个是激活的 List&lt;RouterFactory&gt; extensionFactories = ExtensionLoader.getExtensionLoader(RouterFactory.class) .getActivateExtension(url, \"router\"); // 通过激活的 RouterFactory 获取对应的 Router 对象，其中包括 MockInvokersSelector 对象 List&lt;Router&gt; routers = extensionFactories.stream() .map(factory -&gt; factory.getRouter(url)) .collect(Collectors.toList()); initWithRouters(routers); &#125; public void initWithRouters(List&lt;Router&gt; builtinRouters) &#123; this.builtinRouters = builtinRouters; this.routers = new ArrayList&lt;&gt;(builtinRouters); this.sort(); &#125; route123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class MockInvokersSelector extends AbstractRouter &#123; public static final String NAME = \"MOCK_ROUTER\"; private static final int MOCK_INVOKERS_DEFAULT_PRIORITY = Integer.MIN_VALUE; public MockInvokersSelector() &#123; // 优先级 this.priority = MOCK_INVOKERS_DEFAULT_PRIORITY; &#125; /** * 对 Invoker 列表进行过滤 * * @param invokers invoker list * @param url refer url * @param invocation invocation * @param &lt;T&gt; * @return * @throws RpcException */ @Override public &lt;T&gt; List&lt;Invoker&lt;T&gt;&gt; route(final List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, final Invocation invocation) throws RpcException &#123; if (CollectionUtils.isEmpty(invokers)) &#123; return invokers; &#125; // 1 attachments 为 null，会过滤掉 MockInvoker，只返回普通的Invoker对象 if (invocation.getObjectAttachments() == null) &#123; return getNormalInvokers(invokers); &#125; else &#123; // 2 获取 invocation.need.mock 配置项 String value = (String) invocation.getObjectAttachments().get(INVOCATION_NEED_MOCK); // 2.1 invocation.need.mock 参数值为 null 会过滤掉 MockInvoker，只返回普通的 Invoker 对象 if (value == null) &#123; return getNormalInvokers(invokers); // 2.2 invocation.need.mock为true，只返回 MockInvoker &#125; else if (Boolean.TRUE.toString().equalsIgnoreCase(value)) &#123; return getMockedInvokers(invokers); &#125; &#125; // 3 invocation.need.mock为false，则会将MockInvoker和普通的Invoker一起返回 return invokers; &#125;&#125; MockInvokersSelector 的过滤逻辑是通过判断调用信息 Invocation 的 attachments 中是否存在 invocation.need.mock 参数，如果该参数的值为 true ，则过滤出 MockInvoker 集合，否则只返回普通 Invoker 集合。判断 Invoker 列表中是否存在 MockInvoker 是通过 hasMockProviders 方法完成的。 12345678910111213141516171819+--- MockInvokersSelector /** * 通过 protocol = mock 来判断是否为 MockInvoker * * @param invokers * @param &lt;T&gt; * @return */ private &lt;T&gt; boolean hasMockProviders(final List&lt;Invoker&lt;T&gt;&gt; invokers) &#123; boolean hasMockProvider = false; for (Invoker&lt;T&gt; invoker : invokers) &#123; // 判断是否存在 URL 的 protocol 为 mock 的 Invoker，存在即说明 Invoker 列表中有 MockInvoker if (invoker.getUrl().getProtocol().equals(MOCK_PROTOCOL)) &#123; hasMockProvider = true; break; &#125; &#125; return hasMockProvider; &#125; hasMockProviders 通过判断 Invoker.URL.protocl = mock 来决定该 Invoker 是否为 MockInvoker 。了解了判断 Invoker 是否为 MockInvoker 的依据后，接下来对 Dubbo Mock 路由机制的逻辑进行分析，其中分为三种情况。 未设置 invocation.need.mock 配置项 12345678910111213141516171819+--- MockInvokersSelector // 获取普通的 Invoker private &lt;T&gt; List&lt;Invoker&lt;T&gt;&gt; getNormalInvokers(final List&lt;Invoker&lt;T&gt;&gt; invokers) &#123; // 只要没有 MockInvoker ，就是普通 Invoker if (!hasMockProviders(invokers)) &#123; return invokers; // 若包含 MockInvoker 的情况下，过滤掉 MockInvoker &#125; else &#123; List&lt;Invoker&lt;T&gt;&gt; sInvokers = new ArrayList&lt;Invoker&lt;T&gt;&gt;(invokers.size()); for (Invoker&lt;T&gt; invoker : invokers) &#123; // 根据 URL 的 protocol 进行过滤，只返回 protocol 不为 mock 的 Invoker 对象 if (!invoker.getUrl().getProtocol().equals(MOCK_PROTOCOL)) &#123; sInvokers.add(invoker); &#125; &#125; return sInvokers; &#125; &#125; 设置 invocation.need.mock=true 配置项 1234567891011121314151617181920212223+--- MockInvokersSelector /** * 获取 MockInvoker * * @param invokers * @param &lt;T&gt; * @return */ private &lt;T&gt; List&lt;Invoker&lt;T&gt;&gt; getMockedInvokers(final List&lt;Invoker&lt;T&gt;&gt; invokers) &#123; // 不包含 MockInvoker 的情况下，直接返回 null if (!hasMockProviders(invokers)) &#123; return null; &#125; List&lt;Invoker&lt;T&gt;&gt; sInvokers = new ArrayList&lt;Invoker&lt;T&gt;&gt;(1); for (Invoker&lt;T&gt; invoker : invokers) &#123; // 根据 URL 的 protocol 进行过滤，只返回 protocol 为 mock 的 Invoker 对象 // 一般情况就一个 if (invoker.getUrl().getProtocol().equals(MOCK_PROTOCOL)) &#123; sInvokers.add(invoker); &#125; &#125; return sInvokers; &#125; 设置 invocation.need.mock=false 配置项 将 MockInvoker 和普通的 Invoker 一起返回。 无论是尝试从服务目录中获取 MockInvoker，还是创建 MockInvoker，截止到现在并没有真正执行 Mock 逻辑。Mock 逻辑的执行是通过 MockInvoker 来完成的。下面我们就来分析 Mock 机制最底层的实现。 MockInvokerMockInvoker 用于解析各类 mock 配置，以及根据不同 mock 配置进行不同的处理。即 MockInvoker 实现最终的 Invoke 逻辑。 属性123456789101112131415161718192021222324252627final public class MockInvoker&lt;T&gt; implements Invoker&lt;T&gt; &#123; /** * ProxyFactory 自适应扩展实现 */ private final static ProxyFactory PROXY_FACTORY = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension(); /** * mock 与 Invoker 对象的映射缓存 */ private final static Map&lt;String, Invoker&lt;?&gt;&gt; MOCK_MAP = new ConcurrentHashMap&lt;String, Invoker&lt;?&gt;&gt;(); /** * mock 与 Throwable 对象的映射缓存 */ private final static Map&lt;String, Throwable&gt; THROWABLE_MAP = new ConcurrentHashMap&lt;String, Throwable&gt;(); /** * URL 对象 */ private final URL url; /** * 服务接口类型 */ private final Class&lt;T&gt; type; public MockInvoker(URL url, Class&lt;T&gt; type) &#123; this.url = url; this.type = type; &#125;&#125; invoke1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768+--- MockInvoker @Override public Result invoke(Invocation invocation) throws RpcException &#123; if (invocation instanceof RpcInvocation) &#123; ((RpcInvocation) invocation).setInvoker(this); &#125; // 1 获取 mock 配置项，方法级别 &gt; 接口级别 String mock = null; // 1.1 从URL中的 methodName.mock 参数获取 (方法级别设置 mock) if (getUrl().hasMethodParameter(invocation.getMethodName())) &#123; mock = getUrl().getParameter(invocation.getMethodName() + \".\" + MOCK_KEY); &#125; // 1.2 从URL中的 mock 参数获取 if (StringUtils.isBlank(mock)) &#123; mock = getUrl().getParameter(MOCK_KEY); &#125; // 1.3 没有配置 mock 则直接抛出异常 if (StringUtils.isBlank(mock)) &#123; throw new RpcException(new IllegalAccessException(\"mock can not be null. url :\" + url)); &#125; // 2 标准化 mock 配置项 mock = normalizeMock(URL.decode(mock)); // 3 mock 值以 return 开头，返回对应值的 RpcResult 对象 if (mock.startsWith(RETURN_PREFIX)) &#123; mock = mock.substring(RETURN_PREFIX.length()).trim(); try &#123; // 获取响应结果的类型 Type[] returnTypes = RpcUtils.getReturnTypes(invocation); // 根据响应结果类型，对 mock 值中结果进行转换 Object value = parseMockValue(mock, returnTypes); // 将固定的 mock 值设置到 Result 中 return AsyncRpcResult.newDefaultAsyncResult(value, invocation); &#125; catch (Exception ew) &#123; throw new RpcException(\"mock return invoke error. method :\" + invocation.getMethodName() + \", mock:\" + mock + \", url: \" + url, ew); &#125; // 4 mock 值以 throw 开头 &#125; else if (mock.startsWith(THROW_PREFIX)) &#123; mock = mock.substring(THROW_PREFIX.length()).trim(); // 未指定异常类型，直接抛出RpcException if (StringUtils.isBlank(mock)) &#123; throw new RpcException(\"mocked exception for service degradation.\"); // 抛出自定义异常 &#125; else &#123; // user customized class Throwable t = getThrowable(mock); throw new RpcException(RpcException.BIZ_EXCEPTION, t); &#125; // 5 自定义 Mock 实现，执行自定义逻辑 &#125; else &#123; //impl mock try &#123; // 创建 Invoker 对象（因为调用信息被封装在 invocation 中，因此需要统一使用 Invoker 处理） Invoker&lt;T&gt; invoker = getInvoker(mock); // 执行 Invoker 对象的调用逻辑 return invoker.invoke(invocation); &#125; catch (Throwable t) &#123; throw new RpcException(\"Failed to create mock implementation class \" + mock, t); &#125; &#125; &#125; MockInvoker 调用逻辑主要是根据不同 mock 配置进行不同的处理,主要逻辑如下： 获取 mock 配置项的值，优先方法级别，然后接口级别。不允许 mock 配置项为空。 对 mock 配置项的值进行标准化处理，由 normalizeMock 方法完成处理： return =&gt; return null true/defaul/fail/force =&gt; defaul fail:throw/return foo =&gt; throw/return foo [去前缀] force:throw/return foo =&gt; throw/return foo [去前缀] fail/force:xxx =&gt; xxx [去前缀] 根据标准化后的 mock 分三种情况处理： mock 值以 return 开头：直接返回 mock 指定值的对应数据，该过程由 parseMockValue() 方法进行解析转换。 mock 值以 throw 开头：直接抛出异常，如果 mock 没有指定异常类型，则抛出 RpcException ，否则抛出指定的异常。 mock 值为 default 时会查找服务接口对应的 Mock 实现；如果是其它值，则直接作为服务接口的 Mock 实现。拿到 Mock 实现后会通过 ProxyFactory 转成 Invoker 。该逻辑由 getInvoker 方法处理。最后调用得到的 Invoker 。 了解了 MockInvoker 的总体调用逻辑后，下面我们分别对 mock 标准化处理、parseMockValue 方法以及 getInvoker 方法进行简单说明。 mock 标准化处理12345678910111213141516171819202122232425262728293031323334353637+--- MockInvoker public static String normalizeMock(String mock) &#123; if (mock == null) &#123; return mock; &#125; // mock 去空格 mock = mock.trim(); if (mock.length() == 0) &#123; return mock; &#125; // 1 等于 return ，则返回 return null if (RETURN_KEY.equalsIgnoreCase(mock)) &#123; return RETURN_PREFIX + \"null\"; &#125; // 2 为 \"true\" \"default\" \"fail\" \"force\" 四种字符串，则直接返回 default if (ConfigUtils.isDefault(mock) || \"fail\".equalsIgnoreCase(mock) || \"force\".equalsIgnoreCase(mock)) &#123; return \"default\"; &#125; // 3 以 fail: 开头，则去掉该开头 if (mock.startsWith(FAIL_PREFIX)) &#123; mock = mock.substring(FAIL_PREFIX.length()).trim(); &#125; // 4 以 force: 开头，则去掉该开头 if (mock.startsWith(FORCE_PREFIX)) &#123; mock = mock.substring(FORCE_PREFIX.length()).trim(); &#125; if (mock.startsWith(RETURN_PREFIX) || mock.startsWith(THROW_PREFIX)) &#123; mock = mock.replace('`', '\"'); &#125; return mock; &#125; 需要说明的是，mock 以 fail: 或 force: 开头仅用于 MockClusterInvoker 快速判断是失败 Mock 逻辑还是强制 Mock 逻辑，MockInvoker 在处理时是不关心前缀的。 parseMockValue12345678910111213141516171819202122232425262728293031323334353637383940414243+--- MockInvoker /** * @param mock mock 值 * @param returnTypes 响应结果类型 * @return * @throws Exception */ public static Object parseMockValue(String mock, Type[] returnTypes) throws Exception &#123; Object value = null; // 未赋值的对象，根据返回类型返回 new xxx() 空对象 if (\"empty\".equals(mock)) &#123; value = ReflectUtils.getEmptyObject(returnTypes != null &amp;&amp; returnTypes.length &gt; 0 ? (Class&lt;?&gt;) returnTypes[0] : null); &#125; else if (\"null\".equals(mock)) &#123; value = null; &#125; else if (\"true\".equals(mock)) &#123; value = true; &#125; else if (\"false\".equals(mock)) &#123; value = false; // 使用 '' 或 \"\" 的字符串，截取掉头尾 &#125; else if (mock.length() &gt;= 2 &amp;&amp; (mock.startsWith(\"\\\"\") &amp;&amp; mock.endsWith(\"\\\"\") || mock.startsWith(\"\\'\") &amp;&amp; mock.endsWith(\"\\'\"))) &#123; value = mock.subSequence(1, mock.length() - 1); // 字符串 &#125; else if (returnTypes != null &amp;&amp; returnTypes.length &gt; 0 &amp;&amp; returnTypes[0] == String.class) &#123; value = mock; // 数字 &#125; else if (StringUtils.isNumeric(mock, false)) &#123; value = JSON.parse(mock); // Map &#125; else if (mock.startsWith(\"&#123;\")) &#123; value = JSON.parseObject(mock, Map.class); // List &#125; else if (mock.startsWith(\"[\")) &#123; value = JSON.parseObject(mock, List.class); &#125; else &#123; value = mock; &#125; // 转换成对应的返回类型 if (ArrayUtils.isNotEmpty(returnTypes)) &#123; value = PojoUtils.realize(value, (Class&lt;?&gt;) returnTypes[0], returnTypes.length &gt; 1 ? returnTypes[1] : null); &#125; return value; &#125; parseMockValue 方法用于解析 mock 值，并转换成对应的返回类型。目前支持以下类型的参数： mock 值等于 empty，则根据返回类型返回 new xxx() 空对象。 mock 值为 null、true、false ，则直接返回这些值。 如果是字符串，则返回字符串。 如果是数字、List、Map 类型的 JSON 串，则解析为对应的对象。 如果都没有匹配上，则直接返回 Mock 的参数值。 getInvoker1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162+--- MockInvoker /** * 获取 mock (处理后的) 对应的 Invoker * * @param mockService * @return */ @SuppressWarnings(\"unchecked\") private Invoker&lt;T&gt; getInvoker(String mockService) &#123; // 1 尝试从 MOCK_MAP 中获取对应的 Invoker 对象 Invoker&lt;T&gt; invoker = (Invoker&lt;T&gt;) MOCK_MAP.get(mockService); if (invoker != null) &#123; return invoker; &#125; // 2 获得接口类 Class&lt;T&gt; serviceType = (Class&lt;T&gt;) ReflectUtils.forName(url.getServiceInterface()); // 3 根据 serviceType 查找 mock 的实现对象 T mockObject = (T) getMockObject(mockService, serviceType); // 4 通过 ProxyFactory 创建 mock 对应的 Invoker 对象 // 因为调用信息被封装在 Invocation 中 invoker = PROXY_FACTORY.getInvoker(mockObject, serviceType, url); if (MOCK_MAP.size() &lt; 10000) &#123; // 写入缓存 MOCK_MAP.put(mockService, invoker); &#125; return invoker; &#125; /** * @param mockService mock * @param serviceType 服务接口 * @return */ @SuppressWarnings(\"unchecked\") public static Object getMockObject(String mockService, Class serviceType) &#123; // 1 如果 mockService 为 true 或 default ，则在服务接口后添加 Mock 字符串，作为服务接口的 Mock 实现 if (ConfigUtils.isDefault(mockService)) &#123; mockService = serviceType.getName() + \"Mock\"; &#125; // 2 反射获取 Mock 实现类 Class&lt;?&gt; mockClass = ReflectUtils.forName(mockService); // 3 检查 mockClass 是否实现了服务接口 if (!serviceType.isAssignableFrom(mockClass)) &#123; throw new IllegalStateException(\"The mock class \" + mockClass.getName() + \" not implement interface \" + serviceType.getName()); &#125; try &#123; // 4 创建 Mock 对象 return mockClass.newInstance(); &#125; catch (InstantiationException e) &#123; throw new IllegalStateException(\"No default constructor from mock class \" + mockClass.getName(), e); &#125; catch (IllegalAccessException e) &#123; throw new IllegalStateException(e); &#125; &#125; getInvoker 方法会先尝试从缓存中获取 mock 对应的 Invoker 对象，如果获取失败才会调用 getMockObject 方法创建。在 getMockObject() 方法中会检查 mock 的值是否为 true 或 default，如果是的话，则在服务接口后添加 Mock 字符串，作为服务接口的 Mock 实现；如果不是的话，则直接将 mock 的值作为服务接口的 Mock 实现。 MockProtocolMockProtocol 也是协议的一种实现，扩展名为 mock， 主要是把注册中心的 Mock URL 转换为 MockInvoker 对象。Mock URL 可以通过服务治理平台或其它方式写入注册中心，它被定义为只能引用，不能暴露。 123456789101112131415161718192021222324252627282930313233343536final public class MockProtocol extends AbstractProtocol &#123; @Override public int getDefaultPort() &#123; return 0; &#125; /** * 不能通过 export() 方法暴露服务 * * @param invoker Service invoker * @param &lt;T&gt; * @return * @throws RpcException */ @Override public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; // 直接抛出异常，无法暴露服务 throw new UnsupportedOperationException(); &#125; /** * 支持通过 refer() 方法创建 MockInvoker 对象 * * @param type * @param url * @param &lt;T&gt; * @return * @throws RpcException */ @Override public &lt;T&gt; Invoker&lt;T&gt; protocolBindingRefer(Class&lt;T&gt; type, URL url) throws RpcException &#123; // 直接创建MockInvoker对象 return new MockInvoker&lt;&gt;(url, type); &#125;&#125; 例如，我们在注册中心的 /dubbo/com.code.DemoService/providers 这个服务提供者的目录下写入下面的一条 Mock URL : mock://192.168.1.1/com.code.DemoService?xxx=yyyy.... 注册中心监听到服务提供者的目录发生改变会重新进行服务引用，即调用 Protocol.refer 方法。最终通过 Dubbo SPI 找到 MockProtcol.protocolBindingRefer 方法，进而引用服务。通过前文可以知道，即使不手动添加 Mock URL ，在需要过滤出 MockInvoker 的时候，没有也会自动创建 MockInvoker 对象。 小结本篇文章详细介绍了 Dubbo 中的 Mock 机制。首先对常见 mock 配置进行了介绍，接下来以 MockClusterWrapper 作为出发点进行分析，它是 Cluster 的 Wrapper 实现。沿着执行流程，先对 MockClusterInvoker 进行了分析，它主要是 Mock 的前置处理逻辑，决定是否执行 Mock 逻辑以及执行 Mock 逻辑的时机；在进入 Mock 逻辑之前，需要从服务目录中确定一个 MockInvoker，这个是由 MockInvokersSelector 这个路由实现的，如果没有找到 MockInvoker，则主动创建一个 MockInvoker 。最后，通过 MockInvoker 执行 Mock 逻辑。在文章的最后，分析了 Protocol 层与 Mock 相关的扩展实现 MockProtocol ，它用来将服务提供者目录下的 Mock URL 转为 MockInvoker 。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"集群容错 - Merger","slug":"rpc/集群容错之分组聚合","date":"2020-10-04T16:00:00.000Z","updated":"2021-04-20T10:55:09.545Z","comments":false,"path":"posts/1d657bdb/","link":"","permalink":"https://gentryhuang.com/posts/1d657bdb/","excerpt":"","text":"概述Dubbo 支持通过分组聚合按照 组 合并返回结果。比如菜单服务，服务接口一样，但暴露多种实现，使用 group 区分，消费方需要从每种 group 中调用一次并返回结果，最后合并这些结果后返回。关于分组 Invoker 的组装逻辑是在服务目录 Directory 中完成的，而分组聚合逻辑是在服务引用的过程中，当引用多个服务分组时会自动使用分组聚合的特性，即使用 MergeableCluster 对象。 Merger 相关 UML 图如下： Dubbo 中的 Merger 实现目前包括两部分内容： Merger 实现，其中包括 12 个 Dubbo 内置的 Merger ，Dubbo 还支持自定义 Merger 实现。 MergerCluster 以及对应的 MergerClusterInvoker。MergerCluster 是分组聚合 Cluster 实现类，其创建的 MergerClusterInvoker 封装了分组聚合具体实现逻辑，是对 Merger 的使用。 配置使用 Dubbo 默认合并策略Dubbo 内置多个默认合并策略，具体使用哪种缺省根据返回值类型自动匹配。 合并所有分组12&lt;!-- 这里指定了group为*，即可以引用任何group的Provider，同时merger设置为true，即需要对结果进行合并 --&gt;&lt;dubbo:reference interface=\"com.xxx.MenuService\" group=\"*\" merger=\"true\" /&gt; 合并指定分组12&lt;!-- 这里指定了group为 aaa,bbb，即可以引用aaa和bbb group的Provider，同时merger设置为true，即需要对结果进行合并 --&gt;&lt;dubbo:reference interface=\"com.xxx.MenuService\" group=\"aaa,bbb\" merger=\"true\" /&gt; 合并指定分组下指定服务方法123&lt;dubbo:reference interface=\"com.xxx.MenuService\" group=\"*\"&gt; &lt;dubbo:method name=\"getMenuItems\" merger=\"true\" /&gt;&lt;/dubbo:reference&gt; 某个方法不合并结果，其它都合并结果123&lt;dubbo:reference interface=\"com.xxx.MenuService\" group=\"*\" merger=\"true\"&gt; &lt;dubbo:method name=\"getMenuItems\" merger=\"false\" /&gt;&lt;/dubbo:reference&gt; 指定合并策略Dubbo 支持指定合并策略以及指定合并方法 指定合并策略 1234&lt;dubbo:reference interface=\"com.xxx.MenuService\" group=\"*\"&gt; &lt;!-- mymerge 是自定义的合并策略--&gt; &lt;dubbo:method name=\"getMenuItems\" merger=\"mymerge\" /&gt;&lt;/dubbo:reference&gt; 指定合并方法 1234&lt;dubbo:reference interface=\"com.xxx.MenuService\" group=\"*\"&gt; &lt;!-- 使用调用返回结果类型的指定方法进行合并，合并方法的参数类型必须是返回结果类型本身 --&gt; &lt;dubbo:method name=\"getMenuItems\" merger=\".addAll\" /&gt;&lt;/dubbo:reference&gt; 源码分析下面分别对 Merger 的两部分实现进行源码分析。 Merger12345678910@SPIpublic interface Merger&lt;T&gt; &#123; /** * 合并 T 数组，返回合并后的 T 对象 * * @param items * @return */ T merge(T... items);&#125; Merger 是 Dubbo 的一个扩展点，没有默认扩展实现。用于将对象数组合并成一个对象。Dubbo 内置了 12 个扩展实现，当内置的扩展实现不满足场景时，可以自定义扩展实现。Dubbo 的 Merger 相对比较简单，下面分别介绍 ShortArrayMerger 和自定义 Merger 实现。 ShortArrayMerger12345678910111213141516171819202122232425262728293031323334353637public class ShortArrayMerger implements Merger&lt;short[]&gt; &#123; /** * 将多个 short[] 合并为一个 short[] * * @param items * @return */ @Override public short[] merge(short[]... items) &#123; if (ArrayUtils.isEmpty(items)) &#123; return new short[0]; &#125; // 计算合并后的数组大小 int total = 0; for (short[] array : items) &#123; if (array != null) &#123; total += array.length; &#125; &#125; // 创建结果数组 short[] result = new short[total]; // 合并多个数组 int index = 0; for (short[] array : items) &#123; if (array != null) &#123; for (short item : array) &#123; result[index++] = item; &#125; &#125; &#125; return result; &#125;&#125; 自定义 Merger12345678910111213public class StringMerger implements Merger&lt;String&gt; &#123; @Override public String merge(String... items) &#123; if (ArrayUtils.isEmpty(items)) &#123; return \"\"; &#125; String result = \"\"; for (String item : items) &#123; result += item + \"|\"; &#125; return result; &#125;&#125; StringMerger 用于将多个服务返回的 String 结果通过竖线拼接起来，即将 String[] 对象合并成一个 String 对象。 其它类型的 Merger 实现逻辑类似，这里就不再展开说明。Dubbo 内置的 Merger 扩展配置如下： map=org.apache.dubbo.rpc.cluster.merger.MapMergerset=org.apache.dubbo.rpc.cluster.merger.SetMergerlist=org.apache.dubbo.rpc.cluster.merger.ListMergerbyte=org.apache.dubbo.rpc.cluster.merger.ByteArrayMergerchar=org.apache.dubbo.rpc.cluster.merger.CharArrayMergershort=org.apache.dubbo.rpc.cluster.merger.ShortArrayMergerint=org.apache.dubbo.rpc.cluster.merger.IntArrayMergerlong=org.apache.dubbo.rpc.cluster.merger.LongArrayMergerfloat=org.apache.dubbo.rpc.cluster.merger.FloatArrayMergerdouble=org.apache.dubbo.rpc.cluster.merger.DoubleArrayMergerboolean=org.apache.dubbo.rpc.cluster.merger.BooleanArrayMerger MergerFactory123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class MergerFactory &#123; /** * Merger 实现缓存 * key: 服务接口返回值类型 * value: Merger 实现 */ private static final ConcurrentMap&lt;Class&lt;?&gt;, Merger&lt;?&gt;&gt; MERGER_CACHE = new ConcurrentHashMap&lt;Class&lt;?&gt;, Merger&lt;?&gt;&gt;(); /** * 根据返回值类型获取 Merger ，用于将一个 returnType 数组合并为一个 * * @param returnType the merger will return this type * @return the merger which merges an array of returnType into one, return null if not exist * @throws IllegalArgumentException if returnType is null */ public static &lt;T&gt; Merger&lt;T&gt; getMerger(Class&lt;T&gt; returnType) &#123; if (returnType == null) &#123; throw new IllegalArgumentException(\"returnType is null\"); &#125; Merger result; // returnType 为数组类型 if (returnType.isArray()) &#123; // 获取数组中元素的类型 Class type = returnType.getComponentType(); // 获取元素类型对应的 Merger 实现 result = MERGER_CACHE.get(type); if (result == null) &#123; loadMergers(); result = MERGER_CACHE.get(type); &#125; // 如果Dubbo 没有提供元素类型对应的Merger实现，则使用 ArrayMerger if (result == null &amp;&amp; !type.isPrimitive()) &#123; result = ArrayMerger.INSTANCE; &#125; // 如果returnType不是数组类型，则直接从MERGER_CACHE缓存查找对应的Merger实例 &#125; else &#123; result = MERGER_CACHE.get(returnType); if (result == null) &#123; loadMergers(); result = MERGER_CACHE.get(returnType); &#125; &#125; return result; &#125; /** * 通过 Dubbo SPI 的方式 加载 Merger 接口全部扩展实现 */ static void loadMergers() &#123; // 获取 Merger 接口的所有扩展名称 Set&lt;String&gt; names = ExtensionLoader.getExtensionLoader(Merger.class) .getSupportedExtensions(); // 遍历所有 Merger 扩展实现 for (String name : names) &#123; Merger m = ExtensionLoader.getExtensionLoader(Merger.class).getExtension(name); // 将 Merger 扩展实现 与对应 returnType 的映射关系记录到MERGER_CACHE集合中 // 读取泛型参数类型，即为返回值类型 MERGER_CACHE.putIfAbsent(ReflectUtils.getGenericClass(m.getClass()), m); &#125; &#125;&#125; 在 MergeableClusterInvoker 使用默认 Merger 实现的时候，会通过 MergerFactory 以及服务接口返回值类型（returnType）选择合适的 Merger 实现。 MergeableCluster &amp; MergeableClusterInvokerMergeableCluster 用于创建 MergeableClusterInvoker，MergeableClusterInvoker 封装了分组聚合的逻辑。 MergeableCluster123456789101112public class MergeableCluster extends AbstractCluster &#123; /** * 扩展名 */ public static final String NAME = \"mergeable\"; @Override public &lt;T&gt; AbstractClusterInvoker&lt;T&gt; doJoin(Directory&lt;T&gt; directory) throws RpcException &#123; // 创建 MergeableClusterInvoker 对象 return new MergeableClusterInvoker&lt;T&gt;(directory); &#125;&#125; MergeableCluster 的配置方式和其它 Cluster 实现类不同，当引用多个服务分组时，会自动使用分组聚合的特性，即 MergeableCluster 会根据是否引用多个服务分组进而激活，无需显示设置。其它的 Cluster ，如默认的 FailoverCluster 会在构建服务目录时以 group 维度对多个 Invoker 进行封装，因此，MergeableClusterInvoker 拿到的某个 Invoker 可能就是通过 FailoverCluster 封装后的结果。 MergeableClusterInvoker123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169public class MergeableClusterInvoker&lt;T&gt; extends AbstractClusterInvoker&lt;T&gt; &#123; private static final Logger log = LoggerFactory.getLogger(MergeableClusterInvoker.class); public MergeableClusterInvoker(Directory&lt;T&gt; directory) &#123; super(directory); &#125; /** * @param invocation 调用信息 * @param invokers Invokers 是当前调用方法对应的 Invoker 列表，该列表中的 Invoker 可能是被分组处理后的结果 * @param loadbalance * @return * @throws RpcException */ @Override protected Result doInvoke(Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; // 1 检测候选 Invoker 是否为空 checkInvokers(invokers, invocation); // 2 获取 merger 配置项的值 String merger = getUrl().getMethodParameter(invocation.getMethodName(), MERGER_KEY); // 3 判断调用的目标方法是否有 Merger 合并器 // 如果没有则默认所有调用实例都是一个分组下的，无需做结果合并，直接找到第一个可用的 Invoker 进行调用并返回结果，然后结束流程。 if (ConfigUtils.isEmpty(merger)) &#123; // If a method doesn't have a merger, only invoke one Group for (final Invoker&lt;T&gt; invoker : invokers) &#123; if (invoker.isAvailable()) &#123; try &#123; return invoker.invoke(invocation); &#125; catch (RpcException e) &#123; if (e.isNoInvokerAvailableAfterFilter()) &#123; log.debug(\"No available provider for service\" + getUrl().getServiceKey() + \" on group \" + invoker.getUrl().getParameter(GROUP_KEY) + \", will continue to try another group.\"); &#125; else &#123; throw e; &#125; &#125; &#125; &#125; // 兜底，没有可用的，就调用第一个 Invoker return invokers.iterator().next().invoke(invocation); &#125; // 4 确定调用方法的返回值类型 Class&lt;?&gt; returnType; try &#123; returnType = getInterface().getMethod( invocation.getMethodName(), invocation.getParameterTypes()).getReturnType(); &#125; catch (NoSuchMethodException e) &#123; returnType = null; &#125; // 5 以异步方式调用每个 Invoker 对象，并将调用结果记录到 results 中。 // results ：key 是 服务键，value 是 AsyncRpcResult Map&lt;String, Result&gt; results = new HashMap&lt;&gt;(); for (final Invoker&lt;T&gt; invoker : invokers) &#123; RpcInvocation subInvocation = new RpcInvocation(invocation, invoker); // 指定异步调用 subInvocation.setAttachment(ASYNC_KEY, \"true\"); results.put(invoker.getUrl().getServiceKey(), invoker.invoke(subInvocation)); &#125; Object result = null; List&lt;Result&gt; resultList = new ArrayList&lt;Result&gt;(results.size()); // 6 等待结果返回 for (Map.Entry&lt;String, Result&gt; entry : results.entrySet()) &#123; Result asyncResult = entry.getValue(); try &#123; // AsyncRpcResult.get() 方法 Result r = asyncResult.get(); // 调用异常（包括超时）， 则打印error级别的日志,但最终的结果会部分数据缺失。 if (r.hasException()) &#123; log.error(\"Invoke \" + getGroupDescFromServiceKey(entry.getKey()) + \" failed: \" + r.getException().getMessage(), r.getException()); // 将调用成功的结果保存起来 &#125; else &#123; resultList.add(r); &#125; &#125; catch (Exception e) &#123; throw new RpcException(\"Failed to invoke service \" + entry.getKey() + \": \" + e.getMessage(), e); &#125; &#125; // 7 对调用结果集为空或只有一个的情况处理，对应调用空结果集或方法返回值类型是 void ，则返回一个空结果，不需要合并 if (resultList.isEmpty()) &#123; return AsyncRpcResult.newDefaultAsyncResult(invocation); &#125; else if (resultList.size() == 1) &#123; return resultList.iterator().next(); &#125; if (returnType == void.class) &#123; return AsyncRpcResult.newDefaultAsyncResult(invocation); &#125; // 8 不同合并方式的处理 // 8.1 基于指定的返回类型的方法合并结果（该方法的参数必须是返回结果的类型） // merger 以 . 开头，则直接使用 . 后的方法合并结果。如 merger=\".addAll\" ，则调用的是结果类型的原生方法，如服务方法返回类型是 List，则就调用 List.addAll 方法来合并结果。 if (merger.startsWith(\".\")) &#123; merger = merger.substring(1); Method method; try &#123; // 反射获取指定方法对象，获取失败会抛出异常。也就是不能随意指定合并方法，合并方法必须合理。 method = returnType.getMethod(merger, returnType); &#125; catch (NoSuchMethodException e) &#123; throw new RpcException(\"Can not merge result because missing method [ \" + merger + \" ] in class [ \" + returnType.getName() + \" ]\"); &#125; if (!Modifier.isPublic(method.getModifiers())) &#123; method.setAccessible(true); &#125; // 获取方法的返回结果 result = resultList.remove(0).getValue(); // 反射调用合并方法进行结果的合并 try &#123; // 如果返回类型不是 void，且合并方法返回类型和服务方法返回类型相同，则调用合并方法合并结果，并修改 result if (method.getReturnType() != void.class &amp;&amp; method.getReturnType().isAssignableFrom(result.getClass())) &#123; for (Result r : resultList) &#123; result = method.invoke(result, r.getValue()); &#125; // 合并方法返回类型和服务方法返回类型不同，则调用合并方法把结果合并进去即可 &#125; else &#123; for (Result r : resultList) &#123; method.invoke(result, r.getValue()); &#125; &#125; &#125; catch (Exception e) &#123; throw new RpcException(\"Can not merge result: \" + e.getMessage(), e); &#125; // 8.2 基于 Merger 合并器合并结果 // merger 不是以 . 开头，需要使用 Merger 合并器进行结果的合并 &#125; else &#123; Merger resultMerger; // 8.2.1 merger 参数为 true 或者 default，表示使用内置的 Merger 扩展实现完成合并，即调用 MergerFactory if (ConfigUtils.isDefault(merger)) &#123; resultMerger = MergerFactory.getMerger(returnType); // 8.2.2 merger参数指定了Merger的扩展名称，则使用SPI查找对应的Merger扩展实现对象 &#125; else &#123; resultMerger = ExtensionLoader.getExtensionLoader(Merger.class).getExtension(merger); &#125; // 8.2.3 使用 Merger 进行结果合并 if (resultMerger != null) &#123; // 这里将结果同一转成为 Object 类型 List&lt;Object&gt; rets = new ArrayList&lt;Object&gt;(resultList.size()); for (Result r : resultList) &#123; rets.add(r.getValue()); &#125; // 执行合并操作 result = resultMerger.merge( rets.toArray((Object[]) Array.newInstance(returnType, 0))); &#125; else &#123; throw new RpcException(\"There is no merger to merge result.\"); &#125; &#125; return AsyncRpcResult.newDefaultAsyncResult(result, invocation); &#125; // 省略其它方法&#125; MergeableClusterInvoker.doInvoke 方法逻辑还是比较长的，下面对主要逻辑进行说明： 对候选 Invoker 列表进行校验，需要注意的是这里的 Invoker 列表中的元素可能是由其它 Cluster 实现分组合并过的（服务目录中的逻辑）。 获取 merger 配置项，如果没有设置该配置项，则说明无需进行结果合并，直接调用第一个可用的 Invoker 并结束逻辑。 异步调用候选 Invoker 列表，并阻塞等待执行结果，将调用成功的结果保存起来。 调用结果集大小为空 或 调用结果集大小为 1 或 服务方法返回类型为 void ，则返回一个空的结果并结束逻辑。 拿到结果集后，针对 merger 配置项的值有两种合并方式： 基于指定的返回类型的方法合并结果 基于 Merger 合并器合并结果，可能是 Dubbo 内置的合并器，或者自定义的合并器 小结本篇文章主要介绍了 Dubbo 集群模块中的 Merger 相关知识点。先是介绍了 Dubbo 内置的 Merger 实现，接着介绍了 MergerFactory，最后重点分析了 Dubbo 集群模块对 Merger 的使用，也就是通过 MergeableCluster 以及 MergeableClusterInvoker 对象实现分组聚合能力。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"集群容错 - Cluster","slug":"rpc/集群容错之Cluster","date":"2020-10-02T16:00:00.000Z","updated":"2021-04-08T15:03:15.425Z","comments":false,"path":"posts/7f19ea26/","link":"","permalink":"https://gentryhuang.com/posts/7f19ea26/","excerpt":"","text":"前言前面的几篇文章分别对服务目录 Directory、路由 Router、负载均衡 LoadBalance 以及动态配置 Configurator 进行了介绍，本篇文章将对 Dubbo 的集群容错进行分析，集群容错是基于前面几部分内容实现的。考虑到 Dubbo 2.7.x 集群容错部分新增了一些内容，因此本篇文章基于 Dubbo 2.7.x 版本的源代码进行分析。 概述为了避免单点故障，现在的应用通常至少会部署在两台服务器上，对一些负载比较高的服务，会部署更多的服务器。这样，在同一环境下的服务提供者就会有多台，对于服务消费者来说，需要选择一个服务提供者进行调用，如果调用失败还需要进行失败处理，如重试、抛出异常或者记录异常日志等。为了处理这些问题，Dubbo 定义了集群接口 Cluster 以及 Cluster Invoker 。Cluster 用途是将多个服务提供者对应的 Invoker 合并为一个 Cluster Invoker，并将这个 Invoker 暴露给服务消费者。这样一来，服务消费者只需通过这个 Invoker 进行远程调用即可，至于具体调用哪个服务提供者，以及调用失败后如何处理等问题，现在都交给集群模块去处理。集群模块是服务提供者和服务消费者的中间层，为服务消费者屏蔽了服务提供者的情况，这样服务消费者就可以专心处理远程调用相关事宜。比如发请求，接受服务提供者返回的数据等。这就是集群的作用。 Dubbo 默认内置了若干容错策略，每种容错策略都有独特的应用场景，使用方可以根据具体需要配置不同的容错策略，如果这些内置容错策略不能满足需求，还可以自定义容错策略。 集群容错在分析集群容错相关代码之前，先对涉及的组件进行介绍，主要包括了 Cluster、Cluster Invoker、Directory、Router 和 LoadBalance 等。 集群工作过程可分为两个阶段，具体如下： 创建 Cluster Invoker 实例 在服务消费者初始化期间（服务引用过程），集群 Cluster 实现类为服务消费者创建 Cluster Invoker 实例，即上图中的 merge 操作。 使用 Cluster Invoker 实例 在服务消费者发起远程调用请求时，Cluster Invoker 会依赖 Directory、Router、LoadBalance 等组件得到最终要调用的 Invoker 对象。 其中使用 Cluster Invoker 获取目标 Invoker 的具体流程如下： 通过服务目录 Directory 获取消费端 Invoker 列表（提供者对应的 Invoker 列表），其中的 RegistryDirectory 会感知注册中心的动态变化，实时获取提供者对应的 Invoker 对象。 使用 Router 对服务目录中提供者对应的 Invoker 列表进行路由，过滤掉不符合路由规则的 Invoker 对象。 使用 LoadBalance 从路由后的 Invoker 列表中选择一个目标 Invoker。 ClusterInvoker 会将请求信息传给负载均衡选出的 Invoker 实例，进行真正的远程调用。 以上就是集群工作的正常流程，没有涉及到容错处理，容错处理逻辑是在 Cluster Invoker 中封装的。到这里我们知道了，集群工作的正常流程就是单纯地对其他组件的使用，只有调用出现异常时才会使用到容错逻辑。 Dubbo 主要提供了以下的容错方式： Failover Cluster - 失败自动切换 失败自动切换，是 Dubbo 默认的容错机制。当请求一个提供者节点失败时，会自动切换到其他提供者节点，默认执行 3 次，也就是重试 2 次，适合幂等场景操作。 Failfast Cluster - 快速失败 快速失败。请求失败后返回异常，不进行任务重试。适合非幂等的操作 Failsafe Cluster - 失败安全 失败安全。请求失败后忽略异常，不进行任何重试，返回一个空结果。 Failback Cluster - 失败自动恢复 失败自动恢复。失败后记录到队列，并返回一个空结果，对于失败的调用会定时重试，重试是不关心结果的。 Forking Cluster - 并行调用多个提供者 并行调用多个提供者，只要有一个成功就返回。主要应用在一些对实时性要求比较高的读操作下使用，但这将会耗费更多的资源。 Broadcast Cluster - 广播多个提供者 广播多个提供者，只要有一个失败就失败。通常用于通知类的操作，如通知所有提供者更新缓存或日志等本地资源信息。 Availabel Cluster - 调用首个可用的提供者 遍历所有的 Provider 节点，找到每一个可用的节点，就直接调用。如果没有可用的 Provider 节点，则直接抛出异常。 ZoneAware Cluster - 优先多注册中心选择提供者 在 Dubbo 中使用多个注册中心的情况，服务消费端可以使用 ZoneAwareClusterInvoker 先在多个注册中心之间选择，确定注册中心之后，再选择服务提供者节点。 源码分析集群容错有两个概念，分别是集群接口 Cluster 和封装集群容错功能的 Cluster Invoker ，这两者是不同的。Cluster 是扩展接口，它的扩展实现仅用于创建 Cluster Invoker 。Cluster Invoker 是一种特殊的 Invoker ，服务提供者的选择逻辑，以及远程调用失败后的处理逻辑都是封装在 Cluster Invoker 中。 Cluster1234567891011121314@SPI(FailoverCluster.NAME)public interface Cluster &#123; /** * Merge the directory invokers to a virtual invoker. * * @param &lt;T&gt; * @param directory * @return cluster invoker * @throws RpcException */ @Adaptive &lt;T&gt; Invoker&lt;T&gt; join(Directory&lt;T&gt; directory) throws RpcException;&#125; Cluster 接口是一个扩展接口，通过 @SPI 注解的参数可知其默认实现是 FailoverCluster。它只定义了一个 join 方法，其上添加了 @Adaptive 注解，会动态生成适配器类，其中会优先根据 Directory.getUrl 方法返回的 URL 中的 cluster 参数值选择扩展实现，若无 cluster 参数则使用默认的 FailoverCluster 实现。 Cluster 的继承体系如下图所示： 在每个 Cluster 接口实现中，都会创建对应的 Invoker 对象，它们都继续自 AbstractClusterInvoker 抽象类，继承体系如下图所示： 通过上面的继承关系图不难发现，Cluster 接口和 Invoker 接口都有相应的抽象实现类，这些抽象实现类都提供了一些公共能力。下面我们先对 AbstractCluster 和 AbstractClusterInvoker 这两个抽象类进行介绍。 关于 Mock 和 Merger 相关的实现，会分别在服务降级部分和分组聚合部分进行详细分析，本篇文章暂不展开说明。 AbstractClusterAbstractCluster 核心逻辑是在 AbstractClusterInvoker 外层包装一层 ClusterInterceptor，从而实现类似切面的效果。切面逻辑目前应用不是很多，这是 Dubbo 2.7.x 增加的，这里了解即可。 123456789101112131415161718192021222324252627282930313233343536public abstract class AbstractCluster implements Cluster &#123; private &lt;T&gt; Invoker&lt;T&gt; buildClusterInterceptors(AbstractClusterInvoker&lt;T&gt; clusterInvoker, String key) &#123; AbstractClusterInvoker&lt;T&gt; last = clusterInvoker; // 通过 SPI 方式加载 ClusterInterceptor 扩展实现 List&lt;ClusterInterceptor&gt; interceptors = ExtensionLoader.getExtensionLoader(ClusterInterceptor.class).getActivateExtension(clusterInvoker.getUrl(), key); // 如果存在，则将 InterceptorInvokerNode 首尾连接到一起，形成调用链。 if (!interceptors.isEmpty()) &#123; for (int i = interceptors.size() - 1; i &gt;= 0; i--) &#123; final ClusterInterceptor interceptor = interceptors.get(i); final AbstractClusterInvoker&lt;T&gt; next = last; last = new InterceptorInvokerNode&lt;&gt;(clusterInvoker, interceptor, next); &#125; &#125; return last; &#125; @Override public &lt;T&gt; Invoker&lt;T&gt; join(Directory&lt;T&gt; directory) throws RpcException &#123; // 在 AbstractClusterInvoker 外层包装一层 ClusterInterceptor return buildClusterInterceptors(doJoin(directory), directory.getUrl().getParameter(REFERENCE_INTERCEPTOR_KEY)); &#125; /** * 具体子类创建 AbstractClusterInvoker * * @param directory * @param &lt;T&gt; * @return * @throws RpcException */ protected abstract &lt;T&gt; AbstractClusterInvoker&lt;T&gt; doJoin(Directory&lt;T&gt; directory) throws RpcException; // 省略其他代码&#125; 在 AbstractCluster 抽象类的 join 方法中，首先会调用 doJoin 方法获取最终要调用的 Invoker 对象，该方法由具体子类根据具体策略实现。之后，join 方法会调用 buildClusterInterceptors 方法对 Invoker 对象进行包装，实现切面逻辑。切面逻辑由 InterceptorInvokerNode 对象完成，它会将 ClusterInvoker 对象以及关联的 ClusterInterceptor 对象封装到一起，同时还会维护一个 next 引用，指向下一个 InterceptorInvokerNode 对象，核心逻辑如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647protected class InterceptorInvokerNode&lt;T&gt; extends AbstractClusterInvoker&lt;T&gt; &#123; private AbstractClusterInvoker&lt;T&gt; clusterInvoker; private ClusterInterceptor interceptor; private AbstractClusterInvoker&lt;T&gt; next; public InterceptorInvokerNode(AbstractClusterInvoker&lt;T&gt; clusterInvoker, ClusterInterceptor interceptor, AbstractClusterInvoker&lt;T&gt; next) &#123; this.clusterInvoker = clusterInvoker; this.interceptor = interceptor; this.next = next; &#125; @Override public Result invoke(Invocation invocation) throws RpcException &#123; Result asyncResult; try &#123; // 前置逻辑 interceptor.before(next, invocation); // 执行 invoke() 方法完成远程调用 asyncResult = interceptor.intercept(next, invocation); &#125; catch (Exception e) &#123; // 出现异常时，会触发监听器的 onError 方法 if (interceptor instanceof ClusterInterceptor.Listener) &#123; ClusterInterceptor.Listener listener = (ClusterInterceptor.Listener) interceptor; listener.onError(e, clusterInvoker, invocation); &#125; throw e; &#125; finally &#123; // 后置逻辑 interceptor.after(next, invocation); &#125; return asyncResult.whenCompleteWithContext((r, t) -&gt; &#123; // onResponse callback if (interceptor instanceof ClusterInterceptor.Listener) &#123; ClusterInterceptor.Listener listener = (ClusterInterceptor.Listener) interceptor; if (t == null) &#123; listener.onMessage(r, clusterInvoker, invocation); &#125; else &#123; listener.onError(t, clusterInvoker, invocation); &#125; &#125; &#125;); &#125; // 省略其他代码&#125; ClusterInterceptor用于对 Cluster Invoker 外围包装一层类似切面逻辑，具体有没有该切面逻辑需要看环境中没有对应扩展实现被加载到内存中。 12345678910111213141516171819202122232425262728293031323334353637@SPIpublic interface ClusterInterceptor &#123; /** * 前置拦截方法 * * @param clusterInvoker * @param invocation */ void before(AbstractClusterInvoker&lt;?&gt; clusterInvoker, Invocation invocation); /** * 后置拦截方法 * * @param clusterInvoker * @param invocation */ void after(AbstractClusterInvoker&lt;?&gt; clusterInvoker, Invocation invocation); /** * 调用 clusterInvoker.invoke 方法 * * @param clusterInvoker * @param invocation * @return * @throws RpcException */ default Result intercept(AbstractClusterInvoker&lt;?&gt; clusterInvoker, Invocation invocation) throws RpcException &#123; return clusterInvoker.invoke(invocation); &#125; // 用来监听请求的正常结果以及异常 interface Listener &#123; void onMessage(Result appResponse, AbstractClusterInvoker&lt;?&gt; clusterInvoker, Invocation invocation); void onError(Throwable t, AbstractClusterInvoker&lt;?&gt; clusterInvoker, Invocation invocation); &#125;&#125; Dubbo 提供了两个 ClusterInterceptor 实现类，分别是 ConsumerContextClusterInterceptor 和 ZoneAwareClusterInterceptor，继承关系如下图所示： ConsumerContextClusterInterceptor12345678910111213141516171819202122232425262728293031323334353637383940@Activatepublic class ConsumerContextClusterInterceptor implements ClusterInterceptor, ClusterInterceptor.Listener &#123; @Override public void before(AbstractClusterInvoker&lt;?&gt; invoker, Invocation invocation) &#123; RpcContext context = RpcContext.getContext(); // 设置当前 Consumer 地址 context.setInvocation(invocation).setLocalAddress(NetUtils.getLocalHost(), 0); // 设置此次调用的 Invoker if (invocation instanceof RpcInvocation) &#123; ((RpcInvocation) invocation).setInvoker(invoker); &#125; // 移除 Server Context RpcContext.removeServerContext(); &#125; @Override public void after(AbstractClusterInvoker&lt;?&gt; clusterInvoker, Invocation invocation) &#123; // 移除本地 RpcContext RpcContext.removeContext(true); &#125; /** * 实现了 ClusterInterceptor.Listener 接口 * * @param appResponse * @param invoker * @param invocation */ @Override public void onMessage(Result appResponse, AbstractClusterInvoker&lt;?&gt; invoker, Invocation invocation) &#123; // 获取响应中的 attachments 并设置到 RpcContext RpcContext.getServerContext().setObjectAttachments(appResponse.getObjectAttachments()); &#125; @Override public void onError(Throwable t, AbstractClusterInvoker&lt;?&gt; invoker, Invocation invocation) &#123; &#125;&#125; ZoneAwareClusterInterceptor12345678910111213141516171819202122232425262728293031323334353637/** * Determines the zone information of current request. * &lt;p&gt; * active only when url has key 'cluster=zone-aware' */@Activate(value = \"cluster:zone-aware\")public class ZoneAwareClusterInterceptor implements ClusterInterceptor &#123; @Override public void before(AbstractClusterInvoker&lt;?&gt; clusterInvoker, Invocation invocation) &#123; RpcContext rpcContext = RpcContext.getContext(); // 获取多注册中心相关参数并设置到 Invocation 中，主要是 registry_zone 参数和 registry_zone_force 参数 String zone = (String) rpcContext.getAttachment(REGISTRY_ZONE); String force = (String) rpcContext.getAttachment(REGISTRY_ZONE_FORCE); // 检测用户是否提供了ZoneDetector接口的扩展实现 ExtensionLoader&lt;ZoneDetector&gt; loader = ExtensionLoader.getExtensionLoader(ZoneDetector.class); if (StringUtils.isEmpty(zone) &amp;&amp; loader.hasExtension(\"default\")) &#123; ZoneDetector detector = loader.getExtension(\"default\"); zone = detector.getZoneOfCurrentRequest(invocation); force = detector.isZoneForcingEnabled(invocation, zone); &#125; // 将registry_zone参数和registry_zone_force参数设置到Invocation中 if (StringUtils.isNotEmpty(zone)) &#123; invocation.setAttachment(REGISTRY_ZONE, zone); &#125; if (StringUtils.isNotEmpty(force)) &#123; invocation.setAttachment(REGISTRY_ZONE_FORCE, force); &#125; &#125; @Override public void after(AbstractClusterInvoker&lt;?&gt; clusterInvoker, Invocation invocation) &#123; &#125;&#125; 注意，只有当 URL 中存在 key = cluster=zone-aware 时 ZoneAwareClusterInterceptor 才会激活。该拦截器主要是将多注册中心相关的参数设置到 Invocation 中，为 ZoneAwareClusterInvoker 服务。 AbstractClusterInvoker属性123456789101112131415161718192021222324252627282930313233343536public abstract class AbstractClusterInvoker&lt;T&gt; implements Invoker&lt;T&gt; &#123; private static final Logger logger = LoggerFactory.getLogger(AbstractClusterInvoker.class); /** * 重要- Directory[RegistryDirectory]，通过它，可以获得所有服务提供者的Invoker对象 */ protected final Directory&lt;T&gt; directory; /** * 集群时是否排除非可用的Invoker，默认为true。通过 cluster.availablecheck 配置项设置 */ protected final boolean availablecheck; /** * 是否已经销毁 */ private AtomicBoolean destroyed = new AtomicBoolean(false); /** * 粘滞连接 Invoker */ private volatile Invoker&lt;T&gt; stickyInvoker = null; public AbstractClusterInvoker(Directory&lt;T&gt; directory) &#123; this(directory, directory.getUrl()); &#125; public AbstractClusterInvoker(Directory&lt;T&gt; directory, URL url) &#123; if (directory == null) &#123; throw new IllegalArgumentException(\"service directory == null\"); &#125; this.directory = directory; // sticky: invoker.isAvailable() should always be checked before using when availablecheck is true. this.availablecheck = url.getParameter(Constants.CLUSTER_AVAILABLE_CHECK_KEY, Constants.DEFAULT_CLUSTER_AVAILABLE_CHECK); &#125;&#125; 下面对 AbstractClusterInvoker 中的核心属性进行说明： directory 服务目录，可以获取所有提供者对应的 Invoker 集合。 availablecheck 集群时是否排除非可用的 Invoker，默认为 true，可通过 cluster.availablecheck 配置项设置. destroyed 标记当前 Cluster Invoker 是否已销毁。 stickyInvoker 粘滞连接用于有状态服务，尽可能让客户端总是向同一提供者发起调用，除非该提供者挂了，再连另一台。粘滞连接将自动开启延迟连接，以减少长连接数。 配置：&lt;dubbo:reference stick=&quot;true&quot;/&gt; 或 &lt;dubbo:reference&gt; &lt;dubbo:method name=&quot;&quot; sticky=&quot;true&quot;&gt;&lt;/dubbo:method&gt;&lt;/dubbo:reference&gt; 判断 Cluster Invoker 状态12345678910111213141516+--- AbstractClusterInvoker /** * 判断 Cluster Invoker 是否可用 * 1. 如果存在粘滞 Invoker，则基于该 Invoker 进行判断 * 2. 如果不存在粘滞 Invoker，则基于 Directory 判断 * * @return */ @Override public boolean isAvailable() &#123; Invoker&lt;T&gt; invoker = stickyInvoker; if (invoker != null) &#123; return invoker.isAvailable(); &#125; return directory.isAvailable(); &#125; 获取 Invoker 列表1234+--- AbstractClusterInvoker protected List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException &#123; return directory.list(invocation); &#125; invoke() 调用123456789101112131415161718192021222324252627+--- AbstractClusterInvoker@Override public Result invoke(final Invocation invocation) throws RpcException &#123; // 1 检查当前 Cluster Invoker 是否已销毁 checkWhetherDestroyed(); // 2 将 RpcContext 中的 attachments 添加到 invocation 中 Map&lt;String, Object&gt; contextAttachments = RpcContext.getContext().getObjectAttachments(); if (contextAttachments != null &amp;&amp; contextAttachments.size() != 0) &#123; ((RpcInvocation) invocation).addObjectAttachments(contextAttachments); &#125; // 3 通过 Directory 获取 Invoker 列表 // 注意，该 Invoker 列表是已经经过 Router 过滤后的结果 List&lt;Invoker&lt;T&gt;&gt; invokers = list(invocation); // 4 通过 SPI 加载 LoadBalance // 4.1 如果 Invoker 列表不为空，则根据第一个 Invoker的URL和调用信息初始化 // 4.2 如果 Invoker 列表为空，则使用默认的负载均衡器 LoadBalance loadbalance = initLoadBalance(invokers, invocation); // 5 如果是异步操作，则添加一个 id 调用编号到 invocation 的 attachment 中 RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation); // 6 执行调用逻辑，由子类实现 return doInvoke(invocation, invokers, loadbalance); &#125; AbstractClusterInvoker 的 invoke 方法主要做以下工作： 检查当前 Cluster Invoker 的状态，如果处于销毁状态，则不可调用。 从上下文中取出隐式参数，然后设置到调用信息 Invocation 中。 从服务目录中获取 Invoker 列表，注意是经过 Router 过滤后的结果。 初始化 LoadBalance ，子类将会使用该负载均衡器选择目标 Invoker 。 对异步操作进行处理，添加一个调用编号到调用信息中 子类实现选择目标 Invoker 并调用逻辑。 AbstractClusterInvoker.invoke 逻辑就是为选择和调用目标 Invoker 作准备的，具体地选择和调用目标 Invoker 由子类实现。 通用选择方法AbstractClusterInvoker 并没有简单粗暴地直接使用负载均衡完成选择逻辑，而是做了进一步的封装。在效率方面使用了粘滞连接的特性，在正确性方面使用了重新选择的方式来尽最大努力确保选出的 Invoker 是可用的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152+--- AbstractClusterInvoker /** * * @param loadbalance 负载均衡器 * @param invocation 调用信息 * @param invokers 候选的 Invoker 集合 * @param selected 已选择过的 Invoker 集合（注意，不是所有的集群策略都会传该值，不关心的将会传 null） * @return 目标 Invoker * @throws RpcException exception */ protected Invoker&lt;T&gt; select(LoadBalance loadbalance, Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, List&lt;Invoker&lt;T&gt;&gt; selected) throws RpcException &#123; // 1 候选 Invoker 列表为空，直接返回 null if (CollectionUtils.isEmpty(invokers)) &#123; return null; &#125; // 2 获取调用方法名 String methodName = invocation == null ? StringUtils.EMPTY_STRING : invocation.getMethodName(); // 3 获取 sticky 配置项，优先方法级别的 // sticky 表示粘滞连接，所谓粘滞连接是指 Consumer 会尽可能地调用同一个Provider节点，除非这个Provider无法提供服务 boolean sticky = invokers.get(0).getUrl() .getMethodParameter(methodName, CLUSTER_STICKY_KEY, DEFAULT_CLUSTER_STICKY); // 4 检测候选 Invoker 列表是否包含 sticky Invoker。 // 如果不包含，说明缓存的 sticky Invoker 是不可用的，需要将其置空 if (stickyInvoker != null &amp;&amp; !invokers.contains(stickyInvoker)) &#123; stickyInvoker = null; &#125; // 5 开启了粘滞连接特性 &amp; sticky Invoker 存在且没有被选择过 &amp; sticky Invoker 可用 if (sticky &amp;&amp; // 开启粘滞连接特性 stickyInvoker != null &amp;&amp; // sticky Invoker 不为空 (selected == null || !selected.contains(stickyInvoker))) &#123; // sticky Invoker 未被选择过 // 检测当前 stickyInvoker 是否可用，如果可用，直接返回 sticky Invoker if (availablecheck &amp;&amp; stickyInvoker.isAvailable()) &#123; return stickyInvoker; &#125; &#125; // 6 sticky Invoker 为空或不可用，则执行选择 Invoker 逻辑 Invoker&lt;T&gt; invoker = doSelect(loadbalance, invocation, invokers, selected); // 7 如果开启粘滞连接特性，则更新 stickyInvoker 字段 if (sticky) &#123; stickyInvoker = invoker; &#125; return invoker; &#125; 在 select() 方法中会根据配置决定是否开启粘滞连接特性，如果开启了，则会将上次选择出的 Invoker 缓存起来，只要该粘滞 Invoker 可用就直接使用，不会再进行负载均衡。该方法主要是处理粘滞连接特性。 下面我们继续分析 doSelect() 方法，该方法才会使用负载均衡器选择目标 Invoker，并尽最大努力确保选出的 Invoker 是可用的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455+--- AbstractClusterInvoker /** * @param loadbalance 负载均衡对象 * @param invocation 调用信息 * @param invokers 候选的 Invoker 列表 * @param selected 已选过的 Invoker 集合 * @return * @throws RpcException */ private Invoker&lt;T&gt; doSelect(LoadBalance loadbalance, Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, List&lt;Invoker&lt;T&gt;&gt; selected) throws RpcException &#123; // 1 判断是否需要负载均衡，Invoker 集合为空，则直接返回 null if (CollectionUtils.isEmpty(invokers)) &#123; return null; &#125; // 2 候选 Invoker 仅有一个，则直接返回 if (invokers.size() == 1) &#123; return invokers.get(0); &#125; // 3 使用负载均衡器选择目标 Invoker Invoker&lt;T&gt; invoker = loadbalance.select(invokers, getUrl(), invocation); //If the `invoker` is in the `selected` or invoker is unavailable &amp;&amp; availablecheck is true, reselect. // 4 对负载均衡选出的 Invoker 进行校验，决定是否重新选择 if ((selected != null &amp;&amp; selected.contains(invoker)) // 选出的 Invoker 已经被选择过 || (!invoker.isAvailable() &amp;&amp; getUrl() != null &amp;&amp; availablecheck)) &#123; // 选出的 Invoker 不可用 try &#123; // 4.1 重新进行一次负载均衡 Invoker&lt;T&gt; rInvoker = reselect(loadbalance, invocation, invokers, selected, availablecheck); // 4.2 如果重新选择的 Invoker 对象不为空，则直接使用该 Invoker if (rInvoker != null) &#123; invoker = rInvoker; // 4.3 如果重新选择的Invoker为空，就进行容错，无论如何都要选出一个 &#125; else &#123; // 4.4 第一次选的Invoker如果不是候选Invoker列表中最后一个就选它的下一个，否则就使用候选Invoker列表中的第一个。进行兜底，保证能够获取到一个Invoker int index = invokers.indexOf(invoker); try &#123; //Avoid collision invoker = invokers.get((index + 1) % invokers.size()); &#125; catch (Exception e) &#123; logger.warn(e.getMessage() + \" may because invokers list dynamic change, ignore.\", e); &#125; &#125; &#125; catch (Throwable t) &#123; logger.error(\"cluster reselect fail reason is :\" + t.getMessage() + \" if can not solve, you can set cluster.availablecheck=false in url\", t); &#125; &#125; return invoker; &#125; doSelect() 方法主要做了两件事，其一是通过 LoadBalance 选择 Invoker 对象；其二是如果选出来的 Invoker 不稳定或不可用，会调用 reselect() 方法进行重选。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152+--- AbstractClusterInvoker/** * Reselect, use invokers not in `selected` first, if all invokers are in `selected`, * just pick an available one using loadbalance policy. * * @param loadbalance 负载均衡器 * @param invocation 调用信息 * @param invokers 候选 Invoker 列表 * @param selected 已选过的 Invoker 列表 * @param availablecheck 可用性检查 * @return 目标 Invoker * @throws RpcException exception */ private Invoker&lt;T&gt; reselect(LoadBalance loadbalance, Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, List&lt;Invoker&lt;T&gt;&gt; selected, boolean availablecheck) throws RpcException &#123; // 1 预先分配一个列表 // 注意：这个列表大小比候选的 Invoker列表大小小 1，因为候选Invoker列表中的Invoker可能在selected中或者不可用，从上一步结果可知。 List&lt;Invoker&lt;T&gt;&gt; reselectInvokers = new ArrayList&lt;&gt;( invokers.size() &gt; 1 ? (invokers.size() - 1) : invokers.size()); // 2 将不在 selected 集合中且是可用状态的 Invoker 过滤出来参与负载均衡 for (Invoker&lt;T&gt; invoker : invokers) &#123; if (availablecheck &amp;&amp; !invoker.isAvailable()) &#123; continue; &#125; if (selected == null || !selected.contains(invoker)) &#123; reselectInvokers.add(invoker); &#125; &#125; // 3 reselectInvokers 不为空时，才需要通过负载均衡组件进行选择 if (!reselectInvokers.isEmpty()) &#123; return loadbalance.select(reselectInvokers, getUrl(), invocation); &#125; // 4 线程走到这里，说明 reselectInvokers 集合为空。这时需要兜底，从已经选择过的Invoker列表中选择可用的Invoker列表，然后通过负载均衡器选择一个目标的Invoker if (selected != null) &#123; for (Invoker&lt;T&gt; invoker : selected) &#123; if ((invoker.isAvailable()) // available first &amp;&amp; !reselectInvokers.contains(invoker)) &#123; reselectInvokers.add(invoker); &#125; &#125; &#125; if (!reselectInvokers.isEmpty()) &#123; return loadbalance.select(reselectInvokers, getUrl(), invocation); &#125; // 5 实在选不出来，只能返回 null return null; &#125; reselect 方法会重新进行一次负载均衡，首先会对未尝试过的且可用状态的 Invoker 列表进行负载均衡，选出最终的 Invoker 对象并返回。如果没有可尝试的 Invoker ，则进行兜底操作，只能对尝试过的且是可用状态的 Invoker 列表重新进行负载均衡，选出目标 Invoker 对象。 至此，通用的 Cluster 和 Cluster Invoker 逻辑已经介绍完了，下面我们就来分析 Dubbo 中的具体集群策略。 FailoverCluster &amp; FailoverClusterInvokerFailoverCluster 用于创建 FailoverClusterInvoker 对象，FailoverClusterInvoker 实现了调用失败自动切换的逻辑。 FailoverCluster123456789101112public class FailoverCluster extends AbstractCluster &#123; /** * 扩展名 */ public final static String NAME = \"failover\"; @Override public &lt;T&gt; AbstractClusterInvoker&lt;T&gt; doJoin(Directory&lt;T&gt; directory) throws RpcException &#123; // 创建 FailoverClusterInvoker 对象 return new FailoverClusterInvoker&lt;&gt;(directory); &#125;&#125; FailoverClusterInvoker12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394public class FailoverClusterInvoker&lt;T&gt; extends AbstractClusterInvoker&lt;T&gt; &#123; private static final Logger logger = LoggerFactory.getLogger(FailoverClusterInvoker.class); public FailoverClusterInvoker(Directory&lt;T&gt; directory) &#123; super(directory); &#125; @Override @SuppressWarnings(&#123;\"unchecked\", \"rawtypes\"&#125;) public Result doInvoke(Invocation invocation, final List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; List&lt;Invoker&lt;T&gt;&gt; copyInvokers = invokers; // 1 检查候选 Invoker 列表是否为空 checkInvokers(copyInvokers, invocation); // 2 获取调用方法名 String methodName = RpcUtils.getMethodName(invocation); // 3 获取配置的重试次数，默认重试 2 次，总共执行 3 次 int len = getUrl().getMethodParameter(methodName, RETRIES_KEY, DEFAULT_RETRIES) + 1; if (len &lt;= 0) &#123; len = 1; &#125; // 4 准备调用记录属性 // 记录最后一次调用异常（如果有的情况下） RpcException le = null; // 记录已经调用过的 Invoker List&lt;Invoker&lt;T&gt;&gt; invoked = new ArrayList&lt;Invoker&lt;T&gt;&gt;(copyInvokers.size()); // 记录负载均衡选出来的 Invoker 的网络地址 Set&lt;String&gt; providers = new HashSet&lt;String&gt;(len); // 5 如果出现调用失败，则重试其他服务。这是该集群容错机制的核心。 for (int i = 0; i &lt; len; i++) &#123; // 第一次传进来的 invokers 已经check过了，第二次则是重试，需要重新获取最新的服务列表 if (i &gt; 0) &#123; // 检查当前 ClusterInvoker 是否可用 checkWhetherDestroyed(); // 重新从服务目录中拉取 Invoker 列表 copyInvokers = list(invocation); // 检查 copyInvokers ，防止服务目录中的 Invoker 列表为空 checkInvokers(copyInvokers, invocation); &#125; // 使用 LoadBalance 选择 Invoker 对象，这里传入 invoked 集合 Invoker&lt;T&gt; invoker = select(loadbalance, invocation, copyInvokers, invoked); // 记录此次尝试调用的 Invoker ，之后非兜底情况会过滤掉该 Invoker invoked.add(invoker); // 保存已选过的 Invoker 到上下文 RpcContext.getContext().setInvokers((List) invoked); try &#123; // RPC 调用 Result result = invoker.invoke(invocation); // 经过重试之后，成功了。这里会打印最后一次调用的异常信息。 if (le != null &amp;&amp; logger.isWarnEnabled()) &#123; logger.warn(\"Although retry the method \" + methodName + \" in the service \" + getInterface().getName() + \" was successful by the provider \" + invoker.getUrl().getAddress() + \", but there have been failed providers \" + providers + \" (\" + providers.size() + \"/\" + copyInvokers.size() + \") from the registry \" + directory.getUrl().getAddress() + \" on the consumer \" + NetUtils.getLocalHost() + \" using the dubbo version \" + Version.getVersion() + \". Last error is: \" + le.getMessage(), le); &#125; return result; &#125; catch (RpcException e) &#123; // 如果是业务性质的异常，则不再重试，直接抛出异常 if (e.isBiz()) &#123; // biz exception. throw e; &#125; le = e; // 其他异常同一封装成 RpcException，表示此次尝试失败，会进行重试。 &#125; catch (Throwable e) &#123; le = new RpcException(e.getMessage(), e); &#125; finally &#123; // 记录尝试过的提供者的地址 providers.add(invoker.getUrl().getAddress()); &#125; &#125; // 6 达到重试次数上限后仍然调用失败的话，就抛出异常。 throw new RpcException(le.getCode(), \"Failed to invoke the method \" + methodName + \" in the service \" + getInterface().getName() + \". Tried \" + len + \" times of the providers \" + providers + \" (\" + providers.size() + \"/\" + copyInvokers.size() + \") from the registry \" + directory.getUrl().getAddress() + \" on the consumer \" + NetUtils.getLocalHost() + \" using the dubbo version \" + Version.getVersion() + \". Last error is: \" + le.getMessage(), le.getCause() != null ? le.getCause() : le); &#125;&#125; FailoverClusterInvoker 的 doInvoke 方法首先是获取重试次数，然后根据重试次数进行循环调用，失败后进行重试。在循环逻辑中，先根据负载均衡器选择一个 Invoker，然后再通过这个 Invoker 进行远程调用。如果失败了，记录下异常，并进行重试，直到达到最大重试次数。注意，每次进行重试时都会重新从服务目录中拉取 Invoker 列表防止脏数据，并且会进行一次负载均衡处理。 FailbackCluster &amp; FailbackClusterInvokerFailbackCluster 用于创建 FailbackClusterInvoker 对象，FailbackClusterInvoker 会在调用失败后返回一个空结果给服务消费端，并通过定时任务对失败的调用进行重试，注意，服务消费端已经收到了空的结果，虽然定时重试，但是和调用方已经无关了。 FailbackCluster123456789101112public class FailbackCluster extends AbstractCluster &#123; /** * 扩展名 */ public final static String NAME = \"failback\"; @Override public &lt;T&gt; AbstractClusterInvoker&lt;T&gt; doJoin(Directory&lt;T&gt; directory) throws RpcException &#123; // 创建 FailbackClusterInvoker 对象 return new FailbackClusterInvoker&lt;&gt;(directory); &#125;&#125; FailbackClusterInvoker12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091public class FailbackClusterInvoker&lt;T&gt; extends AbstractClusterInvoker&lt;T&gt; &#123; private static final Logger logger = LoggerFactory.getLogger(FailbackClusterInvoker.class); /** * 重试间隔 */ private static final long RETRY_FAILED_PERIOD = 5; /** * 失败重试次数 */ private final int retries; /** * 失败任务数 */ private final int failbackTasks; /** * 定时器 */ private volatile Timer failTimer; public FailbackClusterInvoker(Directory&lt;T&gt; directory) &#123; super(directory); // 1 获取 retries 配置项，即请求失败重试次数，默认 3 次 int retriesConfig = getUrl().getParameter(RETRIES_KEY, DEFAULT_FAILBACK_TIMES); if (retriesConfig &lt;= 0) &#123; retriesConfig = DEFAULT_FAILBACK_TIMES; &#125; // 2 失败重试的任务数，默认 100 int failbackTasksConfig = getUrl().getParameter(FAIL_BACK_TASKS_KEY, DEFAULT_FAILBACK_TASKS); if (failbackTasksConfig &lt;= 0) &#123; failbackTasksConfig = DEFAULT_FAILBACK_TASKS; &#125; retries = retriesConfig; failbackTasks = failbackTasksConfig; &#125; @Override protected Result doInvoke(Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; Invoker&lt;T&gt; invoker = null; try &#123; // 1 检查候选 Invoker 列表是否为空 checkInvokers(invokers, invocation); // 2 使用 LoadBalance 选择 Invoker 对象，这里传入 invoked 集合 invoker = select(loadbalance, invocation, invokers, null); // 3 RPC 调用 return invoker.invoke(invocation); &#125; catch (Throwable e) &#123; logger.error(\"Failback to invoke method \" + invocation.getMethodName() + \", wait for retry in background. Ignored exception: \" + e.getMessage() + \", \", e); // 4 调用失败后，添加一个定时任务进行定时重试 addFailed(loadbalance, invocation, invokers, invoker); // 5 返回一个空结果 return AsyncRpcResult.newDefaultAsyncResult(null, null, invocation); // ignore &#125; &#125; /** * 添加失败重试定时任务。默认每隔 5s 执行一次，总共重试 3 次。 * * @param loadbalance * @param invocation * @param invokers * @param lastInvoker */ private void addFailed(LoadBalance loadbalance, Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, Invoker&lt;T&gt; lastInvoker) &#123; // 1 初始化时间轮 if (failTimer == null) &#123; synchronized (this) &#123; if (failTimer == null) &#123; failTimer = new HashedWheelTimer( new NamedThreadFactory(\"failback-cluster-timer\", true), 1, TimeUnit.SECONDS, 32, failbackTasks); &#125; &#125; &#125; // 2 创建重试定时任务 RetryTimerTask retryTimerTask = new RetryTimerTask(loadbalance, invocation, invokers, lastInvoker, retries, RETRY_FAILED_PERIOD); try &#123; // 3 将定时任务加载到时间轮中 failTimer.newTimeout(retryTimerTask, RETRY_FAILED_PERIOD, TimeUnit.SECONDS); &#125; catch (Throwable e) &#123; logger.error(\"Failback background works error,invocation-&gt;\" + invocation + \", exception: \" + e.getMessage()); &#125; &#125; FailbackClusterInvoker 主要逻辑如下： 使用 LoadBalance 选择一个 Invoker 对象（存在可用的粘滞 Invoker 就不需要负载均衡了） 使用选出的 Invoker 进行 RPC 调用，如果调用成功则直接返回，也就没有重试的事了 调用失败后，通过 addFailed 方法创建一个失败重试的定时任务，重试任务默认会每隔 5s 执行一次，最多重试 3 次。并且，每次重试都会重新选择 Invoker 。 调用失败后，会返回一个空结果。 了解了 FailbackClusterInvoker 逻辑后，我们继续对重试逻辑进行说明。 RetryTimerTask12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758private class RetryTimerTask implements TimerTask &#123; private final Invocation invocation; private final LoadBalance loadbalance; private final List&lt;Invoker&lt;T&gt;&gt; invokers; private final int retries; private final long tick; private Invoker&lt;T&gt; lastInvoker; private int retryTimes = 0; RetryTimerTask(LoadBalance loadbalance, Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, Invoker&lt;T&gt; lastInvoker, int retries, long tick) &#123; this.loadbalance = loadbalance; this.invocation = invocation; this.invokers = invokers; this.retries = retries; this.tick = tick; this.lastInvoker = lastInvoker; &#125; @Override public void run(Timeout timeout) &#123; try &#123; // 重新选择 Invoker 对象，这里会将上次重试失败的 Invoker 作为 selected 集合传入 Invoker&lt;T&gt; retryInvoker = select(loadbalance, invocation, invokers, Collections.singletonList(lastInvoker)); lastInvoker = retryInvoker; // RPC 调用 retryInvoker.invoke(invocation); // RPC 调用失败时才会尝试重试 &#125; catch (Throwable e) &#123; logger.error(\"Failed retry to invoke method \" + invocation.getMethodName() + \", waiting again.\", e); // 重试次数未达到上限，才会重新添加定时任务，然后等待重试 if ((++retryTimes) &gt;= retries) &#123; logger.error(\"Failed retry times exceed threshold (\" + retries + \"), We have to abandon, invocation-&gt;\" + invocation); &#125; else &#123; rePut(timeout); &#125; &#125; &#125; /** * 重新添加，等待重试 * * @param timeout */ private void rePut(Timeout timeout) &#123; if (timeout == null) &#123; return; &#125; Timer timer = timeout.timer(); if (timer.isStop() || timeout.isCancelled()) &#123; return; &#125; timer.newTimeout(timeout.task(), tick, TimeUnit.SECONDS); &#125; &#125; FailfastCluster &amp; FailfastClusterInvokerFailfastCluster 用于创建 FailfastClusterInvoker 对象，FailfastClusterInvoker 只会进行一次调用，失败后立即抛出异常，这种策略适合非幂等的操作。 FailfastCluster123456789101112public class FailfastCluster extends AbstractCluster &#123; /** * 扩展名 */ public final static String NAME = \"failfast\"; @Override public &lt;T&gt; AbstractClusterInvoker&lt;T&gt; doJoin(Directory&lt;T&gt; directory) throws RpcException &#123; // 创建 FailfastClusterInvoker 对象 return new FailfastClusterInvoker&lt;&gt;(directory); &#125;&#125; FailfastClusterInvoker123456789101112131415161718192021222324252627282930313233public class FailfastClusterInvoker&lt;T&gt; extends AbstractClusterInvoker&lt;T&gt; &#123; public FailfastClusterInvoker(Directory&lt;T&gt; directory) &#123; super(directory); &#125; @Override public Result doInvoke(Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; // 1 检测候选 Invoker 列表是否为空 checkInvokers(invokers, invocation); // 2 使用 LoadBalance 选择 Invoker 对象 Invoker&lt;T&gt; invoker = select(loadbalance, invocation, invokers, null); try &#123; // 3 RPC 调用 return invoker.invoke(invocation); // 4 请求失败，直接抛出异常 &#125; catch (Throwable e) &#123; if (e instanceof RpcException &amp;&amp; ((RpcException) e).isBiz()) &#123; // biz exception. throw (RpcException) e; &#125; throw new RpcException(e instanceof RpcException ? ((RpcException) e).getCode() : 0, \"Failfast invoke providers \" + invoker.getUrl() + \" \" + loadbalance.getClass().getSimpleName() + \" select from all providers \" + invokers + \" for service \" + getInterface().getName() + \" method \" + invocation.getMethodName() + \" on consumer \" + NetUtils.getLocalHost() + \" use dubbo version \" + Version.getVersion() + \", but no luck to perform the invocation. Last error is: \" + e.getMessage(), e.getCause() != null ? e.getCause() : e); &#125; &#125;&#125; FailsafeCluster &amp; FailsafeClusterInvokerFailsafeCluster 用于创建 FailsafeClusterInvoker 对象，FailsafeClusterInvoker 是一种失败安全的 Cluster Invoker 。所谓失败安全指的是，当调用过程出现异常时，FailsafeClusterInvoker 仅会打印异常日志，而不会抛出异常，代替的是返回一个空间结果。 FailsafeCluster123456789101112public class FailsafeCluster extends AbstractCluster &#123; /** * 扩展名 */ public final static String NAME = \"failsafe\"; @Override public &lt;T&gt; AbstractClusterInvoker&lt;T&gt; doJoin(Directory&lt;T&gt; directory) throws RpcException &#123; // 创建 FailsafeClusterInvoker 对象 return new FailsafeClusterInvoker&lt;&gt;(directory); &#125;&#125; FailsafeClusterInvoker1234567891011121314151617181920212223242526public class FailsafeClusterInvoker&lt;T&gt; extends AbstractClusterInvoker&lt;T&gt; &#123; private static final Logger logger = LoggerFactory.getLogger(FailsafeClusterInvoker.class); public FailsafeClusterInvoker(Directory&lt;T&gt; directory) &#123; super(directory); &#125; @Override public Result doInvoke(Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; try &#123; // 1 检测候选 Invoker 列表是否为空 checkInvokers(invokers, invocation); // 2 使用 LoadBalance 选择 Invoker 对象 Invoker&lt;T&gt; invoker = select(loadbalance, invocation, invokers, null); // 3 RPC 调用 return invoker.invoke(invocation); &#125; catch (Throwable e) &#123; logger.error(\"Failsafe ignore exception: \" + e.getMessage(), e); // 4 调用异常，直接返回一个空结果，不会抛出异常 return AsyncRpcResult.newDefaultAsyncResult(null, null, invocation); // ignore &#125; &#125;&#125; ForkingCluster &amp; ForkingClusterInvokerForkingCluster 用于创建 ForkingClusterInvoker 对象，ForkingClusterInvoker 支持并发调用多个服务提供者，只要有一个服务提供者成功返回了结果，就会立即结束运行。 ForkingCluster123456789101112public class ForkingCluster extends AbstractCluster &#123; /** * 扩展名 */ public final static String NAME = \"forking\"; @Override public &lt;T&gt; AbstractClusterInvoker&lt;T&gt; doJoin(Directory&lt;T&gt; directory) throws RpcException &#123; // 创建 ForkingClusterInvoker 对象 return new ForkingClusterInvoker&lt;&gt;(directory); &#125;&#125; ForkingClusterInvoker123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293public class ForkingClusterInvoker&lt;T&gt; extends AbstractClusterInvoker&lt;T&gt; &#123; /** * 执行多个 Invoker RPC 调用的线程池 */ private final ExecutorService executor = Executors.newCachedThreadPool( new NamedInternalThreadFactory(\"forking-cluster-timer\", true)); public ForkingClusterInvoker(Directory&lt;T&gt; directory) &#123; super(directory); &#125; @Override @SuppressWarnings(&#123;\"unchecked\", \"rawtypes\"&#125;) public Result doInvoke(final Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; try &#123; // 1 检查候选 Invoker 集合是否为空 checkInvokers(invokers, invocation); // 保存选择的 Invoker final List&lt;Invoker&lt;T&gt;&gt; selected; // 获取 forks 配置项，即并行数，默认为 2 final int forks = getUrl().getParameter(FORKS_KEY, DEFAULT_FORKS); // 获取 timeout 配置项，即超时时间，默认为 1000 毫秒 final int timeout = getUrl().getParameter(TIMEOUT_KEY, DEFAULT_TIMEOUT); // 2 最大并行数 &lt;= 0 或者 &gt;= Invoker 数，则选择所有的 Invoker if (forks &lt;= 0 || forks &gt;= invokers.size()) &#123; selected = invokers; // 3 根据并行数，选择此次并发调用的 Invoker &#125; else &#123; selected = new ArrayList&lt;&gt;(forks); // 循环并行数，每次循环都要尝试选择一个 Invoker // 注意：可能最终得到的 Invoker 列表大小小于并发数 while (selected.size() &lt; forks) &#123; Invoker&lt;T&gt; invoker = select(loadbalance, invocation, invokers, selected); // 避免重复选择 if (!selected.contains(invoker)) &#123; //Avoid add the same invoker several times. selected.add(invoker); &#125; &#125; &#125; // 4 将选中的 Invoker 列表设置到上下文中 RpcContext.getContext().setInvokers((List) selected); // 记录调用失败数 final AtomicInteger count = new AtomicInteger(); // 记录请求的结果 final BlockingQueue&lt;Object&gt; ref = new LinkedBlockingQueue&lt;&gt;(); // 5 遍历 selected ，将每个 Invoker 的 RPC 调用提交到线程池，并把结果放入到阻塞队列中 for (final Invoker&lt;T&gt; invoker : selected) &#123; executor.execute(() -&gt; &#123; try &#123; // RPC 调用 Result result = invoker.invoke(invocation); // 把调用结果放入到阻塞队列中 ref.offer(result); // 调用失败 &#125; catch (Throwable e) &#123; // 记录调用失败数 int value = count.incrementAndGet(); // 如果选择的 Invoker 全部调用失败，则把最后一次调用异常加入到阻塞队列 // 保证异常对象不会出现在正常结果的前面，这样可从阻塞队列中优先取出正常的结果 if (value &gt;= selected.size()) &#123; ref.offer(e); &#125; &#125; &#125;); &#125; try &#123; // 6 当前线程会阻塞等待任意一个调用结果，如果选择的 Invoker 全部调用失败，则会获取到一个异常结果。 Object ret = ref.poll(timeout, TimeUnit.MILLISECONDS); if (ret instanceof Throwable) &#123; Throwable e = (Throwable) ret; throw new RpcException(e instanceof RpcException ? ((RpcException) e).getCode() : 0, \"Failed to forking invoke provider \" + selected + \", but no luck to perform the invocation. Last error is: \" + e.getMessage(), e.getCause() != null ? e.getCause() : e); &#125; return (Result) ret; &#125; catch (InterruptedException e) &#123; throw new RpcException(\"Failed to forking invoke provider \" + selected + \", but no luck to perform the invocation. Last error is: \" + e.getMessage(), e); &#125; &#125; finally &#123; // clear attachments which is binding to current thread. RpcContext.getContext().clearAttachments(); &#125; &#125;&#125; ForkingClusterInvoker 会在运行依据并行调用数通过线程池创建多个线程，并发调用多个服务提供者，只要有一个服务提供者成功返回了结果，就会立即结束运行。主要应用在一些对实时性要求比较高的读操作下使用，但这将会耗费更多的资源。需要注意的是，因为没有并发控制，并行写操作可能不安全。 主要逻辑如下： 基于并行配置项 forks 的值选出合适数量的 Invoker，选出的 Invoker 数量小于等于并行数。 通过线程池并发调用步骤 1 中的多个 Invoker ，并将每个 Invoker 的调用结果暂存到阻塞队列中。 在阻塞队列中阻塞等待任意一个返回结果，并对返回结果类型进行判断，如果为异常类型，则直接抛出，否则返回。 BroadcastCluster &amp; BroadcastClusterInvokerBroadcastCluster 用于创建 BroadcastClusterInvoker 对象，BroadcastClusterInvoker 会逐个调用每个服务提供者，其中任意一个服务提供者节点报错，都会在全部调用结束之后抛出异常。该类通常用于通知类的操作，如通知所有提供者更新缓存或日志等本地资源信息。 BroadcastCluster12345678public class BroadcastCluster extends AbstractCluster &#123; @Override public &lt;T&gt; AbstractClusterInvoker&lt;T&gt; doJoin(Directory&lt;T&gt; directory) throws RpcException &#123; // 创建 BroadcastClusterInvoker 对象 return new BroadcastClusterInvoker&lt;&gt;(directory); &#125;&#125; BroadcastClusterInvoker1234567891011121314151617181920212223242526272829303132333435363738public class BroadcastClusterInvoker&lt;T&gt; extends AbstractClusterInvoker&lt;T&gt; &#123; private static final Logger logger = LoggerFactory.getLogger(BroadcastClusterInvoker.class); public BroadcastClusterInvoker(Directory&lt;T&gt; directory) &#123; super(directory); &#125; @Override @SuppressWarnings(&#123;\"unchecked\", \"rawtypes\"&#125;) public Result doInvoke(final Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; // 1 检测 Invoker 列表是否为空 checkInvokers(invokers, invocation); RpcContext.getContext().setInvokers((List) invokers); // 用于记录调用异常信息和调用结果 RpcException exception = null; Result result = null; // 遍历所有的 Invoker 对象 for (Invoker&lt;T&gt; invoker : invokers) &#123; try &#123; // RPC 请求 result = invoker.invoke(invocation); &#125; catch (RpcException e) &#123; exception = e; logger.warn(e.getMessage(), e); &#125; catch (Throwable e) &#123; exception = new RpcException(e.getMessage(), e); logger.warn(e.getMessage(), e); &#125; &#125; if (exception != null) &#123; throw exception; &#125; return result; &#125;&#125; AvailableCluster &amp; AvailableClusterInvokerAvailableCluster 用于创建 AvailableClusterInvoker 对象，AvailableClusterInvoker 会遍历整个候选 Invoker 列表，会使用首个可用的 Invoker 进行调用，成功则返回结果，失败则抛出异常终止遍历。需要说明的是，该集群策略没有使用到负载均衡机制。 AvailableCluster123456789101112public class AvailableCluster implements Cluster &#123; /** * 扩展名 */ public static final String NAME = \"available\"; @Override public &lt;T&gt; Invoker&lt;T&gt; join(Directory&lt;T&gt; directory) throws RpcException &#123; // 创建 AvailableClusterInvoker 对象 return new AvailableClusterInvoker&lt;&gt;(directory); &#125;&#125; AvailableClusterInvoker123456789101112131415161718192021public class AvailableClusterInvoker&lt;T&gt; extends AbstractClusterInvoker&lt;T&gt; &#123; public AvailableClusterInvoker(Directory&lt;T&gt; directory) &#123; super(directory); &#125; @Override public Result doInvoke(Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; // 遍历整个候选 Invoker 列表 for (Invoker&lt;T&gt; invoker : invokers) &#123; // 使用首个可用的 Invoker 进行调用 if (invoker.isAvailable()) &#123; return invoker.invoke(invocation); &#125; &#125; // 如果没有找到可用的 Invoker，则抛出异常 throw new RpcException(\"No provider available in \" + invokers); &#125;&#125; ZoneAwareCluster &amp; ZoneAwareClusterInvokerZoneAwareCluster 用于创建 ZoneAwareClusterInvoker 对象，ZoneAwareClusterInvoker 主要优先支持注册中心层面 Invoker 的选择与调用。 ZoneAwareCluster123456789101112public class ZoneAwareCluster extends AbstractCluster &#123; /** * 扩展名 */ public final static String NAME = \"zone-aware\"; @Override protected &lt;T&gt; AbstractClusterInvoker&lt;T&gt; doJoin(Directory&lt;T&gt; directory) throws RpcException &#123; // 创建 ZoneAwareClusterInvoker 对象 return new ZoneAwareClusterInvoker&lt;T&gt;(directory); &#125;&#125; ZoneAwareClusterInvoker12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273/** * When there're more than one registry for subscription. * &lt;p&gt; * This extension provides a strategy to decide how to distribute traffics among them: * 1. registry marked as 'preferred=true' has the highest priority. * 2. check the zone the current request belongs, pick the registry that has the same zone first. * 3. Evenly balance traffic between all registries based on each registry's weight. * 4. Pick anyone that's available. */public class ZoneAwareClusterInvoker&lt;T&gt; extends AbstractClusterInvoker&lt;T&gt; &#123; private static final Logger logger = LoggerFactory.getLogger(ZoneAwareClusterInvoker.class); public ZoneAwareClusterInvoker(Directory&lt;T&gt; directory) &#123; super(directory); &#125; @Override @SuppressWarnings(&#123;\"unchecked\", \"rawtypes\"&#125;) public Result doInvoke(Invocation invocation, final List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; // -------------- 1 基于注册中心选择 Invoker --------------- // 1.1 优先找到 preferred 属性为 true 的注册中心，它是优先级最高的注册中心，只有该注册中心无可用 Provider 节点时，才会回落到其他注册中心 for (Invoker&lt;T&gt; invoker : invokers) &#123; // FIXME, the invoker is a cluster invoker representing one Registry, so it will automatically wrapped by MockClusterInvoker. MockClusterInvoker&lt;T&gt; mockClusterInvoker = (MockClusterInvoker&lt;T&gt;) invoker; if (mockClusterInvoker.isAvailable() &amp;&amp; mockClusterInvoker.getRegistryUrl() .getParameter(REGISTRY_KEY + \".\" + PREFERRED_KEY, false)) &#123; return mockClusterInvoker.invoke(invocation); &#125; &#125; // 1.2 候选的 Invoker 都不在 preferred 属性为 true 的注册中心上，则根据请求中的 zone key 信息，查找该注册中下的 Invoker String zone = (String) invocation.getAttachment(REGISTRY_ZONE); if (StringUtils.isNotEmpty(zone)) &#123; // 遍历候选的 Invoker 列表 for (Invoker&lt;T&gt; invoker : invokers) &#123; MockClusterInvoker&lt;T&gt; mockClusterInvoker = (MockClusterInvoker&lt;T&gt;) invoker; // 根据请求中的 registry_zone 做匹配，选择相同 zone 的注册中心下的 Invoker if (mockClusterInvoker.isAvailable() &amp;&amp; zone.equals(mockClusterInvoker.getRegistryUrl().getParameter(REGISTRY_KEY + \".\" + ZONE_KEY))) &#123; return mockClusterInvoker.invoke(invocation); &#125; &#125; // 是否强制匹配 String force = (String) invocation.getAttachment(REGISTRY_ZONE_FORCE); // 如果强制匹配，只匹配和请求中具有相同 zone 的注册中心下提供者，如果没有匹配到，则抛出异常。如果不是强制匹配，则使用负载均衡选择 Invoker if (StringUtils.isNotEmpty(force) &amp;&amp; \"true\".equalsIgnoreCase(force)) &#123; throw new IllegalStateException(\"No registry instance in zone or no available providers in the registry, zone: \" + zone + \", registries: \" + invokers.stream().map(invoker -&gt; ((MockClusterInvoker&lt;T&gt;) invoker).getRegistryUrl().toString()).collect(Collectors.joining(\",\"))); &#125; &#125; // ------------------ 2 根据负载均衡选择 Invoker ------------------/ Invoker&lt;T&gt; balancedInvoker = select(loadbalance, invocation, invokers, null); if (balancedInvoker.isAvailable()) &#123; return balancedInvoker.invoke(invocation); &#125; // ------------------ 3 以上两种都没有选中 Invoker ，则从候选 Invoker 列表中选择一个可用的即可 --------------/ for (Invoker&lt;T&gt; invoker : invokers) &#123; MockClusterInvoker&lt;T&gt; mockClusterInvoker = (MockClusterInvoker&lt;T&gt;) invoker; if (mockClusterInvoker.isAvailable()) &#123; return mockClusterInvoker.invoke(invocation); &#125; &#125; throw new RpcException(\"No provider available in \" + invokers); &#125;&#125; 在 Dubbo 中使用多个注册中心的情况，服务消费端可以使用 ZoneAwareClusterInvoker 先在多个注册中心之间选择，确定注册中心之后，再选择服务提供者节点。 ZoneAwareClusterInvoker 选择目标 Invoker 的流程如下： 优先找到 preferred 属性为 true 的注册中心下的 Invoker，只有该中心无可用 Invoker 时，才会去匹配其他注册中心下的 Invoker 。 根据请求中的 zone 信息（注册中心信息）做匹配，如果候选 Invoker 中有匹配到该注册中心信息，则选中对应的 Invoker 。 无法根据注册中心信息匹配到目标 Invoker，则使用负载均衡选出目标 Invoker 。 如果以上流程都没有选择出 Invoker，则从候选 Invoker 列表中选出第一个可用的 Invoker 。 注意，前文中介绍的 ZoneAwareClusterInterceptor 会在前置处理方法中设置 registry_zone 参数和 registry_zone_force 参数到调用信息 Invocation 中， 小结本篇文章详细分析了 Dubbo 集群容错的几种实现方式。集群模块处于服务提供者和消费者之间，对于服务消费者来说，集群可向其屏蔽服务提供者集群的情况，使其能够专心进行远程调用。需要说明是，集群模块还包括 Merger 策略以及 Mock 机制，相比本篇文章介绍的几种常见集群策略，它们具有特定地功能机制，在后面的两篇文章中将会详细介绍。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"集群容错 - LoadBalance","slug":"rpc/集群容错之负载均衡","date":"2020-09-30T23:00:00.000Z","updated":"2021-04-06T08:33:39.593Z","comments":false,"path":"posts/9966fbd5/","link":"","permalink":"https://gentryhuang.com/posts/9966fbd5/","excerpt":"","text":"概述Dubbo 中的负载均衡 LoadBalance 的职责是将网络请求或者其它形式的负载 &quot;均摊&quot; 到不同的服务节点上，从而避免服务集群中部分节点压力过大，而另一部分节点比较空闲的情况。通过合理的负载均衡，可以让每个服务节点获取到适合自己处理能力的负载，实现处理能力和流量的合理分配。常用的负载均衡可分为软件负载均衡和硬件负载均衡，在日常开发中一般很难接触到硬件负载均衡，主要有 F5、NetScaler 等；软件负载均衡还是很常见的，比如 Nginx 。常见的 RPC 框架都有负载均衡的概念和相应的实现，Dubbo 也不例外。Dubbo 需要对服务消费者的调用请求进行分配，避免少数提供者节点负载过大，而其它提供者节点处于空闲状态。服务提供者负载过大，会导致部分请求超时、甚至丢失等一系列问题，造成线上故障。因此将负载均衡到每个服务提供者是非常有必要的。 负载均衡策略在集群负载均衡时，Dubbo 提供了 5 种均衡策略，缺省为 random 随机调用。 基于加权随机算法的 RandomLoadBalance 基于加权轮询算法的 RoundRobinLoadBalance 基于最少活跃调用数算法的 LeastActiveLoadBalance 基于一致性 Hash 的 ConsistentHashLoadBalance 基于最短响应时间的 ShortestResponseLoadBalance 继承关系图如下： 其中基于最短响应时间的 ShortestResponseLoadBalance 负载均衡策略是 Dubbo 2.7.x 新增的，和基于最少活跃调用数算法类似。 配置 服务端服务级别1&lt;dubbo:service interface=\"...\" loadbalance=\"roundrobin\" /&gt; 客户端服务级别1&lt;dubbo:reference interface=\"...\" loadbalance=\"roundrobin\" /&gt; 服务端方法级别123&lt;dubbo:service interface=\"...\"&gt; &lt;dubbo:method name=\"...\" loadbalance=\"roundrobin\"/&gt;&lt;/dubbo:service&gt; 客户端方法级别123&lt;dubbo:reference interface=\"...\"&gt; &lt;dubbo:method name=\"...\" loadbalance=\"roundrobin\"/&gt;&lt;/dubbo:reference&gt; 源码分析LoadBalance123456789101112131415@SPI(RandomLoadBalance.NAME)public interface LoadBalance &#123; /** * 根据传入的 URL 和 Invocation ，以及负载均衡算法从 Invoker 集合中选择一个 Invoker * * @param invokers invokers. * @param url refer url * @param invocation invocation. * @return selected invoker. */ @Adaptive(\"loadbalance\") &lt;T&gt; Invoker&lt;T&gt; select(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) throws RpcException;&#125; LoadBalance 是一个扩展接口，默认扩展实现是 RandomLoadBalance ，Dubbo 根据 @Adaptive(&quot;loadbalance&quot;) 注解生成的适配器会按照 URL 中的 loadbalance 参数值选择扩展实现类。 AbstractLoadBalance选择 Invoker123456789101112131415161718192021+--- AbstractLoadBalance /** * @param invokers invokers. * @param url refer url * @param invocation invocation. * @param &lt;T&gt; * @return */ @Override public &lt;T&gt; Invoker&lt;T&gt; select(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) &#123; // 1 Invoker集合为空，直接返回null if (CollectionUtils.isEmpty(invokers)) &#123; return null; &#125; // 2 Invoker集合只包含一个Invoker，则直接返回该Invoker对象 if (invokers.size() == 1) &#123; return invokers.get(0); &#125; // 3 Invoker集合包含多个Invoker对象时，交给doSelect()方法处理，这是个抽象方法，留给子类具体实现 return doSelect(invokers, url, invocation); &#125; AbstractLoadBalance 抽象类并没有真正实现 select() 方法，仅是对 Invoker 集合为空或是只包含一个 Invoker 对象的情况进行了处理，其它情况的选择逻辑交给子类实现。 服务提供者权重计算1234567891011121314151617181920212223242526272829303132333435+--- AbstractLoadBalance int getWeight(Invoker&lt;?&gt; invoker, Invocation invocation) &#123; int weight; URL url = invoker.getUrl(); // 1 多注册中心场景，多注册中心负载均衡。 if (REGISTRY_SERVICE_REFERENCE_PATH.equals(url.getServiceInterface())) &#123; // 1.1 如果是RegistryService接口的话，直接根据配置项 registry.weight 获取权重即可，默认是 100 weight = url.getParameter(REGISTRY_KEY + \".\" + WEIGHT_KEY, DEFAULT_WEIGHT); // 2 非多注册中心场景 &#125; else &#123; // 2.1 从 url 中获取 weight 配置值，默认为 100 weight = url.getMethodParameter(invocation.getMethodName(), WEIGHT_KEY, DEFAULT_WEIGHT); if (weight &gt; 0) &#123; // 2.2 获取服务提供者的启动时间戳 long timestamp = invoker.getUrl().getParameter(TIMESTAMP_KEY, 0L); if (timestamp &gt; 0L) &#123; // 2.3 计算Provider运行时长 long uptime = System.currentTimeMillis() - timestamp; if (uptime &lt; 0) &#123; return 1; &#125; // 2.4 从 url 中获取 Provider 预热时间配置值，默认为10分钟 int warmup = invoker.getUrl().getParameter(WARMUP_KEY, DEFAULT_WARMUP); // 2.5 如果Provider运行时间小于预热时间，则该Provider节点可能还在预热阶段，需要降低其权重 if (uptime &gt; 0 &amp;&amp; uptime &lt; warmup) &#123; weight = calculateWarmupWeight((int) uptime, warmup, weight); &#125; &#125; &#125; &#125; // 3 防御性编程，权重不能为负数 return Math.max(weight, 0); &#125; 在获取服务提供者权重时，需要考虑当前服务提供者是否还在预热阶段（运行时间小于预热时间），如果还在预热阶段需要对其进行降权处理，目的是避免服务提供者一启动就有大量请求涌来，处于高负载状态。服务预热是一个优化手段，一般在服务启动后，让其在小流量状态下运行一段时间，然后再逐步放大流量。 权重计算是在 calculateWarmupWeight 方法中。 12345678910111213141516+--- AbstractLoadBalance /** * 对还在预热状态的 Provider 节点进行降权，避免 Provider 一启动就有大量请求涌进来。 * * @param uptime the uptime in milliseconds 服务运行时间 * @param warmup the warmup time in milliseconds 预热时间 * @param weight the weight of an invoker 配置的服务权重 * @return weight which takes warmup into account 计算的服务权重 */ static int calculateWarmupWeight(int uptime, int warmup, int weight) &#123; // 计算权重，简化为： (uptime/warmup) * weight。 // 随着服务运行时间 uptime 增大，权重计算值 ww 会慢慢接近配置值 weight int ww = (int) (uptime / ((float) warmup / weight)); // 权重范围为 [0,weight] 之间 return ww &lt; 1 ? 1 : (Math.min(ww, weight)); &#125; calculateWarmupWeight() 方法用于计算还处于预热状态的 Provider 节点的权重，随着服务运行时间增大，权重计算值会慢慢接近配置的权重值。 负载均衡的抽象实现主要是对消费端 Invoker 集合为空或仅有一个的情况下直接处理，无需子类进行选择。此外还对消费端 Invoker 权重的获取做了统一实现。了解了负载均衡抽象实现后，下面我们对负载均衡的具体实现进行分析。 RandomLoadBalanceRandomLoadBalance 是加权随机算法的具体实现，它是一个简单、高效的负载均衡实现，也是 Dubbo 默认使用的负载均衡策略。其核心就是加权随机算法，下面我们简单对该算法进行说明。 假设有 3 个服务节点，分别为节点 A、节点 B、节点 C，它们对应的权重依次为 5、2、3，权重总和为 10。现在把这些权重值放到一维坐标上，[0,5)区间属于节点A，[5,7)区间属于节点B，[7,10)区间属于节点C，具体分布如下图所示： 接下来通过随机数生成器在 [0,10) 这个范围内生成一个随机数，然后计算这个随机数会落到哪个区间上。比如，随机生成数字 3 ，就会落到 Provider A 对应的区间上，此时 RandomLoadBalance 就会返回 Provider A 这个节点。权重越大的节点，在坐标轴上对应的区间范围就越大，因此随机数生成器生成的数字就会有更大的概率落到此区间内。只要随机数生成器产生的随机数分布性很好，在经过多次选择后，每个服务节点被选中的次数比例接近其权重比例。比如，经过一万次选择后，服务器 A 被选中的次数大约为 5000 次，服务器 B 被选中的次数约为 3000 次，服务器 C 被选中的次数约为 2000 次。 了解了加权随机算法后，我们开始对 RandomLoadBalance 源码进行分析。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class RandomLoadBalance extends AbstractLoadBalance &#123; /** * 扩展点名称 */ public static final String NAME = \"random\"; /** * Select one invoker between a list using a random criteria * * @param invokers List of possible invokers * @param url URL * @param invocation Invocation * @param &lt;T&gt; * @return The selected invoker */ @Override protected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) &#123; int length = invokers.size(); // 每个 Invoker 权重是否相同的标志 boolean sameWeight = true; // 计算每个 Invoker 对象对应的权重，并填充到 weights 数组中 int[] weights = new int[length]; // 计算第一个 Invoker 权重 int firstWeight = getWeight(invokers.get(0), invocation); weights[0] = firstWeight; // 记录权重总和 int totalWeight = firstWeight; for (int i = 1; i &lt; length; i++) &#123; // 计算第 i 个 Invoker 的权重 int weight = getWeight(invokers.get(i), invocation); weights[i] = weight; // 累加总权重 totalWeight += weight; // 检测是否有不同权重的 Invoker if (sameWeight &amp;&amp; weight != firstWeight) &#123; sameWeight = false; &#125; &#125; // 总权重 &gt; 0 &amp;&amp; 并非所有 Invoker 权重都相同 // 计算随机数落在哪个区间 if (totalWeight &gt; 0 &amp;&amp; !sameWeight) &#123; // 随机获取一个 [0,totalWeight) 区间内的随机数 int offset = ThreadLocalRandom.current().nextInt(totalWeight); // 循环让随机数数减去Invoker的权重值，当随机数小于0时，返回相应的Invoker for (int i = 0; i &lt; length; i++) &#123; offset -= weights[i]; if (offset &lt; 0) &#123; return invokers.get(i); &#125; &#125; &#125; // 如果所有的 Invoker 权重相同 或 权重总权重为 0，则均等随机 return invokers.get(ThreadLocalRandom.current().nextInt(length)); &#125;&#125; RandomLoadBalance 中 doSelect() 方法的实现，主要有以下 3 个关键点： 通过 AbstractLoadBalance.getWeight 方法计算每个 Invoker 的权重值 汇总 Invoker 的总权重值 当每个 Invoker 权重不同时，使用加权随机算法选出对应的 Invoker 对象。 当所有 Invoker 权重相同时，随机返回一个 Invoker 即可。 总体上加权随机负载均衡策略还是比较简单的，同时它也是其它负载均衡算法的基础，如最小活跃调用数负载均衡和最短响应时间负载均衡在具有多个相同条件的 Invoker 时，最后会通过该算法进一步选择目标 Invoker 。 RoundRobinLoadBalanceRoundRobinLoadBalance 是加权轮询算法的具体实现。轮询指的是将请求轮流分配给每个服务节点，例如，有 A、B、C 三个服务节点，按照普通轮询的方式，会将第一个请求分配给 A 节点，将第二个请求分配给 B 节点，第三个请求分配给 C 节点，第四个请求分配给 A 节点……如此循环往复。轮询是一种无状态负载均衡算法，实现简单，适用于每台服务器性能相近的场景。但现实情况下，我们并不能保证每台服务器性能均相近。如果我们将等量的请求分配给性能较差的服务器，这显然是不合理的。因此，这个时候我们需要对轮询过程进行加权，以调控每台服务器的负载。经过加权后，每台服务器能够得到的请求数比例，接近或等于他们的权重比。比如服务节点 A、B、C 权重比为 5:2:1。那么在8次请求中，服务器 A 将收到其中的5次请求，服务器 B 会收到其中的2次请求，服务器 C 则收到其中的1次请求。 RoundRobinLoadBalance 参考自 Nginx 的平滑加权轮询负载均衡。每个服务节点有两个权重，分别为 weight 和 current ，其中 weight 是通过父类的 getWeight 方法计算出来的值，虽然在预热过程是变化的，但这里可以认为是固定的；current 是动态的，初始值为 0 ，每次有新的请求进来时，遍历 Invoker 列表，并用对应的 current 加上 weight 。遍历完成后，找到具有最大 current 的 Invoker 和对应的 WeightedRoundRobin 。在返回选中的 Invoker 之前，将其对应的 WeightedRoundRobin 中的当前权重值 current 减去本次请求累加的总权重值，从而实现平滑负载均衡。 加权轮询算法下面举例对 RoundRobinLoadBalance 的执行流程进行说明。假设有 3 个服务节点，分别为节点 A、节点 B、节点 C，对应的权重依次为：5、1、1 ，选择过程如下： 请求编号 当前权重(current)数组 选择结果 减去权重总和后的当前权重(current)数组 1 [5, 1, 1] A [-2, 1, 1] 2 [3, 2, 2] A [-4, 2, 2] 3 [1, 3, 3] B [1, -4, 3] 4 [6, -3, 4] A [-1, -3, 4] 5 [4, -2, 5] C [4, -2, -2] 6 [9, -1, -1] A [2, -1, -1] 7 [7, 0, 0] A [0, 0, 0] 下面对以上每次请求数据变更进行说明，该过程就是加权轮询算法的实现： 处理第一个请求，每个 Invoker 相关的 currentWeigh 与配置的 weight 相加，即从 [0, 0, 0] 变为 [5, 1, 1]。接下来，从中选择权重最大的 Invoker 作为结果，即节点 A。最后，将节点 A 的 currentWeight 值减去 totalWeight 值，最终得到 currentWeight 数组为 [-2, 1, 1]。 处理第二个请求，每个 Invoker 相关的 currentWeigh 与配置的 weight 相加，即从 [-2, 1, 1] 变为 [3, 2, 2]。接下来，从中选择权重最大的 Invoker 作为结果，即节点 A。最后，将节点 A 的 currentWeight 值减去 totalWeight 值，最终得到 currentWeight 数组为 [-4, 2, 2]。 处理第三个请求，每个 Invoker 相关的 currentWeigh 与配置的 weight 相加，即从 [-4, 2, 2] 变为 [1, 3, 3]。接下来，从中选择权重最大的 Invoker 作为结果，即节点 B。最后，将节点 B 的 currentWeight 值减去 totalWeight 值，最终得到 currentWeight 数组为 [1, -4, 3]。 处理第四个请求，每个 Invoker 相关的 currentWeigh 与配置的 weight 相加，即从 [1, -4, 3] 变为 [6, -3, 4]。接下来，从中选择权重最大的 Invoker 作为结果，即节点 A。最后，将节点 A 的 currentWeight 值减去 totalWeight 值，最终得到 currentWeight 数组为 [-1, -3, 4]。 处理第五个请求，每个 Invoker 相关的 currentWeigh 与配置的 weight 相加，即从 [-1, -3, 4] 变为 [4, -2, 5]。接下来，从中选择权重最大的 Invoker 作为结果，即节点 C。最后，将节点 C 的 currentWeight 值减去 totalWeight 值，最终得到 currentWeight 数组为 [4, -2, -2]。 处理第六个请求，每个 Invoker 相关的 currentWeigh 与配置的 weight 相加，即从 [4, -2, -2] 变为 [9, -1, -1]。接下来，从中选择权重最大的 Invoker 作为结果，即节点 A。最后，将节点 A 的 currentWeight 值减去 totalWeight 值，最终得到 currentWeight 数组为 [2, -1, -1]。 处理第七个请求，每个 Invoker 相关的 currentWeigh 与配置的 weight 相加，即从 [2, -1, -1] 变为 [7, 0, 0]。接下来，从中选择权重最大的 Invoker 作为结果，即节点 A。最后，将节点 A 的 currentWeight 值减去 totalWeight 值，最终得到 currentWeight 数组为 [0, 0, 0]。 以上就是一个轮询的周期。了解了加权轮询的计算过程后，下面我们就对 RoundRobinLoadBalance 源码实现进行分析。 属性123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263+--- RoundRobinLoadBalancepublic class RoundRobinLoadBalance extends AbstractLoadBalance &#123; /** * 扩展点名称 */ public static final String NAME = \"roundrobin\"; /** * 长时间未更新的阈值 60 s */ private static final int RECYCLE_PERIOD = 60000; /** * 每个 Invoker 对应的对象，加权轮流调度器 */ protected static class WeightedRoundRobin &#123; /** * 服务提供者配置权重，在负载均衡过程不会变化(忽略启动预热) */ private int weight; /** * 服务提供者当前权重，在负载均衡过程会动态调整，初始值为 0 */ private AtomicLong current = new AtomicLong(0); /** * 最后更新时间 */ private long lastUpdate; public int getWeight() &#123; return weight; &#125; public void setWeight(int weight) &#123; this.weight = weight; current.set(0); &#125; // Invoker当前权重 + 配置的权重 public long increaseCurrent() &#123; return current.addAndGet(weight); &#125; // Invoker当前权重 - 总权重 public void sel(int total) &#123; current.addAndGet(-1 * total); &#125; public long getLastUpdate() &#123; return lastUpdate; &#125; public void setLastUpdate(long lastUpdate) &#123; this.lastUpdate = lastUpdate; &#125; &#125; /** * 服务方法与 WeightedRoundRobin 的映射关系 * key1: 服务键 + 方法名 -&gt; 完整方法名 * key2: URL串 * value: WeightedRoundRobin */ private ConcurrentMap&lt;String, ConcurrentMap&lt;String, WeightedRoundRobin&gt;&gt; methodWeightMap = new ConcurrentHashMap&lt;String, ConcurrentMap&lt;String, WeightedRoundRobin&gt;&gt;();&#125; RoundRobinLoadBalance 中有 3 个核心属性，下面我们对其进行介绍。 RECYCLE_PERIOD 用于监控 Invoker 对应的 WeightedRoundRobin 的更新频率。由于 Invoker 对应的服务可能会宕机，如果宕机就必须将其对应的 WeightedRoundRobin 缓存清除，RECYCLE_PERIOD 属性就是用来监控长时间未更新的 WeightedRoundRobin。 WeightedRoundRobin 作为 RoundRobinLoadBalance 的内部类，在 RoundRobinLoadBalance 中会为每个 Invoker 对象都创建一个对应的 WeightedRoundRobin 对象，用来记录配置的权重（weight字段）以及随每次负载均衡算法执行变化的当前权重（current字段）。 methodWeightMap12345678910111213# key1: 完整方法名# key2: URL串# value: WeightedRoundRobin &#123; \"...UserService.query\":&#123; \"url1\": WeightedRoundRobin@123, \"url2\": WeightedRoundRobin@456 &#125;, \"...UserService.update\":&#123; \"url1\": WeightedRoundRobin@111, \"url2\": WeightedRoundRobin@222 &#125; &#125; 会基于每个方法创建一个 WeightedRoundRobin 映射关系。 选择目标 Invoker123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172+--- RoundRobinLoadBalance @Override protected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) &#123; // 1 获取请求的完整方法名 String key = invokers.get(0).getUrl().getServiceKey() + \".\" + invocation.getMethodName(); // 2 获取整个Invoker列表对应的 WeightedRoundRobin 映射表，如果为空，则创建一个新的WeightedRoundRobin映射表 ConcurrentMap&lt;String, WeightedRoundRobin&gt; map = methodWeightMap.computeIfAbsent(key, k -&gt; new ConcurrentHashMap&lt;&gt;()); // 总权重 int totalWeight = 0; // 记录 Invoker 列表中最大权重 long maxCurrent = Long.MIN_VALUE; // 获取当前时间戳 long now = System.currentTimeMillis(); // 选中的 Invoker Invoker&lt;T&gt; selectedInvoker = null; // 选中的 Invoker 对应的 WeightedRoundRobin WeightedRoundRobin selectedWRR = null; // 3 遍历 Invoker 列表，选出具有最大 current 的 Invoker for (Invoker&lt;T&gt; invoker : invokers) &#123; // 获取 Invoker 对应的URL串 String identifyString = invoker.getUrl().toIdentityString(); // 获取当前 Invoker 权重 int weight = getWeight(invoker, invocation); // 检测当前 Invoker 是否有相应的 WeightedRoundRobin ，没有则创建 WeightedRoundRobin weightedRoundRobin = map.computeIfAbsent(identifyString, k -&gt; &#123; WeightedRoundRobin wrr = new WeightedRoundRobin(); // 设置权重和初始化当前权重值为0 wrr.setWeight(weight); return wrr; &#125;); // 检测 Invoker 权重是否发生了变化，若变化了则更新相应 WeightedRoundRobin 中的 weight 值 if (weight != weightedRoundRobin.getWeight()) &#123; //weight changed weightedRoundRobin.setWeight(weight); &#125; // 3.1 让 current 加上配置的 weight 🌟 long cur = weightedRoundRobin.increaseCurrent(); // 3.2 更新 lastUpdate 字段 weightedRoundRobin.setLastUpdate(now); // 3.3 寻找具有最大 current 的 Invoker，以及Invoker对应的 WeightedRoundRobin ，暂存起来留作后用 if (cur &gt; maxCurrent) &#123; maxCurrent = cur; selectedInvoker = invoker; selectedWRR = weightedRoundRobin; &#125; // 3.4 计算权重总和 totalWeight += weight; &#125; // 4 Invoker 集合数不等于缓存数，说明存在 Invoker 挂了的可能，此时应该清除无效缓存 if (invokers.size() != map.size()) &#123; // 清除掉长时间未被更新的节点 map.entrySet().removeIf(item -&gt; now - item.getValue().getLastUpdate() &gt; RECYCLE_PERIOD); &#125; // 5 更新选中的 Invoker 对应的 WeightedRoundRobin 中维护的 current 的值，然后返回选中的 Invoker 🌟 if (selectedInvoker != null) &#123; // 用 current 减去 totalWeight selectedWRR.sel(totalWeight); // 返回选中的Invoker对象 return selectedInvoker; &#125; // should not happen here return invokers.get(0); &#125; RoundRobinLoadBalance 中的 doSelect 就是对上面加权轮询计算过程的实现，理解了加权轮询算法就理解了 RoundRobinLoadBalance 负载均衡策略。 LeastActiveLoadBalanceLeastActiveLoadBalance 使用的是 最小活跃数负载均衡算法。活跃调用数越小，表明该服务提供者效率越高，单位时间内可处理更多的请求，此时应优先将请求分配给该服务提供者。在具体实现中，每个服务提供者都对应一个活跃数 active ，初始情况下所有服务提供者活跃数均为 0 ，每收到一个请求，活跃数加 1 ，完成请求后则将活跃数减 1 。在服务运行一段时间后，性能好的服务提供者处理请求的速度更快，因此活跃数下降的也越快，此时这样的服务提供者能够优先获取到新的服务请求。以上就是最小活跃数负载均衡算法的基本思想。 除了最小活跃数，LeastActiveLoadBalance 在实现上还引入了权重，所以准确地说该负载均衡策略是基于加权最小活跃数算法实现的。LeastActiveLoadBalance 需要配合 ActiveLimitFilter使用，ActiveLimitFilter 是 Dubbo 在消费端的限流实现，会记录消费者对一个服务端方法的并发调用量，在进行负载均衡时，只会从活跃调用数最小的 Invoker 集合中挑选 Invoker ，当有多个最小活跃调用数的Invoker时，会在最小活跃调用数基础增加加权随机策略。下面我们对源码进行分析。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113public class LeastActiveLoadBalance extends AbstractLoadBalance &#123; /** * 扩展点名 */ public static final String NAME = \"leastactive\"; @Override protected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) &#123; // ---------------------- 1 🌟 关键属性 ------------------------------/ // Invoker 数量 int length = invokers.size(); // 记录最小的活跃调用数 int leastActive = -1; // 记录具有相同最小活跃调用数（leastActive 的值）的 Invoker 数量 int leastCount = 0; // 记录具有相同最小活跃调用数（leastActive 的值）的 Invoker 在 Invoker 列表中的下标位置。 // leastIndexes 数组中如果有多个值，则说明有两个及以上的 Invoker 具有相同的最小活跃数（leastActive 的值） int[] leastIndexes = new int[length]; // 记录每个 Invoker 的权重值 int[] weights = new int[length]; // 记录最小活跃调用数所有 Invoker 的权重值之和 int totalWeight = 0; // 记录最小活跃请求数 Invoker 集合中第一个 Invoker 的权重值 int firstWeight = 0; // 标记是否具有相同权重的最小活跃数 Invoker boolean sameWeight = true; // ---------------------- 2 🌟 操作关键属性 ------------------------------/ // 遍历所有Invoker，选出最小活跃调用数的Invoker集合 for (int i = 0; i &lt; length; i++) &#123; Invoker&lt;T&gt; invoker = invokers.get(i); // 获取该 Invoker 的活跃调用数 （使用到了消费方限流策略：ActiveLimitFilter） int active = RpcStatus.getStatus(invoker.getUrl(), invocation.getMethodName()).getActive(); // 记录该 Invoker 的权重 int afterWarmup = getWeight(invoker, invocation); weights[i] = afterWarmup; // 比较活跃调用数，发现更小的活跃调用数则更新相关属性。这样情况只有一个 Invoker // 这个是必须要的，因为要的就是最小活跃调用数，具有相同的最小活跃调用数只是一种复杂情况，需要根据权重再处理 if (leastActive == -1 || active &lt; leastActive) &#123; // 重新记录最小的活跃调用数 leastActive = active; // 重新记录最小活跃调用数的 Invoker 个数 leastCount = 1; // 重新记录最小活跃调用数的 Invoker 在 Invoker 列表中的下标 leastIndexes[0] = i; // 重置总权重 totalWeight = afterWarmup; // 记录第一个最小活跃调用数 Invoker 的权重 firstWeight = afterWarmup; // Each invoke has the same weight (only one invoker here) // 重置权重相同标识 sameWeight = true; // 如果当前 Invoker 的活跃调用数等于最小活跃调用数，这样情况下已经存在最小活跃调用数的 Invoker &#125; else if (active == leastActive) &#123; // 记录当前 Invoker 在 Invoker 列表中的下标 leastIndexes[leastCount++] = i; // 累加总权重，针对的是具有相同的最小活跃数 totalWeight += afterWarmup; // 判断是否存在相同权重的最小活跃调用数的 Invoker // 即检测当前 Invoker 的权重与firstWeight是否相等，不相等则将 sameWeight 设置为 false if (sameWeight &amp;&amp; afterWarmup != firstWeight) &#123; sameWeight = false; &#125; &#125; &#125; // ---------------------- 3 🌟 选择 Invoker ------------------------------/ // 3.1 如果只有一个最小活跃调用数的 Invoker ，直接取出即可 if (leastCount == 1) &#123; // 从 Invoker 列表中取出最小活跃数的 Invoker return invokers.get(leastIndexes[0]); &#125; // 3.2 存在多个具有最小活跃数的 Invoker ，但它们的权重不相同且总权重 &gt; 0 ，则使用加权随机算法。 if (!sameWeight &amp;&amp; totalWeight &gt; 0) &#123; // If (not every invoker has the same weight &amp; at least one invoker's weight&gt;0), select randomly based on // totalWeight. int offsetWeight = ThreadLocalRandom.current().nextInt(totalWeight); // Return a invoker based on the random value. for (int i = 0; i &lt; leastCount; i++) &#123; int leastIndex = leastIndexes[i]; offsetWeight -= weights[leastIndex]; if (offsetWeight &lt; 0) &#123; return invokers.get(leastIndex); &#125; &#125; &#125; // 3.3 存在多个 Invoker 具有相同的最小活跃数，但它们的权重相等或总权重为0，则使用随机均等 return invokers.get(leastIndexes[ThreadLocalRandom.current().nextInt(leastCount)]); &#125;&#125; LeastActiveLoadBalance 核心思想是选择最小活跃调用数的服务提供者，如果最小活跃调用数的服务提供者有多个，则使用加权随机算法进行选择。核心思想理解起来很容易，但是实现上显得有点复杂，体现在定义了很多的属性上，下面对整个逻辑进行简单梳理。 遍历 Invoker 列表，寻找活跃调用数最小的 Invoker， 如果存在多个 Invoker 具有相同的最小活跃调用数，此时需要记录下这些 Invoker 在 Invoker 集合中的下标，并累加它们的权重，且比较它们的权重值是否相等。 如果只有一个 Invoker 具有最小活跃数，此时直接返回该 Invoker 即可。 如果存在多个 Invoker 具有最小活跃数，且它们的权重不相等，此时处理方式和加权随机 RandomLoadBalance 一致。 如果存在多个 Invoker 具有最小活跃数，但它们的权重都相等，此时随机返回一个即可。 ConsistentHashLoadBalanceConsistentHashLoadBalance 负载均衡策略使用的是 一致性 Hash 来实现的。在分析具体源码之前，我们现对相关概念进行介绍。 一致性 Hash 算法提出之初是用于大规模缓存系统的负载均衡，它的工作过程是这样的，首先根据缓存节点地址或其它信息为缓存节点生成一个 hash 值，并将这个 hash 值投射到 [0, 2^32 - 1] 的圆环上（Hash环），也就是对 2^32 取模 。当有读写请求时，则为缓存项 key 生成一个 hash 值，然后到 Hash 环上查找第一个大于或等于该 hash 值的缓存节点，最后就可以在找到的缓存节点上进行读写操作了。如果当前缓存节点挂了，则在下一次读写请求时查找其它大于或等于本次请求的 hash 值的缓存节点即可。大致的 Hash 环如下图所示，每个缓存节点在圆环上映射一个位置。如果缓存项 key 的 hash 小于或等于缓存节点对应的 hash 值，则到该缓存节点中进行读写操作。如下面绿色点对应的缓存项将会被存储到 cahce-2 节点中。由于 cache-3 挂了，原本应该存到该节点中的缓存项最终会存储到 cache-4 节点上。 一致性 Hash 在 Dubbo 中的应用就是将缓存节点替换成 Dubbo 的服务提供者节点。理想情况下，一致性 Hash 算法会将 Dubbo 的服务提供者节点均匀地分布到 Hash 环上，请求也可以均匀地分发给 Dubbo 的服务提供者节点。但在实际情况中，提供者节点地址取模后的值可能在 Hash 环上分布不均匀，如下图： 由于 Invoker-1 和 Invoker-2 在圆环上分布不均匀，导致系统中大部分请求都会落到 Invoker-1 上，只有少部分请求会落到 Invoker-2 上，这就出现了数据倾斜的问题。所谓数据倾斜是指由于节点不够分散，导致大量请求落到了同一个节点上，而其他节点只会接收到少量请求的情况。为了解决一致性 Hash 算法中出现的数据倾斜问题，引入了虚拟节点的概念。解决思路是：既然 Dubbo 服务提供者节点在 Hash 环上分布不均匀，那么可以虚拟出 N 组 Invoker-1，Invoker-2，…，Invoker-N 的提供者节点，让多组提供者节点相对均匀分布在 Hash 环上。如下图： 上图中相同颜色的节点属于同一个服务提供者，如 Invoker1-1、Invoker1-2、….、Invoker1-160 表示的都是 Invoker1 这个服务节点，这样做的目的是通过引入虚拟节点，让 Invoker 在圆环上分散开来，避免数据倾斜问题。上图中有三个组。 属性123456789101112131415161718192021222324public class ConsistentHashLoadBalance extends AbstractLoadBalance &#123; /** * 扩展名 */ public static final String NAME = \"consistenthash\"; /** * 虚拟节点数配置项，默认值为 160 * 格式：&lt;dubbo:parameter key=\"hash.nodes\" value=\"320\" /&gt; */ public static final String HASH_NODES = \"hash.nodes\"; /** * 参与Hash计算的参数索引，默认只对第一个参数Hash * 格式：&lt;dubbo:parameter key=\"hash.arguments\" value=\"0,1\" /&gt; */ public static final String HASH_ARGUMENTS = \"hash.arguments\"; /** * key: ServiceKey.methodName -&gt; 完整方法名 * value: ConsistentHashSelector */ private final ConcurrentMap&lt;String, ConsistentHashSelector&lt;?&gt;&gt; selectors = new ConcurrentHashMap&lt;String, ConsistentHashSelector&lt;?&gt;&gt;();&#125; HASH_NODES 和 HASH_ARGUMENTS 属性分别是每个服务节点对应的虚拟节点数和参与Hash计算的请求参数的索引，selectors 属性用于存储 请求调用&quot;完整方法名&quot;到一致性Hash选择器 的映射关系。 选择 Invoker1234567891011121314151617181920212223+--- ConsistentHashLoadBalance @Override protected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) &#123; // 1 获取调用的方法名称 String methodName = RpcUtils.getMethodName(invocation); // 2 将 ServiceKey 和 方法名 拼接起来构成一个 key，即完整方法名 String key = invokers.get(0).getUrl().getServiceKey() + \".\" + methodName; // 3 获取 Invoker 列表的 hashcode（为了在 Invokers 列表发生变化时重新生成 ConsistentHashSelector 对象） int invokersHashCode = invokers.hashCode(); ConsistentHashSelector&lt;T&gt; selector = (ConsistentHashSelector&lt;T&gt;) selectors.get(key); // 4 如果 invokers 是一个新的 List 对象，说明服务提供者数量发生了变化，可能新增也可能减少了 // 此时 selector.identityHashCode != invokersHashCode 成立 if (selector == null || selector.identityHashCode != invokersHashCode) &#123; // 创建 ConsistentHashSelector 对象 selectors.put(key, new ConsistentHashSelector&lt;T&gt;(invokers, methodName, invokersHashCode)); selector = (ConsistentHashSelector&lt;T&gt;) selectors.get(key); &#125; // 5 通过 ConsistentHashSelector 对象选择一个 Invoker 对象 return selector.select(invocation); &#125; ConsistentHashLoadBalance 的 doSelect 方法并没有真正选择目标 Invoker 对象，而是做了一些前置工作，主要是检测 Invoker 列表是否变更了，判断是否需要创建请求方法对应的一致性 Hash 选择器对象，也就是是否需要重新构建 Hash 环。这个准备工作完成后，Hash 环也就构建完毕了，接下来将选择 Invoker 的逻辑交给一致性选择性器 ConsistentHashSelector 对象。下面我们就来分析一致性 Hash 选择器。 ConsistentHashSelectorConsistentHashLoadBalance 实现负载均衡都是委托给一致性 Hash 选择器 ConsistentHashSelector 完成的，下面我们对该内部类进行介绍。 核心属性12345678910111213141516171819202122+--- ConsistentHashLoadBalance private static final class ConsistentHashSelector&lt;T&gt; &#123; /** * 使用 TreeMap 存储 Invoker 虚拟节点，TreeMap 是按照Key排序的 * key: Hash 值 */ private final TreeMap&lt;Long, Invoker&lt;T&gt;&gt; virtualInvokers; /** * Invoker 虚拟节点个数 */ private final int replicaNumber; /** * Invoker 集合的 HashCode 值 */ private final int identityHashCode; /** * 需要参与 Hash 计算的参数索引。 * 如：argumentIndex = [0,1,2] 时，表示调用的目标方法的前三个参数要参与 Hash 计算。 */ private final int[] argumentIndex; &#125; 下面对核心属性进行介绍： 需要说明的是，针对每一个请求的服务方法都会创建一个 ConsistentHashLoadBalance 。 virtualInvokers 用于缓存 Invoker 的虚拟节点，即多个 hash 值映射到同一个 Invoker 。 replicaNumber 用于记录每个 Invoker 虚拟节点的个数。 identityHashCode 用于记录请求涉及的 Invoker 集合的 HashCode 值。 argumentIndex 用于存储参与 Hash 计算的参数索引，用于请求负载均衡时对请求参数进行匹配，确定哪些参数参与 Hash 计算。 构造方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/* * * @param invokers 消费端 Invoker 列表 * @param methodName 方法名 * @param identityHashCode Invoker 列表的 hashCode 的值 */ ConsistentHashSelector(List&lt;Invoker&lt;T&gt;&gt; invokers, String methodName, int identityHashCode) &#123; // 1 初始化 virtualInvokers 字段，用于缓存 Invoker 的虚拟节点 this.virtualInvokers = new TreeMap&lt;Long, Invoker&lt;T&gt;&gt;(); // 2 记录 Invoker 集合的 hashCode，用该 hashCode 值可以判断 Provider 列表是否发生了变化 this.identityHashCode = identityHashCode; // 3 获取消费端 Invoker 的 URL URL url = invokers.get(0).getUrl(); // 4 从配置中获取虚拟节点数（hash.nodes 参数）以及参与 hash 计算的参数下标（hash.arguments 参数） this.replicaNumber = url.getMethodParameter(methodName, HASH_NODES, 160); // 5 对参与 hash 计算的参数下标进行解析，然后存放到 argumentIndex 数组中 String[] index = COMMA_SPLIT_PATTERN.split(url.getMethodParameter(methodName, HASH_ARGUMENTS, \"0\")); argumentIndex = new int[index.length]; for (int i = 0; i &lt; index.length; i++) &#123; argumentIndex[i] = Integer.parseInt(index[i]); &#125; // 6 构建 Invoker 虚拟节点，默认 replicaNumber=160，相当于在 Hash 环上放 160 个槽位。外层轮询 40 次，内层轮询 4 次，共 40 * 4 = 160次，也就是同一个节点虚拟出 160 个槽位 for (Invoker&lt;T&gt; invoker : invokers) &#123; // 6.1 获取服务地址 host:port String address = invoker.getUrl().getAddress(); for (int i = 0; i &lt; replicaNumber / 4; i++) &#123; // 6.2 对 address + i 进行md5运算，得到一个长度为16的字节数组 // 基于服务地址进行 md5 计算 byte[] digest = md5(address + i); // 6.3 对 digest 部分字节进行 4 次 Hash 运算，得到 4 个不同的 long 型正整数 for (int h = 0; h &lt; 4; h++) &#123; // h = 0 时，取 digest 中下标为 0 ~ 3 的4个字节进行位运算 // h = 1 时，取 digest 中下标为 4 ~ 7 的4个字节进行位运算 // h = 2, h = 3 时过程同上 long m = hash(digest, h); // 6.3 将 hash 到 Invoker 的映射关系存储到 virtualInvokers 中 // virtualInvokers 需要提供高效、有序的查询擦操作，因此选用 TreeMap 作为存储结构 virtualInvokers.put(m, invoker); &#125; &#125; &#125; &#125; ConsistentHashSelector 的构造方法核心点是 创建虚拟节点（构建 Hash 环） 和 收集参与一致性Hash计算的参数下标（默认情况下只使用第一个参数，也就是下标为 0） 。需要特别说明的是，ConsistentHashLoadBalance 的负载均衡逻辑只受参数值影响，具有相同参数值的请求将会被分配给同一个服务提供者，ConsistentHashLoadBalance 不关心权重，因此使用时需要注意一下。下面我们就来对其选择 Invoker 的 select 方法进行分析，从该方法就可以看出为什么说该负载均衡策略只受参数值影响。 选择服务123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051+--- ConsistentHashSelector /** * 选择合适的 Invoker 对象 * * @param invocation * @return */ public Invoker&lt;T&gt; select(Invocation invocation) &#123; // 1 将参与一致性 Hash 的参数拼接到一起 String key = toKey(invocation.getArguments()); // 2 对 key 进行 md5 运算 byte[] digest = md5(key); // 3 取 digest 数组的前四个字节进行 hash 运算，再将 hash 值传给 selectForKey 方法，寻找合适的 Invoker return selectForKey(hash(digest, 0)); &#125; /** * 将参与 Hash 计算的参数索引对应的参数值进行拼接。默认对第一个参数进行 Hash 运算。 * * @param args * @return */ private String toKey(Object[] args) &#123; StringBuilder buf = new StringBuilder(); // 对参与 Hash 计算的参数值进行拼接 for (int i : argumentIndex) &#123; if (i &gt;= 0 &amp;&amp; i &lt; args.length) &#123; buf.append(args[i]); &#125; &#125; return buf.toString(); &#125; /** * 选择 Invoker * * @param hash 调用方法参数处理后的 Hash 值 * @return */ private Invoker&lt;T&gt; selectForKey(long hash) &#123; // 1 到 TreeMap 中查找第一个节点值大于或等于当前 hash 的 Invoker Map.Entry&lt;Long, Invoker&lt;T&gt;&gt; entry = virtualInvokers.ceilingEntry(hash); // 2 如果传入的 hash 大于 Invoker 在 Hash 环上最大的位置，此时 entry = null，此时需要回到 Hash 环的开头返回第一个 Invoker 对象 if (entry == null) &#123; entry = virtualInvokers.firstEntry(); &#125; // 3 取出目标 Invoker return entry.getValue(); &#125; 一致性 Hash 选择器 ConsistentHashSelector 选择的过程相对比较简单。先是对参数进行 md5 以及 hash 运算，得到一个 Hash 值，然后再拿这个 Hash 值到 TreeMap 中查找目标 Invoker 即可。 ShortestResponseLoadBalanceShortestResponseLoadBalance 使用的是 最短响应时间的负载均衡算法，和最小活跃数负载均衡算法类似，唯一的差别在于最短响应时间是基于调用成功的请求来计算实现的，而最小活跃数是直接基于当前正在处理的请求数实现的，其它的两者完全一致。最短响应时间越小，表明该服务提供者效率越高，此时可以将请求优先分配给该服务。在具体实现中，会记录每个服务提供者成功处理请求的个数以及对应的处理总时间，这样可以得到一个 成功调用的平均时间 ，最后结合该服务提供者的最小活跃数，计算出最短响应时间。也就是从多个提供者节点中选出调用成功且响应时间最短的服务提供者节点。满足该条件的服务节点可能有多个，这种情况再使用加权随机算法进行一次选择就可以得到最终目标节点。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114public class ShortestResponseLoadBalance extends AbstractLoadBalance &#123; /** * 扩展名 */ public static final String NAME = \"shortestresponse\"; @Override protected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) &#123; // -------------------------- 1 🪐 关键属性 ------------------------/ // 记录 Invoker 集合数量 int length = invokers.size(); // 记录所有 Invoker 集合中最短响应时间 long shortestResponse = Long.MAX_VALUE; // 记录具有相同最短响应时间（shortestResponse 的值）的 Invoker 数量 int shortestCount = 0; // 存放具有相同最短响应时间（shortestResponse 的值）的 Invoker 在 Invoker 列表中的下标 // shortestIndexes 数组中如果有多个值，则说明有两个及以上的 Invoker 具有相同的最短响应时间 int[] shortestIndexes = new int[length]; // 存放每个 Invoker 权重，主要用于当最短响应时间的 Invoker 数量有多个的情况 int[] weights = new int[length]; // 记录具有相同最短响应时间 Invoker 的总权重 int totalWeight = 0; // 记录第一个 Invoker 对象的权重 int firstWeight = 0; // 标记是否具有相同权重的最短响应时间的 Invoker boolean sameWeight = true; // --------------------------- 2 🪐 操作关键属性 -----------------------/ // 遍历所有 Invoker ，选出最短响应时间的 Invoker 集合 for (int i = 0; i &lt; length; i++) &#123; Invoker&lt;T&gt; invoker = invokers.get(i); // 使用到了消费方限流策略：ActiveLimitFilter RpcStatus rpcStatus = RpcStatus.getStatus(invoker.getUrl(), invocation.getMethodName()); // 获取调用成功的平均时间，计算方式：调用成功的请求数总数对应的总耗时 / 调用成功的请求数总数 = 成功调用的平均时间 long succeededAverageElapsed = rpcStatus.getSucceededAverageElapsed(); // 获取该提供者的活跃请求数，也就是当前正在处理中的请求数 int active = rpcStatus.getActive(); // 计算一个处理新请求的预估值，也就是如果当前请求发给该提供者，大概耗时多久处理完成 long estimateResponse = succeededAverageElapsed * active; // 获取该 Invoker 的权重 int afterWarmup = getWeight(invoker, invocation); weights[i] = afterWarmup; // 和 LeastActiveLoadBalance 类似 // 比较最短时间，发现更小值则更新相关属性，这种情况只有一个 Invoker if (estimateResponse &lt; shortestResponse) &#123; // 重新记录最短响应时间 shortestResponse = estimateResponse; // 重新记录最短响应时间的 Invoker 数量 shortestCount = 1; // 重新记录最短响应时间的 Invoker 在 Invoker 列表中的下标 shortestIndexes[0] = i; // 重置总权重 totalWeight = afterWarmup; // 记录第一个最短响应时间的 Invoker 的权重 firstWeight = afterWarmup; // 重置权重相同标识 sameWeight = true; // 出现多个耗时最短的Invoker对象 &#125; else if (estimateResponse == shortestResponse) &#123; // 记录当前 Invoker 在 Invoker 列表中的下标 shortestIndexes[shortestCount++] = i; // 累加总权重，针对的是具有相同的最短响应时间 totalWeight += afterWarmup; // 判断是否存在相同权重的最短响应时间的 Invoker if (sameWeight &amp;&amp; i &gt; 0 &amp;&amp; afterWarmup != firstWeight) &#123; sameWeight = false; &#125; &#125; &#125; //------------------------------ 3 🪐 选择 Invoker ----------------------/ // 仅有一个最短响应时间的 Invoker if (shortestCount == 1) &#123; return invokers.get(shortestIndexes[0]); &#125; // 如果耗时最短的所有Invoker对象的权重不相同，则通过加权随机负载均衡的方式选择一个Invoker返回 if (!sameWeight &amp;&amp; totalWeight &gt; 0) &#123; int offsetWeight = ThreadLocalRandom.current().nextInt(totalWeight); for (int i = 0; i &lt; shortestCount; i++) &#123; int shortestIndex = shortestIndexes[i]; offsetWeight -= weights[shortestIndex]; if (offsetWeight &lt; 0) &#123; return invokers.get(shortestIndex); &#125; &#125; &#125; // 如果耗时最短的所有 Invoker 对象的权重相同，则随机返回一个 return invokers.get(shortestIndexes[ThreadLocalRandom.current().nextInt(shortestCount)]); &#125;&#125; ShortestResponseLoadBalance 核心思想是选择最短响应时间的服务提供者，如果最短响应时间的提供者有多个，则使用加权随机算法继续选择即可。由于和最小活跃数负载均衡策略基本一致，这里就不再具体描述。 小结本篇文章对 Dubbo 的五种负载均衡实现进行了详细分析，理解负载均衡代码逻辑的关键是理解对应的算法本身。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"集群容错 - Router","slug":"rpc/集群容错之Router","date":"2020-09-26T23:00:00.000Z","updated":"2021-04-06T08:32:41.637Z","comments":false,"path":"posts/26e2f6a4/","link":"","permalink":"https://gentryhuang.com/posts/26e2f6a4/","excerpt":"","text":"概述Dubbo 中的路由 Router 的主要功能就是根据用户配置的路由规则以及请求携带信息，过滤出符合条件的 Invoker 集合，供后续负载均衡逻辑使用。相关类图图如下： RouterFactory &amp; RouterRouterFactory123456789101112@SPIpublic interface RouterFactory &#123; /** * * 创建 Router. * * @param url * @return router */ @Adaptive(\"protocol\") Router getRouter(URL url);&#125; RouterFactory 是 Dubbo 的扩展点，没有默认扩展实现，用于创建 Router。其中 getRouter 方法动态生成的适配器会根据 protocol 参数选择扩展实现。 Router123456789101112131415161718192021222324public interface Router extends Comparable&lt;Router&gt; &#123; /** * 获取路由规则URL * * get the router url. * * @return url */ URL getUrl(); /** * 路由，筛选匹配的Invoker 集合 * * route. * * @param invokers Invoker 集合 * @param url refer url * @param invocation * @return routed invokers 路由后的Invoker 集合 * @throws RpcException */ &lt;T&gt; List&lt;Invoker&lt;T&gt;&gt; route(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) throws RpcException;&#125; Router 决定了一次 Dubbo 调用的目标服务，该接口的每个实现类都代表一个路由规则。当消费方调用服务提供方时，Dubbo 根据路由规则从服务目录中筛选出符合条件的服务列表，之后通过负载均衡算法再次进行筛选。 ConditionRouterFactory &amp; ConditionRouterConditionRouterFactory123456789101112public class ConditionRouterFactory implements RouterFactory &#123; /** * 拓展名 */ public static final String NAME = \"condition\"; @Override public Router getRouter(URL url) &#123; // 创建 ConditionRouter 对象 return new ConditionRouter(url); &#125;&#125; ConditionRouterFactory 实现，其扩展名为 condition ，在其 getRouter 方法中会创建 ConditionRouter 对象。 ConditionRouterConditionRouter 是基于条件表达式的路由实现类，再分析条件路由之前，我们先对条件表达式相关内容进行说明，条件路由就是根据这些规则实现的。 下面就是一条基于条件表达式的路由规则： 1host &#x3D; 10.20.153.10 &#x3D;&gt; host &#x3D; 10.20.153.11 规则 =&gt; 之前的为消费者匹配条件，该条件中的所有参数会与消费者的 URL 进行对比，当消费者满足匹配条件时，会对该消费者执行后面的过滤规则，否则直接返回消费端Invoker列表，无需继续提供者过滤条件的匹配。 =&gt; 之后的为提供者地址列表的过滤条件，该条件中的所有参数会与提供者的 URL 进行对比，消费者最终只能拿到过滤后的地址列表 如果匹配条件为空，表示 =&gt; 之后的过滤条件对所有消费方生效，如： =&gt; host!=10.20.153.11，含义是所有的消费方都不能请求 10.20.153.11 这个提供者节点。 如果提供者过滤条件为空，表示禁止访问所提供者，如：host = 10.20.153.10 =&gt;，含义是 10.20.153.10 这个消费方不能访问任何提供者。 表达式参数支持 服务调用信息，如：method、argument 等 URL 本身的字段，如：protocol、host、port 等 URL 上的所有参数，如：application、organization 等 条件支持 等号 = 表示匹配，如：host = 10.20.153.10 不等号 != 表示不匹配，如：host != 10.20.153.10 值支持 以逗号 , 分隔多个值，如：host != 10.20.153.10,10.20.153.11 以星号 * 结尾，表示通配，如：host != 10.20.* 以美元符 $ 开头，表示引用消费者参数，如：host = $host 属性123456789101112131415161718192021222324252627282930313233343536373839public class ConditionRouter implements Router, Comparable&lt;Router&gt; &#123; private static final Logger logger = LoggerFactory.getLogger(ConditionRouter.class); /** * 分组正则匹配，用于切分路由规则的正则表达式 * 说明： * 第一个匹配组-分割符： 用于匹配 \"&amp;\", \"!=\", \"=\" 和 \",\" 等符号，作为匹配规则的分隔符。允许匹配不到，使用了 * 通配符 * 第二个匹配组-内容： 这里用于匹配 英文字母，数字等字符，【不匹配 &amp;!=,】作为匹配规则的匹配内容。 可能出现，这里匹配到了，但是第一匹配组没有匹配到。 */ private static Pattern ROUTE_PATTERN = Pattern.compile(\"([&amp;!=,]*)\\\\s*([^&amp;!=,\\\\s]+)\"); /** * 路由规则 URL * 如： URL.valueOf(\"route://0.0.0.0/com.foo.BarService?category=routers&amp;dynamic=false&amp;rule=\" + URL.encode(\"host = 10.20.153.10 =&gt; host = 10.20.153.11\")) */ private final URL url; /** * 路由规则优先级，用于排序，优先级越大越靠前。优先级越大越靠前执行。默认为0 */ private final int priority; /** * 当路由结果为空时是否强制执行，如果不强制执行，路由匹配结果为空的路由规认为是失效的。如果强制执行，则直接返回空的路由结果。默认为false */ private final boolean force; /** * 消费者匹配的条件集合，通过解析条件表达式规则 '=&gt;' 之前的部分得到 * key: 匹配项 * value: 匹配项对应的匹配对 【包含匹配项对应的 匹配值集合/不匹配值集合 】 * 效果：所有参数和消费者的 URL 进行对比，当消费者满足匹配条件时，对该消费者执行后面的过滤规则。 */ private final Map&lt;String, MatchPair&gt; whenCondition; /** * 提供者匹配的条件集合，通过解析条件表达式规则 '=&gt;' 之后的部分得到 * key: 匹配项 * value: 匹配项对应的匹配对 【包含匹配项对应的 匹配值集合/不匹配值集合 】 * 效果：所有参数和提供者的 URL（合并处理后的）进行对比，消费者最终只拿到过滤后的地址列表。 */ private final Map&lt;String, MatchPair&gt; thenCondition;&#125; 构造方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546+--- ConditionRouter /** * 将条件路由规则解析成预定格式 * * @param url 条件规则 URL */ public ConditionRouter(URL url) &#123; this.url = url; // 1 获取 priority 和 force 配置 this.priority = url.getParameter(Constants.PRIORITY_KEY, 0); this.force = url.getParameter(Constants.FORCE_KEY, false); try &#123; // 2 获取路由规则URL中路由规则 rule 参数的值 String rule = url.getParameterAndDecoded(Constants.RULE_KEY); if (rule == null || rule.trim().length() == 0) &#123; throw new IllegalArgumentException(\"Illegal route rule!\"); &#125; // 3 剔除掉路由规则中的consumer.或者provider. ，如 consumer.host != 192.168.0.1 &amp; method = * =&gt; provider.host != 10.75.25.66 // 剔除调前缀才是真正的规则 rule = rule.replace(\"consumer.\", \"\").replace(\"provider.\", \"\"); // 4 根据 \"=&gt;\" 拆分路由规则 int i = rule.indexOf(\"=&gt;\"); // 5 分别获取消费者匹配规则的串 和 服务提供者过滤规则的串 String whenRule = i &lt; 0 ? null : rule.substring(0, i).trim(); String thenRule = i &lt; 0 ? rule.trim() : rule.substring(i + 2).trim(); // 6 将路由规则串解析为key-value形式 ,key为路由规则匹配项，value为匹配对（包含了匹配项对应的 匹配值集合和不匹配值集合） // 6.1 解析消费方匹配规则 Map&lt;String, MatchPair&gt; when = StringUtils.isBlank(whenRule) || \"true\".equals(whenRule) ? new HashMap&lt;String, MatchPair&gt;() : parseRule(whenRule); // 6.2 解析提供者过滤规则 Map&lt;String, MatchPair&gt; then = StringUtils.isBlank(thenRule) || \"false\".equals(thenRule) ? null : parseRule(thenRule); // 6.3 赋值 消费方匹配条件集合、提供者过滤条件集合 this.whenCondition = when; this.thenCondition = then; &#125; catch (ParseException e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; &#125; 在 ConditionRouter 的构造方法中，会根据 URL 中携带的相应参数初始化 priority、force 等属性。然后从条件路由 URL 的 rule 参数中获取路由规则并进行解析，最后得到匹配项集合，当需要进行匹配时，根据已经解析好的规则对消费方 URL 或提供者 URL 进行匹配即可。 匹配项123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869+--- ConditionRouterprivate static final class MatchPair &#123; /** * 匹配值集合，待匹配项存在于集合，则说明匹配成功 */ final Set&lt;String&gt; matches = new HashSet&lt;String&gt;(); /** * 不匹配值集合，待匹配项存在于集合，则说明匹配失败 */ final Set&lt;String&gt; mismatches = new HashSet&lt;String&gt;(); /** * 判断 value 是否匹配 matches + mismatches * * @param value * @param param * @return */ private boolean isMatch(String value, URL param) &#123; // 1 只匹配 matches，没有匹配上则说明失败了，返回false if (!matches.isEmpty() &amp;&amp; mismatches.isEmpty()) &#123; for (String match : matches) &#123; // 只要入参被 matches 集合中的任意一个元素匹配到，就匹配成功，返回true if (UrlUtils.isMatchGlobPattern(match, value, param)) &#123; return true; &#125; &#125; // 如果所有匹配值都无法匹配到 value，则匹配失败,返回false return false; &#125; // 2 只匹配 mismatches，没有匹配上，则说明成功了，返回true if (!mismatches.isEmpty() &amp;&amp; matches.isEmpty()) &#123; for (String mismatch : mismatches) &#123; // 只要入参被 mismatches 集合中的任意一个元素匹配到，就匹配失败，返回false if (UrlUtils.isMatchGlobPattern(mismatch, value, param)) &#123; return false; &#125; &#125; // mismatches 集合中所有元素都无法匹配到入参，则匹配成功，返回 true return true; &#125; // 3 匹配 mismatches + matches，优先去匹配 mismatches if (!matches.isEmpty() &amp;&amp; !mismatches.isEmpty()) &#123; // 只要 mismatches 集合中任意一个元素与入参匹配成功，则匹配失败，就立即返回 false for (String mismatch : mismatches) &#123; if (UrlUtils.isMatchGlobPattern(mismatch, value, param)) &#123; return false; &#125; &#125; // 只要 matches 集合中任意一个元素与入参匹配成功，则匹配成功，就立即返回 true for (String match : matches) &#123; if (UrlUtils.isMatchGlobPattern(match, value, param)) &#123; return true; &#125; &#125; return false; &#125; // 4 matches 和 mismatches 均为空，此时返回 false return false; &#125; &#125; MatchPair 表示一个匹配项，其中包含两个 Set 集合，匹配值集合和不匹配值集合。具体匹配逻辑如下： 当 mismatches 集合为空时，会遍历 matches 集合中的匹配条件，匹配上任意一条即可返回 true。 当 matches 集合为空时，会遍历 mismatches 集合中的匹配条件，匹配上任意一条即返回 false。 当 matches 集合和 mismatches 集合同时不为空时，会优先匹配 mismatches 集合中的条件，匹配上任意一条规则即返回 false。若 mismatches 中的条件全部匹配失败，才会开始匹配 matches 集合，匹配上任意一条即返回 true。 当 matches 集合和 mismatches 集合同时为空时，则返回 false 其中具体的匹配逻辑都是在 UrlUtils.isMatchGlobPattern 方法中实现的，主要判断逻辑如下： 如果匹配条件以 $ 符号开头，表示从 URL 中获取相应的参数值进行匹配。 对 * 通配符特别处理，会处理通配符在匹配条件开头、中间以及末尾三种情况。 非通配符直接等值匹配 下面简单粘贴下代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566+--- UrlUtils /** * 判断 value 是否匹配 matches/mismatches * 注意：param参数是为了支持从URL中读取参数 * * @param pattern 匹配规则 * @param value 待和匹配值进行匹配的值 * @param param 消息者URL * @return 是否匹配 */ public static boolean isMatchGlobPattern(String pattern, String value, URL param) &#123; // 以美元符 `$` 开头，表示引用消费者参数（从URL中获取相应的参数值），param参数为消费者URL if (param != null &amp;&amp; pattern.startsWith(\"$\")) &#123; pattern = param.getRawParameter(pattern.substring(1)); &#125; // 进行匹配 return isMatchGlobPattern(pattern, value); &#125; public static boolean isMatchGlobPattern(String pattern, String value) &#123; // 全匹配，通配符支持 if (\"*\".equals(pattern)) &#123; return true; &#125; // 匹配规则和待匹配值全部为空，认为两者相等，即匹配 if ((pattern == null || pattern.length() == 0) &amp;&amp; (value == null || value.length() == 0)) &#123; return true; &#125; // 匹配规则和待匹配值有一个为空，不匹配 if ((pattern == null || pattern.length() == 0) || (value == null || value.length() == 0)) &#123; return false; &#125; // 确定 匹配规则中通配符 * 的位置 int i = pattern.lastIndexOf('*'); // 匹配规则中不包含通配符，此时直接比较匹配值和待匹配值 是否相等即可，并返回比较结果 if (i == -1) &#123; return value.equals(pattern); &#125; // 通配符 \"*\" 在匹配规则尾部，比如 192.168.25.* else if (i == pattern.length() - 1) &#123; // 判断待匹配值是否符合含有通配符的匹配规则 return value.startsWith(pattern.substring(0, i)); &#125; // 通配符 \"*\" 在匹配规则头部，如：*。168.25.100 else if (i == 0) &#123; // 判断待匹配值是否符合含有通配符的匹配规则 return value.endsWith(pattern.substring(i + 1)); &#125; // 通配符 \"*\" 在匹配规则中间位置 else &#123; // 以通配符 * 分隔，获取前后缀 String prefix = pattern.substring(0, i); String suffix = pattern.substring(i + 1); // 判断匹配值是否以 前缀开头且以后缀结尾 return value.startsWith(prefix) &amp;&amp; value.endsWith(suffix); &#125; &#125; 解析路由规则123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112+--- ConditionRouter private static Map&lt;String, MatchPair&gt; parseRule(String rule) throws ParseException &#123; // 1 定义条件映射集合，key：匹配项 value: 匹配对MatchPair 。 Map&lt;String, MatchPair&gt; condition = new HashMap&lt;String, MatchPair&gt;(); if (StringUtils.isBlank(rule)) &#123; return condition; &#125; // 2 存储匹配对，即匹配和不匹配条件 MatchPair pair = null; // 3 匹配对中的 匹配值集合/不匹配值集合的临时变量 Set&lt;String&gt; values = null; // 4 按照 分组正则匹配 配整路由个条件表达式 final Matcher matcher = ROUTE_PATTERN.matcher(rule); /** * 5 通过 ROUTE_PATTERN 正则匹配 rule ，遍历匹配结果， * 说明： * 1 find()方法是部分匹配，是查找输入串中与模式匹配的子串，如果该匹配的串有组还可以使用group()函数。当且仅当输入序列的子序列，匹配规则才会返回true，可能可以匹配多个子串 * 2 matcher.group() 返回匹配到的子字符串 * 例子：host = 2.2.2.2 &amp; host != 1.1.1.1 &amp; method = hello * 匹配结果： * 第一个子序列： host 分组一：\"\" 分组二：host * 第二个子序列：= 2.2.2.2 分组一：= 分组二：2.2.2.2 * 第三个子序列：&amp; host 分组一：&amp; 分组二：host * ... */ while (matcher.find()) &#123; // 5.1 获取匹配组一的匹配结果，即分隔符 String separator = matcher.group(1); // 5.2 获取匹配组二的匹配结果，即匹配规则项 String content = matcher.group(2); // 6 匹配组一的匹配结果为空，则说明 content 为参数名称 if (separator == null || separator.length() == 0) &#123; // 创建 MatchPair 对象 pair = new MatchPair(); // 存储 &lt;匹配项, MatchPair&gt; 键值对，比如 &lt;host, MatchPair&gt; condition.put(content, pair); &#125; // 7 如果匹配组一的匹配结果是 '&amp;'，说明是多个表达式 else if (\"&amp;\".equals(separator)) &#123; // 先尝试从 condition 中获取content对应的MatchPair，不存在则新建并放入condition中 if (condition.get(content) == null) &#123; pair = new MatchPair(); condition.put(content, pair); &#125; else &#123; pair = condition.get(content); &#125; &#125; // 8 如果分隔符为 '='，表示KV的分界线，值是匹配值 else if (\"=\".equals(separator)) &#123; if (pair == null) &#123; throw new ParseException(\"Illegal route rule \\\"\" + rule + \"\\\", The error char '\" + separator + \"' at index \" + matcher.start() + \" before \\\"\" + content + \"\\\".\", matcher.start()); &#125; // 匹配对中的匹配值集合，先取再放 values = pair.matches; // 将 content 存入到 MatchPair 的 matches 集合中 values.add(content); &#125; // 9 如果分隔符为 '!='，表示KV的分界线，值就是不匹配值 else if (\"!=\".equals(separator)) &#123; if (pair == null) &#123; throw new ParseException(\"Illegal route rule \\\"\" + rule + \"\\\", The error char '\" + separator + \"' at index \" + matcher.start() + \" before \\\"\" + content + \"\\\".\", matcher.start()); &#125; // 匹配对中的不匹配值集合，先取再放 values = pair.mismatches; // 将 content 存入到 MatchPair 的 mismatches 集合中 values.add(content); &#125; // 10 分隔符为 , 表示某个匹配项有多个值，它们以 ','分隔 else if (\",\".equals(separator)) &#123; if (values == null || values.isEmpty()) &#123; throw new ParseException(\"Illegal route rule \\\"\" + rule + \"\\\", The error char '\" + separator + \"' at index \" + matcher.start() + \" before \\\"\" + content + \"\\\".\", matcher.start()); &#125; // 将 content 存入到上一步获取到的 values 中，可能是 matches，也可能是 mismatches values.add(content); // 11 暂不支持的分割符 &#125; else &#123; throw new ParseException(\"Illegal route rule \\\"\" + rule + \"\\\", The error char '\" + separator + \"' at index \" + matcher.start() + \" before \\\"\" + content + \"\\\".\", matcher.start()); &#125; &#125; return condition; &#125; 解析路由规则主要是根据正则表达式中的两个匹配组，第一个组用来匹配分割符，目前支持 &amp;、!=、= 以及 , 符号；第二个组用来匹配条件内容；其中两个匹配组中间允许有多个空白。 在解析时，规则如下： 第一个匹配组匹配为空或者匹配到 &amp; 符号时，说明第二个匹配项匹配到的是一个条件项，应该为其创建一个匹配项 MatchPair 对象，用于下一个匹配查找存放匹配值或不匹配值。 第一个匹配组匹配为 =、!= 以及 , 时，说明本次查找到匹配的内容了，根据等值或不等值判断，将该内容记录到上一轮的 MatchPair 中的等值或不等值的集合中。 以上就是路由规则的解析逻辑，下面使用一个示例对解析逻辑进行说明。 示例1host &#x3D; 2.2.2.2,1.1.1.1 &amp; method !&#x3D;get &#x3D;&gt; host &#x3D; 3.3.3.3 正则解析结果 - whenCondition123456 第一个匹配组（分割符） 第二匹配组（条件）第一轮： &quot;&quot; host第二轮： &#x3D; 2.2.2.2第三轮： , 1.1.1.1第四轮： &amp; method第五轮： !&#x3D; get 正则解析结果 - thenCondition123 第一个匹配组（分割符） 第二匹配组（条件）第一轮： &quot;&quot; host第二轮： &#x3D; 3.3.3.3 解析后的 conditon 内容如下： whenConditon12345678910&#123; \"host\":&#123; \"matches\":[\"2.2.2.2\",\"1.1.1.1\"], \"mismatches\":[] &#125;, \"method\":&#123; \"matches\":[], \"mismatches\":[\"get\"] &#125;&#125; thenCondition123456&#123; \"host\":&#123; \"matches\":[\"3.3.3.3\"], \"mismatches\":[] &#125;&#125; 服务路由1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768+--- ConditionRouter /** * 路由 * 说明：该方法传入的url参数目前都是消费者URL: * &#123;@link AbstractDirectory#list(com.alibaba.dubbo.rpc.Invocation)&#125; * &#123;@link com.alibaba.dubbo.registry.integration.RegistryDirectory#route(java.util.List, java.lang.String)&#125; * * @param invokers Invoker 集合 * @param url 调用者传入，目前都是消费者URL * @param invocation 调用信息 * @param &lt;T&gt; * @return * @throws RpcException */ @Override public &lt;T&gt; List&lt;Invoker&lt;T&gt;&gt; route(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) throws RpcException &#123; // 判空 if (invokers == null || invokers.isEmpty()) &#123; return invokers; &#125; try &#123; /** * 1 优先执行消费者匹配条件，如果匹配失败，说明当前消费者URL不符合消费者匹配规则，直接返回invoker集合即可，无需继续后面的逻辑。 * 说明： * 消费者 ip：192.168.25.100 * 路由规则：host = 10.20.125.10 =&gt; host = 10.2.12.10 : ip为10.20.125.10的消费者调用ip为10.2.12.10的服务提供者 * 结果：当前消费者ip为192.168.25.100，这条路由规则不适用于当前的消费者，直接返回 * */ if (!matchWhen(url, invocation)) &#123; return invokers; &#125; // 路由过滤后的Invoker结果集 List&lt;Invoker&lt;T&gt;&gt; result = new ArrayList&lt;Invoker&lt;T&gt;&gt;(); // 2 提供者过滤条件未配置的话直接返回空集合，表示无提供者可用 if (thenCondition == null) &#123; logger.warn(\"The current consumer in the service blacklist. consumer: \" + NetUtils.getLocalHost() + \", service: \" + url.getServiceKey()); return result; &#125; // 3 遍历Invoker集合，逐个判断 Invoker 是否符合提供者过滤条件 for (Invoker&lt;T&gt; invoker : invokers) &#123; if (matchThen(invoker.getUrl(), url)) &#123; result.add(invoker); &#125; &#125; // 4 如果 result 非空，则直接返回过滤后的Invoker 集合 if (!result.isEmpty()) &#123; return result; // 5 如果过滤后的Invoker集合为空，根据 force 决定返回空集合还是返回全部 Invoker // 如果 force = true，表示强制返回空列表，否则路由结果为空的路由规则将失效 &#125; else if (force) &#123; logger.warn(\"The route result is empty and force execute. consumer: \" + NetUtils.getLocalHost() + \", service: \" + url.getServiceKey() + \", router: \" + url.getParameterAndDecoded(Constants.RULE_KEY)); return result; &#125; &#125; catch (Throwable t) &#123; logger.error(\"Failed to execute condition router rule: \" + getUrl() + \", invokers: \" + invokers + \", cause: \" + t.getMessage(), t); &#125; // 6 走到这里，说明过滤后的Invoker集合为空，并且非强制执行，则原样返回invoker 集合，即表示该条路由规则失效，忽律路由规则 return invokers; &#125; 服务路由首先判断此次发起调用的消费方是否符合消费端匹配条件，若不符合说明当前路由规则不适用当前的消费者，直接返回整个 Invoker 列表即可。若符合，则继续通过提供者匹配条件对 Invoker 集合进行过滤。其中通过调用 matchWhen 对消费方进行匹配，匹配成功再使用 matchThen 对提供者进行过滤。下面来看一下这两个方法的逻辑： 1234567891011121314151617181920212223242526272829+--- ConditionRouter /** * 对服务消费方进行匹配，如果匹配失败，直接返回Invoker 列表。如果匹配成功，才会对服务提供者进行匹配。 * * @param url 消费者 URL * @param invocation 调用信息 * @return */ boolean matchWhen(URL url, Invocation invocation) &#123; /** * 服务消费者匹配条件为 null 或 空，表示对所有消费方生效，返回true，如： * =&gt; host != 10.2.12.10 ，表示所有的消费者都不能调用 IP 为 10.2.12.10 */ return whenCondition == null || whenCondition.isEmpty() || matchCondition(whenCondition, url, null, invocation); &#125; /** * 对服务提供者进行匹配 * * @param url 提供者URL合并后的 URL * @param param 消费者 URL * @return */ private boolean matchThen(URL url, URL param) &#123; // 服务提供者条件为 null 或 空，表示禁用服务 return !(thenCondition == null || thenCondition.isEmpty()) &amp;&amp; matchCondition(thenCondition, url, param, null); &#125; 这两个方法均是通过调用 matchCondition 方法执行匹配逻辑的，区别在它们各自传参不同。具体传参代码中已经详细标注，下面我们就看具体的匹配逻辑。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970+--- ConditionRouter/** * 匹配条件 * * @param condition 消费者匹配的条件集合/提供者匹配的条件集合 * @param url 消费者URL/提供者URL合并后的URL * @param param 消费者URL，在url参数为提供者URL合并后的URL时才有值。该值仅用于匹配规则引用消费者URL的参数的场景。 * @param invocation 调用信息 * @return */ private boolean matchCondition(Map&lt;String, MatchPair&gt; condition, URL url, URL param, Invocation invocation) &#123; // 1 将服务提供者或消费者 url 转成 Map Map&lt;String, String&gt; sample = url.toMap(); // 标记是否匹配 boolean result = false; // 2 遍历匹配条件集合 for (Map.Entry&lt;String, MatchPair&gt; matchPair : condition.entrySet()) &#123; //--------------------------- 获取匹配项，确定匹配值 --------------------------/ // 2.1 获得匹配项名称，如 host,method String key = matchPair.getKey(); // 2.2 匹配项的值 String sampleValue; // 2.3 如果 Invocation 不为null，且匹配项名称为 method 或 methods，表示进行方法匹配 if (invocation != null &amp;&amp; (Constants.METHOD_KEY.equals(key) || Constants.METHODS_KEY.equals(key))) &#123; // 从Invocation中获取调用方法名 sampleValue = invocation.getMethodName(); &#125; else &#123; // 2.4 从服务提供者或者消费者 URL 中获取匹配项的值，如 host、application sampleValue = sample.get(key); // 2.5 匹配项对应的值不存在，则尝试获取 default.key 的值 if (sampleValue == null) &#123; sampleValue = sample.get(Constants.DEFAULT_KEY_PREFIX + key); &#125; &#125; //--------------------------- 条件匹配 ------------------------------------------/ // 3 匹配项的值不为空 if (sampleValue != null) &#123; // 调用匹配项关联的 MatchPair 的 isMatch 方法进行匹配，只要有一个匹配规则匹配失败，就失败 if (!matchPair.getValue().isMatch(sampleValue, param)) &#123; return false; &#125; else &#123; result = true; &#125; // 4 匹配项的值为空，说明服务提供者或消费者URL中不包含该配置项的值 &#125; else &#123; // 匹配项中的匹配条件 `matches` 不为空，表示匹配失败，返回false // 如我们设置了这样一条规则：ip = 10.2.12.10 ，假设 URL 中不包含 ip 参数，此时 ip 匹配项的值为 null， // 但路由规则限制了 ip = 10.2.12.10，URL中却没有该配置项，这是不符合规则的，因此返回 false if (!matchPair.getValue().matches.isEmpty()) &#123; return false; &#125; else &#123; result = true; &#125; &#125; &#125; return result; &#125; matchCondition 方法核心逻辑是使用消费者匹配条件集合或提供者匹配条件集合，去匹配 消费方URL 或 提供方URL（合并后的结果），匹配项的匹配工作是交给 MatchPair.isMatch 方法完成的。 其中 URL 转成 Map 参数逻辑如下： 1234567891011121314151617+--- URL public Map&lt;String, String&gt; toMap() &#123; Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(parameters); if (protocol != null) map.put(\"protocol\", protocol); if (username != null) map.put(\"username\", username); if (password != null) map.put(\"password\", password); if (host != null) map.put(\"host\", host); if (port &gt; 0) map.put(\"port\", String.valueOf(port)); if (path != null) map.put(\"path\", path); return map; &#125; 可以看到，toMap 方法将 URL 中的主干和参数部分都转成了对应的 K-V 形式，用于和匹配条件集合比对。 总结整体来看条件路由还是比较复杂的，下面对其主要流程进行简单梳理。 条件路由 ConditionRouter 在初始化时会对传入的条件路由规则进行解析、缓存，针对消费方和提供方各有一个条件集合，格式为 &lt;匹配项,MatchPair&lt;匹配项对应的匹配值集合，匹配项对应的不匹配值集合&gt;&gt; 。 进行服务路由的时候，首先使用消费方条件集合对传入的消费者URL进行匹配，匹配失败则说明当前消费者URL不符合消费者匹配条件，直接返回传入的 Invoker 集合即可。如果匹配成功，则使用提供方条件集合对传入的 Invoker 集合逐一匹配，即使用提供方条件集合对Invoker的URL进行匹配，最终筛选出符合条件的 Invoker 列表。如果对传入Invoker 列表过滤后结果为空，则需要根据 force 决定返回空集合还是返回全部 Invoker ，如果 force = true 表示强制返回空列表，否则路由结果为空的路由认为是失效的。如果最终过滤后的结果非空，则直接返回过滤后的 Invoker 列表。 第 2 步的匹配逻辑最终是交给 MatchPair.isMatch 方法处理的，本质上是使用匹配集合匹配URL中对应的参数值。 ScriptRouterFactory &amp; ScriptRouterScriptRouterFactory123456789101112public class ScriptRouterFactory implements RouterFactory &#123; /** * 扩展名 */ public static final String NAME = \"script\"; @Override public Router getRouter(URL url) &#123; // 创建 ScriptRouter 对象 return new ScriptRouter(url); &#125;&#125; ScriptRouterFactory 的扩展名为 script ，其 getRouter 方法中会创建一个 ScriptRouter 对象。 ScriptRouterScriptRouter 支持 JDK 脚本引擎的所有脚本，如：javaScript、JRuby、Groovy 等，通过 type=javascript 参数设置脚本类型，缺省为 javaScript 。 脚本1&quot;script:&#x2F;&#x2F;0.0.0.0&#x2F;com.foo.BarService?category&#x3D;routers&amp;dynamic&#x3D;false&amp;rule&#x3D;&quot; + URL.encode(&quot;（function route(invokers) &#123; ... &#125; (invokers)）&quot;) 基于脚本引擎的路由规则，下面定义一个 route() 函数进行 ip 过滤。 12345678910（function route(invokers) &#123; var result = new java.util.ArrayList(invokers.size()); for (i = 0; i &lt; invokers.size(); i ++) &#123; // 判断 Invoker 的 host 是否符合条件 if (\"10.20.153.10\".equals(invokers.get(i).getUrl().getHost())) &#123; result.add(invokers.get(i)); &#125; &#125; return result;&#125; (invokers)）; // 表示立即执行方法 可以将上面的脚本进行编码并作为路由规则参数 rule 的值添加到 URL 中，该 URL 传入 ScriptRouter 的构造函数时即可被解析。 属性1234567891011121314151617181920212223242526272829public class ScriptRouter implements Router &#123; private static final Logger logger = LoggerFactory.getLogger(ScriptRouter.class); /** * 脚本类型 与脚本引擎的映射缓存 * key：脚本语言的名称 * value: 脚本引擎 */ private static final Map&lt;String, ScriptEngine&gt; engines = new ConcurrentHashMap&lt;String, ScriptEngine&gt;(); /** * 脚本路由规则 */ private final ScriptEngine engine; /** * 路由规则优先级，用于排序，该字段值越大，优先级越高，默认值为 0。 */ private final int priority; /** * 当前 ScriptRouter 使用的具体脚本内容 */ private final String rule; /** * 路由规则 URL，可以从 rule 参数中获取具体的路由规则 */ private final URL url;&#125; 构造方法12345678910111213141516171819202122232425262728+--- ScriptRouter public ScriptRouter(URL url) &#123; this.url = url; // 获取脚本类型和路由优先级 String type = url.getParameter(Constants.TYPE_KEY); this.priority = url.getParameter(Constants.PRIORITY_KEY, 0); // 获取脚本内容 String rule = url.getParameterAndDecoded(Constants.RULE_KEY); if (type == null || type.length() == 0) &#123; type = Constants.DEFAULT_SCRIPT_TYPE_KEY; &#125; if (rule == null || rule.length() == 0) &#123; throw new IllegalStateException(new IllegalStateException(\"route rule can not be empty. rule:\" + rule)); &#125; // 根据脚本类型获取对应的脚本引擎 ScriptEngine engine = engines.get(type); if (engine == null) &#123; engine = new ScriptEngineManager().getEngineByName(type); if (engine == null) &#123; throw new IllegalStateException(new IllegalStateException(\"Unsupported route rule type: \" + type + \", rule: \" + rule)); &#125; engines.put(type, engine); &#125; this.engine = engine; this.rule = rule; &#125; ScriptRouter 构造方法会获取传入URL中的脚本内容，以及获取脚本类型，并根据脚本类型创建脚本引擎，脚本引擎主要用于编译和执行脚本。 服务路由123456789101112131415161718192021222324252627282930313233343536373839404142+--- ScriptRouter @Override @SuppressWarnings(\"unchecked\") public &lt;T&gt; List&lt;Invoker&lt;T&gt;&gt; route(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) throws RpcException &#123; try &#123; List&lt;Invoker&lt;T&gt;&gt; invokersCopy = new ArrayList&lt;Invoker&lt;T&gt;&gt;(invokers); Compilable compilable = (Compilable) engine; // 创建 Bindings 对象作为 Bindings bindings = engine.createBindings(); // 与前面的 javascript的示例脚本结合，这里在 Bindings 中为脚本中的route()函数提供了 invokers、Invocation、context 三个参数 bindings.put(\"invokers\", invokersCopy); bindings.put(\"invocation\", invocation); bindings.put(\"context\", RpcContext.getContext()); // 使用脚本引擎编译脚本 CompiledScript function = compilable.compile(rule); // 执行脚本 Object obj = function.eval(bindings); // 根据结果类型，转换成 (List&lt;Invoker&lt;T&gt;&gt; 类型返回 if (obj instanceof Invoker[]) &#123; invokersCopy = Arrays.asList((Invoker&lt;T&gt;[]) obj); &#125; else if (obj instanceof Object[]) &#123; invokersCopy = new ArrayList&lt;Invoker&lt;T&gt;&gt;(); for (Object inv : (Object[]) obj) &#123; invokersCopy.add((Invoker&lt;T&gt;) inv); &#125; &#125; else &#123; invokersCopy = (List&lt;Invoker&lt;T&gt;&gt;) obj; &#125; return invokersCopy; &#125; catch (ScriptException e) &#123; //fail then ignore rule .invokers. logger.error(\"route error , rule has been ignored. rule: \" + rule + \", method:\" + invocation.getMethodName() + \", url: \" + RpcContext.getContext().getUrl(), e); return invokers; &#125; &#125; ScriptRouter 服务路由相对比较简单，主要依靠 JDK 的脚本引擎对象，对脚本编译、执行，最终获取路由后的 Invoker 集合。 FileRouterFactoryFileRouterFactory 是 ScriptRouterFactory 的装饰器，基于文件读取路由规则。在 ScriptRouterFactory 基础上增加了读取文件的能力，使用方可以将 ScriptRouter 使用的路由规则保存到文件中，然后在 URL 中指定文件路径，FileRouterFactory 从中解析到该脚本文件的路径并进行读取，然后调用 ScriptRouterFactory 去创建相应的 ScriptRouter 对象。 属性12345678910111213141516public class FileRouterFactory implements RouterFactory &#123; /** * 拓展名 */ public static final String NAME = \"file\"; /** * RouterFactory$Adaptive 对象, Dubbo IOC注入 */ private RouterFactory routerFactory; public void setRouterFactory(RouterFactory routerFactory) &#123; this.routerFactory = routerFactory; &#125;&#125; 获取路由12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849+--- FileRouterFactory @Override public Router getRouter(URL url) &#123; try &#123; // router 配置项，默认为 script // 将 file 协议的 URL 转换成 script 协议的 URL // file:///d:/path/to/route.js?router=script ==&gt; script:///d:/path/to/route.js?type=js&amp;rule=&lt;file-content&gt; // 1 获取 router 配置项，默认为 script // Replace original protocol (maybe 'file') with 'script' String protocol = url.getParameter(Constants.ROUTER_KEY, ScriptRouterFactory.NAME); // 使用文件后缀作为类型，如：js、groovy String type = null; // 2 获取path String path = url.getPath(); // 3 获取脚本文件的语言类型 if (path != null) &#123; int i = path.lastIndexOf('.'); if (i &gt; 0) &#123; type = path.substring(i + 1); &#125; &#125; // 4 从文件中读取路由规则，作为 ScriptRouter 的路由规则 String rule = IOUtils.read(new FileReader(new File(url.getAbsolutePath()))); // 5 创建script协议的URL boolean runtime = url.getParameter(Constants.RUNTIME_KEY, false); // 5.1 protocol 决定使用哪种路由，默认为script URL script = url.setProtocol(protocol) // 5.2 type，如：js .addParameter(Constants.TYPE_KEY, type) // 5.3 runtime .addParameter(Constants.RUNTIME_KEY, runtime) // 5.4 路由规则 rule .addParameterAndEncoded(Constants.RULE_KEY, rule); // 获取script对应的Router实现 return routerFactory.getRouter(script); &#125; catch (IOException e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; &#125; 总结FileRouterFactory 核心有两点：其一，将路由规则从脚本文件读取到内存，将作为脚本路由的规则；其二，完成 file协议 的 URL 到 script协议 的 URL 的转换，即基于 file协议 的URL 构建一个 script协议 的 URL 。有了以上两点，就可以实现基于 ScriptRouterFactory 基础增加读取文件内容的能力。 TagRouterFactory &amp; TagRouter标签路由是 Dubbo 2.7.x 支持的路由规则。 TagRouterFactory12345678910111213@Activate(order = 100)public class TagRouterFactory extends CacheableRouterFactory &#123; /** * 扩展名 */ public static final String NAME = \"tag\"; @Override protected Router createRouter(URL url) &#123; // 创建 TagRouter return new TagRouter(url); &#125;&#125; TagRouter简介标签路由通过将某一个或多个服务的提供者划分到同一个分组，约束流量只在指定分组中流转，从而实现流量隔离的目的，可以作为灰度发布等场景的基础。 Provider标签主要是指对 Provider 端应用实例的分组，目前有两种方式可以完成实例分组，分别是 动态规则打标 和 静态规则打标 ，其中动态规则相较于静态规则优先级更高，当两种规则同时存在且出现冲突时，以动态规则为准。 动态打标可随时在 服务治理平台 动态下发标签 1234567891011121314# governance-tagrouter-provider应用增加了两个标签分组tag1和tag2# tag1包含一个实例 127.0.0.1:20880# tag2包含一个实例 127.0.0.1:20881--- force: false runtime: true enabled: true key: governance-tagrouter-provider tags: - name: tag1 addresses: [\"127.0.0.1:20880\"] - name: tag2 addresses: [\"127.0.0.1:20881\"] ... 动态打标规则详解： key 明确规则体作用到哪个应用。必填。 enabled=true 当前路由规则是否生效，可不填，缺省生效。 force=false 当路由结果为空时，是否强制执行，如果不强制执行，路由结果为空的路由规则将自动失效，可不填，缺省为 false。 runtime=false 是否在每次调用时执行路由规则，否则只在提供者地址列表变更时预先执行并缓存结果，调用时直接从缓存中获取路由结果。如果用了参数路由，必须设为 true，需要注意设置会影响调用的性能，可不填，缺省为 false。 priority=1 路由规则的优先级，用于排序，优先级越大越靠前执行，可不填，缺省为 0。 tags 定义具体的标签分组内容，可定义任意n（n&gt;=1）个标签并为每个标签指定实例列表。必填。 name， 标签名称 addresses，当前标签包含的实例列表（标签对应的服务节点地址列表） 静态打标1234&lt;!-- 全局服务级别 --&gt;&lt;dubbo:provider tag=\"tag1\"/&gt;&lt;!--服务接口级别--&gt;&lt;dubbo:service tag=\"tag1\"/&gt; ConsumerConsumer 端可以在 RpcContext 的 attachment 中添加 request.tag 附加属性。 1234// 硬编码RpcContext.getContext().setAttachment(Constants.REQUEST_TAG_KEY,\"tag1\");// 配置&lt;dubbo:reference tag=\"tag1\"/&gt; 请求标签的作用域为每一次 Invocation，使用 attachment 来传递请求标签，注意保存在 attachment 中的值将会在一次完整的远程调用中持续传递，得益于这样的特性，我们只需要在起始调用时进行设置，就可以达到标签的持续传递。 标签路由规则 当设置 request.tag=tag1 时优先选择标记了 tag=tag1 的 Provider。若 Provider 集群中不存在与请求 Tag 对应的 Provider 节点，则默认将降级请求 Tag 为空的 Provider 节点；如果希望在找不到匹配 Tag 的 Provider 节点时抛出异常，需要设置 request.tag.force=true 。 当 request.tag 未设置时，只会匹配 Tag 为空的 Provider 节点，即使集群中存在可用的服务，若 Tag 不匹配也无法调用。也就是说：携带 Tag 的请求可以降级访问到无 Tag 的 Provider，但不携带 Tag 的请求永远无法访问到带有 Tag 的 Provider。 Tag 使用基于 Tag 的测试环境隔离方案 在开发测试中，如果针对每个需求分别独立出一套测试环境的话，会占用大量机器并且维护成本也都比较高。此时，我们就可以通过标签路由实现环境隔离，对 Provider 进行打标，消费方配置目标服务的标签即可。 属性1234567891011121314151617181920212223public class TagRouter extends AbstractRouter implements ConfigurationListener &#123; private static final Logger logger = LoggerFactory.getLogger(TagRouter.class); public static final String NAME = \"TAG_ROUTER\"; /** * 优先级 */ private static final int TAG_ROUTER_DEFAULT_PRIORITY = 100; private static final String RULE_SUFFIX = \".tag-router\"; private String application; /** * 标签路由规则 */ private TagRouterRule tagRouterRule; public TagRouter(URL url) &#123; super(url); // 设置优先级 this.priority = TAG_ROUTER_DEFAULT_PRIORITY; &#125;&#125; 在 TagRouter 中持有 TagRouterRule 对象引用，它表示一个标签路由规则，该对象主要用于动态打标的方式，下面我们对其进行简单介绍。 TagRouterRule123456789101112131415161718192021222324252627282930313233343536public class TagRouterRule extends AbstractRouterRule &#123; /** * Tag 集合 */ private List&lt;Tag&gt; tags; /** * address 到 tag 名称的映射 */ private Map&lt;String, List&lt;String&gt;&gt; addressToTagnames = new HashMap&lt;&gt;(); /** * tag 名称到 address 的映射 */ private Map&lt;String, List&lt;String&gt;&gt; tagnameToAddresses = new HashMap&lt;&gt;(); /** * 根据 Tag 集合初始化 addressToTagnames 和 tagnameToAddresses */ public void init() &#123; if (!isValid()) &#123; return; &#125; tags.stream().filter(tag -&gt; CollectionUtils.isNotEmpty(tag.getAddresses())).forEach(tag -&gt; &#123; // tag 名称 到 address 的映射 tagnameToAddresses.put(tag.getName(), tag.getAddresses()); // address 到 tag 名称的映射 tag.getAddresses().forEach(addr -&gt; &#123; List&lt;String&gt; tagNames = addressToTagnames.computeIfAbsent(addr, k -&gt; new ArrayList&lt;&gt;()); tagNames.add(tag.getName()); &#125;); &#125;); &#125; // 省略获取 Tag 集合中地址、标签名信息等方法&#125; TagRouterRule 主要为动态打标服务，继承了 AbstractRouterRule , 其中定义了路由规则的公用属性。 AbstractRouterRule1234567891011121314151617181920212223242526272829303132333435363738394041public abstract class AbstractRouterRule &#123; /** * 路由规则解析前的原始字符串配置 */ private String rawRule; /** * 表示是否在每次调用时执行该路由规则。 * 如果设置为 false，则会在 Provider 列表变更时预先执行并缓存结果，调用时直接从缓存中获取路由结果。 */ private boolean runtime = true; /** * 当路由结果为空时，是否强制执行，如果不强制执行，路由结果为空的路由规则将自动失效。该字段默认值为 false。 */ private boolean force = false; /** * 标识解析生成当前 RouterRule 对象的配置是否合法。 */ private boolean valid = true; /** * 标识当前路由规则是否生效。 */ private boolean enabled = true; /** * 用于表示当前 RouterRule 的优先级。 */ private int priority; /** * 表示该路由规则是否为持久数据，当注册方退出时，路由规则是否依然存在。 */ private boolean dynamic = false; /** * 范围：application/service */ private String scope; /** * 明确规则体作用在哪个服务或应用 * 1 scope 为 service: 由 [&#123;group&#125;:]&#123;service&#125;[:&#123;version&#125;] 构成 * 2 scope 为 application: application */ private String key;&#125; 此外，TagRouterRule 中维护了一个 Tag 集合，因为一个标签路由规则支持多个 Tag，而每个 Tag 对象中维护了一个 Tag 名称，以及该 Tag 绑定的服务节点网络地址集合。 Tag12345678910public class Tag &#123; /** * Tag 名称 */ private String name; /** * Tag 绑定的网络地址集合 */ private List&lt;String&gt; addresses;&#125; 标签路由规则如下： 解析标签路由规则TagRouter 实现了 ConfigurationListener 接口，用于监听配置的变化，用于更新动态打标信息，其中就包括 TagRouterRule 配置的变更。 12345678910111213141516171819202122232425262728+--- TagRouter /** * 监听配置的变化 * * @param event config change event */ @Override public synchronized void process(ConfigChangedEvent event) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Notification of tag rule, change type is: \" + event.getChangeType() + \", raw rule is:\\n \" + event.getContent()); &#125; try &#123; // 1 DELETED 事件会直接清空 tagRouterRule if (event.getChangeType().equals(ConfigChangeType.DELETED)) &#123; this.tagRouterRule = null; // 2 其它事件会解析最新的路由规则，并记录到 tagRouterRule 字段中 &#125; else &#123; // 通过 TagRuleParser 解析配置 this.tagRouterRule = TagRuleParser.parse(event.getContent()); &#125; &#125; catch (Exception e) &#123; logger.error(\"Failed to parse the raw tag router rule and it will not take effect, please check if the \" + \"rule matches with the template, the raw rule is:\\n \", e); &#125; &#125; TagRuleParser 用于解析 yaml 格式的 TagRouterRule 配置，将规则配置信息读入到 TagRouterRule 中。 服务路由路由的最终目的是要过滤符合条件的 Invoker 对象，下面我们就来看 TagRouter 是如何使用 TagRouterRule 路由逻辑进行 Invoker 过滤的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889+--- TagRouter /*** * 服务路由 * @param invokers invoker list * @param url refer url * @param invocation invocation * @param &lt;T&gt; * @return * @throws RpcException */ @Override public &lt;T&gt; List&lt;Invoker&lt;T&gt;&gt; route(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) throws RpcException &#123; // 1 如果 invokers 为空，直接返回空集合 if (CollectionUtils.isEmpty(invokers)) &#123; return invokers; &#125; // 2 优先使用动态规则 // 检查动态规则 tagRouterRule 是否可用，如果不可用，则调用 filterUsingStaticTag 方法使用静态规则进行过滤 final TagRouterRule tagRouterRuleCopy = tagRouterRule; if (tagRouterRuleCopy == null || !tagRouterRuleCopy.isValid() || !tagRouterRuleCopy.isEnabled()) &#123; return filterUsingStaticTag(invokers, url, invocation); &#125; // 使用动态规则 List&lt;Invoker&lt;T&gt;&gt; result = invokers; // 3 获取此次请求的 tag 信息，尝试从 Invocation 以及 URL 中获取 String tag = StringUtils.isEmpty(invocation.getAttachment(TAG_KEY)) ? url.getParameter(TAG_KEY) : invocation.getAttachment(TAG_KEY); // 4 此次请求指定了 tag (优先选择tag对应的Provider，如果没有Provider则降级处理，选择 tag 为空的 Provider) if (StringUtils.isNotEmpty(tag)) &#123; // 4.1 从动态规则中获取请求 tag 对应的 address 集合 List&lt;String&gt; addresses = tagRouterRuleCopy.getTagnameToAddresses().get(tag); if (CollectionUtils.isNotEmpty(addresses)) &#123; // 4.1.2 根据请求 tag 对应的 address 集合去匹配符合条件的 Invoker result = filterInvoker(invokers, invoker -&gt; addressMatches(invoker.getUrl(), addresses)); // 如果存在符合条件的Invoker，则直接将过滤得到的Invoker集合返回。否则，根据force配置决定是否返回空Invoker集合 if (CollectionUtils.isNotEmpty(result) || tagRouterRuleCopy.isForce()) &#123; return result; &#125; // 4.2 如果请求 tag 没有对应 address &#125; else &#123; // 4.2.1 将请求携带的 tag 与 Provider URL 中的 tag 参数值进行比较，匹配出符合条件的 Invoker 集合。 result = filterInvoker(invokers, invoker -&gt; tag.equals(invoker.getUrl().getParameter(TAG_KEY))); &#125; // 4.3 存在符合条件的Invoker 或是 force=true，则直接返回过滤后的结果 if (CollectionUtils.isNotEmpty(result) || isForceUseTag(invocation)) &#123; return result; &#125; // 4.4 如果 Invoker 过滤后的结果为空，且 force 配置为 false，则返回所有不包含任何 tag 的 Provider 列表。(降级) // FAILOVER: return all Providers without any tags. else &#123; List&lt;Invoker&lt;T&gt;&gt; tmp = filterInvoker(invokers, invoker -&gt; addressNotMatches(invoker.getUrl(), tagRouterRuleCopy.getAddresses())); return filterInvoker(tmp, invoker -&gt; StringUtils.isEmpty(invoker.getUrl().getParameter(TAG_KEY))); &#125; // 5 如果此次请求未携带 tag 信息（只匹配tag为空的Provier） &#125; else &#123; // List&lt;String&gt; addresses = tagRouterRule.filter(providerApp); // return all addresses in dynamic tag group. // 5.1 获取 TagRouterRule 规则中全部 tag 关联的 address 集合 List&lt;String&gt; addresses = tagRouterRuleCopy.getAddresses(); // 5.2 如果 address 集合不为空，则过滤出不在 address 集合中的 Invoker 并添加到结果集合中。 if (CollectionUtils.isNotEmpty(addresses)) &#123; result = filterInvoker(invokers, invoker -&gt; addressNotMatches(invoker.getUrl(), addresses)); // 1. all addresses are in dynamic tag group, return empty list. if (CollectionUtils.isEmpty(result)) &#123; return result; &#125; // 2. if there are some addresses that are not in any dynamic tag group, continue to filter using the // static tag group. &#125; // 5.3 将 Provider URL 中的 tag 值与 TagRouterRule 中的 tag 名称进行比较，过滤出不匹配的 tag，得到最终的 Invoker 集合。 return filterInvoker(result, invoker -&gt; &#123; String localTag = invoker.getUrl().getParameter(TAG_KEY); return StringUtils.isEmpty(localTag) || !tagRouterRuleCopy.getTagNames().contains(localTag); &#125;); &#125; &#125; 进行标签路由时，如果动态规则为空或不可用，则使用静态规则。使用静态规则路由规则如下： 123456789101112131415161718192021222324252627+--- TagRouter private &lt;T&gt; List&lt;Invoker&lt;T&gt;&gt; filterUsingStaticTag(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) &#123; List&lt;Invoker&lt;T&gt;&gt; result = invokers; // 1 获取请求携带的 tag // Dynamic param String tag = StringUtils.isEmpty(invocation.getAttachment(TAG_KEY)) ? url.getParameter(TAG_KEY) : invocation.getAttachment(TAG_KEY); // 2 请求携带了 tag // Tag request if (!StringUtils.isEmpty(tag)) &#123; // 2.1 比较请求携带的 tag 值与 Provider URL 中的 tag 参数值 result = filterInvoker(invokers, invoker -&gt; tag.equals(invoker.getUrl().getParameter(TAG_KEY))); // 2.2 集群中不存在与请求tag对应的服务，默认降级请求 tag 为空的 Provider。 if (CollectionUtils.isEmpty(result) &amp;&amp; !isForceUseTag(invocation)) &#123; result = filterInvoker(invokers, invoker -&gt; StringUtils.isEmpty(invoker.getUrl().getParameter(TAG_KEY))); &#125; // 3 请求没有携带 tag，只会匹配 tag 为空的 Provider 。 &#125; else &#123; result = filterInvoker(invokers, invoker -&gt; StringUtils.isEmpty(invoker.getUrl().getParameter(TAG_KEY))); &#125; return result; &#125; 从代码层面上验证了前文提到的标签路由规则，下面对服务路由进行概述： 请求指定了tag信息 优先选择tag对应的Provider 降级请求tag为空的provider 请求未指定tag信息 只需匹配tag为空的Provider 总结标签路由是通过动态或静态打标的方式为服务提供者设置 Tag。其中动态打标方式的规则存储到 TagRouterRule 对象中，是通过 &lt;tag名称，Provider节点地址集合&gt; 映射关系体现过滤规则的。静态打标方式的规则是作为配置信息存储到提供者URL中的，是通过 tag 参数体现过滤规则的。当消费请求进来，会通过 TagRouterRule 和 tag 参数进行 Invoker 列表的过滤。 小结本篇文章中对 条件路由、脚本路由、文件路由 进行了介绍，最后对 Dubbo 2.7.x 中新支持的 标签路由 进行了介绍。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"集群容错 - 动态配置","slug":"rpc/集群容错之Dubbo动态配置","date":"2020-09-22T23:00:00.000Z","updated":"2021-04-06T08:32:25.772Z","comments":false,"path":"posts/a965bdb8/","link":"","permalink":"https://gentryhuang.com/posts/a965bdb8/","excerpt":"","text":"概述在介绍动态服务目录 RegistryDirectory 相关内容时，提到了 RegistryDirectory 会监听注册中心的 providers、routers 和 configurators 三个目录，当配置变更时会做出相应的处理。此外在服务暴露过程中，服务提供者会向注册中心注册监听器，监听 configurators 目录下数据的变更。本篇文章对 Dubbo 动态配置进行分析，并对 Configurator 的集成进行介绍。Configurator 相关类图如下： 覆盖规则是 Dubbo 设计的在无需重启应用的情况下，动态调整 RPC 调用行为的一种能力。从 2.7.0 版本开始，支持从服务和应用两个粒度来调整动态配置。 基础协议在分析源码之前，我们先了解下动态配置的两种协议。下面以 override 协议为例： override://0.0.0.0/com.foo.BarService?category=configurators&amp;dynamic=false&amp;enabled=true&amp;application=foo&amp;timeout=1000 下面对上述 URL 进行解析： override:// 表示数据采用覆盖方式，Dubbo 支持 override 和 absent 两种协议，可扩展，必填。 0.0.0.0 表示对所有 IP 地址生效，如果只想覆盖某个 IP 的数据，请填入具体 IP，必填。 com.foo.BarService 表示只对指定的服务生效，必填。 category=configurators 表示该 URL 为动态配置类型，必填。 dynamic=false 表示该 URL 为持久数据，即使注册该 URL 的节点退出，该 URL 依旧会保存在注册中心，必填。 enabled=true 表示该 URL 的覆盖规则生效，可不填，缺省生效。 application=foo 表示只对指定应用生效，可不填，表示对所有应用生效。 timeout=1000 表示将满足以上条件的 URL 中的 timeout 参数的值覆盖为 1000 。如果想覆盖其他配置，可以直接以参数的形式添加到 override URL 之上。 使用示例： 禁用某个提供者（通常用于临时剔除某个 Provider 节点） override://10.20.153.10/com.foo.BarService?category=configurators&amp;dynamic=false&amp;disbaled=true 调整某个提供者的权重（通常用于容量评估，缺省权重为 100） override://10.20.153.10/com.foo.BarService?category=configurators&amp;dynamic=false&amp;weight=200 调整负载均衡策略（缺省负载均衡策略为 random） override://10.20.153.10/com.foo.BarService?category=configurators&amp;dynamic=false&amp;loadbalance=leastactive 服务降级（通常用于临时屏蔽某个出错的非关键服务） override://0.0.0.0/com.foo.BarService?category=configurators&amp;dynamic=false&amp;application=foo&amp;mock=force:return+null 源码分析ConfiguratorFactory123456789101112@SPIpublic interface ConfiguratorFactory &#123; /** * 创建 Configurator 配置规则对象 * * @param url - configurator url. * @return configurator instance. */ @Adaptive(\"protocol\") Configurator getConfigurator(URL url);&#125; ConfiguratorFactory 是 Dubbo 的一个扩展点，没有默认的扩展实现。作为 Configurator 工厂接口，其中的 @Adaptive(&quot;protocol&quot;) 注解会基于 Dubbo 自适应扩展机制获取 ConfiguratorFactory 具体实现，即根据配置规则 URL 的 protocol 属性获取 Configurator 实现。目前配置 URL 的协议支持 override 和 absent 两种，对应的实现分别为 OverrideConfiguratorFactory 和 AbsentConfiguratorFactory 。 OverrideConfiguratorFactory1234567public class OverrideConfiguratorFactory implements ConfiguratorFactory &#123; @Override public Configurator getConfigurator(URL url) &#123; // 创建 OverrideConfigurator 对象 return new OverrideConfigurator(url); &#125;&#125; AbsentConfiguratorFactory12345678public class AbsentConfiguratorFactory implements ConfiguratorFactory &#123; @Override public Configurator getConfigurator(URL url) &#123; // 创建 AbsentConfigurator return new AbsentConfigurator(url); &#125;&#125; Configurator123456789101112131415161718public interface Configurator extends Comparable&lt;Configurator&gt; &#123; /** * 获得配置URL，里面带有配置规则 * * @return configurator url. */ URL getUrl(); /** * 将 Configurator 应用到 URL * * @param url - old rovider url. * @return new provider url. */ URL configure(URL url);&#125; Configurator 接口抽象了一条配置信息，即一个 Configurator 对象对应一条配置规则。需要注意的是，该接口实现了 Comparable 接口，因为 Configurator 有优先级的要求。 AbstractConfiguratorAbstractConfigurator 作为 Configurator 抽象实现类，实现了公用的配置规则的匹配、排序逻辑，将配置规则应用到目标 URL 上的工作交给了具体子类完成。 获取配置规则1234567891011121314151617181920212223public abstract class AbstractConfigurator implements Configurator &#123; /** * 配置规则url */ private final URL configuratorUrl; public AbstractConfigurator(URL url) &#123; if (url == null) &#123; throw new IllegalArgumentException(\"configurator url == null\"); &#125; this.configuratorUrl = url; &#125; /** * 获得配置规则URL * * @return */ @Override public URL getUrl() &#123; return configuratorUrl; &#125;&#125; 应用配置准备工作123456789101112131415161718192021222324252627282930313233343536373839+--- AbstractConfigurator /** * 设置配置规则到指定URl中 * * @param url 待应用配置规则的URL * @return */ @Override public URL configure(URL url) &#123; // 1 参数检查，配置规则中必须要有 ip if (configuratorUrl == null || configuratorUrl.getHost() == null || url == null || url.getHost() == null) &#123; return url; &#125; // 2 配置规则Url有端口，则说明这个配置规则Url是操作某个服务提供者的，可以通过配置Url的特性参数来控制服务提供者。配置成功后，既可以在服务提供者端生效也可以在服务消费端生效。 if (configuratorUrl.getPort() != 0) &#123; // 配置规则Url有端口，且和待处理的url的端口一致 if (url.getPort() == configuratorUrl.getPort()) &#123; // 因为操作的是服务提供者，所以这里使用的是url的host return configureIfMatch(url.getHost(), url); &#125; // 3 配置规则Url没有端口 &#125; else &#123; // 3.1 如果 url 是消费端地址，目的是控制一个特定的消费者实例，只在消费端生效，服务端收到后忽略 if (url.getParameter(Constants.SIDE_KEY, Constants.PROVIDER).equals(Constants.CONSUMER)) &#123; // NetUtils.getLocalHost() 是消费端注册到注册中心的地址 return configureIfMatch(NetUtils.getLocalHost(), url); // 3.2 如果 url 是服务端地址，意图匹配全部服务提供者。【注意：这种情况暂不支持指定机器服务提供者】 &#125; else if (url.getParameter(Constants.SIDE_KEY, Constants.CONSUMER).equals(Constants.PROVIDER)) &#123; // 对所有服务端生效，因此地址必须是0.0.0.0，否则它将不会执行到此if分支 return configureIfMatch(Constants.ANYHOST_VALUE, url); &#125; &#125; return url; &#125; configure 方法主要的逻辑如下： 对配置规则和传入的URL进行校验，ip 都不能为空。配置规则决定是否应用到目标URL中，要看配置规则的 ip 是否匹配目标URL中的 ip 值。注意，配置规则URL中的 ip 值如果为 0.0.0.0 表示匹配所有 ip 。 对配置规则进行判断，有以下三种情况： 配置规则URL中有 port ，且和待处理的URL的 port 一致。目的是匹配指定的一个服务提供者 ，因此 ip 使用提供者URL中的 host 属性值。 配置规则URL中没有 port，传入的URL是消费端URL。目的是匹配指定的一个消费者，因此 ip 使用 NetUtils.getLocalHost() 的值。 配置规则URL中没有 port，传入的URL是服务端URL。目的是匹配全部提供者，因此 ip 使用 0.0.0.0 。 确定好是对提供者还是消费者后应用配置后，接下来就是对不能动态修改属性的排除工作了，主要逻辑在 configureIfMatch 方法中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556+--- AbstractConfigurator private URL configureIfMatch(String host, URL url) &#123; // 1 匹配 host // 如果配置 url 的 host 为 0.0.0.0，或者配置 url 的 host 等于传入的 host，则继续匹配应用。否则直接返回url if (Constants.ANYHOST_VALUE.equals(configuratorUrl.getHost()) || host.equals(configuratorUrl.getHost())) &#123; // 2 获得配置url中的 application，即应用名 String configApplication = configuratorUrl.getParameter(Constants.APPLICATION_KEY, configuratorUrl.getUsername()); // 3 获得传入 url 的application，即应用名 String currentApplication = url.getParameter(Constants.APPLICATION_KEY, url.getUsername()); //4 匹配应用， 如果配置url的应用名为null，或者为 \"*\"，或者和url的应用名相同，则执行配置规则逻辑。 if (configApplication == null || Constants.ANY_VALUE.equals(configApplication) || configApplication.equals(currentApplication)) &#123; // 5 排除不能动态修改的属性，除了四个内置的，还可以包括 带有\"～\"开头的key、\"application\" 、 \"side\" Set&lt;String&gt; conditionKeys = new HashSet&lt;String&gt;(); // category conditionKeys.add(Constants.CATEGORY_KEY); // check conditionKeys.add(Constants.CHECK_KEY); // dynamic conditionKeys.add(Constants.DYNAMIC_KEY); // enabled conditionKeys.add(Constants.ENABLED_KEY); /** * 遍历配置url的 parameter 参数集合 * 1 把符合要求的条件加入到 conditionKeys 中，即：带有\"～\"开头的key、\"application\" 、 \"side\" * 2 判断传入的url是否匹配配置规则Url的条件，注意是parameter部分比较，并且不是整个parameter集合的比较，只是 \"～\"开头的key 或 \"application\" 或 \"side\" 这个三个key/valu的比较 */ for (Map.Entry&lt;String, String&gt; entry : configuratorUrl.getParameters().entrySet()) &#123; // 参数key String key = entry.getKey(); // 参数key对应的value String value = entry.getValue(); // 如果 配置url的parameter参数的key是： \"～\" 或 \"application\" 或 \"side\"，那么也加入到配置Url的条件集合中，需要剔除，不能参与应用到目标URL if (key.startsWith(\"~\") || Constants.APPLICATION_KEY.equals(key) || Constants.SIDE_KEY.equals(key)) &#123; // 把key加入到条件集合中，用于剔除 conditionKeys.add(key); // 如果目标URL中不存在配置URL中的剔除参数值（以 ～ 开头的参数），则说明url不匹配配置规则，直接返回url if (value != null &amp;&amp; !Constants.ANY_VALUE.equals(value) &amp;&amp; !value.equals(url.getParameter(key.startsWith(\"~\") ? key.substring(1) : key))) &#123; return url; &#125; &#125; &#125; // 从配置Url中排除不能动态修改的属性，然后把剩余的属性配置到URL中 return doConfigure(url, configuratorUrl.removeParameters(conditionKeys)); &#125; &#125; return url; &#125; configureIfMatch 方法主要做了三件事： 通过 ip 判断配置URL是否能够应用到目标URL上，配置URL中的ip支持 0.0.0.0 表示匹配所有ip。 通过 application 应用名判断配置URL是否能够应用到目标URL上，配置URL中的 application 允许为空或 * ，表示匹配所有应用。 剔除配置URL中不能动态修改的属性。 应用配置123456789+--- AbstractConfigurator /** * 将配置规则配置到url中 * * @param currentUrl 目标url * @param configUrl 配置url * @return */ protected abstract URL doConfigure(URL currentUrl, URL configUrl); 应用配置规则是一个抽象方法，具体实现交给具体子类实现。 配置排序12345678910111213141516171819+--- AbstractConfigurator @Override public int compareTo(Configurator o) &#123; if (o == null) &#123; return -1; &#125; // 1 根据 ip 升序 int ipCompare = getUrl().getHost().compareTo(o.getUrl().getHost()); // 2 如果 ip 相同，则按照 priority 降序 if (ipCompare == 0) &#123; int i = getUrl().getParameter(Constants.PRIORITY_KEY, 0), j = o.getUrl().getParameter(Constants.PRIORITY_KEY, 0); return i &lt; j ? -1 : (i == j ? 0 : 1); &#125; else &#123; return ipCompare; &#125; &#125; Configurator 排序首先按照 ip 进行排序，所有 ip 的优先级都高于 0.0.0.0，当 ip 相同时，会按照 priority 参数值进行排序。 OverrideConfigurator1234567891011121314151617public class OverrideConfigurator extends AbstractConfigurator &#123; /** * 构造方法会调用父类的构造方法 * * @param url */ public OverrideConfigurator(URL url) &#123; super(url); &#125; @Override public URL doConfigure(URL currentUrl, URL configUrl) &#123; // 覆盖添加，即直接用配置URL中剩余的全部参数，覆盖原始 URL 中相应参数 return currentUrl.addParameters(configUrl.getParameters()); &#125;&#125; OverrideConfigurator 是一种直接覆盖策略，即直接使用配置URL中剩余的全部参数（在父类中已经剔除了不能动态修改的参数），覆盖原始 URL 中相应参数。 AbsentConfigurator1234567891011121314151617public class AbsentConfigurator extends AbstractConfigurator &#123; /** * 构造方法会调用父类的构造方法 * * @param url */ public AbsentConfigurator(URL url) &#123; super(url); &#125; @Override public URL doConfigure(URL currentUrl, URL configUrl) &#123; // 尝试用配置 URL 中的参数添加到原始 URL 中，如果原始 URL 中已经有了该参数是不会被覆盖的 return currentUrl.addParametersIfAbsent(configUrl.getParameters()); &#125;&#125; AbsentConfigurator 是一种选择性覆盖策略，当目标URL中不存参数时才会使用配置中的参数。 Configurator 集成Dubbo 框架中集成 Configurator 如下： 小结本篇文章介绍了 Dubbo 中配置相关实现。首先对配置协议 override 和 absent URL 进行了介绍，然后分析了 Configurator 覆盖目标 URL 的实现，最后列出了 Dubbo 中对 Configuratgor 的集成代码片段。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"集群容错 - Directory","slug":"rpc/集群容错之Directory","date":"2020-09-18T03:00:00.000Z","updated":"2021-04-20T08:23:40.107Z","comments":false,"path":"posts/e43ac0a6/","link":"","permalink":"https://gentryhuang.com/posts/e43ac0a6/","excerpt":"","text":"概述本篇文章对 Dubbo 集群模块中的 Directory 服务目录进行介绍。服务目录 RegistryDirectory 中存储了一些和服务提供者有关的信息（附加服务治理参数），通过服务目录消费者可获取到服务提供者的信息，比如 ip、端口、服务协议等。服务目录本质上是对注册中心上服务配置信息的整合结果，最终会结合配置信息以及消费端信息组装消费端的 Invoker 。服务目录可以看做是 Invoker 的集合，且这个集合中的元素会随注册中心的变化而进行动态调整。 继承体系服务目录 Directory 继承关系如下图所示： 服务目录内置实现分别为 StaticDirectory 和 RegistryDirectory ，前者用于将传入的 Invoker 集合封装成静态的 Directory 对象，后者是基于注册中心的动态 Directory 对象。下面我们从源码层面上分析服务目录的实现。 源码分析Directory1234567891011121314151617public interface Directory&lt;T&gt; extends Node &#123; /** * 获得服务接口类型，如：com.alibaba.dubbo.demo.DemoService * * @return service type. */ Class&lt;T&gt; getInterface(); /** * 根据传入的 Invocation 请求返回符合条件的 Invoker 集合 * * @return invokers */ List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException;&#125; Directory 接口表示的是一个服务目录，由多个 Invoker 构成，后续的 路由处理、负载均衡、集群容错等都是基于 Directory 实现的。需要注意的是，一个服务目录 Directory 仅对应一个服务类型，管理的是该类型的多个服务。 该接口包含了一个重要的方法定义，即 list(Invocation)，用于列举 Invoker。下面我们对它的抽象实现进行说明。 AbstractDirectoryAbstractDirectory 是 Directory 接口的抽象实现，其中除了维护消费端的 URL 信息，还维护了路由信息。此外，封装了获取 Invoker 列表的流程，具体的逻辑由子类实现。下面我们先来看该抽象实现源码。 属性1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public abstract class AbstractDirectory&lt;T&gt; implements Directory&lt;T&gt; &#123; private static final Logger logger = LoggerFactory.getLogger(AbstractDirectory.class); /** * 注册中心URL */ private final URL url; /** * 是否已经销毁 */ private volatile boolean destroyed = false; /** * 消费者 URL * 注意：如果没有显示调用构造方法，那么该属性的值为 url的值 */ private volatile URL consumerUrl; /** * 路由数组 */ private volatile List&lt;Router&gt; routers; public AbstractDirectory(URL url) &#123; this(url, null); &#125; public AbstractDirectory(URL url, List&lt;Router&gt; routers) &#123; this(url, url, routers); &#125; public AbstractDirectory(URL url, URL consumerUrl, List&lt;Router&gt; routers) &#123; if (url == null) &#123; throw new IllegalArgumentException(\"url == null\"); &#125; // 设置url this.url = url; // 设置consumerUrl this.consumerUrl = consumerUrl; // 设置路由数组 setRouters(routers); &#125;&#125; 构造方法中会维护传入的 注册中心 URL、消费端 URL 以及 设置路由列表。在处理路由时，除了保存传入的路由外，如果配置了路由也会将其加入到路由集合中，下面我们看下其实现。 123456789101112131415161718192021222324+--- AbstractDirectory protected void setRouters(List&lt;Router&gt; routers) &#123; // 1 保存传入的路由集合 routers = routers == null ? new ArrayList&lt;Router&gt;() : new ArrayList&lt;Router&gt;(routers); // 2 从URL中取出配置的路由 String routerkey = url.getParameter(Constants.ROUTER_KEY); // 3 如果配置了路由，则获取对应的路由实现，并加入到 routers集合 中 if (routerkey != null &amp;&amp; routerkey.length() &gt; 0) &#123; RouterFactory routerFactory = ExtensionLoader.getExtensionLoader(RouterFactory.class).getExtension(routerkey); routers.add(routerFactory.getRouter(url)); &#125; // 4 统一添加 MockInvokersSelector 路由 routers.add(new MockInvokersSelector()); // 5 排序 Collections.sort(routers); // 6 放入缓存 this.routers = routers; &#125; 创建服务目录时，会同时维护路由，维护的路由由三部分组成，外部传入的Router + 配置的Router + MockInvokersSelector 。关于路由的介绍会在后面的文章中单独说明，这里不再展开。 拉取 Invoker 集合123456789101112131415161718192021222324252627282930313233343536+--- AbstractDirectory @Override public List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException &#123; // 1 服务目录销毁了就直接抛出异常 if (destroyed) &#123; throw new RpcException(\"Directory already destroyed .url: \" + getUrl()); &#125; // 2 调用 doList 方法获取 Invokers 集合，具体实现交给子类 List&lt;Invoker&lt;T&gt;&gt; invokers = doList(invocation); // 3 使用路由 List&lt;Router&gt; localRouters = this.routers; // 使用路由规则筛选Invoker集合 if (localRouters != null &amp;&amp; !localRouters.isEmpty()) &#123; for (Router router : localRouters) &#123; try &#123; /** * 根据路由的URL值以及 runtime 参数，决定是否进行路由 * 注意： * Router的runtime参数决定是否每次调用服务时都执行路由规则。如果 runtime配置为true，每次调用服务前都需要进行服务路由，这个会对性能会造成影响。 */ if (router.getUrl() == null || router.getUrl().getParameter(Constants.RUNTIME_KEY, false)) &#123; // 使用路由筛选 Invoker invokers = router.route(invokers, getConsumerUrl(), invocation); &#125; &#125; catch (Throwable t) &#123; logger.error(\"Failed to execute router: \" + getUrl() + \", cause: \" + t.getMessage(), t); &#125; &#125; &#125; // 4 返回路由后的结果 return invokers; &#125; AbstractDirectory 拉取 Invoker 列表的主要逻辑如下： 调用子类实现的 doList 方法获取 Invoker 列表。 使用路由，根据 Router 的 getUrl 返回值是否为空，以及 runtime 参数决定是否进行路由过滤。 需要说明的是，Router 的 runtime 参数决定了是否每次调用服务时都要执行路由规则。如果 runtime 为 true，那么每次调用服务前，都需要进行服务路由，这个会对性能造成影响。 StaticDirectoryStaticDirectory 实现中维护的 Invoker 集合是静态的，在 StaticDirectory 对象创建完毕后，是不会发生改变的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788public class StaticDirectory&lt;T&gt; extends AbstractDirectory&lt;T&gt; &#123; /** * Invoker 集合，这个集合中的元素是不变的 */ private final List&lt;Invoker&lt;T&gt;&gt; invokers; public StaticDirectory(List&lt;Invoker&lt;T&gt;&gt; invokers) &#123; this(null, invokers, null); &#125; public StaticDirectory(List&lt;Invoker&lt;T&gt;&gt; invokers, List&lt;Router&gt; routers) &#123; this(null, invokers, routers); &#125; public StaticDirectory(URL url, List&lt;Invoker&lt;T&gt;&gt; invokers) &#123; this(url, invokers, null); &#125; public StaticDirectory(URL url, List&lt;Invoker&lt;T&gt;&gt; invokers, List&lt;Router&gt; routers) &#123; // 确定url有效性 super(url == null &amp;&amp; invokers != null &amp;&amp; !invokers.isEmpty() ? invokers.get(0).getUrl() : url, routers); if (invokers == null || invokers.isEmpty()) &#123; throw new IllegalArgumentException(\"invokers == null\"); &#125; this.invokers = invokers; &#125; /** * 获取接口 * * @return Invoker对应的接口 */ @Override public Class&lt;T&gt; getInterface() &#123; return invokers.get(0).getInterface(); &#125; /** * 检测服务目录是否可用 * * @return */ @Override public boolean isAvailable() &#123; // 若已经销毁，则不可用 if (isDestroyed()) &#123; return false; &#125; // 任意一个Invoker 可用，当前服务目录就可用 for (Invoker&lt;T&gt; invoker : invokers) &#123; if (invoker.isAvailable()) &#123; return true; &#125; &#125; return false; &#125; @Override public void destroy() &#123; // 已销毁，则跳过 if (isDestroyed()) &#123; return; &#125; // 销毁 super.destroy(); // 销毁每个 Invoker for (Invoker&lt;T&gt; invoker : invokers) &#123; invoker.destroy(); &#125; // 清空Invoker 集合 invokers.clear(); &#125; /** * 直接返回由构造方法传入进来的Invoker 集合 * * @param invocation * @return * @throws RpcException */ @Override protected List&lt;Invoker&lt;T&gt;&gt; doList(Invocation invocation) throws RpcException &#123; return invokers; &#125;&#125; RegistryDirectoryRegistryDirectory 是一个动态的 Directory 实现，实现了 NotifyListener 接口，订阅注册中心的数据，实现监听功能。当注册中心的服务配置发生变更时，会触发回调 NotifyListener.notify 方法，RegistryDirectory 收到变更通知后会根据注册中心推送的通知，重新引用服务，即 刷新 Invoker 列表。该实现类为了让本地服务目录和注册中心的服务信息保持一致做了很多的工作，下文我们一一分析。 属性1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192public class RegistryDirectory&lt;T&gt; extends AbstractDirectory&lt;T&gt; implements NotifyListener &#123; private static final Logger logger = LoggerFactory.getLogger(RegistryDirectory.class); /** * 集群扩展实现 Cluster$Adaptive 对象 - 对同组 Invoker 进行合并 */ private static final Cluster cluster = ExtensionLoader.getExtensionLoader(Cluster.class).getAdaptiveExtension(); /** * 路由工厂扩展实现 RouterFactory$Adaptive对象 - 创建路由 */ private static final RouterFactory routerFactory = ExtensionLoader.getExtensionLoader(RouterFactory.class).getAdaptiveExtension(); /** * 配置规则工厂实现 ConfiguratorFactory$Adaptive 对象 - 创建配置对象 */ private static final ConfiguratorFactory configuratorFactory = ExtensionLoader.getExtensionLoader(ConfiguratorFactory.class).getAdaptiveExtension(); /** * 注册中心URL的服务键， 如：com.alibaba.dubbo.registry.RegistryService */ private final String serviceKey; /** * 服务接口类型，如：com.alibaba.dubbo.demo.DemoService * 每一个服务引用都对应一个服务目录 */ private final Class&lt;T&gt; serviceType; /** * 服务消费者 URL 的配置项 Map。即 Consumer URL 中 refer 参数解析后得到的全部 KV */ private final Map&lt;String, String&gt; queryMap; /** * 只保留 Consumer 属性的 URL，也就是由 queryMap 集合重新生成的 URL，URL 主体仍然是注册中心的 URL信息。 */ private final URL directoryUrl; /** * 引用的服务接口方法数组 */ private final String[] serviceMethods; /** * 是否引用多个服务分组 - 服务分组概念 */ private final boolean multiGroup; /** * 注册中心的Protocol 对象 */ private Protocol protocol; /** * 注册中心 */ private Registry registry; /** * 是否禁止访问： * 1 当没有服务提供者 * 2 当服务提供者被禁用 */ private volatile boolean forbidden = false; /** * 结合配置规则，重写原始目录URL得到的 */ private volatile URL overrideDirectoryUrl; /** * 配置规则数组 * override rules * Priority: override&gt;-D&gt;consumer&gt;provider * Rule one: for a certain provider &lt;ip:port,timeout=100&gt; * Rule two: for all providers &lt;* ,timeout=5000&gt; */ private volatile List&lt;Configurator&gt; configurators; /** * &lt;服务提供者URL合并处理后的URL串,服务引用创建的Invoker&gt; * Map&lt;url, Invoker&gt; cache service url to invoker mapping. */ private volatile Map&lt;String, Invoker&lt;T&gt;&gt; urlInvokerMap; /** * 方法名与引用Invoker集合的映射 * Map&lt;methodName, Invoker&gt; cache service method to invokers mapping. */ private volatile Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; methodInvokerMap; /** * 当前缓存的所有 Provider 的 URL * Set&lt;invokerUrls&gt; cache invokeUrls to invokers mapping. */ private volatile Set&lt;URL&gt; cachedInvokerUrls;&#125; 构造方法123456789101112131415161718192021222324252627282930313233343536373839+--- RegistryDirectory /** * 构造方法，根据注册中心URL初始化相关属性 * * @param serviceType 服务接口类型 * @param url 注册中心 URL */ public RegistryDirectory(Class&lt;T&gt; serviceType, URL url) &#123; // 调用父类构造方法 super(url); // 如果服务类型为空，抛出异常 if (serviceType == null) &#123; throw new IllegalArgumentException(\"service type is null.\"); &#125; // Url对应的服务键为空，抛出异常 if (url.getServiceKey() == null || url.getServiceKey().length() == 0) &#123; throw new IllegalArgumentException(\"registry serviceKey is null.\"); &#125; // 设置服务类型 和 注册中心URL的服务键 this.serviceType = serviceType; this.serviceKey = url.getServiceKey(); // 设置服务消费者 URL 的配置项 Map，即解析 refer 参数值，得到 Consumer 的配置参数 parameters 的值 this.queryMap = StringUtils.parseQueryString(url.getParameterAndDecoded(Constants.REFER_KEY)); // 构造的时候，this.overrideDirectoryUrl == this.directoryUrl // 将 queryMap 中的 KV 作为参数，重新构造 URL，URL主体不变 this.overrideDirectoryUrl = this.directoryUrl = url.setPath(url.getServiceInterface()).clearParameters().addParameters(queryMap).removeParameter(Constants.MONITOR_KEY); // 从消费者配置项中获取分组参数 String group = directoryUrl.getParameter(Constants.GROUP_KEY, \"\"); // 设置多分组标识 this.multiGroup = group != null &amp;&amp; (\"*\".equals(group) || group.contains(\",\")); // 从消费者配置项中获取服务方法串 String methods = queryMap.get(Constants.METHODS_KEY); // 设置引用服务接口中的方法数组 this.serviceMethods = methods == null ? null : Constants.COMMA_SPLIT_PATTERN.split(methods); &#125; RegistryDirectory 中的部分属性会根据注册中心URL初始化。下面对较为重要的属性进行说明： this.queryMap: Consumer 端的 URL 的参数配置项 parameters 的值 this.directoryUrl: 传入的注册中心 URL 的主干部分 + Consumer 端的 URL 的 parameters（this.queryMap） this.overrideDirectoryUrl 初始值为 this.directoryUrl，在接收注册中心目录（某个服务接口下的目录，其中一服务接口对应一个服务目录）变更通知时会先结合配置规则 Configurator 重写 this.directoryUrl，然后再将服务端URL合并后的URL参数配置项选择性的合并（提供方的参数配置项优先级最低）。 InvokerDelegateInvokerDelegate 是 RegistryDirectory 的内部类，继承了 InvokerWrapper 这个 Invoker 的包装类。这个代理类主要用于存储注册中心下发的服务提供者的URL以及服务引用创建的 Invoker 。 123456789101112131415161718192021+--- RegistryDirectory private static class InvokerDelegate&lt;T&gt; extends InvokerWrapper&lt;T&gt; &#123; /** * 服务提供者URL，注意：这是未经过配置合并的URL */ private URL providerUrl; /** * @param invoker Protocol.refer 引用的 Invoker * @param url 合并后的 URL * @param providerUrl 服务提供者URL */ public InvokerDelegate(Invoker&lt;T&gt; invoker, URL url, URL providerUrl) &#123; super(invoker, url); this.providerUrl = providerUrl; &#125; public URL getProviderUrl() &#123; return providerUrl; &#125; &#125; 拉取 Invoker拉取 Invoker 逻辑封装在 doList 方法中，是父类 AbstractDirectory 的模版方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950+--- RegistryDirectory @Override public List&lt;Invoker&lt;T&gt;&gt; doList(Invocation invocation) &#123; // 1 检测forbidden字段，当该字段在 refreshInvoker() 过程中设置为true时，表示无 Provider 可用，直接抛出异常 if (forbidden) &#123; // 1. No service provider 2. Service providers are disabled throw new RpcException(RpcException.FORBIDDEN_EXCEPTION, \"No provider available from registry \" + getUrl().getAddress() + \" for service \" + getConsumerUrl().getServiceKey() + \" on consumer \" + NetUtils.getLocalHost() + \" use dubbo version \" + Version.getVersion() + \", please check status of providers(disabled, not registered or in blacklist).\"); &#125; List&lt;Invoker&lt;T&gt;&gt; invokers = null; // 2 获取Invoker本地缓存 （服务引用的过程 methodInvokerMap 中的值已经有了，并且该值会随着订阅的服务而变化） Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; localMethodInvokerMap = this.methodInvokerMap; // 3 从 Invoker 本地缓存信息中选出目标 Invoker 集合 if (localMethodInvokerMap != null &amp;&amp; localMethodInvokerMap.size() &gt; 0) &#123; // 获得调用的方法名和方法参数列表 String methodName = RpcUtils.getMethodName(invocation); Object[] args = RpcUtils.getArguments(invocation); if (args != null &amp;&amp; args.length &gt; 0 &amp;&amp; args[0] != null &amp;&amp; (args[0] instanceof String || args[0].getClass().isEnum())) &#123; // 3.1 根据第一个参数和本身的方法名拼接确定最后的方法名，然后获得Invoker集合。 invokers = localMethodInvokerMap.get(methodName + args[0]); // The routing can be enumerated according to the first parameter &#125; if (invokers == null) &#123; // 3.2 根据方法名获得 Invoker 集合，一般会成功 invokers = localMethodInvokerMap.get(methodName); &#125; if (invokers == null) &#123; // 3.3 通过通配符 * 获取 Invoker 集合，如 回声探测方法 invokers = localMethodInvokerMap.get(Constants.ANY_VALUE); &#125; if (invokers == null) &#123; //4 使用 methodInvokerMap 第一个Invoker。防御性编程。 Iterator&lt;List&lt;Invoker&lt;T&gt;&gt;&gt; iterator = localMethodInvokerMap.values().iterator(); if (iterator.hasNext()) &#123; invokers = iterator.next(); &#125; &#125; &#125; // 4 返回目标Invoker集合 return invokers == null ? new ArrayList&lt;Invoker&lt;T&gt;&gt;(0) : invokers; &#125; 以上方法用于从 RegistryDirectory 的 Invoker 缓存中获取本次调用的消费端 Invoker 列表。其中获取的方式有以下 4 种： 根据调用的方法名 + 参数值确定最终的调用方法名。使用例子如下：12345678910// 接口定义public interface DemoService &#123; void hello(String name); void hello01(String name);&#125;// 消费方调用DemoService demoService = (DemoService) context.getBean(\"demoService\");// 最终调用到的是 DemoService 中的 hello01 方法demoService.hello(\"01\"); 根据调用方法名获取 Invoker 集合。 使用全量 Invoker 集合。 基于防御性编程，使用第一个 Invoker 集合。 以上方法可以看作是对 RegistryDirectory 中 Invoker 缓存的读操作，写操作是在收到通知的时候完成的，后续会详细分析。 订阅1234567+--- RegistryDirectory public void subscribe(URL url) &#123; // 设置服务消费者URL setConsumerUrl(url); // 向注册中心发起订阅 registry.subscribe(url, this); &#125; 该方法会在消费端进行订阅时被调用，通过调用 Registry 的 subscribe 方法完成订阅，同时还会将当前 RegistryDirectory 以 NotifyListener 监听器形式添加到 Registry 上。 消费端订阅触发时机是在服务引用过程，具体源码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546+--- RegistryProtocol /** * 执行服务引用，返回Invoker对象 * * @param cluster Cluster 对象 * @param registry 注册中心对象 * @param type 服务接口类型 * @param url 注册中心URL * @param &lt;T&gt; 泛型 * @return Invoker 对象 */ private &lt;T&gt; Invoker&lt;T&gt; doRefer(Cluster cluster, Registry registry, Class&lt;T&gt; type, URL url) &#123; // 1 创建RegistryDirectory对象【服务目录】，并设置注册中心到它的属性，该对象包含了注册中心的所有服务提供者 List&lt;Invoker&gt; RegistryDirectory&lt;T&gt; directory = new RegistryDirectory&lt;T&gt;(type, url); // 1.1 设置注册中心和协议 directory.setRegistry(registry); directory.setProtocol(protocol); // 2 获得服务引用配置集合parameters。注意：url传入RegistryDirectory后，经过处理并重新创建，所以 url != directory.url， Map&lt;String, String&gt; parameters = new HashMap&lt;String, String&gt;(directory.getUrl().getParameters()); // 3 生成消费者URL URL subscribeUrl = new URL(Constants.CONSUMER_PROTOCOL, parameters.remove(Constants.REGISTER_IP_KEY), 0, type.getName(), parameters); // 4 注册服务消费者，在consumers目录下 if (!Constants.ANY_VALUE.equals(url.getServiceInterface()) &amp;&amp; url.getParameter(Constants.REGISTER_KEY, true)) &#123; registry.register(subscribeUrl.addParameters(Constants.CATEGORY_KEY, Constants.CONSUMERS_CATEGORY, Constants.CHECK_KEY, String.valueOf(false))); &#125; // 5 向注册中心订阅 服务提供者 + 路由规则 + 配置规则 节点下的数据 directory.subscribe(subscribeUrl.addParameter(Constants.CATEGORY_KEY, Constants.PROVIDERS_CATEGORY + \",\" + Constants.CONFIGURATORS_CATEGORY + \",\" + Constants.ROUTERS_CATEGORY)); // 6 基于 RegistryDirectory 创建 Invoker 对象 Invoker invoker = cluster.join(directory); // 向本地注册表，注册消费者 ProviderConsumerRegTable.registerConsumer(invoker, url, subscribeUrl, directory); return invoker; &#125; 消费端在服务引用过程会进行服务订阅，当监听的节点发生变更时，注册中心会将节点下的数据以 全量 形式通知给订阅方，也就是对应的 NotifyListener 们。关于订阅通知可以参考 订阅通知 。下面粘贴注册中心模块通知逻辑代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public abstract class AbstractRegistry implements Registry &#123; // $&#123;省略其他代码&#125; /* * 订阅URL映射的节点对应的子节点发生变化时，通知监听器 * @param url 订阅URL * @param listener 订阅ULR对应的监听器 * @param urls 订阅URL映射的路径下的子路径集合（全量数据） */ protected void notify(URL url, NotifyListener listener, List&lt;URL&gt; urls) &#123; if (url == null) &#123; throw new IllegalArgumentException(\"notify url == null\"); &#125; if (listener == null) &#123; throw new IllegalArgumentException(\"notify listener == null\"); &#125; if ((urls == null || urls.isEmpty()) &amp;&amp; !Constants.ANY_VALUE.equals(url.getServiceInterface())) &#123; logger.warn(\"Ignore empty notify urls for subscribe url \" + url); return; &#125; if (logger.isInfoEnabled()) &#123; logger.info(\"Notify urls for subscribe url \" + url + \", urls: \" + urls); &#125; // 1 将 `urls` 按照 URL中的 'category` 参数进行分类，添加到Map集合result中 Map&lt;String, List&lt;URL&gt;&gt; result = new HashMap&lt;String, List&lt;URL&gt;&gt;(); // 遍历 for (URL u : urls) &#123; // 子路径URL是否匹配订阅URL if (UrlUtils.isMatch(url, u)) &#123; // 获取分类，默认为 providers String category = u.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY); // 加入到结果集 List&lt;URL&gt; categoryList = result.get(category); if (categoryList == null) &#123; categoryList = new ArrayList&lt;URL&gt;(); result.put(category, categoryList); &#125; categoryList.add(u); &#125; &#125; if (result.size() == 0) &#123; return; &#125; // 获得订阅URL对应的缓存`notified`,即通知的 URL 变化结果（全量数据），会把result中的值放入到 categoryNotified中 Map&lt;String, List&lt;URL&gt;&gt; categoryNotified = notified.get(url); if (categoryNotified == null) &#123; notified.putIfAbsent(url, new ConcurrentHashMap&lt;String, List&lt;URL&gt;&gt;()); categoryNotified = notified.get(url); &#125; // 处理通知的 URL 变化结果（全量数据），即按照分类，循环处理通知的URL变化结果（全量数据） for (Map.Entry&lt;String, List&lt;URL&gt;&gt; entry : result.entrySet()) &#123; // 获得分类名 String category = entry.getKey(); // 获得分类名对应的通知ULR列表 List&lt;URL&gt; categoryList = entry.getValue(); // 1 将result 覆盖到 `notified`缓存【更新notified集合中的通知ULR列表】，需要注意：当某个分类的数据为空时，会依然有URL，如 empty://...` ，通过这种方式统一处理所有订阅URL对应的数据为空的情况。 categoryNotified.put(category, categoryList); // 2 保存订阅url对应的被通知的URL到 properties和文件 中 // 在循环中的保存的原因是，订阅url对应的通知url可能是变动的，上一步的操作会更新notified集合，为了让 properties和文件中的 订阅-通知关系正确就需要不断更新。 saveProperties(url); // 3 调用传入的listener的notify()方法 listener.notify(categoryList); &#125; &#125; // $&#123;省略其他代码&#125; 因为 RegistryDirectory 作为一个 NotifyListener 向注册中心 Registry 发起了订阅，因此会收到通知。由通知代码逻辑可知，是按照分类循环通知的，也就说可能订阅的分类有多个，但是每次通知只有一类 URL 。 通知RegistryDirectory 是一个动态服务目录，它需要监听注册中心上的相关数据变更进而动态调整，因此实现了 NotifyListener 接口，通过该接口获取注册中心变更通知。下面我们来看具体实现。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960+--- RegistryDirectory @Override public synchronized void notify(List&lt;URL&gt; urls) &#123; // 1 根据URL的分类，分成三个类别：1 服务提供者URL 2 路由URL 3 配置URL List&lt;URL&gt; invokerUrls = new ArrayList&lt;URL&gt;(); List&lt;URL&gt; routerUrls = new ArrayList&lt;URL&gt;(); List&lt;URL&gt; configuratorUrls = new ArrayList&lt;URL&gt;(); // 2 遍历 urls，进行分类 for (URL url : urls) &#123; // 2.1 获取协议 String protocol = url.getProtocol(); // 2.2 获取 category 参数的值，默认是 providers String category = url.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY); // 2.3 根据 category 参数将 url 分别放到不同的列表中 // 2.3.1 符合路由规则 if (Constants.ROUTERS_CATEGORY.equals(category) || Constants.ROUTE_PROTOCOL.equals(protocol)) &#123; routerUrls.add(url); // 2.3.2 符合配置规则 &#125; else if (Constants.CONFIGURATORS_CATEGORY.equals(category) || Constants.OVERRIDE_PROTOCOL.equals(protocol)) &#123; configuratorUrls.add(url); // 2.3.3 符合服务提供者 &#125; else if (Constants.PROVIDERS_CATEGORY.equals(category)) &#123; invokerUrls.add(url); &#125; else &#123; logger.warn(\"Unsupported category \" + category + \" in notified url: \" + url + \" from registry \" + getUrl().getAddress() + \" to consumer \" + NetUtils.getLocalHost()); &#125; &#125; // 3 configurators 下的数据变更，则将配置规则URL集合转换成对应的 Configurator 集合 if (configuratorUrls != null &amp;&amp; !configuratorUrls.isEmpty()) &#123; this.configurators = toConfigurators(configuratorUrls); &#125; // 4 routers 下的数据变更，则将路由URL集合转换成对应的Router集合 if (routerUrls != null &amp;&amp; !routerUrls.isEmpty()) &#123; List&lt;Router&gt; routers = toRouters(routerUrls); // 如果处理得到的Router非空，调用父类的#setRouters方法，设置路由规则。 if (routers != null) &#123; setRouters(routers); &#125; &#125; // 5 合并配置规则到 directoryUrl, 形成 overrideDirectoryUrl 变量 List&lt;Configurator&gt; localConfigurators = this.configurators; this.overrideDirectoryUrl = directoryUrl; if (localConfigurators != null &amp;&amp; !localConfigurators.isEmpty()) &#123; for (Configurator configurator : localConfigurators) &#123; // 使用配置规则器 将 配置规则应用到 overrideDirectoryUrl this.overrideDirectoryUrl = configurator.configure(overrideDirectoryUrl); &#125; &#125; // 6 刷新Invoker列表 refreshInvoker(invokerUrls); &#125; 通过前面的介绍我们知道，在服务引用的过程中会创建 RegistryDirectory 对象，一方面做为 NotifyListener 监听注册中心的 providers、configurators 和 routers 三个目录，所以在这三个目录下发生变化的时候，就会触发 RegistryDirectory 的 notify 方法。另一方面作为消费端的 Invoker 源供集群策略使用。在该方法中，首先会按照 category 参数 对变更的 URL 进行分类，并分别对不同类型的 URL 进行处理： 将 router 类型的 URL 转化为 Router ，并保存到服务目录中。 将 configurators 类型的 URL 转化为 Configurator ，并保存到服务目录中。 将 provider 类型的 URL 转化为 Invoker ，并保存到服务目录中，该过程是最核心的逻辑。 RegistryDirectory 中有很多核心属性，它们的更新主要在注册中心通知的过程，Dubbo 使用了 synchronized 锁来处理线程安全问题。 其中在将 configurators 类型 URL 转为 Configurator 后，还会将配置规则应用在 overrideDirectoryUrl 。下面我们对以上 3 个关键流程进行分析。 转换 Configurator123456789101112131415161718192021222324252627282930313233343536+--- RegistryDirectorypublic static List&lt;Configurator&gt; toConfigurators(List&lt;URL&gt; urls) &#123; // 1 配置规则URL集合为空，表示不使用配置规则 if (urls == null || urls.isEmpty()) &#123; return Collections.emptyList(); &#125; // 2 遍历配置规则 URL ，创建Configurator 配置规则 List&lt;Configurator&gt; configurators = new ArrayList&lt;Configurator&gt;(urls.size()); for (URL url : urls) &#123; // 2.1 如果协议为 empty:// ，会清空所有配置规则，返回空集合 if (Constants.EMPTY_PROTOCOL.equals(url.getProtocol())) &#123; configurators.clear(); break; &#125; // 2.2 获取配置规则URL的key-value参数集合 Map&lt;String, String&gt; override = new HashMap&lt;String, String&gt;(url.getParameters()); // 2.3 override 上的 anyhost 可能是自动添加的，为了防止影响下面的判断，需要先删除掉 override.remove(Constants.ANYHOST_KEY); // 2.4 如果配置Url参数部分为空，会清空所有配置规则 if (override.size() == 0) &#123; configurators.clear(); continue; &#125; // 2.5 由工厂创建Configurator 对象，并添加到 configurators 集合中 configurators.add(configuratorFactory.getConfigurator(url)); &#125; // 对多个配置规则对象排序 Collections.sort(configurators); return configurators; &#125; 以上方法用于将配置规则 URL 转换成对应的配置规则 Configurator 对象，用于实现服务治理功能。配置规则 URL 可能值如下： override://0.0.0.0/…( or override://ip:port…?anyhost=true)&amp;para1=value1… means global rules (all of the providers take effect) ## 表示全局规则（对所有的提供者全部生效） override://ip:port…?anyhost=false Special rules (only for a certain provider) ## 特殊规则（只针对某个提供者生效） override:// rule is not supported… ,needs to be calculated by registry itself. ## 不支持override:// 规则，需要注册中心自行计算 override://0.0.0.0/ without parameters means clearing the override ## 不带参数,表示清除override 转换 Router12345678910111213141516171819202122232425262728293031323334353637+--- RegistryDirectory private List&lt;Router&gt; toRouters(List&lt;URL&gt; urls) &#123; List&lt;Router&gt; routers = new ArrayList&lt;Router&gt;(); // 1 路由规则 URL集合判空 if (urls == null || urls.isEmpty()) &#123; return routers; &#125; // 2 遍历路由规则 URL if (urls != null &amp;&amp; !urls.isEmpty()) &#123; for (URL url : urls) &#123; // 2.1 如果是 empty:// ，则忽略。 // 一般情况下，当所有路由规则被删除时，有且仅有一条协议为 empty:// 的路由规则 URL if (Constants.EMPTY_PROTOCOL.equals(url.getProtocol())) &#123; continue; &#125; // 2.2 获取配置的 router 配置项，如果有设置则使用设置的配置项 String routerType = url.getParameter(Constants.ROUTER_KEY); if (routerType != null &amp;&amp; routerType.length() &gt; 0) &#123; url = url.setProtocol(routerType); &#125; try &#123; // 2.3 通过路由工厂创建 Router Router router = routerFactory.getRouter(url); if (!routers.contains(router)) &#123; routers.add(router); &#125; &#125; catch (Throwable t) &#123; logger.error(\"convert router url to router error, url: \" + url, t); &#125; &#125; &#125; return routers; &#125; 以上方法用于将路由规则 URL 转换成对应路由规则 Router 对象，用于过滤服务目录中的服务集合。 刷新 Invoker 列表刷新 Invoker 列表是为了保证服务目录随注册中心变化而变化，使消费端的 Invoker 是最新的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970+--- RegistryDirectory// invokerUrls 是 .../providers 路径下的子路径列表，全量数据private void refreshInvoker(List&lt;URL&gt; invokerUrls) &#123; // 1 所有服务不可用 // 当 invokerUrls 集合大小为1，并且协议是 empty://，说明所有的服务都已经下线了，即禁用所有服务。Zookeeper 册中心可参见 &#123;@link ZookeeperRegistry#toUrlsWithEmpty&#125; if (invokerUrls != null &amp;&amp; invokerUrls.size() == 1 &amp;&amp; invokerUrls.get(0) != null &amp;&amp; Constants.EMPTY_PROTOCOL.equals(invokerUrls.get(0).getProtocol())) &#123; // 1.1 设置禁止访问，后续请求将直接抛出异常 this.forbidden = true; // 1.2 置空 方法名与Invoker集合映射 methodInvokerMap this.methodInvokerMap = null; // 1.3 清空 Invoker 缓存，销毁所有的 Invoker destroyAllInvokers(); // 2 存在可用服务 &#125; else &#123; // 2.1 设置允许访问 this.forbidden = false; // 2.2 保存旧的 urlInvokerMap，为后续逻辑是否存在无效的 invoker 作为判断依据。 Map&lt;String, Invoker&lt;T&gt;&gt; oldUrlInvokerMap = this.urlInvokerMap; // 2.3 传入的 invokerUrls 为空说明 注册中心中的 providers 目录未发生变化， // 是路由规则或者配置规则发生改变。那么直接使用缓存的服务提供者 Invoker 的URL集合 if (invokerUrls.isEmpty() &amp;&amp; this.cachedInvokerUrls != null) &#123; invokerUrls.addAll(this.cachedInvokerUrls); // 2.4 传入的 invokerUrls 非空，说明注册中心中的 providers 目录发生了改变，即服务提供者发生了改变（第一次全量拉取数据也是一种改变，从无到有） // 则使用传入的 invokerUrls 更新 cachedInvokerUrls &#125; else &#123; this.cachedInvokerUrls = new HashSet&lt;URL&gt;(); //缓存invokerUrls列表，便于交叉对比 this.cachedInvokerUrls.addAll(invokerUrls); &#125; // 2.4 invokerUrls 为空则直接忽略（例如：初始是按照 configurators =&gt; routers =&gt; providers ，那么前两个会出现为空的情况） if (invokerUrls.isEmpty()) &#123; return; &#125; // 2.5 将变更的URL列表转成 URL串 到 Invoker 的映射 (最核心的方法) Map&lt;String, Invoker&lt;T&gt;&gt; newUrlInvokerMap = toInvokers(invokerUrls);// Translate url list to Invoker map // 2.6 将上一步得到的 newUrlInvokerMap 转换成 方法名到Invoker列表的映射 Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; newMethodInvokerMap = toMethodInvokers(newUrlInvokerMap); // Change method name to map Invoker Map // 2.7 如果转换错误，则忽略本次转换 if (newUrlInvokerMap == null || newUrlInvokerMap.size() == 0) &#123; logger.error(new IllegalStateException(\"urls to invokers error .invokerUrls.size :\" + invokerUrls.size() + \", invoker.size :0. urls :\" + invokerUrls.toString())); return; &#125; // 2.8 如果引用多个服务分组，那么就按照 method + group 维度合并Invoker this.methodInvokerMap = multiGroup ? toMergeMethodInvokerMap(newMethodInvokerMap) : newMethodInvokerMap; // 2.9 保存 URL串 到 Invoker 的映射 this.urlInvokerMap = newUrlInvokerMap; try &#123; // 2.10 比较新旧两组 Invoker 集合，销毁已经下线的 Invoker 集合，避免服务消费方调用已经下线的服务 destroyUnusedInvokers(oldUrlInvokerMap, newUrlInvokerMap); // Close the unused Invoker &#125; catch (Exception e) &#123; logger.warn(\"destroyUnusedInvokers error. \", e); &#125; &#125; &#125; 服务目录转换服务提供者URL -&gt; Invoker 的规则如下： 如果 URL 已经转换为 Invoker，则不再重新引用，直接从缓存中获取。需要注意的是，如果 URL 中任何一个参数变更都会重新引用。 如果传入的服务提供者URL列表大小为 1 且协议是 empty://，说明所有的服务都已经下线，要禁用所有服务。 如多传入的服务提供者URL列表为空，则表示只是下发配置规则和路由规则。 注意，上面规则中提到的 URL 并非是服务提供者URL，而是合并后的服务提供者URL，关于合并规则下文会详细说明。 刷新 Invoker 列表的逻辑如下： 根据入参 invokerUrls 的数量和协议判断是否禁用所有服务，如果禁用则将禁用标志 forbidden 设置为 true ，并销毁引用所有的 Invoker 。 非禁用，则将 invokerUrls 中的 URL 进行合并操作，然后转换成 Invoker（引用 Invoker），得到新的 &lt;url串,Invoker&gt; 的映射关系。 将第 2 步中得到的 &lt;url串,Invoker&gt; 进一步转成 &lt;methodName,Invoker列表&gt; 。 如果消费方引用多个服务分组，则根据 method + group 进行多组合并操作，同样得到 &lt;methodName,Invoker列表&gt; 数据，doList 方法中读取的就是该数据，而这里是写操作。 新的消费端 Invoker 列表生成后，根据第 2 步得到的 &lt;url串,Invoker&gt; ，同旧的 &lt;url串,Invoker&gt; 对比，销毁无用的 Invoker，避免服务消费者调用已经下线的服务。 刷新 Invoker 逻辑中会变更两个核心的属性：urlInvokerMap 和 methodInvokerMap ，前者以URL维度后者以方法名维度，前者用于判断是否需要重新引用服务，后者用于存储引用的Invoker集合供 doList 方法拉取。 接下来我们对上面涉及到的核心步骤进行分析。 转换 Invoker123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104+--- RegistryDirectory private Map&lt;String, Invoker&lt;T&gt;&gt; toInvokers(List&lt;URL&gt; urls) &#123; // &lt;URL串,Invoker&gt; Map&lt;String, Invoker&lt;T&gt;&gt; newUrlInvokerMap = new HashMap&lt;String, Invoker&lt;T&gt;&gt;(); // 若为空直接返回 if (urls == null || urls.isEmpty()) &#123; return newUrlInvokerMap; &#125; // 1 记录已初始化的服务提供者URL串，即已经处理过的服务提供者URL Set&lt;String&gt; keys = new HashSet&lt;String&gt;(); // 2 获取消费者配置的协议 (一般情况下，我们不在消费端 &lt;dubbo:reference protocol=\"\"/&gt; 配置服务协议) String queryProtocols = this.queryMap.get(Constants.PROTOCOL_KEY); // 3 循环遍历变更的提供者URL集合 for (URL providerUrl : urls) &#123; // 4 对消费端配置协议的处理逻辑 // 4.1 如果消费端配置了协议，则只选择和消费端匹配的协议 if (queryProtocols != null &amp;&amp; queryProtocols.length() &gt; 0) &#123; boolean accept = false; // 可能配置了多协议 String[] acceptProtocols = queryProtocols.split(\",\"); // 4.2 根据消费方protocol过滤不匹配协议，因为Dubbo允许在消费方配置只消费指定协议的服务 for (String acceptProtocol : acceptProtocols) &#123; if (providerUrl.getProtocol().equals(acceptProtocol)) &#123; accept = true; break; &#125; &#125; // 4.3 如果当前URL不支持Consumer端的协议，也就无法执行后续转换成Invoker的逻辑 if (!accept) &#123; continue; &#125; &#125; // 5 跳过 empty:// 协议的 URL if (Constants.EMPTY_PROTOCOL.equals(providerUrl.getProtocol())) &#123; continue; &#125; // 6 如果消费端不支持变更的服务端的协议，则忽略 if (!ExtensionLoader.getExtensionLoader(Protocol.class).hasExtension(providerUrl.getProtocol())) &#123; logger.error(new IllegalStateException(\"Unsupported protocol \" + providerUrl.getProtocol() + \" in notified url: \" + providerUrl + \" from registry \" + getUrl().getAddress() + \" to consumer \" + NetUtils.getLocalHost() + \", supported protocol: \" + ExtensionLoader.getExtensionLoader(Protocol.class).getSupportedExtensions())); continue; &#125; // 7 合并URL数据，即将配置规则，消费端配置参数合并到服务提供者URl中 // 注意服务提供者URL的主体信息不变，合并的只是参数部分 URL url = mergeUrl(providerUrl); // 8 URL字符串，该字符串是服务提供者URL合并处理后的，作为是否需要重新引用的标志 String key = url.toFullString(); // 9 跳过重复的 URL，防止重复引用 if (keys.contains(key)) &#123; continue; &#125; // 加入到 keys 集合中，为了防止重复 keys.add(key); // 10 判断 key 是否已经引用过，引用过则无需重新引用，直接使用对应的缓存即可 // 如果没有引用过，则通过 Protocol.refer 方法引用服务，创建 Invoker Map&lt;String, Invoker&lt;T&gt;&gt; localUrlInvokerMap = this.urlInvokerMap; Invoker&lt;T&gt; invoker = localUrlInvokerMap == null ? null : localUrlInvokerMap.get(key); // 没有引用过 if (invoker == null) &#123; try &#123; // 通过获取配置项 enable 和 disable 的值判断服务是否开启 boolean enabled = true; if (url.hasParameter(Constants.DISABLED_KEY)) &#123; enabled = !url.getParameter(Constants.DISABLED_KEY, false); &#125; else &#123; enabled = url.getParameter(Constants.ENABLED_KEY, true); &#125; // 如果开启，则创建 Invoker 对象 if (enabled) &#123; // 通过 Protocol.refer 方法创建对应的 Invoker 对象，并使用 InvokerDelegate 装饰引用的 Invoker invoker = new InvokerDelegate&lt;T&gt;(protocol.refer(serviceType, url), url, providerUrl); &#125; &#125; catch (Throwable t) &#123; logger.error(\"Failed to refer invoker for interface:\" + serviceType + \",url:(\" + url + \")\" + t.getMessage(), t); &#125; // 将key和Invoker对象之间的映射关系记录到newUrlInvokerMap中 if (invoker != null) &#123; newUrlInvokerMap.put(key, invoker); &#125; // 缓存命中，直接使用缓存的 Invoker &#125; else &#123; newUrlInvokerMap.put(key, invoker); &#125; &#125; // 11 清空keys标记集合 keys.clear(); // 12 返回新的消费端 Invoker return newUrlInvokerMap; &#125; 转换 Invoker 方法用于将服务提供者URL最终转为Invoker，即使用protocol.refer方法进行服务引用，也就是一条服务提供者URL对应一个消费端Invoker。主要核心逻辑如下： 对服务提供者 URL 进行检测，若服务消费端的配置不支持服务端的协议，或服务端 URL 协议头为 empty 时，则忽略服务提供方 URL。 合并 URL ，即将配置规则和消费端配置参数合并到服务提供者URL中。 根据合并后的 URL 访问缓存，尝试获取与 URL 对应的 Invoker。缓存未命中，则通过 Protocol.refer 进行服务引用，并将创建的 Invoker 进行缓存。 toInvokers() 方法的核心逻辑就是调用 Protocol.refer() 方法创建 Invoker 对象，其他的逻辑都是在判断是否调用该方法以及调用该方法前的准备工作。下面我们对 URL 参数合并逻辑简单介绍。 123456789101112131415161718192021222324252627282930+--- RegistryDirectory private URL mergeUrl(URL providerUrl) &#123; // 1 将消费端URL参数配置项合并到服务提供者的URL中 // 1.1 移除 Provider URL 中只在 Provider 端生效的属性，如：threadname、threadpool、corethreads、threads、queues、alive、transporter // 1.2 用 Consumer 端的参数配置（parameters）覆盖 Provider URL 的相应配置，但：version、group、methods、timestamp等参数以Provider端的配置优先，因为它们是远程配置的参数。 // 1.3 合并 Provider 端和 Consumer 端配置的 Filter 以及 Listener providerUrl = ClusterUtils.mergeUrl(providerUrl, queryMap); // 2 合并配置规则URL到 providerUrl中，配置规则URL可以是： // 2.1 第一类是注册中心 Configurators 目录下的的URL（override 协议） // 2.2 第二类是服务治理控制台动态添加配置 List&lt;Configurator&gt; localConfigurators = this.configurators; // local reference if (localConfigurators != null &amp;&amp; !localConfigurators.isEmpty()) &#123; for (Configurator configurator : localConfigurators) &#123; // 使用配置规则器 将 配置规则应用到 providerUrl providerUrl = configurator.configure(providerUrl); &#125; &#125; // 3 增加check=false，即只有在调用时，才检查Provider是否可用 providerUrl = providerUrl.addParameter(Constants.CHECK_KEY, String.valueOf(false)); // 4 更新 overrideDirectoryUrl this.overrideDirectoryUrl = this.overrideDirectoryUrl.addParametersIfAbsent(providerUrl.getParameters()); // Merge the provider side parameters // 忽略 对 1.0 版本的兼容 // 5 返回处理后的新的服务提供者 URL return providerUrl; &#125; 合并 URL 的逻辑如下： 将消费端URL参数配置项合并到服务提供者URL中，但 group、version、methods 等参数以服务端的配置优先，因为它们是远程服务配置参数。 filter 和 listener 参数使用两端的配置项。 将注册中心中 configurators 目录下的 URL，以及服务治理控制台动态添加的配置与 Provider URL 进行合并，即覆盖 Provider URL 原有的一些信息。 增加check=false，即只有在调用时，才检查Provider是否可用。 更新 overrideDirectoryUrl 的值：注册中心URL + 消费端URL参数配置项 -&gt; 注册中心URL + 消费端URL参数配置项 + 服务端URL合并后的URL参数配置项。 需要说明的是，合并 URL 参数的优先级：配置规则 -&gt; 系统参数 -&gt; 消费端配置 -&gt; 服务端配置 toInvokers 方法返回的是 &lt;url串,Invoker&gt; 映射关系，接下来还会对该结果进一步处理，得到方法名到 Invoker 列表的映射关系。 方法名-&gt;Invoker列表123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687+--- RegistryDirectory private Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; toMethodInvokers(Map&lt;String, Invoker&lt;T&gt;&gt; invokersMap) &#123; // 方法名到Invoker集合映射 Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; newMethodInvokerMap = new HashMap&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt;(); // 记录服务提供者Invoker集合 List&lt;Invoker&lt;T&gt;&gt; invokersList = new ArrayList&lt;Invoker&lt;T&gt;&gt;(); // 按照服务提供者URL声明的 method 分类，兼容注册中心执行路由过滤掉的 methods if (invokersMap != null &amp;&amp; invokersMap.size() &gt; 0) &#123; // 循环每个服务提供者Invoker for (Invoker&lt;T&gt; invoker : invokersMap.values()) &#123; // 1 服务提供者URL声明的 methods String parameter = invoker.getUrl().getParameter(Constants.METHODS_KEY); // 2 遍历方法集合 if (parameter != null &amp;&amp; parameter.length() &gt; 0) &#123; // 切割 methods 参数值，处理成方法名数组 String[] methods = Constants.COMMA_SPLIT_PATTERN.split(parameter); if (methods != null &amp;&amp; methods.length &gt; 0) &#123; // 3 循环每个方法，按照方法名的维度收集引用的 Invoker for (String method : methods) &#123; // 当服务提供者的方法为 * 时，代表泛化调用，不处理。 if (method != null &amp;&amp; method.length() &gt; 0 &amp;&amp; !Constants.ANY_VALUE.equals(method)) &#123; List&lt;Invoker&lt;T&gt;&gt; methodInvokers = newMethodInvokerMap.get(method); if (methodInvokers == null) &#123; methodInvokers = new ArrayList&lt;Invoker&lt;T&gt;&gt;(); newMethodInvokerMap.put(method, methodInvokers); &#125; // 根据方法名获取Invoker集合 methodInvokers.add(invoker); &#125; &#125; &#125; &#125; // 4 收集引用的 Invoker invokersList.add(invoker); &#125; &#125; // 5 进行服务级别路由，即对引用的服务进行路由 List&lt;Invoker&lt;T&gt;&gt; newInvokersList = route(invokersList, null); // 6 存储 &lt;*, newInvokersList&gt; 映射关系 newMethodInvokerMap.put(Constants.ANY_VALUE, newInvokersList); // 7 对引用的服务接口中的方法进行方法级别路由 if (serviceMethods != null &amp;&amp; serviceMethods.length &gt; 0) &#123; // 遍历服务方法数组基于每个方法路由，匹配方法对应的Invoker集合 for (String method : serviceMethods) &#123; List&lt;Invoker&lt;T&gt;&gt; methodInvokers = newMethodInvokerMap.get(method); if (methodInvokers == null || methodInvokers.isEmpty()) &#123; methodInvokers = newInvokersList; &#125; // 进行方法级别路由 newMethodInvokerMap.put(method, route(methodInvokers, method)); &#125; &#125; // 8 排序，转成不可变集合 for (String method : new HashSet&lt;String&gt;(newMethodInvokerMap.keySet())) &#123; List&lt;Invoker&lt;T&gt;&gt; methodInvokers = newMethodInvokerMap.get(method); Collections.sort(methodInvokers, InvokerComparator.getComparator()); newMethodInvokerMap.put(method, Collections.unmodifiableList(methodInvokers)); &#125; return Collections.unmodifiableMap(newMethodInvokerMap); &#125;---+ private List&lt;Invoker&lt;T&gt;&gt; route(List&lt;Invoker&lt;T&gt;&gt; invokers, String method) &#123; // 创建Invocation 对象 Invocation invocation = new RpcInvocation(method, new Class&lt;?&gt;[0], new Object[0]); // 获得 Router 数组 List&lt;Router&gt; routers = getRouters(); // 根据路由规则，筛选Invoker 集合 if (routers != null) &#123; for (Router router : routers) &#123; if (router.getUrl() != null) &#123; invokers = router.route(invokers, getConsumerUrl(), invocation); &#125; &#125; &#125; return invokers; &#125; 将引用的 Invoker 列表进行映射，得到方法名到 Invoker 的映射。主要过程如下： 对传入的引用 Invoker 进行遍历，获取其中的 methods 参数，并切分成数组。然后以方法名为键，Invoker 列表为值进行缓存。 先后基于服务级别和方法级别对 Invoker 列表进行路由操作，筛选目标 Invoker 。 对路由后的 Invoker 列表进行排序，并转成不可变列表。 多分组聚合12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849+--- RegistryDirectoryprivate Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; toMergeMethodInvokerMap(Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; methodMap) &#123; Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; result = new HashMap&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt;(); // 循环map集合，根据 method + group 聚合 Invoker 集合 for (Map.Entry&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; entry : methodMap.entrySet()) &#123; // 1 获取方法名 String method = entry.getKey(); // 2 获取方法名对应的invoker列表 List&lt;Invoker&lt;T&gt;&gt; invokers = entry.getValue(); // 3 按照 group 聚合 Invoker 集合的结果，key：group value：Invoker集合 Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; groupMap = new HashMap&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt;(); // 4 遍历Invoker集合 。注意：一个方法对应的 Invoker 列表可能属于多个组 for (Invoker&lt;T&gt; invoker : invokers) &#123; // 4.1 获取分组名 String group = invoker.getUrl().getParameter(Constants.GROUP_KEY, \"\"); // 4.2 以分组名聚合Invoker集合 List&lt;Invoker&lt;T&gt;&gt; groupInvokers = groupMap.get(group); if (groupInvokers == null) &#123; groupInvokers = new ArrayList&lt;Invoker&lt;T&gt;&gt;(); groupMap.put(group, groupInvokers); &#125; groupInvokers.add(invoker); &#125; // 5 如果只有一个group，则直接使用该group分组对应的Invoker集合作为结果 if (groupMap.size() == 1) &#123; result.put(method, groupMap.values().iterator().next()); // 6 有多个分组的话，将每个group对应的Invoker集合经过Cluster合并成一个Invoker &#125; else if (groupMap.size() &gt; 1) &#123; List&lt;Invoker&lt;T&gt;&gt; groupInvokers = new ArrayList&lt;Invoker&lt;T&gt;&gt;(); for (List&lt;Invoker&lt;T&gt;&gt; groupList : groupMap.values()) &#123; // 这里使用到StaticDirectory以及Cluster合并每个group中的Invoker groupInvokers.add(cluster.join(new StaticDirectory&lt;T&gt;(groupList))); &#125; result.put(method, groupInvokers); // 没有的话，就使用原来的数据 &#125; else &#123; result.put(method, invokers); &#125; &#125; return result; &#125; 多分组聚合方法用于在 &lt;methodName,Invoker列表&gt; 基础中，对同一个方法对应的 Invoker 列表进行 group 维度的分类，同一个 group 维度的 Invoker 列表通过 Cluster 合并成一个 Invoker 。 这里按照 group 进行聚合的目的是，为 MergeableCluster 创建的 MergeableClusterInvoker 提供分组后的服务列表。当引用多个服务分组时，会自动使用分组聚合的特性，这个特性就是由 MergeableCluster 创建的 MergeableClusterInvoker 完成的。 123456789101112131415161718192021222324252627282930313233+--- RegistryProtocol @Override @SuppressWarnings(\"unchecked\") public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; // 获得真实的注册中心的URL url = url.setProtocol(url.getParameter(Constants.REGISTRY_KEY, Constants.DEFAULT_REGISTRY)).removeParameter(Constants.REGISTRY_KEY); // 获得注册中心 Registry registry = registryFactory.getRegistry(url); // todo 这是干嘛的？为什么要给RegistryService 类型生成Invoker if (RegistryService.class.equals(type)) &#123; return proxyFactory.getInvoker((T) registry, type, url); &#125; // 获得服务引用配置参数集合Map Map&lt;String, String&gt; qs = StringUtils.parseQueryString(url.getParameterAndDecoded(Constants.REFER_KEY)); // 获取group属性 String group = qs.get(Constants.GROUP_KEY); // 分组聚合 group=\"a,b\" or group=\"*\" if (group != null &amp;&amp; group.length() &gt; 0) &#123; if ((Constants.COMMA_SPLIT_PATTERN.split(group)).length &gt; 1 || \"*\".equals(group)) &#123; // 通过SPI加载MergeableCluster实例，并调用doRefer继续执行引用服务逻辑。 // 注意这里使用的是 MergeableCluster，并不是配置的cluster或者默认的cluster不再使用了， // 对于分组聚合来说，cluster用在了聚合同一个group下的 Invoker 列表 return doRefer(getMergeableCluster(), registry, type, url); &#125; &#125; // 执行服务引用 return doRefer(cluster, registry, type, url); &#125; 销毁无用 Invoker123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051+--- RegistryDirectory private void destroyUnusedInvokers(Map&lt;String, Invoker&lt;T&gt;&gt; oldUrlInvokerMap, Map&lt;String, Invoker&lt;T&gt;&gt; newUrlInvokerMap) &#123; // 1 安全处理 if (newUrlInvokerMap == null || newUrlInvokerMap.size() == 0) &#123; // 销毁所有服务提供者Invoker destroyAllInvokers(); return; &#125; // 2 比较新老集合，确定需要销毁哪些Invoker。 // 原则是：以新的为基准，如果新的中不包含老的，说明老的应该被销毁 List&lt;String&gt; deleted = null; if (oldUrlInvokerMap != null) &#123; // 获取新生成的 Invoker 集合 Collection&lt;Invoker&lt;T&gt;&gt; newInvokers = newUrlInvokerMap.values(); // 遍历老的 &lt;url串, Invoker&gt; 映射表 for (Map.Entry&lt;String, Invoker&lt;T&gt;&gt; entry : oldUrlInvokerMap.entrySet()) &#123; // 如果新的集合中不包含老的Invoker，则表示可以把当前老的Invoker删除 if (!newInvokers.contains(entry.getValue())) &#123; if (deleted == null) &#123; deleted = new ArrayList&lt;String&gt;(); &#125; // 若不包含，则将老的 Invoker 对应的 url 存入 deleted 列表中 deleted.add(entry.getKey()); &#125; &#125; &#125; // 3 有需要销毁的Invoker就进行销毁 if (deleted != null) &#123; // 遍历 deleted 集合，并到老的 &lt;url, Invoker&gt; 映射关系表查出 Invoker并销毁 for (String url : deleted) &#123; if (url != null) &#123; // 从老的Invoker集合中移除要销毁的Invoker Invoker&lt;T&gt; invoker = oldUrlInvokerMap.remove(url); if (invoker != null) &#123; try &#123; // 销毁Invoker invoker.destroy(); if (logger.isDebugEnabled()) &#123; logger.debug(\"destroy invoker[\" + invoker.getUrl() + \"] success. \"); &#125; &#125; catch (Exception e) &#123; logger.warn(\"destroy invoker[\" + invoker.getUrl() + \"] faild. \" + e.getMessage(), e); &#125; &#125; &#125; &#125; &#125; &#125; 销毁无用 Invoker 关键看旧的 Invoker 是否在新的 Invoker 集合中，不在则说明需要销毁。 小结本篇文章对 Dubbo 的服务目录进行了分析，相比静态服务目录 StaticDirectory ，动态的服务目录 RegistryDirectory 要复杂得多。为了让本地服务目录和注册中心保持一致，需要做很多工作。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"Dubbo源码分析 - 集群模块总览","slug":"rpc/集群模块总览","date":"2020-09-11T16:00:00.000Z","updated":"2021-04-06T08:31:35.563Z","comments":false,"path":"posts/7aca9035/","link":"","permalink":"https://gentryhuang.com/posts/7aca9035/","excerpt":"","text":"概述为了保证服务的可靠性、吞吐量以及容错能力，通常会在多个服务器上运行相同的应用程序，然后以集群的形式对外提供服务。根据应用场景不同，每个集群中的服务实例个数也不尽相同。Dubbo 中的 Cluster 是外围概念，用于将多个 Invoker 伪装成一个 Invoker，这样调用方只需关注 Protocol 层 Invoker 即可，加上 Cluster 或者去掉 Cluster 对其它层都不会造成影响，因为只有一个提供者时，是不需要 Cluster 的。 Cluster 层 在 Dubbo 架构中的位置如下图所示： Cluster 架构Dubbo 的集群模块主要功能是将多个服务提供者伪装成一个提供者供消费方调用，核心组件如下图所示： 从上图可以看出，Dubbo 集群模块涉及以下 4 个核心组件： Directory - 服务目录 代表多个 Invoker，可以把它看成 List&lt;Invoker&gt; ，但与 List 不同的是，它的值可能是动态变化的，比如注册中心推送变更。它是后续路由规则、负载均衡策略以及集群容错的基础。 Cluster - 集群 将 Directory 中的多个 Invoker 伪装成一个 Invoker ，对上层透明。伪装过程包含了容错逻辑，用于在某些 Provider 节点发生故障时让 Consumer 的调用请求能够发送到正常的 Provider 节点，从而保证整个系统的可用性。 Router - 路由 负责从 Directory 中按路由规则选出子集，比如应用在 读写分离、应用隔离 、灰度发布 等。 LoadBalance - 负载均衡 负责从 Router 中选出具体的一个 Invoker。选的过程包含了负载均衡算法。 Cluster 层的核心流程： 当调用进入 Cluster 模块时，Cluster 会从 Directory 中获取当前 Invoker 集合；然后按照 Router 进行路由，从 Directory 中筛选出符合条件的 Invoker 子集；接着按照 LoadBalance 进行负载均衡，从 Router 子集中选出一个最终要调用的 Invoker 对象。 Cluster 模块了解了 Dubbo 的 Cluster 架构，下面我们对 Dubbo 集群模块的实现简单说明下。 Dubbo 的 Cluster 模块代码实现如上图所示。 小结本篇文章相对比较轻松，简单介绍了 Cluster 层在 Dubbo 架构中所处的位置和其架构的组成。在后面几篇文章中，我们会分别介绍这些组件。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"Dubbo源码分析 - HTTP协议","slug":"rpc/HTTP协议","date":"2020-09-05T16:00:00.000Z","updated":"2021-03-15T03:08:20.553Z","comments":false,"path":"posts/c5a37c18/","link":"","permalink":"https://gentryhuang.com/posts/c5a37c18/","excerpt":"","text":"前言RPC 实现 远程过程调用需要解决以下问题： 寻址：客户端调用的时候需要告诉服务端调用的是哪个服务、哪个方法、哪些参数以及附加属性。 序列化/反序列化：由于客户端和服务端不是同一个进程不能通过内存来传递参数，需要网络传输，因此客户端需要将参数序列化成字节流然后经网络传递给服务端，服务端收到字节流后反序列化为自己能读取的格式。序列化/反序列化可以使用 Hessian、Dubbo、Protobuf、JSON 等。 网络传输：客户端和服务端需要通过网络连接来传输数据，网络传输可以使用 Socket、TCP、UDP、HTTP、HTTP2 等。 HTTP HTTP 请求调用本身也可以看作是 RPC 的一种具体形式，HTTP 请求也是从客户端发出请求到服务端，服务端执行具体逻辑，然后返回结果给客户端。HTTP 请求非常常见，一般开放服务给任意的一方调用，使用 HTTP API的形式是非常合适的。对于内部通信为了灵活、高效，可以根据实际需要自定制一套 RPC 框架，坏处就是没有那么通用。 JSON-RPC JSON-RPC 是基于 JSON 的跨语言远程调用（RPC）协议，其 传输的内容以JSON方式（注意，传输格式是二进制形式），相比 XML-RPC、WebService 等基于文本的协议传输数据格式小。相对 Dubbo、Hessian 等二进制协议，JSON-RPC 更便于调试、实现和扩展。目前主流语言几乎都基于 JSON-RPC 实现了框架，Java 中较好的 JSON-RPC 实现框架有 jsonrpc4j、jpoxy 以及 json-rpc ，其中 jsonrpc4j 既可单独使用，又可与 Spring 无缝整合。 二进制协议和文本协议 二进制协议需要通信双方约定协议的结构（如 Dubbo 协议的结构），发送方在发送数据前按照协议的结构组装数据然后序列化成字节流传送给对端，接收方收到字节流后按照协议的结构进行解析就可以了。文本协议（如 JSON-RPC协议）不需要通信双方约定协议结构，发送方只需将具体的文本数据（如 JSON数据）序列化成字节流发送到对端即可，接收方收到字节流后按照同样的文本格式（如 JSON）解析就可以了。 二进制协议的优点在于，进行数据转化时不需要包含定义数据的结构信息，相比文本协议要小；文本协议的优点在于不需要定义数据的传输格式，较为方便。需要说明的是，无论是二进制协议还是文本协议，都是以二进制数据形式进行网络传输的，区别在于二进制协议需要定制结构，而文本协议不需要。 协议和序列化 协议和序列化是不同的东西，它们之间属于组合关系，协议需要用到序列化技术，而序列化技术可以服务于不同的协议。 跨语言 跨语言调用一个重要的思路就是要有一个通用的协议，或者使用一定的策略完成协议适配，对于前者而言 HTTP 协议就是很好的选择，如异构语言对 SpringCloud 的调用只需提供 HTTP 客户端便可以实现跨语言调用。 跨语言难点在于 异构语言如何表示目标服务所需的数据类型 和 序列化方案如何做到跨语言，如 nodejs 对 dubbo 协议下的 Java 服务的调用是利用 dubbo2.js 组件来实现的，使用 js-to-java类库使得 node.js具备 Java 对象的表达能力，使用 hessian.js 提供了序列化能力，这样一来 nodejs 就能通过自己的 socket 发送一套 dubbo 协议的报文，最终实现服务调用。 概述Dubbo 中支持的 HTTP 协议并非是通用的 HTTP协议，而是将 HTTP协议 与 Spring 结合使用，基于 HTTP 表单的远程调用协议，采用 Spring 的 HttpInvoker 实现，但在 Dubbo 的 2.7.x 版本中摒弃了 HttpInvoker 实现方式，代替的是将 HTTP协议 与 JSON-RPC 结合使用，实现跨语言调用的效果。 Dubbo 2.6.x 实现Dubbo 2.6.x 版本中的 HTTP 协议是基于 HTTP 表单的远程调用协议，采用 Spring 的 HttpInvoker 实现。 特点 连接个数：多连接连接方式：短连接传输协议：HTTP传输方式：同步传输序列化：表单序列化（默认使用的是 java 序列化的方式）适用范围：传入传出参数数据包大小混合，提供者比消费者个数多，可用浏览器查看，可用表单或URL传入参数，暂不支持传文件。适用场景：需同时给应用程序和浏览器 JS 使用的服务。 配置 12&lt;!-- 使用的应用服务器默认是 jetty --&gt;&lt;dubbo:protocol name=\"http\" port=\"8080\" server=\"jetty\"/&gt; 当服务消费者向服务提供者发起调用时，底层便会使用标准的 HTTP 协议进行通信。在分析 Dubbo 2.6.x 版本中的 “HTTP协议” 之前，让我们先了解下 Spring 的 HttpInvoker 实现。 HttpInvoker 原生实现服务提供者1234567@Servicepublic class InvokerServiceImpl implements IInvokerService &#123; @Override public String sayHello(String msg) &#123; return \"hello \" + msg; &#125;&#125; 暴露服务1234567891011121314@Configurationpublic class HttpInvokerConfig &#123; /** * @param iInvokerService * @return */ @Bean(\"/invokerService\") public HttpInvokerServiceExporter httpInvokerServiceExporter(IInvokerService iInvokerService) &#123; HttpInvokerServiceExporter httpInvokerServiceExporter = new HttpInvokerServiceExporter(); httpInvokerServiceExporter.setService(iInvokerService); httpInvokerServiceExporter.setServiceInterface(IInvokerService.class); return httpInvokerServiceExporter; &#125;&#125; 暴露服务逻辑如下： 1 对外提供的服务，访问路径格式: http://ip:port/上下文/invokerService 2 HttpInvokerServiceExporter 是 Spring 封装的一个服务暴露器，它会以 serviceInterface 为公共接口，以 service 为实现类向外提供服务。 Spring封装了远程调用的逻辑，网络传输使用的是 HTTP，当有请求过来，当前服务会进行处理并将处理后的结果传输到对端。 3 @Bean(“/invokerService”) 不仅仅指定了 IOC 容器中 bean 的名字，还充当了路径映射的功能，如果本地服务器暴露在 8080 端口，则示例服务的访问路径为 http://localhost:8080/上下文/invokerService 服务消费者123ConfigurableApplicationContext applicationContext = SpringApplication.run(Application.class, args);IInvokerService iInvokerService = applicationContext.getBean(IInvokerService.class);System.out.println(iInvokerService.sayHello(\"shunhua!\")); 服务引用123456789101112131415161718@Configurationpublic class ClientConfig &#123; /** * 访问服务路径 */ private String serviceUrl = \"http://localhost:8080/上下文/invokerService\"; /** * * @return */ @Bean public HttpInvokerProxyFactoryBean httpInvokerProxyFactoryBean() &#123; HttpInvokerProxyFactoryBean httpInvokerProxyFactoryBean = new HttpInvokerProxyFactoryBean(); httpInvokerProxyFactoryBean.setServiceUrl(serviceUrl); httpInvokerProxyFactoryBean.setServiceInterface(IInvokerService.class); return httpInvokerProxyFactoryBean; &#125;&#125; 服务引用逻辑如下： 1 HttpInvokerProxyFactoryBean 是 Spring 封装的一个服务引用器，serviceInterface 指定了生成代理的接口，serviceUrl 指定了服务所在的地址，与之前配置的服务暴露者的路径需要对应。 2 HttpInvokerProxyFactoryBean 注册到 Spring 容器中时，会同时生成一个指定接口的代理类，由 Spring 封装远程调用的逻辑，使用 HTTP 传输数据，默认使用java 序列化的方式。 源码实现Dubbo 的 HTTP 协议实现代码结构如下： 对比 Dubbo 协议可以看出，HTTP 协议实现的非常简单，主要原因如下： 使用 HTTP 通信，不需要自定义编解码器。 使用的序列化是 JDK 原生的 借助了 Spring 提供的服务暴露和服务引用机制 HttpProtocol属性123456789101112131415161718192021222324252627282930313233343536373839public class HttpProtocol extends AbstractProxyProtocol &#123; /** * 默认服务器端口 */ public static final int DEFAULT_PORT = 80; /** * Http 服务器集合 * key: ip:port * value: Http服务器 */ private final Map&lt;String, HttpServer&gt; serverMap = new ConcurrentHashMap&lt;String, HttpServer&gt;(); /** * Spring 的 HttpInvokerServiceExporter 集合 * key: path 服务名 * value: spring的HttpInvokerServiceExporter * 请求处理过程说明： * HttpServer -&gt; DispatcherServlet -&gt; InternalHandler -&gt; HttpInvokerServiceExporter */ private final Map&lt;String, HttpInvokerServiceExporter&gt; skeletonMap = new ConcurrentHashMap&lt;String, HttpInvokerServiceExporter&gt;(); /** * HttpBinder$Adaptive 对象,通过 &#123;@link #setHttpBinder(HttpBinder)&#125;方法，Dubbo SPI IOC注入 */ private HttpBinder httpBinder; public HttpProtocol() &#123; super(RemoteAccessException.class); &#125; public void setHttpBinder(HttpBinder httpBinder) &#123; this.httpBinder = httpBinder; &#125; @Override public int getDefaultPort() &#123; return DEFAULT_PORT; &#125; 服务暴露123456789101112131415161718192021222324252627282930313233343536373839+--- HttpProtocol @Override protected &lt;T&gt; Runnable doExport(final T impl, Class&lt;T&gt; type, URL url) throws RpcException &#123; // 1 获取服务器地址 ip:port String addr = getAddr(url); // 2 根据地址从缓存中获得 HttpServer 对象，若不存在，进行创建 HttpServer server = serverMap.get(addr); if (server == null) &#123; /** * 1 通过SPI机制获取具体的 HttpBinder的拓展实现 * 2 具体的HttpBinder实现调用bind方法： * 1）启动服务 * 2）为服务设置请求处理器(InternalHandler对象) */ server = httpBinder.bind(url, new InternalHandler()); // 将创建好的服务加入缓存 serverMap.put(addr, server); &#125; // 3 获取 url 的 path，以此为 key缓存 HttpInvokerServiceExporter final String path = url.getAbsolutePath(); skeletonMap.put(path, createExporter(impl, type)); // 4 支持泛化，只需将服务实现的接口替换成泛化接口 GenericService 即可 final String genericPath = path + \"/\" + Constants.GENERIC_KEY; skeletonMap.put(genericPath, createExporter(impl, GenericService.class)); // 5 返回取消暴露的回调 Runnable return new Runnable() &#123; /** * 在回调时会移除对应的缓存 HttpInvokerServiceExporter */ @Override public void run() &#123; skeletonMap.remove(path); skeletonMap.remove(genericPath); &#125; &#125;; &#125; HttpProtocol 的 doExport() 方法是对其父类 AbstractProxyProtocol 服务暴露模版方法的实现，该方法的逻辑主要过程如下： 基于服务地址维度查询缓存的 HTTP服务器 HttpServer。 使用 HTTP 绑定器创建并启动 HTTP服务器，该服务器用于接收请求。 创建 HttpInvokerServiceExporter 服务暴露器，向外提供服务，用于处理 HTTP 服务器接收的请求。其中支持泛化实现，即使用服务暴露器暴露一个泛化服务即可。 返回取消暴露的回调 Runnable 。 为了适配各种 HTTP 服务器，如 Tomcat、Jetty，以及需要外部 Servlet 容器的 Servlet ，Dubbo 在 Transporter 层提供了一系列接口，代码结构如下图所示： 从代码结构结合 Servlet 知识点我们不难看出，Dubbo 使用了四个不同的组件将 Servlet 串联起来。下面我们分别来看这三个组件类。 HTTP 绑定器12345678910111213@SPI(\"jetty\")public interface HttpBinder &#123; /** * 基于Dubbo SPI 机制，加载对应的Server 实现。 * * bind the server. * * @param url server url. * @return server. */ @Adaptive(&#123;Constants.SERVER_KEY&#125;) HttpServer bind(URL url, HttpHandler handler);&#125; HttpBinder 用于创建并启动 HTTP 服务器，默认扩展实现为 JettyHttpServer 。 Jetty 绑定器 1234567public class JettyHttpBinder implements HttpBinder &#123; @Override public HttpServer bind(URL url, HttpHandler handler) &#123; // 用于创建并启动 Jetty 服务器。 return new JettyHttpServer(url, handler); &#125;&#125; Tomcat 绑定器 1234567public class TomcatHttpBinder implements HttpBinder &#123; @Override public HttpServer bind(URL url, HttpHandler handler) &#123; // 用于创建并启动 Tomcat 服务器。 return new TomcatHttpServer(url, handler); &#125;&#125; Servlet 绑定器 123456789public class ServletHttpBinder implements HttpBinder &#123; @Override @Adaptive() public HttpServer bind(URL url, HttpHandler handler) &#123; // 这种方式并不直接创建服务器，而是将请求处理器保存起来，用于处理外部 Servlet 容器转发的请求。 // 也就是说，需要外部配置 Servlet ，该外部 Servlet 接收的请求交由 handler 来处理 return new ServletHttpServer(url, handler); &#125;&#125; HTTP 服务器HttpServer123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public interface HttpServer extends Resetable &#123; /** * get http handler. 获取处理器 * * @return http handler. */ HttpHandler getHttpHandler(); /** * get url. * * @return url */ URL getUrl(); /** * get local address. * * @return local address. */ InetSocketAddress getLocalAddress(); /** * close the channel. */ void close(); /** * Graceful close the channel. */ void close(int timeout); /** * is bound. * * @return bound */ boolean isBound(); /** * is closed. * * @return closed */ boolean isClosed();&#125; HttpServer 继承了 Resetable 接口，定义了 HTTP 服务器接口。在 dubbo-rpc 模块中，http://、rest://、hessian://、webservice:// 协议实现等，都是基于 HTTP 服务器实现请求处理的。 AbstractHttpServer123456789101112131415161718192021222324252627282930313233343536373839404142434445public abstract class AbstractHttpServer implements HttpServer &#123; /** * URL 对象 */ private final URL url; /** * 处理器 */ private final HttpHandler handler; /** * 是否关闭标记 */ private volatile boolean closed; public AbstractHttpServer(URL url, HttpHandler handler) &#123; if (url == null) &#123; throw new IllegalArgumentException(\"url == null\"); &#125; if (handler == null) &#123; throw new IllegalArgumentException(\"handler == null\"); &#125; this.url = url; this.handler = handler; &#125; @Override public void close() &#123; closed = true; &#125; // 不支持超时关闭 @Override public void close(int timeout) &#123; close(); &#125; @Override public boolean isClosed() &#123; return closed; &#125; // 省略其它代码...&#125; HTTP 服务器抽象类仅是对处理器和URL的简单封装，外加标记服务器关闭标志。下面我们具体分析 Dubbo 如何实现内置的 Servlet 容器的。考虑到 JettyHttpServer 实现逻辑 和 TomcatHttpServer 实现逻辑类似，这里我们只对 Tomcat 服务器实现进行分析。 TomcatHttpServer1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class TomcatHttpServer extends AbstractHttpServer &#123; private static final Logger logger = LoggerFactory.getLogger(TomcatHttpServer.class); /** * 内嵌Tomcat */ private final Tomcat tomcat; /** * URL 对象 */ private final URL url; public TomcatHttpServer(URL url, final HttpHandler handler) &#123; super(url, handler); this.url = url; // 1 注册请求处理器HttpHandler 到 DispatcherServlet的 处理器集合中 DispatcherServlet.addHttpHandler(url.getPort(), handler); // 2 创建内嵌Tomcat String baseDir = new File(System.getProperty(\"java.io.tmpdir\")).getAbsolutePath(); tomcat = new Tomcat(); tomcat.setBaseDir(baseDir); // 设置端口 tomcat.setPort(url.getPort()); // 设置最大线程数 tomcat.getConnector().setProperty(\"maxThreads\", String.valueOf(url.getParameter(Constants.THREADS_KEY, Constants.DEFAULT_THREADS)));// tomcat.getConnector().setProperty(// \"minSpareThreads\", String.valueOf(url.getParameter(Constants.THREADS_KEY, Constants.DEFAULT_THREADS))); // 设置最大连接池 tomcat.getConnector().setProperty(\"maxConnections\", String.valueOf(url.getParameter(Constants.ACCEPTS_KEY, -1))); // 编码为UTF-8 tomcat.getConnector().setProperty(\"URIEncoding\", \"UTF-8\"); // 连接超时 60 秒 tomcat.getConnector().setProperty(\"connectionTimeout\", \"60000\"); tomcat.getConnector().setProperty(\"maxKeepAliveRequests\", \"-1\"); tomcat.getConnector().setProtocol(\"org.apache.coyote.http11.Http11NioProtocol\"); // 3 创建并添加DispatcherServlet 到 Tomcat 中，作为 Tomcat 的处理器分发器 Context context = tomcat.addContext(\"/\", baseDir); Tomcat.addServlet(context, \"dispatcher\", new DispatcherServlet()); context.addServletMapping(\"/*\", \"dispatcher\"); // 4 添加ServletContext 上下文对象 到 ServletManager 中 ServletManager.getInstance().addServletContext(url.getPort(), context.getServletContext()); try &#123; // 5 启动tomcat tomcat.start(); &#125; catch (LifecycleException e) &#123; throw new IllegalStateException(\"Failed to start tomcat server at \" + url.getAddress(), e); &#125; &#125;&#125; TomcatHttpServer 的构造方法中会创建一个内置的 Tomcat 服务器，然后设置 启动端口、最大线程以及调度器 等参数，其中 调度器 是用来处理 内置Tomcat 接收的请求的，该调度器是 Dubbo 框架通过继承 HttpServer 实现的，作用和 Spring 的 DispatcherServlet 类似，用来派发请求，我们会在下文中详细说明。 服务关闭如下： 1234567891011121314+--- TomcatHttpServer @Override public void close() &#123; // 标记关闭 super.close(); // 移除 ServletContext 对象 ServletManager.getInstance().removeServletContext(url.getPort()); // 关闭tomcat try &#123; tomcat.stop(); &#125; catch (Exception e) &#123; logger.warn(e.getMessage(), e); &#125; &#125; ServletHttpServer1234567public class ServletHttpServer extends AbstractHttpServer &#123; public ServletHttpServer(URL url, HttpHandler handler) &#123; super(url, handler); // 注册HttpHandler 到 DispatcherServlet 中 DispatcherServlet.addHttpHandler(url.getParameter(Constants.BIND_PORT_KEY, 8080), handler); &#125;&#125; ServletHttpServer 是基于 Servlet 的服务器实现类，该方式需要配置 DispatcherServlet(Dubbo 实现的 HttpServlet) 到 web.xml 中，通过这样的方式，让外部的Servlet容器可以进行转发请求。 HTTP 调度器DispatcherServlet 继承了 javax.servlet.http.HttpServlet ，是 Dubbo 实现的服务器请求调度 Servlet。用于调度请求，将请求交给对应的处理器执行。无论是内置的 Jetty 实现，还是 Tomcat 实现，或者是作为外部的 Servlet , DispatcherServlet 作用都是一致的，用于调度请求。 属性12345678910111213141516171819202122232425262728293031323334353637383940public class DispatcherServlet extends HttpServlet &#123; private static final long serialVersionUID = 5766349180380479888L; /** * 处理器缓存集合 */ private static final Map&lt;Integer, HttpHandler&gt; handlers = new ConcurrentHashMap&lt;Integer, HttpHandler&gt;(); /** * 单例 - 饿汉模式 */ private static DispatcherServlet INSTANCE; public DispatcherServlet() &#123; DispatcherServlet.INSTANCE = this; &#125; /** * 添加处理器 * * @param port 服务器端口 * @param processor 处理器 */ public static void addHttpHandler(int port, HttpHandler processor) &#123; handlers.put(port, processor); &#125; public static DispatcherServlet getInstance() &#123; return INSTANCE; &#125; /** * 移除处理器 * * @param port 服务器端口 */ public static void removeHttpHandler(int port) &#123; handlers.remove(port); &#125;&#125; 调度请求12345678910111213+--- DispatcherServlet @Override protected void service(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; // 1 从HANDLERS集合中查询端口对应的HttpHandler对象 HttpHandler handler = handlers.get(request.getLocalPort()); // 2 没有处理器就报错 if (handler == null) &#123; response.sendError(HttpServletResponse.SC_NOT_FOUND, \"Service not found.\"); &#125; else &#123; // 3 将请求委托给对应的HttpHandler对象处理 handler.handle(request, response); &#125; &#125; DispatcherServlet 将接收到的请求交给请求 HTTP 处理器处理。 HTTP 处理器1234567891011public interface HttpHandler &#123; /** * 处理请求 * * @param request request. 请求 * @param response response. 响应 * @throws IOException * @throws ServletException */ void handle(HttpServletRequest request, HttpServletResponse response) throws IOException, ServletException;&#125; 基于 HTTP 服务的 Protocol 都有各自的实现，下面我们分析 HttpProtocol 中的实现。 1234567891011121314151617181920212223242526272829303132333435+--- HttpProtocol private class InternalHandler implements HttpHandler &#123; /** * 处理请求 * * @param request request 请求 * @param response response 响应 * @throws IOException * @throws ServletException */ @Override public void handle(HttpServletRequest request, HttpServletResponse response) throws IOException, ServletException &#123; // 1 获取请求的uri String uri = request.getRequestURI(); // 2 从缓存中取出uri对应的 HttpInvokerServiceExporter 对象 HttpInvokerServiceExporter skeleton = skeletonMap.get(uri); // 3 必须是post请求（ Dubbo 2.6.x 的 http 协议是基于HTTP表单的远程调用协议) if (!request.getMethod().equalsIgnoreCase(\"POST\")) &#123; // 不是post请求就直接返回500 response.setStatus(500); &#125; else &#123; // 4 设置远程调用地址 RpcContext.getContext().setRemoteAddress(request.getRemoteAddr(), request.getRemotePort()); try &#123; // 5 处理请求，结果写到response中 // 响应数据类型使用的也是 application/x-java-serialized-object skeleton.handleRequest(request, response); &#125; catch (Throwable e) &#123; throw new ServletException(e); &#125; &#125; &#125; &#125; HttpProtocol 中 HTTP 处理器是一个内部实现类，用于处理 HTTP 调度器转发过来的请求，最终又会将请求交给 HttpInvokerServiceExporter 暴露的服务处理。其中请求的 uri 作为映射 HttpInvokerServiceExporter 暴露的服务的键，在服务引用方法 doRefer 中会设置好这个请求路径。 提供服务使用 HttpInvokerServiceExporter 向外提供服务。 123456789101112131415private &lt;T&gt; HttpInvokerServiceExporter createExporter(T impl, Class&lt;?&gt; type) &#123; // 1 创建 HttpInvokerServiceExporter，以 serviceInterface 为公共接口，以 service 为实现类向外提供服务。 final HttpInvokerServiceExporter httpServiceExporter = new HttpInvokerServiceExporter(); // 2 设置接口 httpServiceExporter.setServiceInterface(type); // 3 设置实现 httpServiceExporter.setService(impl); try &#123; // 4 根据接口和实现，创建代理对象（Spring实现的），是 HttpInvokerServiceExporter 中的一个属性。 httpServiceExporter.afterPropertiesSet(); &#125; catch (Exception e) &#123; throw new RpcException(e.getMessage(), e); &#125; return httpServiceExporter;&#125; 需要注意的是，HttpInvokerServiceExporter 默认使用的序列化为 application/x-java-serialized-object，即 Java 序列方式。理论上可以通过 HttpInvokerServiceExporter.setContentType() 方法指定序列化方式。 服务引用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566+--- HttpProtocol @Override @SuppressWarnings(\"unchecked\") protected &lt;T&gt; T doRefer(final Class&lt;T&gt; serviceType, final URL url) throws RpcException &#123; // 1 判断是否是泛化调用 final String generic = url.getParameter(Constants.GENERIC_KEY); final boolean isGeneric = ProtocolUtils.isGeneric(generic) || serviceType.equals(GenericService.class); // 2 创建 HttpInvokerProxyFactoryBean 对象 // Spring 封装的一个服务引用器，serviceInterface 指定了生成代理的接口，serviceUrl 指定了服务所在的地址（与服务暴露者的路径需要对应） final HttpInvokerProxyFactoryBean httpProxyFactoryBean = new HttpInvokerProxyFactoryBean(); // 3 设置远程调用信息，其中包括对附加属性和泛化调用的处理 httpProxyFactoryBean.setRemoteInvocationFactory(new RemoteInvocationFactory() &#123; @Override public RemoteInvocation createRemoteInvocation(MethodInvocation methodInvocation) &#123; RemoteInvocation invocation = new HttpRemoteInvocation(methodInvocation); if (isGeneric) &#123; invocation.addAttribute(Constants.GENERIC_KEY, generic); &#125; return invocation; &#125; &#125;); // 4 设置目标服务的调用地址 ，如：http://10.1.31.48:8080/com.alibaba.dubbo.demo.DemoService String key = url.toIdentityString(); // 4.1 调用泛化服务 如：http://10.1.31.48:8080/com.alibaba.dubbo.demo.DemoService/generic if (isGeneric) &#123; key = key + \"/\" + Constants.GENERIC_KEY; &#125; // 4.2 设置访问服务路径，格式：ip:port/path httpProxyFactoryBean.setServiceUrl(key); // 4.3 设置生成代理的接口 httpProxyFactoryBean.setServiceInterface(serviceType); // 5 初始化客户端类型 client 参数 String client = url.getParameter(Constants.CLIENT_KEY); // 根据客户端类型不同，创建不同的 执行器，默认创建 SimpleHttpInvokerRequestExecutor 对象，即使用的是 JDK 的 HTTP 功能。 // 以下两种方式 Content-Type 的值为 application/x-java-serialized-object，即使用的序列化方式为 java 序列化 if (client == null || client.length() == 0 || \"simple\".equals(client)) &#123; // 使用的HttpClient 是 JDK HttpClent SimpleHttpInvokerRequestExecutor httpInvokerRequestExecutor = new SimpleHttpInvokerRequestExecutor() &#123; @Override protected void prepareConnection(HttpURLConnection con, int contentLength) throws IOException &#123; super.prepareConnection(con, contentLength); con.setReadTimeout(url.getParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT)); con.setConnectTimeout(url.getParameter(Constants.CONNECT_TIMEOUT_KEY, Constants.DEFAULT_CONNECT_TIMEOUT)); &#125; &#125;; httpProxyFactoryBean.setHttpInvokerRequestExecutor(httpInvokerRequestExecutor); &#125; else if (\"commons\".equals(client)) &#123; // 使用的HttpClient 是 Apache HttpClient HttpComponentsHttpInvokerRequestExecutor httpInvokerRequestExecutor = new HttpComponentsHttpInvokerRequestExecutor(); httpInvokerRequestExecutor.setReadTimeout(url.getParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT)); httpInvokerRequestExecutor.setConnectTimeout(url.getParameter(Constants.CONNECT_TIMEOUT_KEY, Constants.DEFAULT_CONNECT_TIMEOUT)); httpProxyFactoryBean.setHttpInvokerRequestExecutor(httpInvokerRequestExecutor); &#125; else &#123; throw new IllegalStateException(\"Unsupported http protocol client \" + client + \", only supported: simple, commons\"); &#125; // 6 返回指定接口的代理对象 httpProxyFactoryBean.afterPropertiesSet(); return (T) httpProxyFactoryBean.getObject(); &#125; 服务引用的关键有两点：其一，确定好目标服务访问路径，访问路径的 uri 部分使用 Dubbo URL 中的 path参数。其二，设置 目标服务的接口，注意泛化调用的实现方式。 关系类图 HTTP 报文信息上图中的客户端之所以是 Apache-HttpClient，是配置了 client=commons。默认采用 Java 的客户端，如： User-Agent: Java/1.8.0_211。 基于 HTTP 表单的远程调用协议，采用 Spring 的 HttpInvoker 实现的 HTTP协议，总体来看比较鸡肋。一方面网络传输使用的是 HTTP 方式，其本身具有通用性，但采用的序列化方式却是 Java 的序列化，这使得其在一定程度上丧失了跨语言的优势。 Dubbo 2.7.x 实现Dubbo 2.7.x 中使用 HTTP协议 + JSON-RPC 的方式来实现跨语言调用，其中 HTTP 协议和 JSON 都是天然跨语言的标准，几乎各种语言中都有成熟的类库。该版本中支持的 HTTP 协议实际上使用的是 JSON-RPC 协议，具体是使用 jsonrpc4j 库来实现 JSON-RPC 协议的。 JSON-RPC 原生使用描述JSON-RPC 协议非常简单，发起远程调用时向服务端传输数据格式如下： 12345678&#123; \"id\": 1, \"jsonrpc\" : 2.0, \"method\": \"sayHello\", \"params\": [ \"Hello JSON-RPC\" ] &#125; 参数说明： id：调用标识符，用于标示一次远程调用过程。 jsonrpc: 定义 JSON-RPC 版本 method: 调用的方法名 params: 方法传入参数，需要是数组格式，若无参数则传入 [] 。 服务器收到调用请求后会查找到相应的方法并进行调用，然后将方法的返回值整理成如下格式，返回给客户端： 123456&#123; \"id\": 1, \"jsonrpc\" : 2.0, \"result\": \"Hello JSON-RPC\", \"error\": null&#125; 参数说明： id: 调用标识符，与调用方传入的标识符一致。 jsonrpc: 定义 JSON-RPC 版本 result: 方法返回值，若无返回值，则返回null。若调用错误，返回null。 error: 调用发生异常时错误信息，无错误返回null。 jsonrpc4j 使用示例服务暴露123456789101112131415161718192021@Controllerpublic class RpcController &#123; /** * 这里使用 SpringMvc 接收请求，然后将请求交给 JsonRpcServer * * @param request * @param response * @throws IOException */ @RequestMapping(\"/json_rpc\") public void handle(HttpServletRequest request, HttpServletResponse response) throws IOException &#123; /** * 1 将服务 IJsonRpcService 与 JSON-RPC 关联起来，HTTP 请求委托给 JsonPpcServer 进行处理 * 2 JsonRpcServer 会按照 json-rpc 请求调用 JsonRpcServiceImpl 中的方法。其中 IJsonRrcService 没有用到。 */ JsonRpcServer rpcServer = new JsonRpcServer(new JsonRpcServiceImpl(), IJsonRrcService.class); rpcServer.handle(request, response); &#125;&#125; 该案例借助 Servlet 容器接收请求，然后将请求委托给 JsonRpcServer 处理。 下面我们简单对 jsonrpc4j 进行分析，这样可以更直观地感受 JSON-RPC 协议实现。 源码分析创建 JsonRpcServer123456789101112131415161718192021222324+--- JsonRpcServer // 省略属性 /** * @param handler 服务实现 * @param remoteInterface 服务接口，没有用到 */ public JsonRpcServer(Object handler, Class&lt;?&gt; remoteInterface) &#123; // 创建 jackson 域对象 this(new ObjectMapper(), handler, (Class) null); &#125; public JsonRpcServer(ObjectMapper mapper, Object handler, Class&lt;?&gt; remoteInterface) &#123; this.backwardsComaptible = true; this.rethrowExceptions = false; this.allowExtraParams = false; this.allowLessParams = false; this.errorResolver = null; this.exceptionLogLevel = Level.WARNING; this.mapper = mapper; // mapper this.handler = handler; // 服务对象 this.remoteInterface = remoteInterface; // null &#125; 处理请求123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137+--- JsonRpcServer public void handle(HttpServletRequest request, HttpServletResponse response) throws IOException &#123; if (LOGGER.isLoggable(Level.FINE)) &#123; LOGGER.log(Level.FINE, \"Handing HttpServletRequest \" + request.getMethod()); &#125; // 1 响应数据类型 response.setContentType(\"application/json-rpc\"); InputStream input = null; // 获取输出流 OutputStream output = response.getOutputStream(); // 2 判断请求类型 if (request.getMethod().equals(\"POST\")) &#123; // 2.1 如果是 POST 请求，那么请求内容在请求体中 input = request.getInputStream(); &#125; else &#123; if (!request.getMethod().equals(\"GET\")) &#123; throw new IOException(\"Invalid request method, only POST and GET is supported\"); &#125; // 2.2 如果是 GET 请求，则需要把关键的请求参数提取出来，并封装成 InputStream 对象 input = createInputStream(request.getParameter(\"method\"), request.getParameter(\"id\"), request.getParameter(\"params\")); &#125; // 3 处理请求 this.handle((InputStream) input, (OutputStream) output); &#125; public void handle(InputStream ips, OutputStream ops) throws IOException &#123; JsonNode jsonNode = null; try &#123; // 将请求的字节数据反序列化成对象 jsonNode = this.mapper.readTree(new NoCloseInputStream(ips)); &#125; catch (JsonParseException var5) &#123; this.writeAndFlushValue(ops, this.createErrorResponse(\"jsonrpc\", \"null\", -32700, \"Parse error\", (Object) null)); return; &#125; // 进一步处理请求 this.handleNode(jsonNode, ops); &#125; /** * @param node 请求字节流反序列化的对象 * @param ops 响应输出流 * @throws IOException */ public void handleNode(JsonNode node, OutputStream ops) throws IOException &#123; // 根据不同的请求参数类型，进行不同的处理 if (node.isObject()) &#123; // 最终有效的请求会走这个分支 this.handleObject((ObjectNode) ObjectNode.class.cast(node), ops); &#125; else if (node.isArray()) &#123; this.handleArray((ArrayNode) ArrayNode.class.cast(node), ops); &#125; else &#123; this.writeAndFlushValue(ops, this.createErrorResponse(\"2.0\", \"null\", -32600, \"Invalid Request\", (Object) null)); &#125; &#125; // node 请求信息 ： &#123;\"id\":\"7325124684462669617\",\"jsonrpc\":\"2.0\",\"method\":\"getUser\",\"params\":[1]&#125; public void handleObject(ObjectNode node, OutputStream ops) throws IOException &#123; if (LOGGER.isLoggable(Level.FINE)) &#123; LOGGER.log(Level.FINE, \"Request: \" + node.toString()); &#125; if ((this.backwardsComaptible || node.has(\"jsonrpc\")) &amp;&amp; node.has(\"method\")) &#123; // 1 获取请求信息 JsonNode jsonPrcNode = node.get(\"jsonrpc\"); // json-rpc 协议版本 JsonNode methodNode = node.get(\"method\"); // 调用信息 - 方法 JsonNode idNode = node.get(\"id\"); // 调用信息 - 调用唯一id JsonNode paramsNode = node.get(\"params\"); // 调用信息 - 参数 String jsonRpc = jsonPrcNode != null &amp;&amp; !jsonPrcNode.isNull() ? jsonPrcNode.asText() : \"2.0\"; // 版本 String methodName = this.getMethodName(methodNode); // 方法名 String serviceName = this.getServiceName(methodNode); // 服务名 ，目前版本返回 null Object id = this.parseId(idNode); // 调用id Set&lt;Method&gt; methods = new HashSet(); // 2 反射获取方法对象，即根据服务对象和方法名，反射获取方法对象。 // getHandlerInterfaces 方法的 serviceName 没有用到，直接是使用 this.handler 获取 Class 信息，即服务对象的Class methods.addAll(ReflectionUtil.findMethods(this.getHandlerInterfaces(serviceName), methodName)); if (methods.isEmpty()) &#123; this.writeAndFlushValue(ops, this.createErrorResponse(jsonRpc, id, -32601, \"Method not found\", (Object) null)); &#125; else &#123; // 获取方法对象和方法的参数值 JsonRpcServer.MethodAndArgs methodArgs = this.findBestMethodByParamsNode(methods, paramsNode); if (methodArgs == null) &#123; this.writeAndFlushValue(ops, this.createErrorResponse(jsonRpc, id, -32602, \"Invalid method parameters\", (Object) null)); &#125; else &#123; JsonNode result = null; Throwable thrown = null; try &#123; // 3 反射调用服务方法 // this.getHandler(serviceName) 直接返回 this.handler，即服务对象 result = this.invoke(this.getHandler(serviceName), methodArgs.method, methodArgs.arguments); &#125; catch (Throwable var17) &#123; thrown = var17; &#125; if (id != null) &#123; JsonError error = null; Throwable e; if (thrown != null) &#123; e = thrown; if (InvocationTargetException.class.isInstance(thrown)) &#123; e = ((InvocationTargetException) InvocationTargetException.class.cast(thrown)).getTargetException(); &#125; if (this.errorResolver != null) &#123; error = this.errorResolver.resolveError(e, methodArgs.method, methodArgs.arguments); &#125; else &#123; error = DEFAULT_ERRROR_RESOLVER.resolveError(e, methodArgs.method, methodArgs.arguments); &#125; if (error == null) &#123; error = new JsonError(0, e.getMessage(), e.getClass().getName()); &#125; &#125; e = null; ObjectNode response; if (error != null) &#123; // 4 封装错误响应 response = this.createErrorResponse(jsonRpc, id, error.getCode(), error.getMessage(), error.getData()); &#125; else &#123; // 4 封装响应对象 response = this.createSuccessResponse(jsonRpc, id, result); &#125; // 5 将结果通过 ops 响应给客户端 this.writeAndFlushValue(ops, response); &#125; if (thrown != null) &#123; if (LOGGER.isLoggable(this.exceptionLogLevel)) &#123; LOGGER.log(this.exceptionLogLevel, \"Error in JSON-RPC Service\", thrown); &#125; if (this.rethrowExceptions) &#123; throw new RuntimeException(thrown); &#125; &#125; &#125; &#125; &#125; else &#123; this.writeAndFlushValue(ops, this.createErrorResponse(\"2.0\", \"null\", -32600, \"Invalid Request\", (Object) null)); &#125; &#125; 服务引用12345678910111213public class Client &#123; public static void main(String[] args) throws Throwable &#123; // 1 创建 JsonRpcHttpClient JsonRpcHttpClient client = new JsonRpcHttpClient(new URL(\"http://127.0.0.1:8080/json_rpc\")); // 2 通过 JsonRpcHttpClient.invoke 方法进行调用 // 2.1 指定调用方法 // 2.2 指定方法参数，要求数组 // 2.3 选填，这里是返回值类型 Integer[] params = new Integer[]&#123;1&#125;; User getUser = client.invoke(\"getUser\", params, User.class); System.out.println(getUser); &#125;&#125; 创建 JsonRpcHttpClient 对象，并通过 JsonRpcHttpClient 请求服务端。 源码分析创建 JsonRpcHttpClient1234567891011121314151617+--- JsonRpcHttpClient public JsonRpcHttpClient(URL serviceUrl) &#123; // 创建 jackson 阈对象 this(new ObjectMapper(), serviceUrl, new HashMap()); &#125; public JsonRpcHttpClient(ObjectMapper mapper, URL serviceUrl, Map&lt;String, String&gt; headers) &#123; super(mapper); // JackJson 对象 this.connectionProxy = Proxy.NO_PROXY; this.connectionTimeoutMillis = 60000; this.readTimeoutMillis = 120000; this.sslContext = null; this.hostNameVerifier = null; this.headers = new HashMap(); this.serviceUrl = serviceUrl; // 服务URL this.headers.putAll(headers); &#125; 调用服务123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687+--- JsonRpcHttpClient/** * @param methodName 方法名 * @param argument 参数 ，数组形式 * @param clazz 返回值类型 * @param &lt;T&gt; * @return * @throws Throwable */ public &lt;T&gt; T invoke(String methodName, Object argument, Class&lt;T&gt; clazz) throws Throwable &#123; return this.invoke(methodName, argument, (Type) Type.class.cast(clazz)); &#125; public Object invoke(String methodName, Object argument, Type returnType, Map&lt;String, String&gt; extraHeaders) throws Throwable &#123; // 1 打开连接，连接服务 （JDK 的 HTTP 功能） HttpURLConnection con = this.prepareConnection(extraHeaders); con.connect(); // 2 获取连接的输出流对象 OutputStream ops = con.getOutputStream(); try &#123; // 3 调用 JsonRpcClient 中 invoke 方法。该方法涉及到请求数据的封装、序列化 super.invoke(methodName, argument, ops); &#125; finally &#123; ops.close(); &#125; // 4 获取连接的输入流 InputStream ips = con.getInputStream(); Object var8; try &#123; // 5 反序列化 var8 = super.readResponse(returnType, ips); &#125; finally &#123; ips.close(); &#125; return var8; &#125; /** * 初始化 HTTP 连接 * * @param extraHeaders * @return * @throws IOException */ protected HttpURLConnection prepareConnection(Map&lt;String, String&gt; extraHeaders) throws IOException &#123; // 打开 Http连接 // this.serviceUrl 服务URL HttpURLConnection con = (HttpURLConnection) this.serviceUrl.openConnection(this.connectionProxy); con.setConnectTimeout(this.connectionTimeoutMillis); con.setReadTimeout(this.readTimeoutMillis); con.setAllowUserInteraction(false); con.setDefaultUseCaches(false); con.setDoInput(true); con.setDoOutput(true); con.setUseCaches(false); con.setInstanceFollowRedirects(true); // 设置请求方式为 POST con.setRequestMethod(\"POST\"); if (HttpsURLConnection.class.isInstance(con)) &#123; HttpsURLConnection https = (HttpsURLConnection) HttpsURLConnection.class.cast(con); if (this.hostNameVerifier != null) &#123; https.setHostnameVerifier(this.hostNameVerifier); &#125; if (this.sslContext != null) &#123; https.setSSLSocketFactory(this.sslContext.getSocketFactory()); &#125; &#125; Iterator i$ = this.headers.entrySet().iterator(); Entry entry; while (i$.hasNext()) &#123; entry = (Entry) i$.next(); con.setRequestProperty((String) entry.getKey(), (String) entry.getValue()); &#125; i$ = extraHeaders.entrySet().iterator(); while (i$.hasNext()) &#123; entry = (Entry) i$.next(); con.setRequestProperty((String) entry.getKey(), (String) entry.getValue()); &#125; // 设置请求数据类型固定为 application/json-rpc con.setRequestProperty(\"Content-Type\", \"application/json-rpc\"); return con; &#125; JsonRpcHttpClient.invoke() 方法流程主要完成 JDK HTTP连接的创建， 响应数据的读取，以及反序列化数据。请求的数据的封装和发送是又其父类 JsonRpcClient 完成。 发起调用12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697+--- JsonRpcClient /** * 执行调用 * * @param methodName 方法名，如：getUser * @param argument 方法参数值 * @param ops 连接的输出流对象 * @throws IOException */ public void invoke(String methodName, Object argument, OutputStream ops) throws IOException &#123; // 这里会生成一个调用id this.invoke(methodName, argument, ops, this.random.nextLong() + \"\"); &#125; /** * @param methodName * @param argument * @param ops * @param id 当前调用的唯一标识别 * @throws IOException */ public void invoke(String methodName, Object argument, OutputStream ops, String id) throws IOException &#123; this.writeRequest(methodName, argument, ops, id); ops.flush(); &#125; // 发送请求 public void writeRequest(String methodName, Object argument, OutputStream ops, String id) throws IOException &#123; // 内部发送请求 this.internalWriteRequest(methodName, argument, ops, id); &#125; private void internalWriteRequest(String methodName, Object arguments, OutputStream ops, String id) throws IOException &#123; // 1 构造请求对象 ObjectNode request = this.mapper.createObjectNode(); // 1.1 id if (id != null) &#123; request.put(\"id\", id); &#125; // 1.2 jsonrpc request.put(\"jsonrpc\", \"2.0\"); // 1.3 method request.put(\"method\", methodName); // 1.4 params ArrayNode paramsNode; // 1.4.1 数组 if (arguments != null &amp;&amp; arguments.getClass().isArray()) &#123; Object[] args = (Object[]) Object[].class.cast(arguments); if (args.length &gt; 0) &#123; paramsNode = new ArrayNode(this.mapper.getNodeFactory()); Object[] arr$ = args; int len$ = args.length; for (int i$ = 0; i$ &lt; len$; ++i$) &#123; Object arg = arr$[i$]; JsonNode argNode = this.mapper.valueToTree(arg); paramsNode.add(argNode); &#125; request.put(\"params\", paramsNode); &#125; // 1.4.2 集合 &#125; else if (arguments != null &amp;&amp; Collection.class.isInstance(arguments)) &#123; Collection&lt;?&gt; args = (Collection) Collection.class.cast(arguments); if (!args.isEmpty()) &#123; paramsNode = new ArrayNode(this.mapper.getNodeFactory()); Iterator i$ = args.iterator(); while (i$.hasNext()) &#123; Object arg = i$.next(); JsonNode argNode = this.mapper.valueToTree(arg); paramsNode.add(argNode); &#125; request.put(\"params\", paramsNode); &#125; // 1.4.3 Map &#125; else if (arguments != null &amp;&amp; Map.class.isInstance(arguments)) &#123; if (!((Map) Map.class.cast(arguments)).isEmpty()) &#123; request.put(\"params\", this.mapper.valueToTree(arguments)); &#125; &#125; else if (arguments != null) &#123; request.put(\"params\", this.mapper.valueToTree(arguments)); &#125; if (this.requestListener != null) &#123; this.requestListener.onBeforeRequestSent(this, request); &#125; if (LOGGER.isLoggable(Level.FINE)) &#123; LOGGER.log(Level.FINE, \"JSON-PRC Request: \" + request.toString()); &#125; // 2 使用连接的输出流将请求数据写出去（发送到对端） this.writeAndFlushValue(ops, request); &#125; private void writeAndFlushValue(OutputStream ops, Object value) throws IOException &#123; // 将请求对象序列化，然后写出去 this.mapper.writeValue(new NoCloseOutputStream(ops), value); ops.flush(); &#125; 源码实现 HTTP 协议实现相关的代码结构如上图所示。 HttpProtocol属性123456789101112131415161718192021222324252627public class HttpProtocol extends AbstractProxyProtocol &#123; // 跨域支持 public static final String ACCESS_CONTROL_ALLOW_ORIGIN_HEADER = \"Access-Control-Allow-Origin\"; public static final String ACCESS_CONTROL_ALLOW_METHODS_HEADER = \"Access-Control-Allow-Methods\"; public static final String ACCESS_CONTROL_ALLOW_HEADERS_HEADER = \"Access-Control-Allow-Headers\"; /** * 服务路径（path）到 JsonRpcServer 的映射 * 请求处理过程说明：HttpServer -&gt; DispatcherServlet -&gt; InternalHandler -&gt; JsonRpcServer */ private final Map&lt;String, JsonRpcServer&gt; skeletonMap = new ConcurrentHashMap&lt;&gt;(); // HTTP绑定器 private HttpBinder httpBinder; public HttpProtocol() &#123; super(HttpException.class, JsonRpcClientException.class); &#125; // HttpBinder$Adaptive 对象,通过 &#123;@link #setHttpBinder(HttpBinder)&#125;方法，Dubbo SPI IOC注入 public void setHttpBinder(HttpBinder httpBinder) &#123; this.httpBinder = httpBinder; &#125; @Override public int getDefaultPort() &#123; return 80; &#125;&#125; 服务暴露12345678910111213141516171819202122232425262728293031323334+--- HttpProtocol @Override protected &lt;T&gt; Runnable doExport(final T impl, Class&lt;T&gt; type, URL url) throws RpcException &#123; // 1 获取服务器地址 ip:port String addr = getAddr(url); // 2 根据地址从缓存中获得 HTTP 服务，若不存在，进行创建 ProtocolServer protocolServer = serverMap.get(addr); if (protocolServer == null) &#123; /** * 1 通过SPI机制获取具体的 HttpBinder的拓展实现 * 2 具体的HttpBinder实现调用bind方法： * 1）启动服务 * 2）为服务设置请求处理器(InternalHandler对象)，支持设置跨域参数 * 3 缓存 HTTP 服务 */ RemotingServer remotingServer = httpBinder.bind(url, new InternalHandler(url.getParameter(\"cors\", false))); serverMap.put(addr, new ProxyProtocolServer(remotingServer)); &#125; // 3 获取 url 的 path ，以此为 key 缓存 JsonRpcServer。如：/org.apache.dubbo.demo.GreetingService final String path = url.getAbsolutePath(); // 4 支持泛化，如：/org.apache.dubbo.demo.GreetingService/generic final String genericPath = path + \"/\" + GENERIC_KEY; // 5 创建 JsonRpcServer，暴露服务 JsonRpcServer skeleton = new JsonRpcServer(impl, type); JsonRpcServer genericServer = new JsonRpcServer(impl, GenericService.class); // 6 分别缓存服务和泛化服务的 JsonRpcServer skeletonMap.put(path, skeleton); skeletonMap.put(genericPath, genericServer); return () -&gt; &#123; skeletonMap.remove(path); skeletonMap.remove(genericPath); &#125;; &#125; HTTP 处理器1234567891011121314151617181920212223242526272829303132333435363738394041424344+--- HttpProtocolprivate class InternalHandler implements HttpHandler &#123; /** * 是否跨域支持 */ private boolean cors; public InternalHandler(boolean cors) &#123; this.cors = cors; &#125; @Override public void handle(HttpServletRequest request, HttpServletResponse response) throws ServletException &#123; // 1 获取请求的uri String uri = request.getRequestURI(); // 2 从缓存中取出请求uri 对应的 JsonRpcServer JsonRpcServer skeleton = skeletonMap.get(uri); // 3 处理跨域 if (cors) &#123; response.setHeader(ACCESS_CONTROL_ALLOW_ORIGIN_HEADER, \"*\"); response.setHeader(ACCESS_CONTROL_ALLOW_METHODS_HEADER, \"POST\"); response.setHeader(ACCESS_CONTROL_ALLOW_HEADERS_HEADER, \"*\"); &#125; // 4 响应跨域探测请求 if (request.getMethod().equalsIgnoreCase(\"OPTIONS\")) &#123; response.setStatus(200); // 5 必须是 POST 请求 &#125; else if (request.getMethod().equalsIgnoreCase(\"POST\")) &#123; // 设置远程调用地址 RpcContext.getContext().setRemoteAddress(request.getRemoteAddr(), request.getRemotePort()); try &#123; // 处理请求 skeleton.handle(request.getInputStream(), response.getOutputStream()); &#125; catch (Throwable e) &#123; throw new ServletException(e); &#125; // 请求方法不匹配直接抛出 500 &#125; else &#123; response.setStatus(500); &#125; &#125; &#125; 服务引用1234567891011121314151617181920212223242526272829303132333435363738+--- HttpProtocol @Override protected &lt;T&gt; T doRefer(final Class&lt;T&gt; serviceType, URL url) throws RpcException &#123; // 1 判断是否是泛化调用 final String generic = url.getParameter(GENERIC_KEY); final boolean isGeneric = ProtocolUtils.isGeneric(generic) || serviceType.equals(GenericService.class); // 2 工厂对象 JsonProxyFactoryBean jsonProxyFactoryBean = new JsonProxyFactoryBean(); JsonRpcProxyFactoryBean jsonRpcProxyFactoryBean = new JsonRpcProxyFactoryBean(jsonProxyFactoryBean); // 3 附加属性和泛化调用支持 jsonRpcProxyFactoryBean.setRemoteInvocationFactory((methodInvocation) -&gt; &#123; RemoteInvocation invocation = new JsonRemoteInvocation(methodInvocation); // 泛化调用 if (isGeneric) &#123; invocation.addAttribute(GENERIC_KEY, generic); &#125; return invocation; &#125;); // 4 服务访问路径，如 http://10.1.31.48:80/org.apache.dubbo.demo.DemoService String key = url.setProtocol(\"http\").toIdentityString(); // 5 泛化调用服务访问路径，如: http://10.1.31.48:80/org.apache.dubbo.demo.DemoService/generic if (isGeneric) &#123; key = key + \"/\" + GENERIC_KEY; &#125; // 6.1 设置服务访问路径，设置到 jsonProxyFactoryBean 中 jsonRpcProxyFactoryBean.setServiceUrl(key); // 6.2 设置服务接口，设置到 jsonProxyFactoryBean 中 jsonRpcProxyFactoryBean.setServiceInterface(serviceType); // 6.3 执行Spring的InitializingBean方法， 创建 JsonRpcHttpClient &amp; 接口代理对象 jsonProxyFactoryBean.afterPropertiesSet(); // 7 返回接口的代理对象，拦截功能是 MethodInterceptor，基于aopalliance提供AOP的拦截处理机制。 // 在执行接口的目标方法时，会进行拦截，执行 com.googlecode.jsonrpc4j.spring.JsonProxyFactoryBean.invoke 方法，进而使用 JsonRpcHttpClient 进行远程调用 return (T) jsonProxyFactoryBean.getObject(); &#125; 创建 JsonRpcHttpClient &amp; 接口代理对象12345678910111213141516171819202122232425262728293031323334353637383940+--- public class JsonProxyFactoryBean extends UrlBasedRemoteAccessor implements MethodInterceptor, InitializingBean, FactoryBean&lt;Object&gt;, ApplicationContextAware @Override @SuppressWarnings(\"unchecked\") public void afterPropertiesSet() &#123; super.afterPropertiesSet(); // 1 创建接口代理对象，拦截增强使用 MethodInterceptor proxyObject = ProxyFactory.getProxy(getServiceInterface(), this); // find the ObjectMapper if (objectMapper == null &amp;&amp; applicationContext != null &amp;&amp; applicationContext.containsBean(\"objectMapper\")) &#123; objectMapper = (ObjectMapper) applicationContext.getBean(\"objectMapper\"); &#125; if (objectMapper == null &amp;&amp; applicationContext != null) &#123; try &#123; objectMapper = (ObjectMapper)BeanFactoryUtils .beanOfTypeIncludingAncestors(applicationContext, ObjectMapper.class); &#125; catch (Exception e) &#123; /* no-op */ &#125; &#125; if (objectMapper==null) &#123; objectMapper = new ObjectMapper(); &#125; // 2 创建 JsonRpcHttpClient try &#123; jsonRpcHttpClient = new JsonRpcHttpClient(objectMapper, new URL(getServiceUrl()), extraHttpHeaders); jsonRpcHttpClient.setRequestListener(requestListener); jsonRpcHttpClient.setSslContext(sslContext); jsonRpcHttpClient.setHostNameVerifier(hostNameVerifier); &#125; catch (MalformedURLException mue) &#123; throw new RuntimeException(mue); &#125; &#125; 拦截增强123456789101112131415161718192021222324252627282930313233+--- public class JsonProxyFactoryBean extends UrlBasedRemoteAccessor implements MethodInterceptor, InitializingBean, FactoryBean&lt;Object&gt;, ApplicationContextAware /** * &#123;@inheritDoc&#125; */ public Object invoke(MethodInvocation invocation) throws Throwable &#123; // 1 handle toString() Method method = invocation.getMethod(); if (method.getDeclaringClass() == Object.class &amp;&amp; method.getName().equals(\"toString\")) &#123; return proxyObject.getClass().getName() + \"@\" + System.identityHashCode(proxyObject); &#125; // 2 get return type Type retType = (invocation.getMethod().getGenericReturnType() != null) ? invocation.getMethod().getGenericReturnType() : invocation.getMethod().getReturnType(); // 3 get arguments Object arguments = ReflectionUtil.parseArguments( invocation.getMethod(), invocation.getArguments(), useNamedParams); // 4 invoke it return jsonRpcHttpClient.invoke( invocation.getMethod().getName(), arguments, retType, extraHttpHeaders); &#125; 以切面的方式对目标方法进行拦截，进而使用 JsonRpcHttpClient 调用远程服务方法。 销毁12345678910111213141516171819+--- HttpProtocol @Override public void destroy() &#123; super.destroy(); // 关闭服务 for (String key : new ArrayList&lt;&gt;(serverMap.keySet())) &#123; ProtocolServer server = serverMap.remove(key); if (server != null) &#123; try &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Close jsonrpc server \" + server.getUrl()); &#125; server.close(); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; &#125; &#125; &#125; 其它HTTP 绑定器、HTTP 调度器、HTTP 服务器 和 Dubbo 2.6.x 中的一致。 HTTP 报文信息 从 Dubbo 2.7.x 中的 HTTP 报文体的组织和序列化方式可以看出，相比 Spring 的 HttpInvoker ，使用 JSON-RPC 协议更加适合跨语言调用，更适合戴上 http 协议的帽子。 小结本篇文章介绍了 Dubbo 不同版本中 HTTP协议的实现，从协议名来看这是支持通用调用的协议，但是真正地实现并非如此。基于 HTTTP 表单的远程调用协议采用了 Spring 的 HttpInvoker 实现，序列化使用 Java 语言的序列化技术，远程调用逻辑由 Spring 封装，这显然失去了跨语言的能力。为了实现跨语言调用，Dubbo 转而使用 HTTP协议 + JSON-RPC 的方案，这依赖 HTTP 协议 和 JSON 都是跨语言的标准，几乎在各种语言中都有成熟的类库。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"Protocol","slug":"Protocol","permalink":"https://gentryhuang.com/tags/Protocol/"}]},{"title":"Dubbo源码分析 - Dubbo协议","slug":"rpc/Dubbo协议","date":"2020-08-29T16:00:00.000Z","updated":"2021-03-11T14:49:25.093Z","comments":false,"path":"posts/a064181a/","link":"","permalink":"https://gentryhuang.com/posts/a064181a/","excerpt":"","text":"前言在 多协议概览 中，我们对 Dubbo 的协议的两大分支从抽象层面进行了介绍，本篇文章将对 Dubbo 协议进行详细分析。 概述Dubbo 框架缺省协议就是 Dubbo 协议，该协议采用单一长连接和 NIO 异步通讯，适合于小数据量大并发的服务调用，以及服务消费者机器数远大于服务提供者机器数的情况。Dubbo 协议调用简化图如下： Transporter: mina, netty, grizzy Serialization: dubbo, hessian2, java, json Dispatcher: all, direct, message, execution, connection ThreadPool: fixed, cached,limited,eager 特性 连接个数：单一连接连接方式：长连接传输协议：TCP传输方式：NIO 异步传输序列化：默认采用 Hessian 二进制序列化适用范围：传入传出参数数据包较小（建议小于100K），消费者比提供者个数多，单一消费者无法压满提供者，尽量不要用 dubbo 协议传输大文件或超大字符串。 问题 为什么要消费者比提供者个数多？ 因为 Dubbo 协议采用单一长连接，每条连接数据压网卡的字节数据量是一定的，理论上一个服务提供者需要多个服务消费者才能压满网卡。 为什么不能传大包？ 因为 Dubbo 协议采用单一长连接，如果每次请求的数据包太大，单个服务提供者的 TPS 会降低，因为网络带宽是一定的。此外，单个消费者调用单个服务提供者的 TPS 也会随着请求包变大而降低。 为什么采用异步单一长连接？ 通过单一连接保证单一消费者不会压垮提供者；长连接减少连接握手验证等；使用异步 IO 复用线程池，防止 C10K 问题。 Dubbo 协议 QA不使用 HTTP 的原因: 在设计 RPC 的时候，为了高性能和吞吐量，基于 TCP 性能更快。 一般 RPC 为了吞吐量，会异步发送请求，等待响应，所以需要知道哪个应答对应哪个请求，而 HTTP 属于无状态协议，无法实现请求跟响应关联。 版本不是很低的 HTTP 都支持 Keep-Alive 链接，可以避免了链接重复创建开销，也能支持长连接，但是目前应用 HTTP 更多是使用短连接。 Dubbo 协议现存问题: Dubbo 协议是直接定义在 TCP 传输层协议之上，由于 TCP 高可靠全双工的特点，为 Dubbo 协议的定义提供了最大的灵活性，但同时也正是因为这样的灵活性，RPC 协议普遍都是定制化的私有协议，Dubbo 同样也面临这个问题。 相比于直接构建与 TPC 传输层的私有 RPC 协议，构建于 HTTP 之上的远程调用解决方案会有更好的通用性，如 WebServices 或 REST 架构，使用 HTTP + JSON 可以说是一个事实标准的解决方案。之所以选择构建在 HTTP 之上，有两大的优势： HTTP 的语义和可扩展性能很好的满足 RPC 调用需求。 - 扩展性 通用性，HTTP 协议几乎被网络上的所有设备所支持，具有很好的协议穿透性。- 通用性 优化点： Dubbo 协议体 Body 中有一个可扩展的 attachments 部分，这给 RPC 方法之外额外传递附加属性提供了可能，是一个很好的设计。但是类似的 Header 部分，却缺少类似的可扩展 attachments，这点可参考 HTTP 定义的 Ascii Header 设计，将 Body Attachments 和 Header Attachments 做职责划分。 Body 协议体中的一些 RPC 请求定位符如 Service Name、Method Name、Version 等，可以提到 Header 中，和具体的序列化协议解耦，以更好的被网络基础设施识别或用于流量管控。 扩展性不够好，欠缺协议升级方面的设计，如 Header 头中没有预留的状态标识位，或者像 HTTP 有专为协议升级或协商设计的特殊 packet。协议头要支持可扩展，可以定义一个扩展字段用于存放扩展信息，扩展后的协议头的长度就不能固定了，可以在协议头中加入一个标识头长度的字段。 Dubbo 协议设计上没有足够的前瞻性，但周边也有不少配件组件，如 dubbo2.js、dubbo-go、dubbo-cpp 等，在一定程度上解决了多语言问题。关于 Dubbo 协议具体可以参考 编解码器 中的介绍。 DubboProtocol属性1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class DubboProtocol extends AbstractProtocol &#123; /** * 协议名 */ public static final String NAME = \"dubbo\"; /** * 协议默认端口 */ public static final int DEFAULT_PORT = 20880; /** * 参数回调用相关字段 */ private static final String IS_CALLBACK_SERVICE_INVOKE = \"_isCallBackServiceInvoke\"; /** * DubboProtocol */ private static DubboProtocol INSTANCE; /** * 通信服务集合 * key: 服务器地址。格式：host:port * value: ExchangeServer 信息交换服务接口 */ private final Map&lt;String, ExchangeServer&gt; serverMap = new ConcurrentHashMap&lt;String, ExchangeServer&gt;(); /** * 通信连接集合 * key: 服务器地址 格式：host:port * value: 客户端 */ private final Map&lt;String, ReferenceCountExchangeClient&gt; referenceClientMap = new ConcurrentHashMap&lt;String, ReferenceCountExchangeClient&gt;(); /** * 通信连接集合 - 延迟连接的创建 * key: 服务器地址 格式:host:port * value: 客户端 */ private final ConcurrentMap&lt;String, LazyConnectExchangeClient&gt; ghostClientMap = new ConcurrentHashMap&lt;String, LazyConnectExchangeClient&gt;(); /** * 用于jvm 锁集合 */ private final ConcurrentMap&lt;String, Object&gt; locks = new ConcurrentHashMap&lt;String, Object&gt;(); /** * 已初始化的 SerializationOptimizer 实现类名的集合 * 用于序列化优化 */ private final Set&lt;String&gt; optimizers = new ConcurrentHashSet&lt;String&gt;(); //consumer side export a stub service for dispatching event 和本地存根相关 private final ConcurrentMap&lt;String, String&gt; stubServiceMethodsMap = new ConcurrentHashMap&lt;String, String&gt;(); public DubboProtocol() &#123; INSTANCE = this; &#125; public static DubboProtocol getDubboProtocol() &#123; if (INSTANCE == null) &#123; // dubbo SPI 获取 DubboProtocl ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(DubboProtocol.NAME); &#125; return INSTANCE; &#125;&#125; DubboProtocol中的属性包括以下几个方面的信息： Dubbo 协议的默认端口、Protocol 扩展实现 Dubbo 协议下的服务器和客户端缓存 序列化优化器实现 服务暴露1234567891011121314151617181920212223242526272829303132333435+--- DubboProtocol @Override public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; // 1 获取URL URL url = invoker.getUrl(); //2 服务暴露 //2.1 获取服务键,如：demoGroup/com.alibaba.dubbo.demo.DemoService:1.0.0:20880 String key = serviceKey(url); //2.2 将上层传入的 Invoker 对象封装成 DubboExporter 对象 DubboExporter&lt;T&gt; exporter = new DubboExporter&lt;T&gt;(invoker, key, exporterMap); //2.3 缓存 DubboExporter 到父类AbstractProtocol Map缓存中,相同则覆盖 exporterMap.put(key, exporter); //export an stub service for dispatching event 和本地存根有关 Boolean isStubSupportEvent = url.getParameter(Constants.STUB_EVENT_KEY, Constants.DEFAULT_STUB_EVENT); // 参数回调相关 Boolean isCallbackservice = url.getParameter(Constants.IS_CALLBACK_SERVICE, false); if (isStubSupportEvent &amp;&amp; !isCallbackservice) &#123; String stubServiceMethods = url.getParameter(Constants.STUB_EVENT_METHODS_KEY); if (stubServiceMethods == null || stubServiceMethods.length() == 0) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(new IllegalStateException(\"consumer [\" + url.getParameter(Constants.INTERFACE_KEY) + \"], has set stubproxy support event ,but no stub methods founded.\")); &#125; &#125; else &#123; stubServiceMethodsMap.put(url.getServiceKey(), stubServiceMethods); &#125; &#125; // 3 启动服务器 openServer(url); // 4 优化序列化 optimizeSerialization(url); // 5 将 Invoker 以 Exporter 形式暴露出去 return exporter; &#125; DubboProtcol 直接实现了 Protocol 的服务暴露接口，因为 AbstractProtocol 并没有对服务暴露接口进行实现。Dubbo 协议下的服务暴露核心就两点，将具有服务能力的 Invoker 封装成 DubboExporter，接着启动 NIO服务器 用于接收请求。 下面分别对启动服务和优化序列化部分详细分析。 启动NIO服务1234567891011121314151617181920212223+--- DubboProtocol private void openServer(URL url) &#123; // 获取 host:port，并将其作为服务器实例缓存 key，用于标识当前的服务起实例 String key = url.getAddress(); // 参数配置项 isserver，只有Server端才能启动Server对象 boolean isServer = url.getParameter(Constants.IS_SERVER_KEY, true); // 只有Server端才能启动Server对象 if (isServer) &#123; // 从serverMap缓存中获取服务器 ExchangeServer server = serverMap.get(key); // 无 Server监听该地址 if (server == null) &#123; // 不存在则创建 Server serverMap.put(key, createServer(url)); &#125; else &#123; // 如果已有 Server 实例，则尝试根据URL信息重置 Server // com.alibaba.dubbo.remoting.transport.AbstractServer.reset server.reset(url); &#125; &#125; &#125; 创建并启动服务是以 Dubbo 的主机绑定结果 host:port 进行的，并且同一台服务器同一个端口上仅允许启动一个服务器实例，若某个端口上已有服务器实例，此时reset方法就会调用，重置服务器的一些配置。 123456789101112131415161718192021222324252627282930313233343536373839+--- DubboProtocol private ExchangeServer createServer(URL url) &#123; // 1 默认开启 在 Server 关闭的时候，只能发送 ReadOnly 请求 url = url.addParameterIfAbsent(Constants.CHANNEL_READONLYEVENT_SENT_KEY, Boolean.TRUE.toString()); // 2 默认开启 心跳 【heartbeat参数会在HeaderExchangeServer启动心跳计时器使用】,默认值为 60000，表示默认的心跳时间间隔为 60 秒 url = url.addParameterIfAbsent(Constants.HEARTBEAT_KEY, String.valueOf(Constants.DEFAULT_HEARTBEAT)); // 3 检测SERVER_KEY参数指定的Transporter扩展实现是否合法, 即Dubbo SPI扩展是否存在，默认是Netty String str = url.getParameter(Constants.SERVER_KEY, Constants.DEFAULT_REMOTING_SERVER); if (str != null &amp;&amp; str.length() &gt; 0 &amp;&amp; !ExtensionLoader.getExtensionLoader(Transporter.class).hasExtension(str)) &#123; throw new RpcException(\"Unsupported server type: \" + str + \", url: \" + url); &#125; // 4 设置编码解码器参数 ，默认为 DubboCountCodec url = url.addParameter(Constants.CODEC_KEY, DubboCodec.NAME); // 5 创建、启动服务器 ExchangeServer server; try &#123; // 5.1 通过Exchangers门面类，创建ExchangeServer对象。 // 需要传入 ExchangeHandler 对象，该对象用于处理通道相关事件 server = Exchangers.bind(url, requestHandler); &#125; catch (RemotingException e) &#123; throw new RpcException(\"Fail to start server(url: \" + url + \") \" + e.getMessage(), e); &#125; // 6 校验Client 的 Dubbo SPI拓展是否存在。可指定netty,mina str = url.getParameter(Constants.CLIENT_KEY); if (str != null &amp;&amp; str.length() &gt; 0) &#123; // 获取所有的Transporter 实现类名称集合，比如 netty,mina Set&lt;String&gt; supportedTypes = ExtensionLoader.getExtensionLoader(Transporter.class).getSupportedExtensions(); // 检测当前Dubbo 所支持的Transporter实现类名称列表中是否包含client所表示的 Transporter ，若不包含则抛出异常 if (!supportedTypes.contains(str)) &#123; throw new RpcException(\"Unsupported client type: \" + str); &#125; &#125; return server; &#125; DubboProtol 在创建并启动 NIO服务器 之前，会为 URL 添加功能参数： 1 channel.readonly.sent: 开启 在 Server 关闭的时候只能发送 ReadOnly 请求2 heartbeat: 开启心跳，默认值为 60000 ，表示默认的心跳时间间隔为 60 s3 codec: 设置编解码器，默认为 DubboCountCodec 功能参数设置完毕后，通过信息交换层的 Exchangers 门面类创建 ExchangeServer 对象，并传入通道处理器 ExchangeHandler 对象。关于信息交换层的介绍可以参考 信息交换层 一文。下面我们来看看 DubboProtocol 的通道处理器实现。 通道处理器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149+--- DubboProtocol private ExchangeHandler requestHandler = new ExchangeHandlerAdapter() &#123; /** * 处理服务消费者的 同步调用和异步调用的请求 * * @param channel * @param message * @return * @throws RemotingException */ @Override public Object reply(ExchangeChannel channel, Object message) throws RemotingException &#123; // 判断消息类型。其实，经过前面的 Hander 处理后这里收到的 Message 必须是 Invocation 类型的对象 if (message instanceof Invocation) &#123; Invocation inv = (Invocation) message; /** * 获取此次调用的Invoker： * 1 先获取 Exporter （在服务暴露时就已经初始化好了） * 2 从 exporter 中获取 Invoker */ Invoker&lt;?&gt; invoker = getInvoker(channel, inv); /** * 如果是参数回调： * 1 需要处理高版本调用低版本的问题 * 2 校验服务消费者实际存在对应的回调方法，通过方法名判断 */ if (Boolean.TRUE.toString().equals(inv.getAttachments().get(IS_CALLBACK_SERVICE_INVOKE))) &#123; String methodsStr = invoker.getUrl().getParameters().get(\"methods\"); boolean hasMethod = false; if (methodsStr == null || methodsStr.indexOf(\",\") == -1) &#123; hasMethod = inv.getMethodName().equals(methodsStr); &#125; else &#123; String[] methods = methodsStr.split(\",\"); for (String method : methods) &#123; if (inv.getMethodName().equals(method)) &#123; hasMethod = true; break; &#125; &#125; &#125; if (!hasMethod) &#123; logger.warn(new IllegalStateException(\"The methodName \" + inv.getMethodName() + \" not found in callback service interface ,invoke will be ignored.\" + \" please update the api interface. url is:\" + invoker.getUrl()) + \" ,invocation is :\" + inv); return null; &#125; &#125; // 设置调用方的地址，即将消费方地址记录到 RpcContext 中 RpcContext.getContext().setRemoteAddress(channel.getRemoteAddress()); /** * 执行调用 * 1 执行 Filter链 ：EchoFilter-&gt;ClassLoaderFilter-&gt;GenericFilter-&gt;ContextFilter-&gt;TraceFilter-&gt;TimeoutFilter-&gt;MonitorFilter-&gt;ExceptionFilter -&gt; Invoker逻辑 * 2 然后执行真正的Invoker的调用逻辑：AbstractProxyInvoker.invoke -&gt; JavassistProxyFactory$AbstractProxyInvoker.doInvoke -&gt; Wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments) -&gt; ref.xxxYYY方法 */ return invoker.invoke(inv); &#125; throw new RemotingException(channel, \"Unsupported request: \" + (message == null ? null : (message.getClass().getName() + \": \" + message)) + \", channel: consumer: \" + channel.getRemoteAddress() + \" --&gt; provider: \" + channel.getLocalAddress()); &#125; /** *处理读取到的数据 * * @param channel * @param message * @throws RemotingException */ @Override public void received(Channel channel, Object message) throws RemotingException &#123; // 判断消息类型是不是 Invocation if (message instanceof Invocation) &#123; reply((ExchangeChannel) channel, message); &#125; else &#123; super.received(channel, message); &#125; &#125; //---------------- 以下是对设置的 onconnect 和 ondisconnect 方法的处理 -----------------/ /** * 在服务提供者上可以配置 onconnect 配置项指定连接上服务时会调用的方法 - 不是很重要 * @param channel * @throws RemotingException */ @Override public void connected(Channel channel) throws RemotingException &#123; invoke(channel, Constants.ON_CONNECT_KEY); &#125; /** * 在服务提供者上可以配置 'ondisconnect' 配置项指定方法，在服务提供者连接断开时会调用该方法 - 不是很重要 * * @param channel * @throws RemotingException */ @Override public void disconnected(Channel channel) throws RemotingException &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"disconnected from \" + channel.getRemoteAddress() + \",url:\" + channel.getUrl()); &#125; invoke(channel, Constants.ON_DISCONNECT_KEY); &#125; /** * 进行调用，执行对应的方法 * * @param channel 通道 * @param methodKey 方法名 */ private void invoke(Channel channel, String methodKey) &#123; // 创建调用信息 Invocation 对象 Invocation invocation = createInvocation(channel, channel.getUrl(), methodKey); // 如果 invocation 不为空，执行received方法 if (invocation != null) &#123; try &#123; received(channel, invocation); &#125; catch (Throwable t) &#123; logger.warn(\"Failed to invoke event method \" + invocation.getMethodName() + \"(), cause: \" + t.getMessage(), t); &#125; &#125; &#125; /** * 创建 Invocation * @param channel * @param url * @param methodKey * @return */ private Invocation createInvocation(Channel channel, URL url, String methodKey) &#123; String method = url.getParameter(methodKey); if (method == null || method.length() == 0) &#123; return null; &#125; RpcInvocation invocation = new RpcInvocation(method, new Class&lt;?&gt;[0], new Object[0]); invocation.setAttachment(Constants.PATH_KEY, url.getPath()); invocation.setAttachment(Constants.GROUP_KEY, url.getParameter(Constants.GROUP_KEY)); invocation.setAttachment(Constants.INTERFACE_KEY, url.getParameter(Constants.INTERFACE_KEY)); invocation.setAttachment(Constants.VERSION_KEY, url.getParameter(Constants.VERSION_KEY)); if (url.getParameter(Constants.STUB_EVENT_KEY, false)) &#123; invocation.setAttachment(Constants.STUB_EVENT_KEY, Boolean.TRUE.toString()); &#125; return invocation; &#125; &#125;; DubboProtocol 中实现了信息交换层中的 ExchangeHandlerAdapter 通道处理器逻辑，服务消费者的远程调用是通过 #reply 方法处理的，该方法的核心逻辑如下： 根据连接信息和调用信息组装服务健，并根据服务健获取具有服务能力的 Invoker 对象。 如果设置了参数回调用，则对参数回调逻辑进行处理。关于参数回调内容会在 Dubbo 高级特性中介绍。 将调用方的地址即消费端地址记录到上下文中。 执行 Invoker.invoke 。 下面我们继续分析获取 Invoker 对象的方法。 服务端侧 Invoker1234567891011121314151617181920212223242526272829303132333435363738+--- DubboProtocol Invoker&lt;?&gt; getInvoker(Channel channel, Invocation inv) throws RemotingException &#123; boolean isCallBackServiceInvoke = false; boolean isStubServiceInvoke = false; // 获取端口 int port = channel.getLocalAddress().getPort(); // 从调用信息中国获取 path String path = inv.getAttachments().get(Constants.PATH_KEY); // 对客户端 Callback 的处理 isStubServiceInvoke = Boolean.TRUE.toString().equals(inv.getAttachments().get(Constants.STUB_EVENT_KEY)); if (isStubServiceInvoke) &#123; // 从Channel中获取 端口 port port = channel.getRemoteAddress().getPort(); &#125; // 参数回调处理，获得真正的服务名 `path` isCallBackServiceInvoke = isClientSide(channel) &amp;&amp; !isStubServiceInvoke; if (isCallBackServiceInvoke) &#123; path = inv.getAttachments().get(Constants.PATH_KEY) + \".\" + inv.getAttachments().get(Constants.CALLBACK_SERVICE_KEY); inv.getAttachments().put(IS_CALLBACK_SERVICE_INVOKE, Boolean.TRUE.toString()); &#125; // 获得服务键，格式： group/path:version:port // 根据 Invocation 携带的信息：attachments 中的path、group、version以及从channel中获取的port 计算服务健 String serviceKey = serviceKey(port, path, inv.getAttachments().get(Constants.VERSION_KEY), inv.getAttachments().get(Constants.GROUP_KEY)); // 根据服务健查找缓存的 DubboExporter DubboExporter&lt;?&gt; exporter = (DubboExporter&lt;?&gt;) exporterMap.get(serviceKey); // 没有对应的 Exporter，直接抛出异常 if (exporter == null) &#123; throw new RemotingException(channel, \"Not found exported service: \" + serviceKey + \" in \" + exporterMap.keySet() + \", may be version or group mismatch \" + \", channel: consumer: \" + channel.getRemoteAddress() + \" --&gt; provider: \" + channel.getLocalAddress() + \", message:\" + inv); &#125; // 取出Exporter中的Invoker 对象 return exporter.getInvoker(); &#125; 获取服务端侧 Invoker 就是根据 服务键 从缓存中取出服务暴露时存储在内存中的 Expoter 对象，进而从该 Expoter 中取出对应的 Invoker 对象。注意，服务键的 group、path、verison 都是从调用信息中获取的，因为调用方更清楚目标服务，而 port 部分则是通过通道获取的，调用方无需关心端口，提供方自己更加清楚。 优化序列化1234567891011121314151617181920212223242526272829303132333435363738394041424344private void optimizeSerialization(URL url) throws RpcException &#123; // 获得 optimizer 序列化优化器 配置项 String className = url.getParameter(Constants.OPTIMIZER_KEY, \"\"); // 如果系统中没有指定序列化优化器就直接返回 if (StringUtils.isEmpty(className) || optimizers.contains(className)) &#123; return; &#125; logger.info(\"Optimizing the serialization process for Kryo, FST, etc...\"); try &#123; // 根据 序列化优化器名 加载 SerializationOptimizer 实现类 Class clazz = Thread.currentThread().getContextClassLoader().loadClass(className); // 是否是 SerializationOptimizer.class，或者 是SerializationOptimizer 的子类 if (!SerializationOptimizer.class.isAssignableFrom(clazz)) &#123; throw new RpcException(\"The serialization optimizer \" + className + \" isn't an instance of \" + SerializationOptimizer.class.getName()); &#125; // 创建 SerializationOptimizer 对象 SerializationOptimizer optimizer = (SerializationOptimizer) clazz.newInstance(); // 没有要优化的类直接返回 if (optimizer.getSerializableClasses() == null) &#123; return; &#125; // 将要优化的类注册到 SerializableClassRegistry 中 // 在使用 Kryo,FST 等序列化算法时，会读取该集合中的类，完成注册. for (Class c : optimizer.getSerializableClasses()) &#123; SerializableClassRegistry.registerClass(c); &#125; // 将 序列化优化器实现类名 加入到缓存中 optimizers.add(className); &#125; catch (ClassNotFoundException e) &#123; throw new RpcException(\"Cannot find the serialization optimizer class: \" + className, e); &#125; catch (InstantiationException e) &#123; throw new RpcException(\"Cannot instantiate the serialization optimizer class: \" + className, e); &#125; catch (IllegalAccessException e) &#123; throw new RpcException(\"Cannot instantiate the serialization optimizer class: \" + className, e); &#125; &#125; 服务暴露时会进行序列化优化，通过自定义 SerializationOptimizer 对象将需要优化的类全部加入到该对象中即可。关于序列化的介绍可以参考 序列化优化器 一文。 服务暴露流程图 Dubbo 框架采用 Dubbo 协议进行服务发布的流程如上图所示。从 Protocol 协议层 的 openServer 方法会一路调用到 Exchange 信息交换层、Transport 网络传输层，最终创建并启动 Netty 服务 来接收客户端的请求。 领域模型DubboExpoter 是对服务端侧的 Invoker 的封装，服务端侧的 Invoker 内部封装了具体服务实现，具备服务能力。DubboExpoter 继承了 AbstractExpoter 抽象类，具体实现如下： 12345678910111213141516171819202122232425262728293031323334353637public class DubboExporter&lt;T&gt; extends AbstractExporter&lt;T&gt; &#123; /** * 服务键 */ private final String key; /** * Exporter 集合 * key : 服务键 * value: DubboProtocol 发布的服务 */ private final Map&lt;String, Exporter&lt;?&gt;&gt; exporterMap; /** * 封装 Invoker * * @param invoker Invoker * @param key 服务键 * @param exporterMap AbstractProtocol.exporterMap属性 */ public DubboExporter(Invoker&lt;T&gt; invoker, String key, Map&lt;String, Exporter&lt;?&gt;&gt; exporterMap) &#123; super(invoker); this.key = key; this.exporterMap = exporterMap; &#125; /** * 取消暴露 */ @Override public void unexport() &#123; // 取消暴露 super.unexport(); //清理该 DubboExporter 实例在 exporterMap 中相应的元素 exporterMap.remove(key); &#125;&#125; 服务引用1234567891011121314+--- DubboProtocol @Override public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; serviceType, URL url) throws RpcException &#123; // 1 初始化序列化优化器 optimizeSerialization(url); // 2 创建 DubboInvoker 对象 DubboInvoker&lt;T&gt; invoker = new DubboInvoker&lt;T&gt;(serviceType, url, getClients(url), invokers); // 3 添加到 invokers 缓存中 invokers.add(invoker); return invoker; &#125; DubboProtocol 直接实现了 Protocol 的服务引用接口。Dubbo 协议下的服务引用核心就一个，创建 DubboInvoker 对象，该对象会对 Client 进行封装，用于发送请求和接收响应。初始化序化优化器同服务暴露中的一致。 连接NIO服务器getClients 方法创建了底层发送请求和接收响应的 Client 集合，即创建客户端与服务端的长连接。其核心实现分为两部分，一个是针对共享连接的处理，另一个是针对独享连接的处理。实现逻辑如下： 123456789101112131415161718192021222324252627282930+--- DubboProtocolprivate ExchangeClient[] getClients(URL url) &#123; // 是否使用共享连接 boolean service_share_connect = false; // 获取 connections 配置项，该值决定了后续建立连接的数量。不配置的情况下默认为0，并使用共享连接的方式，建立一条共享连接。 int connections = url.getParameter(Constants.CONNECTIONS_KEY, 0); // 如果没有连接数的相关配置，默认使用共享连接的方式，且连接数为 1 // Dubbo 在 2.7 版本中支持共享连接数的配置 SHARE_CONNECTIONS_KEY if (connections == 0) &#123; service_share_connect = true; connections = 1; &#125; // 创建连接服务提供者的 ExchangeClient 对象数组 ExchangeClient[] clients = new ExchangeClient[connections]; for (int i = 0; i &lt; clients.length; i++) &#123; // 1 共享连接 if (service_share_connect) &#123; clients[i] = getSharedClient(url); // 2 取独享连接，connections 的值为多少就会创建几个独享连接，在调用时会轮流使用。 // 注意和 Dubbo 负载均衡的区别。 &#125; else &#123; clients[i] = initClient(url); &#125; &#125; return clients; &#125; ExchangeClient 实际上并不具有通信能力，通信能力依赖其封装的更底层客户端实例，如 NettyClient、MinaClient 等。 当使用独享连接时，针对每个服务（对应一个Service）创建固定数量的 Client ，每个 Client 维护一个底层连接。如下图所示，connections 配置项设置了 2 ，也就是针对每个 Service 都启动了两个独享连接。 当使用共享连接时，会根据节点地址（host:port），一个地址只创建固定数量的共享连接。如下图所示，shareconnections 配置项设置了 2，也就是针对每个服务节点都会创建两个共享连接，这两个共享连接被节点中的所有服务使用，如 Consumer 调用 Provider1 提供者中的多个服务时，是使用固定数量的共享长连接进行数据传输，这样就可以达到减少服务端连接的目的。 共享连接123456789101112131415161718192021222324252627282930313233343536373839404142434445+--- DubboProtocol private ExchangeClient getSharedClient(URL url) &#123; // 1 获取从注册中心拉取的服务提供者的地址（ip:port），连接服务自然需要知道服务地址 String key = url.getAddress(); // 2 从 referenceClientMap 中获取与该地址连接的带有引用记数功能的ExchangeClient ReferenceCountExchangeClient client = referenceClientMap.get(key); if (client != null) &#123; if (!client.isClosed()) &#123; /** 若未关闭，增加指向该Client 的数量 &#123;@link #refenceCount&#125; */ client.incrementAndGetCount(); return client; // 若已关闭，移除 &#125; else &#123; referenceClientMap.remove(key); &#125; &#125; // 新增锁对象 locks.putIfAbsent(key, new Object()); // 针对指定地址的客户端创建进行加锁，这里使用分区加锁可以提高并发度 synchronized (locks.get(key)) &#123; // double check if (referenceClientMap.containsKey(key)) &#123; return referenceClientMap.get(key); &#125; // 3 初始化 ExchangeClient 客户端 ExchangeClient exchangeClient = initClient(url); // 4 使用装饰者模式将initClient返回的HeaderExchangeClient实例或LazyConnectExchangeClient实例封装为ReferenceCountExchangeClient对象 // 注意，在使用共享连接时需要注意一个问题，如果两个以上的Invoker 共享这个连接的话，那么必须所有的Invoker 都关闭才能关闭连接。 client = new ReferenceCountExchangeClient(exchangeClient, ghostClientMap); // 5 添加到缓存集合 referenceClientMap.put(key, client); // 6 新建了ExchangeClient，不需要进行兜底，移除兜底集合 ghostClientMap 中的元素 ghostClientMap.remove(key); //将作为锁标识的元素从集合中移除 locks.remove(key); return client; &#125; &#125; 共享连接的创建是在独享连接创建的基础上进行的，共享连接的缓存基于对端地址（ip:port），同时共享连接的实现是 ReferenceCountExchangeClient，它是 ExchangeClient 的一个装饰器，在原始的 ExchangeClient 对象基础上添加了引用计数的功能。 客户端共享连接使用的客户端实现是 ReferenceCountExchangeClient ，它是对信息交换层的 ExchangeClient 接口的直接实现，是 ExchangeClient 的装饰器，在原始的 ExchangeClient 对象基础上添加了引用计数功能，用于共享连接模式。在介绍信息交换层的客户端时，其中的 HeaderExchangeClient 也是对 ExchangeClient 接口的直接实现，这里 ReferenceCountExchangeClient 装饰的 ExchangeClient 就是 HeaderExchangeClient 对象。Dubbo 协议客户端继承关系如下图所示： 下面对 ReferenceCountExchangeClient 进行介绍。 属性123456789101112131415161718192021222324252627282930313233343536final class ReferenceCountExchangeClient implements ExchangeClient &#123; /** * URL */ private final URL url; /** * 引用计数变量，用于记录 Client 被应用的次数。 每当该对象被引用一次refenceCount 都会进行自增。 每当close方法被调用时，referenceCount 就会进行自减 */ private final AtomicInteger refenceCount = new AtomicInteger(0); /** * 维护close掉的client，用于兜底。和 &#123;@link Protocol#ghostClentMap&#125; 一致 */ private final ConcurrentMap&lt;String, LazyConnectExchangeClient&gt; ghostClientMap; /** * 客户端 【类型是： HeaderExchangeClient】，被装饰对象 */ private ExchangeClient client; /** * 将HeaderExchangeClient 实例封装为ReferenceCountExchangeClient。 * * @param client * @param ghostClientMap */ public ReferenceCountExchangeClient(ExchangeClient client, ConcurrentMap&lt;String, LazyConnectExchangeClient&gt; ghostClientMap) &#123; this.client = client; // 引用计数递增 refenceCount.incrementAndGet(); this.url = client.getUrl(); if (ghostClientMap == null) &#123; throw new IllegalStateException(\"ghostClientMap can not be null, url: \" + url); &#125; this.ghostClientMap = ghostClientMap; &#125;&#125; ReferenceCountExchangeClient 中持有的 client 属性就是被装饰的信息交换层的客户端对象，refenceCount 属性用于记录该 Client 被引用的次数，在 ReferenceCountExchangeClient 的构造方法以及 incrementAndGetCount() 方法中会增加引用次数，在 close() 方法中则会减少引用次数。 1234567+--- ReferenceCountExchangeClient /** * 该方法一般由外部调用，引用计数递增 */ public void incrementAndGetCount() &#123; refenceCount.incrementAndGet(); &#125; 其它方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128+--- ReferenceCountExchangeClient // ----------- ExchangeChannel 接口方法实现 --------------/ @Override public ResponseFuture request(Object request) throws RemotingException &#123; return client.request(request); &#125; @Override public ResponseFuture request(Object request, int timeout) throws RemotingException &#123; return client.request(request, timeout); &#125; @Override public ExchangeHandler getExchangeHandler() &#123; return client.getExchangeHandler(); &#125; // ------------- Endpoint 接口方法实现 -----------------/ @Override public void send(Object message, boolean sent) throws RemotingException &#123; client.send(message, sent); &#125; @Override public void send(Object message) throws RemotingException &#123; client.send(message); &#125; @Override public URL getUrl() &#123; return client.getUrl(); &#125; @Override public ChannelHandler getChannelHandler() &#123; return client.getChannelHandler(); &#125; @Override public InetSocketAddress getLocalAddress() &#123; return client.getLocalAddress(); &#125; @Override public void reset(Parameters parameters) &#123; client.reset(parameters); &#125; @Override public void reset(URL url) &#123; client.reset(url); &#125; /** * close() is not idempotent any longer */ @Override public void close() &#123; close(0); &#125; /** * 引用次数减少到0时 ，ExchangeClient 连接关闭 * * @param timeout */ @Override public void close(int timeout) &#123; // 引用计数减一，若无指向，进行真正的关闭 if (refenceCount.decrementAndGet() &lt;= 0) &#123; if (timeout == 0) &#123; client.close(); &#125; else &#123; client.close(timeout); &#125; // 关闭ExchangeClient对象之后，会替换 client 为 LazyConnectExchangeClient 对象，即将关闭之后的连接变成一个懒加载的client client = replaceWithLazyClient(); &#125; &#125; @Override public void startClose() &#123; client.startClose(); &#125; @Override public boolean isClosed() &#123; return client.isClosed(); &#125; // ---- Channel 接口实现 ----------/ @Override public boolean isConnected() &#123; return client.isConnected(); &#125; @Override public Object getAttribute(String key) &#123; return client.getAttribute(key); &#125; @Override public boolean hasAttribute(String key) &#123; return client.hasAttribute(key); &#125; @Override public void setAttribute(String key, Object value) &#123; client.setAttribute(key, value); &#125; @Override public void removeAttribute(String key) &#123; client.removeAttribute(key); &#125; @Override public InetSocketAddress getRemoteAddress() &#123; return client.getRemoteAddress(); &#125; // --- Client 接口实现 ----------/ @Override public void reconnect() throws RemotingException &#123; client.reconnect(); &#125; 采用装饰器模式，每个方法的实现都是交给被装饰的 client 处理，也就是 HeaderExchangeClient 处理。以上方法实现来源于不同的接口或类，和 HeaderExchangeClient 中的实现几乎一致，看起来比较乱，但是追溯到最底层可以发现，这些方法几乎都是交给通道 Channel 来处理的，Client 只完成了重连的逻辑。 关闭12345678910111213141516171819202122232425262728293031323334353637383940+--- ReferenceCountExchangeClient @Override public void close(int timeout) &#123; // 引用计数减一，若无指向，进行真正的关闭 if (refenceCount.decrementAndGet() &lt;= 0) &#123; if (timeout == 0) &#123; client.close(); &#125; else &#123; client.close(timeout); &#125; // 关闭ExchangeClient对象之后，会替换 client 为 LazyConnectExchangeClient 对象，即将关闭之后的连接变成一个懒加载的client client = replaceWithLazyClient(); &#125; &#125; private LazyConnectExchangeClient replaceWithLazyClient() &#123; // 在原有的URL之上，添加一些LazyConnectExchangeClient特有的参数 URL lazyUrl = url.addParameter(Constants.LAZY_CONNECT_INITIAL_STATE_KEY, Boolean.FALSE) // 关闭重连 .addParameter(Constants.RECONNECT_KEY, Boolean.FALSE) .addParameter(Constants.SEND_RECONNECT_KEY, Boolean.TRUE.toString()) .addParameter(\"warning\", Boolean.TRUE.toString()) .addParameter(LazyConnectExchangeClient.REQUEST_WITH_WARNING_KEY, true) .addParameter(\"_client_memo\", \"referencecounthandler.replacewithlazyclient\"); // 从 ghostClientMap 缓存中查找 String key = url.getAddress(); // in worst case there's only one ghost connection. LazyConnectExchangeClient gclient = ghostClientMap.get(key); // 如果当前client字段已经指向了LazyConnectExchangeClient，则不需要再次创建 if (gclient == null || gclient.isClosed()) &#123; // ChannelHandler 依旧使用原始ExchangeClient使用的Handler，即DubboProtocol中的requestHandler字段 gclient = new LazyConnectExchangeClient(lazyUrl, client.getExchangeHandler()); ghostClientMap.put(key, gclient); &#125; return gclient; &#125; 从 ReferenceCountExchangeClient 关闭逻辑可以发现： 当引用次数减到 0 的时候，ExchangeClient 连接允许关闭。当引用次数未减到 0 的时候，底层的 ExchangeClient 不能关闭。 在关闭底层 ExchangeClient 对象之后，会立即创建一个 LazyConnectExchangeClient 对象，用于异常情况的兜底。这个连接的特点是在需要发送请求的时候才会进行 Client 的创建。 前文也提到，共享连接的创建是在独享连接的基础上，独享连接创建是通过 initClient 方法，而共享连接是以地址（host:port）作为标识将独享连接缓存，避免同一地址创建多条连接。下面我们就来分析独享连接的创建。 独享连接123456789101112131415161718192021222324252627282930313233343536+--- DubboProtocol private ExchangeClient initClient(URL url) &#123; // 1. 获取客户端类型，默认为netty。下面逻辑会检查该扩展 String str = url.getParameter(Constants.CLIENT_KEY, url.getParameter(Constants.SERVER_KEY, Constants.DEFAULT_REMOTING_CLIENT)); // 2. 设置编解码器Codec2的扩展名,即DubboCountCodec &#123;@link DubboCountCodec&#125; url = url.addParameter(Constants.CODEC_KEY, DubboCodec.NAME); // 3. 默认开启heartbeat,60 * 1000 url = url.addParameterIfAbsent(Constants.HEARTBEAT_KEY, String.valueOf(Constants.DEFAULT_HEARTBEAT)); // 校验配置的Client 的 Dubbo SPI拓展是否存在，若不存在，抛出RpcException if (str != null &amp;&amp; str.length() &gt; 0 &amp;&amp; !ExtensionLoader.getExtensionLoader(Transporter.class).hasExtension(str)) &#123; throw new RpcException(\"Unsupported client type: \" + str + \",\" + \" supported client type is \" + StringUtils.join(ExtensionLoader.getExtensionLoader(Transporter.class).getSupportedExtensions(), \" \")); &#125; // 4 连接服务器，创建客户端 ExchangeClient client; try &#123; // 4.1 如果配置了延迟创建连接的特性 if (url.getParameter(Constants.LAZY_CONNECT_KEY, false)) &#123; // 创建延迟建立连接的对象（在请求时才会初始化连接） client = new LazyConnectExchangeClient(url, requestHandler); // 4.2 未使用延迟连接功能，则通过Exchangers的 connect 方法创建 ExchangeClient 客户端，这里是 HeaderExchangeClient &#125; else &#123; client = Exchangers.connect(url, requestHandler); &#125; &#125; catch (RemotingException e) &#123; throw new RpcException(\"Fail to create remoting client for service(\" + url + \"): \" + e.getMessage(), e); &#125; return client; &#125; DubboProtocol 创建连接的流程如下： 对客户端扩展名进行校验，默认使用 netty 设置编解码器 Codec2 的扩展名，这里固定是 DubboCountCodec 设置心跳时间 连接NIO服务器，创建客户端。这里会根据是否设置延迟创建连接的特性创建不同的 Client 没有设置延迟创建连接的配置项时直接使用信息交换层的 Exchangers.connect 创建 HeaderExchangeClient 对象，否则创建 LazyConnectExchangeClient 对象，该对象不会立刻初始化连接而是在请求时才会初始化。 LazyConnectExchangeClientLazyConnectExchangeClient 同样是 ExchangeClient 的装饰器，它会在原有 ExchangeClient 对象的基础上添加延迟初始化连接的功能，即在发送请求的时候才会进行初始化。 属性1234567891011121314151617181920212223242526272829303132333435final class LazyConnectExchangeClient implements ExchangeClient &#123; private final static Logger logger = LoggerFactory.getLogger(LazyConnectExchangeClient.class); // 延迟连接告警配置项 static final String REQUEST_WITH_WARNING_KEY = \"lazyclient_request_with_warning\"; /** * 请求时，是否检查告警 */ protected final boolean requestWithWarning; /** * URL */ private final URL url; /** * 通道处理器 */ private final ExchangeHandler requestHandler; /** * 连接锁 */ private final Lock connectLock = new ReentrantLock(); /** * 懒连接初始化状态 */ private final boolean initialState; /** * 通信客户端 */ private volatile ExchangeClient client; /** * 警告计数器。每超过一定次数，打印告警日志。参见 &#123;@link #warning(Object)&#125; */ private AtomicLong warningcount = new AtomicLong(0);&#125; LazyConnectExchangeClient 中的 url 和 requestHandler 是创建对象的时候封装的属性，LazyConnectExchangeClient 在构造方法中不会创建底层持有连接的 Client，而是在需要发送请求的时候才会调用 initClient() 方法进行 Client 的创建。 构造方法123456789+--- LazyConnectExchangeClient public LazyConnectExchangeClient(URL url, ExchangeHandler requestHandler) &#123; // 延迟连接需要设置 send.reconnect 为 true，防止通道不良状态 this.url = url.addParameter(Constants.SEND_RECONNECT_KEY, Boolean.TRUE.toString()); this.requestHandler = requestHandler; // 懒连接初始化状态默认值为 true this.initialState = url.getParameter(Constants.LAZY_CONNECT_INITIAL_STATE_KEY, Constants.DEFAULT_LAZY_CONNECT_INITIAL_STATE); this.requestWithWarning = url.getParameter(REQUEST_WITH_WARNING_KEY, false); &#125; 请求方法1234567891011121314151617181920212223242526272829303132+--- LazyConnectExchangeClient @Override public ResponseFuture request(Object request) throws RemotingException &#123; warning(request); initClient(); return client.request(request); &#125; @Override public ResponseFuture request(Object request, int timeout) throws RemotingException &#123; warning(request); initClient(); return client.request(request, timeout); &#125; /** * 发送消息/请求前，都会调用该方法，确保客户端已经初始化 * * @param message * @throws RemotingException */ @Override public void send(Object message) throws RemotingException &#123; initClient(); client.send(message); &#125; @Override public void send(Object message, boolean sent) throws RemotingException &#123; initClient(); client.send(message, sent); &#125; 初始化连接1234567891011121314151617181920212223+--- LazyConnectExchangeClient private void initClient() throws RemotingException &#123; // 已初始化，则跳过 if (client != null) &#123; return; &#125; if (logger.isInfoEnabled()) &#123; logger.info(\"Lazy connect to \" + url); &#125; // 获得锁 connectLock.lock(); try &#123; // 已初始化，跳过 if (client != null) &#123; return; &#125; // 创建Client,连接服务器 this.client = Exchangers.connect(url, requestHandler); &#125; finally &#123; // 释放锁 connectLock.unlock(); &#125; &#125; 其它方法LazyConnectExchangeClient 中的其它方法同样是对不同接口和类中的方法实现，如获取地址的方法，获取处理器的方法，关闭相关的方法以及和通道属性相关的方法。 服务引用流程图 Dubbo 框架采用 Dubbo 协议进行服务引用的流程图如上图所示。从 Protocol 协议层 的 getClients 方法会一路调用到 Exchange 信息交换层、Transport 网络传输层，最终启动客户端并连接到服务器，后续就可以使用处于健康状态的连接进行双向远程通信了。 销毁在 DubboProtocol 销毁的时候，会调用 destroy() 方法释放底层资源。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364+--- DubboProtocol @Override public void destroy() &#123; // 1 销毁所有通信服务器 ExchangeServer for (String key : new ArrayList&lt;String&gt;(serverMap.keySet())) &#123; // 1.1 先从缓存中删除通信服务器 ExchangeServer server = serverMap.remove(key); if (server != null) &#123; try &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Close dubbo server: \" + server.getLocalAddress()); &#125; // 在close()方法中，下层（如HeaderExchangeServer）会发送ReadOnly请求、阻塞指定时间、关闭底层的定时任务、关闭相关线程池，最终，会断开所有连接，关闭Server。 // 这些逻辑在前文介绍HeaderExchangeServer、NettyServer等实现的时候 // 在优雅停机的等待时长内关闭 [保证了服务平滑的下线] server.close(ConfigUtils.getServerShutdownTimeout()); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; &#125; &#125; // 2 销毁所有通信客户端 ExchangeClient for (String key : new ArrayList&lt;String&gt;(referenceClientMap.keySet())) &#123; // 2.1 先从缓存中删除通信客户端 ExchangeClient client = referenceClientMap.remove(key); if (client != null) &#123; try &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Close dubbo connect: \" + client.getLocalAddress() + \"--&gt;\" + client.getRemoteAddress()); &#125; // ReferenceCountExchangeClient 中只有引用减到 0，底层的 Client 才会真正销毁 // 在优雅停机的等待时长内关闭 【保证在处理的请求能够尽可能的在优雅停机时间内完成处理】 client.close(ConfigUtils.getServerShutdownTimeout()); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; &#125; &#125; // 3 销毁所有的通信客户端 LazyConnectExchangeClient for (String key : new ArrayList&lt;String&gt;(ghostClientMap.keySet())) &#123; // 3.1 先从缓存中删除 ExchangeClient client = ghostClientMap.remove(key); if (client != null) &#123; try &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Close dubbo connect: \" + client.getLocalAddress() + \"--&gt;\" + client.getRemoteAddress()); &#125; // 在优雅停机的等待时长内关闭 client.close(ConfigUtils.getServerShutdownTimeout()); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; &#125; &#125; // 清理 stub 缓存 stubServiceMethodsMap.clear(); // 4 执行父类 AbstractProtocol 的销毁方法 super.destroy(); &#125; DubboProtocol 执行销毁的逻辑主要针对三类对象，分别对该三类对象进行优雅关闭。 优雅关闭ExchangeServer对象，保证服务平稳下线。 优雅关闭ExchangeClient对象，尽可能保证请求完成。 优雅关闭LazyConnectExchangeClient对象。 领域模型DubboProtocol.refer() 方法会将底层的 ExchangeClient 集合封装成 DubboInvoker，然后由上层逻辑封装成代理对象。这样业务层就可以像调用本地对象一样，完成远程调用。相关继承关系如下图所示： 关于 AbstractInvoker 在前面已经介绍过了，可以参考 AbstractInvoker 。下面我们对 DubboInvoker 进行介绍。 DubboInvokerDubboInvoker 是 AbstractInvoker 的实现类，其 doInvoke() 方法是远程调用的直接入口。 属性123456789101112131415161718192021222324252627282930313233343536public class DubboInvoker&lt;T&gt; extends AbstractInvoker&lt;T&gt; &#123; /** * 远程通信客户端数组 */ private final ExchangeClient[] clients; /** * 使用的 &#123;@link #clients&#125; 的位置 */ private final AtomicPositiveInteger index = new AtomicPositiveInteger(); /** * 版本 */ private final String version; /** * 销毁方法中使用的jvm 锁 */ private final ReentrantLock destroyLock = new ReentrantLock(); /** * Invoker 集合，从&#123;@link DubboProtocol#invokers&#125; 获取 */ private final Set&lt;Invoker&lt;?&gt;&gt; invokers; public DubboInvoker(Class&lt;T&gt; serviceType, URL url, ExchangeClient[] clients) &#123; this(serviceType, url, clients, null); &#125; public DubboInvoker(Class&lt;T&gt; serviceType, URL url, ExchangeClient[] clients, Set&lt;Invoker&lt;?&gt;&gt; invokers) &#123; super(serviceType, url, new String[]&#123;Constants.INTERFACE_KEY, Constants.GROUP_KEY, Constants.TOKEN_KEY, Constants.TIMEOUT_KEY&#125;); this.clients = clients; // get version. this.version = url.getParameter(Constants.VERSION_KEY, \"0.0.0\"); this.invokers = invokers; &#125;&#125; 远程调用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475+--- DubboInvoker@Override protected Result doInvoke(final Invocation invocation) throws Throwable &#123; RpcInvocation inv = (RpcInvocation) invocation; // 1 获得当前调用的方法名 final String methodName = RpcUtils.getMethodName(invocation); // 2 向Invocation中添加附加信息，这里将URL的path（服务名），version 添加到 attachment 中 inv.setAttachment(Constants.PATH_KEY, getUrl().getPath()); inv.setAttachment(Constants.VERSION_KEY, version); // 3 选择一个远程通信客户端 ExchangeClient ExchangeClient currentClient; // 默认是单一长连接 if (clients.length == 1) &#123; currentClient = clients[0]; &#125; else &#123; currentClient = clients[index.getAndIncrement() % clients.length]; &#125; // 4 远程调用 try &#123; // 4.1 判断是否异步调用 boolean isAsync = RpcUtils.isAsync(getUrl(), invocation); // 4.2 判断是否单向调用 boolean isOneway = RpcUtils.isOneway(getUrl(), invocation); // 4.3 根据调用的方法名称和配置获取此次调用的超时时间（毫秒），默认是 1s int timeout = getUrl().getMethodParameter(methodName, Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT); /** * - 发送 oneway 请求的方式是send() 方法，而后面发送 twoway 请求的方式是 request() 方法 * - request() 方法会相应地创建 DefaultFuture 对象以及检测超时的定时任务，而 send() 方法则不会创建这些东西，它是直接将 Invocation 包装成 oneway 类型的 Request 发送出去 */ // 4.4 单向调用，不需要关注返回值的请求 if (isOneway) &#123; boolean isSent = getUrl().getMethodParameter(methodName, Constants.SENT_KEY, false); // 注意，调用的是 ExchangeClient#send(invocation, sent) 方法 currentClient.send(inv, isSent); // 设置 RpcContext.future = null ，无需异步回调 RpcContext.getContext().setFuture(null); // 返回 空结果 return new RpcResult(); // 4.5 异步调用，需要关注返回值的请求 &#125; else if (isAsync) &#123; /** * 调用 ExchangeClient#request(invocation, timeout) 方法，发送请求 * DefaultFuture是ResponseFuture的实现类，实际上这里返回的就是DefaultFuture实例，而该实例就是HeaderExchangeChannel.request(Object request, int timeout)返回的future实例 */ ResponseFuture future = currentClient.request(inv, timeout); /** * 1 调用 RpcContext#setFuture(future) 方法，在需要的时候可以使用 Future 进行回调。 * 2 将DefaultFuture 对象封装到 FutureAdapter实例中，并将 FutureAdapter实例设置到RpcContext 中，我们可以在需要的地方取出使用 【在合适的地方调用 get方法】 * 3 FutureAdapter 是一个适配器，用于将 Dubbo 中的 ResponseFuture 与 JDK 中的 Future 进行适配，这样当用户线程调用 Future 的 get 方法时，经过 FutureAdapter 适配，最终会调用 ResponseFuture 实现类对象的 get 方法，也就是 DefaultFuture 的 get 方法 */ RpcContext.getContext().setFuture(new FutureAdapter&lt;Object&gt;(future)); // 返回 空结果 return new RpcResult(); // 4.6 同步调用 &#125; else &#123; // 设置 RpcContext.future = null，无需异步回调 RpcContext.getContext().setFuture(null); /** * 1 调用 ExchangeClient#request(invocation, timeout) 方法，发送请求 * 2 用 ResponseFuture#get() 方法，阻塞等待返回结果 */ return (Result) currentClient.request(inv, timeout).get(); &#125; &#125; catch (TimeoutException e) &#123; throw new RpcException(RpcException.TIMEOUT_EXCEPTION, \"Invoke remote method timeout. method: \" + invocation.getMethodName() + \", provider: \" + getUrl() + \", cause: \" + e.getMessage(), e); &#125; catch (RemotingException e) &#123; throw new RpcException(RpcException.NETWORK_EXCEPTION, \"Failed to invoke remote method: \" + invocation.getMethodName() + \", provider: \" + getUrl() + \", cause: \" + e.getMessage(), e); &#125; &#125; DubboInvoker.doInvoke() 方法是调用方使用 ExchangeClient 向服务提供方发起请求的入口，下面对该过程进行分析： 向 Invocation 调用信息中添加 path、version 属性。 获取当前调用的超时时间，默认是 1s 。双向调用时是调用端最大等待时长，否则抛出请求超时异常。 判断调用模式，单向调用 or 异步调用 or 同步调用。 单向调用：使用 ExchangeClient.send 方法，无需关注返回值。RpcContext 中的 Future 置空，无需异步回调。 异步调用：使用 ExchangeClient.request 方法，调用时传入超时时间，作为调用方最大等待时长。返回结果 ResponseFuture 作为 RpcContext 中的 Future ，在需要的时候可以取出 Future 进行回调。 同步调用：和异步调用类似，唯一的区别是，同步调用是拿到返回的 ResponseFuture 后立即调用其 get() 进行调用结果的获取，在结果没有返回时将阻塞业务线程。 Invoker 状态1234567891011121314151617181920+--- DubboInvoker @Override public boolean isAvailable() &#123; // 当前 Invoker 的状态 - 是否可用 if (!super.isAvailable()) &#123; return false; &#125; for (ExchangeClient client : clients) &#123; /** * 即使Client处于连接中，但如果 Server 处于正在关闭中，连接也是不可用的，即服务端广播客户端 READONLY_EVENT 事件 * * &#123;@link HeaderExchangeServer#sendChannelReadOnlyEvent()&#125; */ if (client.isConnected() &amp;&amp; !client.hasAttribute(Constants.CHANNEL_ATTRIBUTE_READONLY_KEY)) &#123; //cannot write == not Available ? return true; &#125; &#125; return false; &#125; DubboInvoker.isAvailable() 方法用于检查当前 DubboInvoker 是否可用，是否可以体现如下： 当前 Invoker 的状态是否是可用的 当前 Invoker 封装的连接是否有可用的 当前 Invoker 封装的连接的对端是否关闭，根据是否广播只读事件 销毁 Invoker123456789101112131415161718192021222324252627282930313233343536373839+--- DubboInvoker @Override public void destroy() &#123; // 如果已经销毁，则忽略 if (super.isDestroyed()) &#123; return; &#125; else &#123; // double check to avoid dup close // 双重检锁，避免已经销毁 destroyLock.lock(); try &#123; // 再次检测是否销毁 if (super.isDestroyed()) &#123; return; &#125; // 标记 DubboInvoker 销毁 super.destroy(); // 从缓存中移除当前Invoker if (invokers != null) &#123; invokers.remove(this); &#125; // 关闭当前 Invoker 中封装的连接 for (ExchangeClient client : clients) &#123; try &#123; // 等待时长内关闭 ExchangeClient client.close(ConfigUtils.getServerShutdownTimeout()); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; &#125; &#125; finally &#123; // 释放锁 destroyLock.unlock(); &#125; &#125; &#125; 销毁 DubboInvoker 首先设置自身的销毁状态，接着关闭封装的连接。 编解码器DubboProtocol 的服务暴露和服务引用都设置了编解码 DubboCountCodec，关于编解码器可以参考 编解码器 一文，这里就不再重复说明。 小结本篇文章主要对 Dubbo 协议下的服务暴露和服务引用的核心流程进行了介绍。服务暴露涉及到 NIO 服务的启动，RpcInvocation 实现，通道处理器的实现以及优化序列实现。服用引用涉及到 Client 的初始化，Dubbo 支持 共享连接 和 独享连接，其中使用 ReferenceCountExchangeClient 和 LazyConnectExchangeClient 对 ExchangeClient 进行装饰，分别实现具有引用计数功能和延时初始化功能的客户端。接着对相关的领域模型 DubboExpoter 和 DubboInvoker 进行了介绍，这两个是非常重要的模型，作为提供方服务暴露实现和消费方服务引用实现。DubboProtocol 相关的编解码由于在之前的文章中已经详细说明，就不再介绍。需要说明的是，在 Dubbo 2.7.x 版本中进行了异步化改造，对消费端和提供的调用进行了优化，关于差异部分会在后面的文章中单独说明。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"Protocol","slug":"Protocol","permalink":"https://gentryhuang.com/tags/Protocol/"}]},{"title":"Dubbo源码分析 - 多协议概览","slug":"rpc/多协议概览","date":"2020-08-24T16:00:00.000Z","updated":"2021-03-10T05:53:22.017Z","comments":false,"path":"posts/450e3eda/","link":"","permalink":"https://gentryhuang.com/posts/450e3eda/","excerpt":"","text":"前言在协议层总览中对Protocol层进行了总体介绍，其中对相关的核心包和核心类进行了说明。本篇文章将对 Dubbo 中的多协议进行概览，后续文章中将对具体协议实现进行介绍。 ProtocolProtocol 接口中主要定义了 export() 和 refer() 方法，分别用于服务暴露和服务引用。Protocol 接口相关的 UML 图如下： 需要说明的是，Protocol 的 RegistryProtocol 实现类并没有包含在内，虽然它不是协议的直接相关实现类，但它不可或缺。它是服务提供者、服务消费者以及注册中心之间的纽带。 Protocol 接口具体定义如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@SPI(\"dubbo\")public interface Protocol &#123; /** * 默认端口 * Get default port when user doesn't config the port. * * @return default port */ int getDefaultPort(); /** * 将一个 Invoker 暴露出去 &lt;br&gt; * 1. 接收到请求后，协议应该记录请求源地址: RpcContext.getContext().setRemoteAddress();&lt;br&gt; * 2. export()必须是幂等的，也就是说，在暴露相同的URL时，调用一次和调用两次没有区别 &lt;br&gt; * 3. Invoker 是由框架传入的，协议不需要关心 &lt;br&gt; * * @param &lt;T&gt; Service type * @param invoker Service invoker * @return exporter reference for exported service, useful for unexport the service later * @throws RpcException thrown when error occurs during export the service, for example: port is occupied */ @Adaptive &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException; /** * 引用一个 Invoker &lt;br&gt; * 1. 协议的责任是根据参数返回一个 Invoker 对象，由 refer() 方法返回。&lt;br&gt; * 2. Consumer端可以通过这个Invoker请求到Provider端的服务. &lt;br&gt; * * @param &lt;T&gt; Service type * @param type Service class * @param url URL address for the remote service * @return invoker service's local proxy * @throws RpcException when there's any error while connecting to the service provider */ @Adaptive &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException; /** * 释放当前 Protocol 对象底层占用的资源 &lt;br&gt; * 1. 销毁export()方法以及refer()方法使用到的Invoker对象 &lt;br&gt; * 2. 释放所有占用资源, 如: 连接, 端口, 等等. &lt;br&gt; * 3. 协议可以继续导出和引用新的服务，即使它被销毁。 */ void destroy();&#125; 在 Protocol 接口的实现中，export() 方法并不是简单地将 Invoker 对象包装成 Exporter 对象返回，该过程还会涉及代理对象的创建、底层 Server 的启动等操作。refer() 方法除了根据传入的服务接口以及URL参数查询 Invoker 之外，还会涉及到 Client 的创建等操作。Protocol 接口的继承关系如下图所示： 从上图的 Protocol 接口的继承关系图可以发现，具体协议实现有两个分支：以 AbstractProtocol 为一支的协议实现，以 AbstractProxyProtocol 为另一支的协议实现。从整体上看这两个分支体现了 Dubbo 的多协议，后面会详细说明。 AbstractProtocol1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public abstract class AbstractProtocol implements Protocol &#123; protected final Logger logger = LoggerFactory.getLogger(getClass()); /** * 用于存储暴露出去的服务集合（包括 injvm 协议暴露的服务） * 1 key: 服务键，&#123;@link #serviceKey(URL)&#125; 或者 &#123;@link URL#getServiceKey()&#125;,不同协议会有所差别： * - InjvmProtocol使用 URL#getServicekey() * - DubboProtocol使用 #serviceKey(URL) * 2 value: 服务键对应的 Exporter 对象 */ protected final Map&lt;String, Exporter&lt;?&gt;&gt; exporterMap = new ConcurrentHashMap&lt;String, Exporter&lt;?&gt;&gt;(); /** * 服务引用集合 */ protected final Set&lt;Invoker&lt;?&gt;&gt; invokers = new ConcurrentHashSet&lt;Invoker&lt;?&gt;&gt;(); /** * 获取服务健 * * @param url * @return */ protected static String serviceKey(URL url) &#123; // 绑定端口 int port = url.getParameter(Constants.BIND_PORT_KEY, url.getPort()); return serviceKey( port, // 端口 url.getPath(),// 服务接口全路径名 url.getParameter(Constants.VERSION_KEY), // 服务版本 url.getParameter(Constants.GROUP_KEY)); // 分组名 &#125; /** * 获取服务键 * * @param port 端口 * @param serviceName 服务名 * @param serviceVersion 服务版本 * @param serviceGroup 分组名 * @return */ protected static String serviceKey(int port, String serviceName, String serviceVersion, String serviceGroup) &#123; return ProtocolUtils.serviceKey(port, serviceName, serviceVersion, serviceGroup); &#125; /** * 1 销毁全部的服务引用 * 2 销毁发布出去的服务 */ @Override public void destroy() &#123; // 销毁协议对应的服务消费者的所有 Invoker， // 如： 如果是Dubbo协议，那么这里的服务消费者的所有Invoker则为 DubboInvoker for (Invoker&lt;?&gt; invoker : invokers) &#123; if (invoker != null) &#123; invokers.remove(invoker); try &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Destroy reference: \" + invoker.getUrl()); &#125; invoker.destroy(); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; &#125; &#125; // 销毁协议对应的服务提供者的所有Exporter // 如：如果是Dubbo协议，那么这里的服务提供者的所有Exporter则为 DubboExporter for (String key : new ArrayList&lt;String&gt;(exporterMap.keySet())) &#123; Exporter&lt;?&gt; exporter = exporterMap.remove(key); if (exporter != null) &#123; try &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Unexport service: \" + exporter.getInvoker().getUrl()); &#125; exporter.unexport(); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; &#125; &#125; &#125;&#125; AbstractProtocol 实现了 Protocol ，提供了一些 Protocol 实现所需的公共方法及字段，概括如下： 1 存储暴露服务的 Map 2 存储服务引用的 Set 3 获取服务键方法（Injvm 所需服务键非这里的方法，并且两者服务键构成有所差别） 4 释放协议底层占用资源 服务键格式如下： Injvm 协议中的服务键格式如下： AbstractProxyProtocolAbstractProxyProtocol 继承了 AbstractProtocol 抽象类，从命名就可以看出该类是一个代理协议类，其本身及其实现本质上并没有单独实现一套协议，而是使用 HTTP 协议进行通信。 属性1234567891011121314151617181920212223242526272829303132public abstract class AbstractProxyProtocol extends AbstractProtocol &#123; /** * 需要抛出的异常类集合，详细: &#123;@link #doRefer(Class, URL)&#125; 方法 */ private final List&lt;Class&lt;?&gt;&gt; rpcExceptions = new CopyOnWriteArrayList&lt;Class&lt;?&gt;&gt;(); /** * 代理工厂 - IOC注入 */ private ProxyFactory proxyFactory; public AbstractProxyProtocol() &#123; &#125; public AbstractProxyProtocol(Class&lt;?&gt;... exceptions) &#123; for (Class&lt;?&gt; exception : exceptions) &#123; addRpcException(exception); &#125; &#125; public void addRpcException(Class&lt;?&gt; exception) &#123; this.rpcExceptions.add(exception); &#125; public ProxyFactory getProxyFactory() &#123; return proxyFactory; &#125; public void setProxyFactory(ProxyFactory proxyFactory) &#123; this.proxyFactory = proxyFactory; &#125;&#125; AbstractProxyProtocol 中的 proxyFactory 用于为传入的 Invoker 创建代理对象，并且支持将服务实例封装成 Invoker 。rpcExceptions 用于保存当前协议指定的异常，执行 RPC 调用出现异常时，如果异常是协议对应的异常，则抛出当前异常。 服务暴露123456789101112131415161718192021222324252627282930313233343536373839404142434445464748+--- AbstractProxyProtocol /** * 服务暴露 * * @param invoker Service invoker * @param &lt;T&gt; * @return * @throws RpcException */ @Override @SuppressWarnings(\"unchecked\") public &lt;T&gt; Exporter&lt;T&gt; export(final Invoker&lt;T&gt; invoker) throws RpcException &#123; // 获得服务键 final String uri = serviceKey(invoker.getUrl()); // 获得服务健对应的 Exporter 对象，若已经暴露，直接返回 Exporter&lt;T&gt; exporter = (Exporter&lt;T&gt;) exporterMap.get(uri); if (exporter != null) &#123; return exporter; &#125; // 通过 ProxyFactory 创建代理对象，将 Invoker 封装成业务接口的代理对象。 final Runnable runnable = doExport(proxyFactory.getProxy(invoker, true), invoker.getInterface(), invoker.getUrl()); // 创建 Exporter 对象 exporter = new AbstractExporter&lt;T&gt;(invoker) &#123; /** * 基于 AbstractExporter 抽象类覆写 unexport方法，会调用 Runnable */ @Override public void unexport() &#123; // 取消服务暴露 super.unexport(); // 从缓存中移除对应的 Exporter exporterMap.remove(uri); // doExport()方法返回的 Runnable 是一个回调，其中会销毁底层的 Server。 if (runnable != null) &#123; try &#123; runnable.run(); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; &#125; &#125; &#125;; // 添加到 Exporter 集合中 exporterMap.put(uri, exporter); return exporter; &#125; AbstractProxyProtocol 进行服务暴露时，会通过子类实现的 doExport() 方法启动底层服务，以接收 HTTP 请求，请求的处理交给代理对象，具体的 HTTP 服务器实现取决于具体子类实现。下面对服务暴露过程进行简单概述： 根据服务健检查 Exporter 缓存，判断是否已经暴露过服务。 缓存没有命中则调用 ProxyFactory.getProxy() 方法将 Invoker 封装成业务接口的代理对象，这里统一对泛化进行了支持，代理对象负责对请求的处理。 通过 AbstractProxyProtocol 的子类实现的 doExport() 方法启动底层的服务，这个底层服务可以是 Servlet、Tomcat，Jetty。 创建 AbstractExporter 匿名对象，进行服务暴露，且基于 AbstractExporter 抽象类覆写 unexport方法，调用 Runnable 以销毁底层的 Server。 服务引用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354+--- AbstractProxyProtocol /** * 服务引用 * * @param type Service class * @param url URL address for the remote service * @param &lt;T&gt; * @return * @throws RpcException */ @Override public &lt;T&gt; Invoker&lt;T&gt; refer(final Class&lt;T&gt; type, final URL url) throws RpcException &#123; // 执行引用服务并通过代理工厂获取对应的 Invoker 对象 final Invoker&lt;T&gt; target = proxyFactory.getInvoker(doRefer(type, url), type, url); // 创建 Invoker 匿名对象 Invoker&lt;T&gt; invoker = new AbstractInvoker&lt;T&gt;(type, url) &#123; /** * 覆写 doInvoke 方法 * @param invocation * @return * @throws Throwable */ @Override protected Result doInvoke(Invocation invocation) throws Throwable &#123; try &#123; // 执行RPC调用 Result result = target.invoke(invocation); // 若执行异常，并且是需要抛出的异常，则直接抛出 Throwable e = result.getException(); if (e != null) &#123; for (Class&lt;?&gt; rpcException : rpcExceptions) &#123; if (rpcException.isAssignableFrom(e.getClass())) &#123; throw getRpcException(type, url, invocation, e); &#125; &#125; &#125; return result; &#125; catch (RpcException e) &#123; // 若是未知异常，获得异常对应的错误码 if (e.getCode() == RpcException.UNKNOWN_EXCEPTION) &#123; e.setCode(getErrorCode(e.getCause())); &#125; throw e; &#125; catch (Throwable e) &#123; // 抛出 RpcException 异常 throw getRpcException(type, url, invocation, e); &#125; &#125; &#125;; // 添加到Invoker 集合 invokers.add(invoker); return invoker; &#125; AbstractProxyProtocol 进行服务引用时，会通过子类实现的 doRefer() 方法返回远程服务对象，一般是个代理对象，通过该对象可以发起 HTTP 请求。接着通过 ProxyFactory.getInvoker() 方法将远程服务对象封装成一个 Invoker 对象，该对象具备调用远程服务的能力，客户端的代理对象就是使用该对象的能力发起远程调用的。下面对服务引用过程进行简单概述： 通过子类实现的 doRefer() 方法获取远程服务，一般是个代理对象。 调用 ProxyFactory.getInvoker() 方法对远程服务进行封装，包装成 Invoker 对象。 创建一个匿名 AbstractInvoker 对象，内部调用逻辑使用的就是第 2 步封装的 Invoker 的执行逻辑。 返回创建的匿名 AbstractInvoker 对象。 服务地址1234567891011121314151617+--- AbstractProxyProtocol /** * 获取URL中的 bind.ip 和 bind.port * * @param url * @return */ protected String getAddr(URL url) &#123; // 先从URL中获取bind.ip的值作为ip的值 String bindIp = url.getParameter(Constants.BIND_IP_KEY, url.getHost()); // 如果URL中设置了anyhost属性，那么ip的值取 0.0.0.0 if (url.getParameter(Constants.ANYHOST_KEY, false)) &#123; bindIp = Constants.ANYHOST_VALUE; &#125; // 返回： ip:port return NetUtils.getIpByHost(bindIp) + \":\" + url.getParameter(Constants.BIND_PORT_KEY, url.getPort()); &#125; 获取服务地址的时候需要注意绑定地址和注册地址，绑定地址是启动服务的地址，注册地址是注册到注册中心，供消费者进行服务查找。 模版方法1234567891011121314151617181920212223+--- AbstractProxyProtocol /** * 执行暴露，并返回取消暴露的回调 Runnable * * @param impl 服务 Proxy 对象 * @param type 服务接口类型 * @param url URL * @param &lt;T&gt; 服务接口 * @return 取消服务暴露的回调 Runnable * @throws RpcException */ protected abstract &lt;T&gt; Runnable doExport(T impl, Class&lt;T&gt; type, URL url) throws RpcException; /** * 执行引用，并返回调用远程服务的Service 对象 * * @param type 服务接口 * @param url URL * @param &lt;T&gt; 服务接口 * @return 调用远程服务的Service 对象 * @throws RpcException */ protected abstract &lt;T&gt; T doRefer(Class&lt;T&gt; type, URL url) throws RpcException; AbstractProxyProtocol 中的模版方法有两个，分别定义了服务暴露和服务引用方法，前者用于启动HTTP服务，后者用于创建远程服务的代理对象。 领域模型AbstractExporter123456789101112131415161718192021222324252627282930313233343536373839404142434445public abstract class AbstractExporter&lt;T&gt; implements Exporter&lt;T&gt; &#123; protected final Logger logger = LoggerFactory.getLogger(getClass()); /** * Invoker对象 */ private final Invoker&lt;T&gt; invoker; /** * 是否取消服务暴露 */ private volatile boolean unexported = false; public AbstractExporter(Invoker&lt;T&gt; invoker) &#123; if (invoker == null) &#123; throw new IllegalStateException(\"service invoker == null\"); &#125; if (invoker.getInterface() == null) &#123; throw new IllegalStateException(\"service type == null\"); &#125; if (invoker.getUrl() == null) &#123; throw new IllegalStateException(\"service url == null\"); &#125; this.invoker = invoker; &#125; @Override public Invoker&lt;T&gt; getInvoker() &#123; return invoker; &#125; /** * 取消服务的暴露 */ @Override public void unexport() &#123; // 已经取消暴露就直接返回 if (unexported) &#123; return; &#125; // 标记已经取消暴露 unexported = true; // 销毁 getInvoker().destroy(); &#125;&#125; AbstractExporter 是对 Invoker 的简单封装，并且实现了取消服务暴露的方法。 AbstractInvokerAbstractInvoker 主要提供了 Invoker 的通用属性和 #invoke() 方法的通用实现，具体的实现逻辑交给子类。 属性12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public abstract class AbstractInvoker&lt;T&gt; implements Invoker&lt;T&gt; &#123; protected final Logger logger = LoggerFactory.getLogger(getClass()); /** * 该 Invoker 对象封装的业务接口 */ private final Class&lt;T&gt; type; /** * 与当前 Invoker 关联的 URL 对象，其中包含了全部的配置信息 */ private final URL url; /** * 当前 Invoker 关联的一些附加信息，这些附加信息可以来自关联的 URL. * 共用的隐式传参，在&#123;@link #invoke(Invocation)&#125;方法中使用 */ private final Map&lt;String, String&gt; attachment; /** * 当前 Invoker 的状态 - 是否可用 */ private volatile boolean available = true; /** * 当前 Invoker 的状态 - 是否销毁 */ private AtomicBoolean destroyed = new AtomicBoolean(false); public AbstractInvoker(Class&lt;T&gt; type, URL url) &#123; this(type, url, (Map&lt;String, String&gt;) null); &#125; /** * 调用 convertAttachment() 方法，会从关联的 URL 对象获取指定的 KV 记录到 attachment 中 * * @param type * @param url * @param keys */ public AbstractInvoker(Class&lt;T&gt; type, URL url, String[] keys) &#123; this(type, url, convertAttachment(url, keys)); &#125; public AbstractInvoker(Class&lt;T&gt; type, URL url, Map&lt;String, String&gt; attachment) &#123; if (type == null) &#123; throw new IllegalArgumentException(\"service type == null\"); &#125; if (url == null) &#123; throw new IllegalArgumentException(\"service url == null\"); &#125; this.type = type; this.url = url; this.attachment = attachment == null ? null : Collections.unmodifiableMap(attachment); &#125;&#125; AbstractInvoker 通用属性包括：业务接口、URL、附加参数以及用于标记服务状态的两个字段。 标记销毁12345678910+--- AbstractInvoker @Override public void destroy() &#123; // destroyed 设置为 true if (!destroyed.compareAndSet(false, true)) &#123; return; &#125; // available 设置为 false setAvailable(false); &#125; 服务调用12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667+--- AbstractInvoker @Override public Result invoke(Invocation inv) throws RpcException &#123; // if invoker is destroyed due to address refresh from registry, let's allow the current invoke to proceed if (destroyed.get()) &#123; logger.warn(\"Invoker for service \" + this + \" on consumer \" + NetUtils.getLocalHost() + \" is destroyed, \" + \", dubbo version is \" + Version.getVersion() + \", this invoker should not be used any longer\"); &#125; // 1 将传入的 Invocation 转为 RpcInvocation RpcInvocation invocation = (RpcInvocation) inv; // 注意： 执行到这里是真正的Invoker，之前的Invoker都是层层嵌套 invocation.setInvoker(this); // 2 将 attachment集合添加为 Invocation 的附加信息 if (attachment != null &amp;&amp; attachment.size() &gt; 0) &#123; invocation.addAttachmentsIfAbsent(attachment); &#125; // 3 将 RpcContext 的附加信息添加到 Invocation 的附加信息中。注意使用RpcContext进行隐式传参。 Map&lt;String, String&gt; contextAttachments = RpcContext.getContext().getAttachments(); if (contextAttachments != null &amp;&amp; contextAttachments.size() != 0) &#123; invocation.addAttachments(contextAttachments); &#125; // 4 如果方法是异步的就设置异步标志 if (getUrl().getMethodParameter(invocation.getMethodName(), Constants.ASYNC_KEY, false)) &#123; // 4.1 设置异步信息到 RpcInvocation#attachment 中 invocation.setAttachment(Constants.ASYNC_KEY, Boolean.TRUE.toString()); &#125; // 4.2 如果是异步调用，给invocation的attachment 添加一个 id 属性，并设置唯一ID值。 RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation); try &#123; // 5 执行调用，由不同协议对应具体的子类实现 return doInvoke(invocation); &#125; catch (InvocationTargetException e) &#123; // biz exception Throwable te = e.getTargetException(); if (te == null) &#123; return new RpcResult(e); &#125; else &#123; if (te instanceof RpcException) &#123; ((RpcException) te).setCode(RpcException.BIZ_EXCEPTION); &#125; return new RpcResult(te); &#125; &#125; catch (RpcException e) &#123; if (e.isBiz()) &#123; return new RpcResult(e); &#125; else &#123; throw e; &#125; &#125; catch (Throwable e) &#123; return new RpcResult(e); &#125; &#125; /** * 子类实现调用逻辑 * * @param invocation * @return * @throws Throwable */ protected abstract Result doInvoke(Invocation invocation) throws Throwable; 小结本篇文章主要对 Protocol 的继承体系抽象部分进行了介绍，这些抽象定义可以看作是具体实现的通用逻辑和工具。在接下来的几篇文章中会对不同的实现进行详细分析。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"Protocol","slug":"Protocol","permalink":"https://gentryhuang.com/tags/Protocol/"}]},{"title":"Dubbo源码分析 - 泛化实现","slug":"rpc/Dubbo过滤器-泛化实现","date":"2020-08-14T16:00:00.000Z","updated":"2021-02-22T06:01:32.390Z","comments":false,"path":"posts/bb5fc918/","link":"","permalink":"https://gentryhuang.com/posts/bb5fc918/","excerpt":"","text":"概述Dubbo 中的泛化接口实现主要用于服务端没有 API 接口及模型类元的情况，泛化实现需要实现 GenericService 接口。调用端在引用某个服务时可以指定通用调用（generic配置项），进而可以调用该服务对应的泛化实现。服务消费端无需关注泛化实现的细节，只需要引用服务的时候指定通用调用即可。 应用场景通常用于框架集成，比如：实现一个通用的远程服务 Mock 框架，可通过实现 GenericService 接口处理所有服务请求。 使用示例服务端服务端需要实现 GenericService 接口以实现泛化功能。 泛化实现 12345678910111213141516171819@Servicepublic class MyGenericService implements GenericService &#123; /** * 泛化实现 * * @param method 调用端调用的方法名 * @param parameterTypes 方法参数类型 * @param args 参数值 * @return * @throws GenericException */ @Override public Object $invoke(String method, String[] parameterTypes, Object[] args) throws GenericException &#123; if (\"sayHello\".equals(method)) &#123; return \"print \" + args[0]; &#125; return \"not find method!\"; &#125;&#125; 服务暴露1&lt;dubbo:service interface=\"com.code.dubbo.DemoService\" ref=\"myGenericService\"/&gt; 说明：泛化实现暴露出去需要依托已有的服务接口，将接口的实现设置成泛化实现即可。 消费端 服务引入1&lt;dubbo:reference id=\"demoService\" interface=\"com.code.dubbo.DemoService\" generic=\"true\"/&gt; 说明： 消费端需要引入 interface 配置项的依赖，并且设置 generic 属性，以指定引用的服务为通用调用。 generic 配置项支持设置 true、nativejava 以及 bean，在 Dubbo 2.7 中还支持了 protobuf-json 和 raw.return ，用于对参数进行序列化和反序列化。 消费端调用服务和普通的消费者一摸一样。 远程调用12DemoService demoService = (DemoService) applicationContext.getBean(\"demoService\");String result = demoService.sayHello(\"gentryhuang\"); GenericImplFilter123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145@Activate(group = Constants.CONSUMER, value = Constants.GENERIC_KEY, order = 20000)public class GenericImplFilter implements Filter &#123; private static final Logger logger = LoggerFactory.getLogger(GenericImplFilter.class); /** * 泛化参数类型 */ private static final Class&lt;?&gt;[] GENERIC_PARAMETER_TYPES = new Class&lt;?&gt;[]&#123;String.class, String[].class, Object[].class&#125;; @Override public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; // 1. 获得 generic 配置项 String generic = invoker.getUrl().getParameter(Constants.GENERIC_KEY); // 泛化实现的调用 - 客户端调用的服务是 GenericService if (ProtocolUtils.isGeneric(generic) // 判断是否开启了泛化引用 &amp;&amp; !Constants.$INVOKE.equals(invocation.getMethodName()) // 方法名非 $invoke // 调用信息是 RpcInvocation 类型 &amp;&amp; invocation instanceof RpcInvocation) &#123; // 2. 序列化参数 RpcInvocation invocation2 = (RpcInvocation) invocation; // 调用的方法名 String methodName = invocation2.getMethodName(); // 参数类型列表 Class&lt;?&gt;[] parameterTypes = invocation2.getParameterTypes(); // 参数值列表 Object[] arguments = invocation2.getArguments(); // 参数类型名列表 String[] types = new String[parameterTypes.length]; for (int i = 0; i &lt; parameterTypes.length; i++) &#123; types[i] = ReflectUtils.getName(parameterTypes[i]); &#125; // 3. 根据 generic 的值选择对应序列化参数的方式 Object[] args; // 3.1 generic == bean if (ProtocolUtils.isBeanGenericSerialization(generic)) &#123; args = new Object[arguments.length]; for (int i = 0; i &lt; arguments.length; i++) &#123; // 将参数进行转换： POJO -&gt; JavaBeanDescriptor args[i] = JavaBeanSerializeUtil.serialize(arguments[i], JavaBeanAccessor.METHOD); &#125; // 3.2 generic != bean &#125; else &#123; // 将参数进行转换：POJO -&gt; Map args = PojoUtils.generalize(arguments); &#125; // 4、重新设置RPC调用信息，通过新的PpcInvocation就能调用到泛化实现的服务 // 4.1 设置调用方法的名字为 $invoke invocation2.setMethodName(Constants.$INVOKE); // 4.2 设置调用方法的参数类型为 GENERIC_PARAMETER_TYPES invocation2.setParameterTypes(GENERIC_PARAMETER_TYPES); // 4.3 设置调用方法的参数数据，分别为方法名，参数类型数组，参数数组 invocation2.setArguments(new Object[]&#123;methodName, types, args&#125;); // 5 方法调用 Result result = invoker.invoke(invocation2); // 6、反序列化结果及异常结果处理 if (!result.hasException()) &#123; // 获取调用结果 Object value = result.getValue(); try &#123; // 反射方法对象 Method method = invoker.getInterface().getMethod(methodName, parameterTypes); // generic=bean 的情况，反序列化： JavaBeanDescriptor -&gt; 结果 if (ProtocolUtils.isBeanGenericSerialization(generic)) &#123; if (value == null) &#123; return new RpcResult(value); &#125; else if (value instanceof JavaBeanDescriptor) &#123; return new RpcResult(JavaBeanSerializeUtil.deserialize((JavaBeanDescriptor) value)); &#125; else &#123; throw new RpcException( \"The type of result value is \" + value.getClass().getName() + \" other than \" + JavaBeanDescriptor.class.getName() + \", and the result is \" + value); &#125; // generic = true，反序列化： Map -&gt; Pojo &#125; else &#123; return new RpcResult(PojoUtils.realize(value, method.getReturnType(), method.getGenericReturnType())); &#125; &#125; catch (NoSuchMethodException e) &#123; throw new RpcException(e.getMessage(), e); &#125; // 异常结果处理 &#125; else if (result.getException() instanceof GenericException) &#123; GenericException exception = (GenericException) result.getException(); try &#123; String className = exception.getExceptionClass(); Class&lt;?&gt; clazz = ReflectUtils.forName(className); Throwable targetException = null; Throwable lastException = null; try &#123; // 创建异常对象 targetException = (Throwable) clazz.newInstance(); &#125; catch (Throwable e) &#123; lastException = e; for (Constructor&lt;?&gt; constructor : clazz.getConstructors()) &#123; try &#123; targetException = (Throwable) constructor.newInstance(new Object[constructor.getParameterTypes().length]); break; &#125; catch (Throwable e1) &#123; lastException = e1; &#125; &#125; &#125; if (targetException != null) &#123; try &#123; Field field = Throwable.class.getDeclaredField(\"detailMessage\"); if (!field.isAccessible()) &#123; field.setAccessible(true); &#125; field.set(targetException, exception.getExceptionMessage()); &#125; catch (Throwable e) &#123; logger.warn(e.getMessage(), e); &#125; result = new RpcResult(targetException); &#125; else if (lastException != null) &#123; throw lastException; &#125; &#125; catch (Throwable e) &#123; throw new RpcException(\"Can not deserialize exception \" + exception.getExceptionClass() + \", message: \" + exception.getExceptionMessage(), e); &#125; &#125; return result; &#125; // 省略泛化引用的调用 - GenericService 调用服务接口 // 普通调用 return invoker.invoke(invocation); &#125; GenericImplFilter 是服务消费端的过滤器，主要是对 泛化引用 和 泛化实现 在调用端的处理。关于泛化引用部分在泛化调用中已经详细说明，下面对泛化实现的逻辑进行说明： 获取 generic 配置项，判断是否开启泛化引用。 从调用信息对象 RpcInvocation 中获取调用的方法名、参数类型列表、参数值列表。 根据 generic 的值选择对应的序列化方式对参数进行序列化。 重置调用信息对象中的方法名、方法参数类型、方法参数，本质上将普通方法调用转为 $invoke 方法调用，重置完成后进行方法调用。 对正常结果进行反序列化，以及根据 GenericException 异常，创建原始异常 targetException 并返回给调用端。 这里需要说明的是上述的第 5 步，为什么执行 invoker.invoke(invocation2) 方法就会调用泛化实现 $invoke 方法？ 原因如下： 服务暴露的过程确定了服务实现对象和服务接口12345678910+--- ServiceConfig#doExport // 检测ref是否泛化接口的实现 if (ref instanceof GenericService) &#123; // 设置 interfaceClass 为 GenericService.class interfaceClass = GenericService.class; if (StringUtils.isEmpty(generic)) &#123; // 设置 generic = \"true\" generic = Boolean.TRUE.toString(); &#125; &#125; 注意： 虽然接口设置为了 GenericService ，但是不影响服务暴露，服务暴露的 URL 中使用接口名表示服务接口信息，也就是 interface 的值。 将服务实例封装成 Invoker ,服务实例就是 GenericService 实例。12345678910111213/** * 将传入的服务实例封装成Invoker * &lt;p&gt; * create invoker. * * @param &lt;T&gt; * @param proxy Service对象 * @param type Service接口类型 * @param url Service对应的Dubbo URL * @return invoker */@Adaptive(&#123;Constants.PROXY_KEY&#125;)&lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) throws RpcException; GenericFilterGenericFilter 不会特别处理泛化实现的调用，将这种情况当作普通调用对待。 泛化实现流程图 小结Dubbo 提供了 GenericService 接口用于实现泛化服务，由于泛化实现对于调用端来说是没有具体接口的，因此泛化实现必须依托现有的服务接口。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"Filter","slug":"Filter","permalink":"https://gentryhuang.com/tags/Filter/"}]},{"title":"Dubbo源码分析 - 泛化调用","slug":"rpc/Dubbo过滤器-泛化调用","date":"2020-08-12T14:59:38.000Z","updated":"2021-02-22T05:59:04.128Z","comments":false,"path":"posts/ffce7d6d/","link":"","permalink":"https://gentryhuang.com/posts/ffce7d6d/","excerpt":"","text":"概述Dubbo 中的泛化调用主要用于客户端没有 API接口及模型类元 的情况。即客户端只需根据服务端提供的API文档，无需引入相关接口依赖，直接通过 GenericSerive 接口来发起服务调用，参数及返回值中的所有 POJO 均使用 Map 表示。泛化调用对于服务提供端是无需关注的，按正常服务暴露即可。 应用场景服务测试框架服务测试框架是作为各个 RPC 服务的调用端，一般情况下，调用端是需要依赖服务提供方接口的。而作为一个通用的测试框架不应该依赖所有服务提供方的接口，不能因为每发布一个新的服务就升级这个测试框架。这时就需要让调用方在没有服务提供方接口的情况下，仍然可以正常地发起 RPC 调用。 服务网关各个业务方可以使用 HTTP 的方式，通过服务网关调用其它服务。这种场景和通用的服务测试框架有同样的问题，不应该也不能依赖所有服务提供方的接口，也需要调用方在没有服务提供方接口的情况下，仍然可以正常地发起 RPC 调用。 代理必要性在 Dubbo 调用的过程中，调用端是通过动态代理向服务端发起远程调用，一般调用端是通过服务端接口自动生成代理对象的。但 RPC 调用的本质是调用端向服务端发送一条请求消息，服务端接收并处理，然后向调用端发送一条响应消息，调用端收到并处理响应消息，一次 RPC 调用就完成了。不难看出，是否使用代理，是否使用服务接口代理不是最重要的，重要的是调用端在没有服务接口的情况下仍然能够向服务端发送正确的请求消息。对于调用端来说，服务接口的作用仅用于创建代理对象，基于面向接口开发。 关键点在于，只要调用端将调用环境信息，如接口名，方法名，参数信息等发送给服务端，服务端就能解析并处理这条请求消息。但 Dubbo 的调用端向服务端发送消息是通过代理对象来完成的，基于这种情况，Dubbo 定义了一个统一的接口 GenericSerive ，调用端在使用该接口的代理时指定相关调用信息即可。GenericSerive 接口定义如下： 123456789101112131415161718192021222324252627282930public interface GenericService &#123; /** * 泛化调用 * * @param method 方法名 * @param parameterTypes 参数类型数组 * @param args 参数数组 * @return invocation 调用结果 * @throws GenericException potential exception thrown from the invocation */ Object $invoke(String method, String[] parameterTypes, Object[] args) throws GenericException; /** * 泛化调用异步支持 （2.7 新增） * * @param method * @param parameterTypes * @param args * @return * @throws GenericException */ default CompletableFuture&lt;Object&gt; $invokeAsync(String method, String[] parameterTypes, Object[] args) throws GenericException &#123; Object object = $invoke(method, parameterTypes, args); if (object instanceof CompletableFuture) &#123; return (CompletableFuture&lt;Object&gt;) object; &#125; return CompletableFuture.completedFuture(object); &#125;&#125; 使用示例服务端服务端无需关注泛化调用，不做任何处理，正常服务暴露即可。 接口定义 123public interface NotGenericService &#123; String getRemark(GenericRequest request);&#125; 服务暴露1&lt;dubbo:service interface=\"com.code.dubbo.NotGenericService\" ref=\"notGenericServiceImpl\"/&gt; 消费端 服务引入1&lt;dubbo:reference id=\"notGenericService\" interface=\"com.code.dubbo.NotGenericService\" generic=\"true\"/&gt; 说明： 消费端无需引入 interface 配置项的依赖，因为设置了 generic 属性，此时 Dubbo 只会将该配置项值看作是一个字符串，不会检查该接口是否存在。 interface 配置项的值是要引用的服务，通过该配置，可以从注册中心获取到所有该服务的提供方的地址。 generic 配置项支持设置 true、nativejava 以及 bean，在 Dubbo 2.7 中还支持了 protobuf-json 和 raw.return ，用于对参数进行序列化和反序列化。 服务调用1234567GenericService genericService = (GenericService) applicationContext.getBean(\"notGenericService\");// 通过 GenericSerive 发起服务调用，参数及返回值中的所有 `POJO` 均使用 `Map` 表示Map&lt;String, Object&gt; genericParamMap = new HashMap&lt;&gt;(2);genericParamMap.put(\"class\",\"com.code.dubbo.GenericRequest\");genericParamMap.put(\"remark\", \"this is remark!\");// 泛化值类型 MapObject getRemark = genericService.$invoke(\"getRemark\", new String[]&#123;\"com.code.dubbo.GenericRequest\"&#125;, new Object[]&#123;genericParamMap&#125;); 泛化接口类型调用方在进行泛化调用的时候之所以可以直接使用 GenericService 转换，是在服务引用的时候会判断是否是泛化引用，如果是泛化引用则将接口类型设置为 GenericService 。 1234567891011121314151617+--- ReferenceConfig#init // 是否是泛化引用，就直接设置当前接口为 GenericService if (ProtocolUtils.isGeneric(getGeneric())) &#123; interfaceClass = GenericService.class; // 普通接口的实现 &#125; else &#123; try &#123; // 根据接口名，获得对应的接口类 interfaceClass = Class.forName(interfaceName, true, Thread.currentThread().getContextClassLoader()); &#125; catch (ClassNotFoundException e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; // 校验接口和方法 checkInterfaceAndMethods(interfaceClass, methods); &#125; 说明： 泛化引用虽然会将服务接口类型设置为 GenericService ，但是并不影响服务发现。 GenericImplFilter123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@Activate(group = Constants.CONSUMER, value = Constants.GENERIC_KEY, order = 20000)public class GenericImplFilter implements Filter &#123; private static final Logger logger = LoggerFactory.getLogger(GenericImplFilter.class); /** * 泛化参数类型 */ private static final Class&lt;?&gt;[] GENERIC_PARAMETER_TYPES = new Class&lt;?&gt;[]&#123;String.class, String[].class, Object[].class&#125;; @Override public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; // 1. 获得 generic 配置项 String generic = invoker.getUrl().getParameter(Constants.GENERIC_KEY); // 泛化实现的调用 - 客户端调用的服务是 GenericService if (ProtocolUtils.isGeneric(generic) // 判断是否开启了泛化引用 &amp;&amp; !Constants.$INVOKE.equals(invocation.getMethodName()) // 方法名非 $invoke // 调用信息是 RpcInvocation 类型 &amp;&amp; invocation instanceof RpcInvocation) &#123; // 省略客户端调用泛化实现的逻辑 &#125; // 泛化引用的调用 - GenericService 调用服务接口 if (invocation.getMethodName().equals(Constants.$INVOKE) // 调用方法是 $invoke &amp;&amp; invocation.getArguments() != null &amp;&amp; invocation.getArguments().length == 3 // 方法参数是 3 个 // 判断是否开启了泛化引用 &amp;&amp; ProtocolUtils.isGeneric(generic)) &#123; // 2 方法参数列表 Object[] args = (Object[]) invocation.getArguments()[2]; // 3. 根据 generic 的值校验参数值 // 3.1 genecric = nativejava的情况，校验方法参数是否都为 byte[] if (ProtocolUtils.isJavaGenericSerialization(generic)) &#123; for (Object arg : args) &#123; if (!(byte[].class == arg.getClass())) &#123; error(generic, byte[].class.getName(), arg.getClass().getName()); &#125; &#125; // 3.2 generic = bean 的情况，校验方法参数 为 JavaBeanDescriptor &#125; else if (ProtocolUtils.isBeanGenericSerialization(generic)) &#123; for (Object arg : args) &#123; if (!(arg instanceof JavaBeanDescriptor)) &#123; error(generic, JavaBeanDescriptor.class.getName(), arg.getClass().getName()); &#125; &#125; &#125; // 4 通过隐式参数，传递 generic 配置项 ((RpcInvocation) invocation).setAttachment(Constants.GENERIC_KEY, invoker.getUrl().getParameter(Constants.GENERIC_KEY)); &#125; // 5 普通调用 return invoker.invoke(invocation); &#125;&#125; GenericImplFilter 是服务消费端的过滤器，主要是对 泛化引用 和 泛化实现 在调用端的处理。 泛化调用调用端进行泛化调用的时候，会对参数进行校验，防止服务端接收到参数时反序列化失败；还会将 generic 配置项通过隐式参数的形式传递到服务端。 泛化实现调用端对泛化实现的服务进行调用时，会对参数进行序列化，并重新设置 RpcInvocation 的方法名、参数类型以及参数值。 GenericFilter123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116@Activate(group = Constants.PROVIDER, order = -20000)public class GenericFilter implements Filter &#123; @Override public Result invoke(Invoker&lt;?&gt; invoker, Invocation inv) throws RpcException &#123; // 1 是否是泛化调用: 方法名：$invoke &amp; 参数个数：3 &amp; 调用接口非 GenericService if (inv.getMethodName().equals(Constants.$INVOKE) &amp;&amp; inv.getArguments() != null &amp;&amp; inv.getArguments().length == 3 &amp;&amp; !invoker.getInterface().equals(GenericService.class)) &#123; // 调用的服务方法名 String name = ((String) inv.getArguments()[0]).trim(); // 调用的服务方法参数类型 String[] types = (String[]) inv.getArguments()[1]; // 嗲用的服务方法参数列表 Object[] args = (Object[]) inv.getArguments()[2]; try &#123; // 2. 反射获得提供方的方法对象，注意这里的 invoker 是服务端的，因此 interface 是服务接口，而非GenericService Method method = ReflectUtils.findMethodByMethodSignature(invoker.getInterface(), name, types); // 2.1 获取服务提供方的目标方法的参数类型 Class&lt;?&gt;[] params = method.getParameterTypes(); if (args == null) &#123; args = new Object[params.length]; &#125; // 3 获得 generic 配置项 String generic = inv.getAttachment(Constants.GENERIC_KEY); if (StringUtils.isBlank(generic)) &#123; generic = RpcContext.getContext().getAttachment(Constants.GENERIC_KEY); &#125; // 4 根据 generic 的配置项反序列化参数值 // 4.1 如果没有设置 generic 或者 generic = true，反序列化参数，Map-&gt;Pojo (在 java 中，pojo通常用map来表示) if (StringUtils.isEmpty(generic) || ProtocolUtils.isDefaultGenericSerialization(generic)) &#123; args = PojoUtils.realize(args, params, method.getGenericParameterTypes()); // 4.2 generic = nativejava, 反序列化参数， byte[]-&gt; Pojo &#125; else if (ProtocolUtils.isJavaGenericSerialization(generic)) &#123; for (int i = 0; i &lt; args.length; i++) &#123; if (byte[].class == args[i].getClass()) &#123; try &#123; UnsafeByteArrayInputStream is = new UnsafeByteArrayInputStream((byte[]) args[i]); args[i] = ExtensionLoader.getExtensionLoader(Serialization.class) .getExtension(Constants.GENERIC_SERIALIZATION_NATIVE_JAVA) .deserialize(null, is).readObject(); &#125; catch (Exception e) &#123; throw new RpcException(\"Deserialize argument [\" + (i + 1) + \"] failed.\", e); &#125; &#125; else &#123; throw new RpcException( \"Generic serialization [\" + Constants.GENERIC_SERIALIZATION_NATIVE_JAVA + \"] only support message type \" + byte[].class + \" and your message type is \" + args[i].getClass()); &#125; &#125; // 4.3 generic = bean ，反序列化参数，JavaBeanDescriptor -&gt; Pojo &#125; else if (ProtocolUtils.isBeanGenericSerialization(generic)) &#123; for (int i = 0; i &lt; args.length; i++) &#123; if (args[i] instanceof JavaBeanDescriptor) &#123; args[i] = JavaBeanSerializeUtil.deserialize((JavaBeanDescriptor) args[i]); &#125; else &#123; throw new RpcException( \"Generic serialization [\" + Constants.GENERIC_SERIALIZATION_BEAN + \"] only support message type \" + JavaBeanDescriptor.class.getName() + \" and your message type is \" + args[i].getClass().getName()); &#125; &#125; &#125; // 5 方法参数转换完毕，进行方法调用。 // 注意此时创建了一个新的 RpcInvocation 对象。$invoke 泛化调用被转为具体的普通调用 Result result = invoker.invoke(new RpcInvocation(method, args, inv.getAttachments())); // 如果调用结果有异常，并且非GenericException异常，则使用 GenericException 包装 if (result.hasException() &amp;&amp; !(result.getException() instanceof GenericException)) &#123; return new RpcResult(new GenericException(result.getException())); &#125; // generic=nativejava的情况下，序列化结果， 结果 -&gt; btyp[] if (ProtocolUtils.isJavaGenericSerialization(generic)) &#123; try &#123; UnsafeByteArrayOutputStream os = new UnsafeByteArrayOutputStream(512); ExtensionLoader.getExtensionLoader(Serialization.class) .getExtension(Constants.GENERIC_SERIALIZATION_NATIVE_JAVA) .serialize(null, os).writeObject(result.getValue()); return new RpcResult(os.toByteArray()); &#125; catch (IOException e) &#123; throw new RpcException(\"Serialize result failed.\", e); &#125; // generic=bean 的情况下，序列化结果， 结果 -&gt; JavaBeanDescriptor &#125; else if (ProtocolUtils.isBeanGenericSerialization(generic)) &#123; return new RpcResult(JavaBeanSerializeUtil.serialize(result.getValue(), JavaBeanAccessor.METHOD)); // generic=true 的情况下，序列化结果，Pojo -&gt; Map &#125; else &#123; return new RpcResult(PojoUtils.generalize(result.getValue())); &#125; &#125; catch (NoSuchMethodException e) &#123; throw new RpcException(e.getMessage(), e); &#125; catch (ClassNotFoundException e) &#123; throw new RpcException(e.getMessage(), e); &#125; &#125; // 普通调用（包括调用泛化实现） return invoker.invoke(inv); &#125;&#125; GenericFilter 是服务端的过滤器，用于处理泛化调用逻辑，不会处理对泛化实现的调用，会将其当作普通调用处理。该过滤主要逻辑如下： 从调用信息 Invocation 中获取服务方法名、方法参数类型、方法参数列表。 反射获取提供方的方法对象，注意这里的 invoker 是服务端的，因此 interface 是服务接口，而非GenericService 。 从隐式参数中获取 generic 配置项，该配置项决定了参数反序列化的方式。 构建新的 RpcInvocation 对象进行方法调用，本质上是将 $invoke 泛化调用被转为具体的普通调用。 对调用结果进行处理，其中会对正常结果进行序列化处理，然后响应给调用端。若是异常结果，且非 GenericException 异常，则使用 GenericException 包装后返回，防止异常在服务消费端不存在导致反序列化失败。 泛化调用流程图 小结Dubbo 泛化调用实际是在 Filter 过滤链上执行的序列化和反序列化操作，服务端通过调用端传递的调用信息反射获取对应的服务方法，进而进行服务调用。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"Filter","slug":"Filter","permalink":"https://gentryhuang.com/tags/Filter/"}]},{"title":"Dubbo过滤器 - FutureFilter","slug":"rpc/Dubbo过滤器-FutureFilter","date":"2020-08-10T12:20:38.000Z","updated":"2021-02-26T08:06:23.729Z","comments":false,"path":"posts/a87a4615/","link":"","permalink":"https://gentryhuang.com/posts/a87a4615/","excerpt":"","text":"概述FutureFilter 是 Dubbo 在消费端的过滤器，用于处理消费端的事件通知。在调用之前、调用之后、出现异常时，会触发 oninvoke、onreturn、onthrow 三个事件，可以配置当事件发生时，通知哪个类的哪个方法。 示例服务接口123interface IDemoService &#123; String sayHello(String name);&#125; 服务提供端服务实现1234567@Servicepublic class DemoServiceImpl implements DemoService &#123; @Override public String sayHello(String name) &#123; return \"nice to meet you - \" + name; &#125;&#125; 服务配置1&lt;dubbo:service interface=\"com.code.dubbo.DemoService\" ref=\"demoServiceImpl\"/&gt; 服务消费端Callback 接口12345678910111213141516171819202122232425public interface Notify &#123; /** * 前置方法，必须具有与原调用方法相同的入参列表 * * @param requestParam 请求参数 */ void oninvoke(String requestParam); /** * 正常回调方法，至少要有一个入参来接收返回结果 * * @param result 用于接收原调用方法的结果 * @param requestParam 用于接收原调用方法的请求参数 */ void onreturn(String result, String requestParam); /** * 异常回调方法，至少要有一个入参且第一个入参类型为Throwable或其子类接收返回结果 * * @param ex 用于接收调用出现的异常 * @param requestPram 用于接收原调用方法的请求参数 */ void onthrow(Throwable ex, String requestPram);&#125; Callback 实现1234567891011121314151617@Servicepublic class NotifyImpl implements Notify &#123; @Override public void oninvoke(String requestParam) &#123; System.out.println(\"oninvoke is running !\"); &#125; @Override public void onreturn(String result, String requestParam) &#123; System.out.println(\"onreturn is running !\"); &#125; @Override public void onthrow(Throwable ex, String requestParam) &#123; System.out.println(\"onthrow is running !\"); &#125;&#125; 消费配置1234567891011&lt;!-- 1 oninvoke 在方法调用前触发（如果调用出现异常则会直接触发onthrow方法） 2 onreturn 在方法返回会触发（如果调用出现异常则会直接触发onthrow方法） 3 onthrow 调用出现异常时候触发 --&gt; &lt;dubbo:reference id=\"demoService\" check=\"false\" interface=\"com.code.dubbo.DemoService\"&gt; &lt;dubbo:method name=\"sayHello\" oninvoke=\"notifyImpl.oninvoke\" onreturn=\"notifyImpl.onreturn\" onthrow=\"notifyImpl.onthrow\"/&gt; &lt;/dubbo:reference&gt; FutureFilter123456789101112131415161718192021222324252627@Activate(group = Constants.CONSUMER)public class FutureFilter implements Filter &#123; protected static final Logger logger = LoggerFactory.getLogger(FutureFilter.class); @Override public Result invoke(final Invoker&lt;?&gt; invoker, final Invocation invocation) throws RpcException &#123; // 1 是否异步调用 final boolean isAsync = RpcUtils.isAsync(invoker.getUrl(), invocation); // 2 触发前置方法，即 执行 Callback.oninvoke 方法 fireInvokeCallback(invoker, invocation); // 3 调用服务提供者 Result result = invoker.invoke(invocation); // 4 异步回调 onreturn/onthrow if (isAsync) &#123; asyncCallback(invoker, invocation); // 5 同步回调用 onreturn/onth &#125; else &#123; syncCallback(invoker, invocation, result); &#125; // 返回结果，如果是异步调用或单向调用，结果是空的 return result; &#125;&#125; FutureFilter 用于触发消费端的事件通知，执行逻辑如下： 在方法调用前触发 oninvoke 指定的方法。 服务调用。 根据同步调用还是异步调用，走不同的逻辑分支。同步和异步调用的主要处理区别： 同步调用，事件触发是直接调用的，没有额外逻辑。 异步调用，需要从上下文中先获取到调用产生的 Future 对象，给该对象设置回调对象，回调对象在合适的时机触发事件通知。 触发 oninvoke12345678910111213141516171819202122232425262728293031+--- FutureFilter private void fireInvokeCallback(final Invoker&lt;?&gt; invoker, final Invocation invocation) &#123; // 获得前置方法和方法所在对象 final Method onInvokeMethod = (Method) StaticContext.getSystemContext().get(StaticContext.getKey(invoker.getUrl(), invocation.getMethodName(), Constants.ON_INVOKE_METHOD_KEY)); final Object onInvokeInst = StaticContext.getSystemContext().get(StaticContext.getKey(invoker.getUrl(), invocation.getMethodName(), Constants.ON_INVOKE_INSTANCE_KEY)); // 没有设置直接返回 if (onInvokeMethod == null &amp;&amp; onInvokeInst == null) &#123; return; &#125; if (onInvokeMethod == null || onInvokeInst == null) &#123; throw new IllegalStateException(\"service:\" + invoker.getUrl().getServiceKey() + \" has a onreturn callback config , but no such \" + (onInvokeMethod == null ? \"method\" : \"instance\") + \" found. url:\" + invoker.getUrl()); &#125; // 设置访问权限 if (!onInvokeMethod.isAccessible()) &#123; onInvokeMethod.setAccessible(true); &#125; // 获得原调用方法的入参 Object[] params = invocation.getArguments(); try &#123; // 反射调用前置方法，可以发现 oninvoke 的方法参数要与调用的方法参数一致 onInvokeMethod.invoke(onInvokeInst, params); &#125; catch (InvocationTargetException e) &#123; // 触发异常回调 fireThrowCallback(invoker, invocation, e.getTargetException()); &#125; catch (Throwable e) &#123; // 触发异常回调 fireThrowCallback(invoker, invocation, e); &#125; &#125; oninvoke 指定的方法就是前置方法，该方法会在调用服务之前执行，且该方法必须具有和原调用方法相同的入参列表。 同步回调123456789101112+--- FutureFilter private void syncCallback(final Invoker&lt;?&gt; invoker, final Invocation invocation, final Result result) &#123; // 有异常，触发异常回调 if (result.hasException()) &#123; // 注意：如果是consumer自己throw的异常，不会走到这里,而是直接执行 onthrow 方法 fireThrowCallback(invoker, invocation, result.getException()); // 正常，触发正常回调 &#125; else &#123; // 执行 onreturn 方法 fireReturnCallback(invoker, invocation, result.getValue()); &#125; &#125; 同步调用，事件触发是直接调用的。调用结果有异常则触发 onthrow 方法，没有异常则触发 onreturn 方法。 异步回调123456789101112131415161718192021222324252627282930313233343536373839404142434445464748+--- FutureFilterprivate void asyncCallback(final Invoker&lt;?&gt; invoker, final Invocation invocation) &#123; // 获得 Future 对象 。由于异步不知道服务提供方什么时候会执行完毕，所以要添加回调等待服务提供者返回结果。 Future&lt;?&gt; f = RpcContext.getContext().getFuture(); // 设置回调 ResponseCallback 到 DefaultFuture中 if (f instanceof FutureAdapter) &#123; ResponseFuture future = ((FutureAdapter&lt;?&gt;) f).getFuture(); // 当provider返回响应时，执行 DefaultFuture.doReceived 方法，该方法会调用ResponseCallback对象的done或者caught方法 future.setCallback(new ResponseCallback() &#123; /** * 正常回调 * @param rpcResult */ @Override public void done(Object rpcResult) &#123; if (rpcResult == null) &#123; logger.error(new IllegalStateException(\"invalid result value : null, expected \" + Result.class.getName())); return; &#125; ///must be rpcResult if (!(rpcResult instanceof Result)) &#123; logger.error(new IllegalStateException(\"invalid result type :\" + rpcResult.getClass() + \", expected \" + Result.class.getName())); return; &#125; // 根据调用结果，调用 ResponseCallback 对象的 done 或者 caught 方法 Result result = (Result) rpcResult; if (result.hasException()) &#123; fireThrowCallback(invoker, invocation, result.getException()); &#125; else &#123; fireReturnCallback(invoker, invocation, result.getValue()); &#125; &#125; /** * 触发异常回调方法 * @param exception */ @Override public void caught(Throwable exception) &#123; fireThrowCallback(invoker, invocation, exception); &#125; &#125;); &#125; &#125; 异步事件通知逻辑需要从上下文中先获取到调用产生的 Future 对象，然后给该对象设置回调对象，回调对象在合适的时机触发事件通知。信息交换层 中的结果通知和回调紧密关联，关于两者的交互可以参考 信息交换层。 触发 onreturn123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657+--- FutureFilter private void fireReturnCallback(final Invoker&lt;?&gt; invoker, final Invocation invocation, final Object result) &#123; // 获得 onreturn 方法和对象 final Method onReturnMethod = (Method) StaticContext.getSystemContext().get(StaticContext.getKey(invoker.getUrl(), invocation.getMethodName(), Constants.ON_RETURN_METHOD_KEY)); final Object onReturnInst = StaticContext.getSystemContext().get(StaticContext.getKey(invoker.getUrl(), invocation.getMethodName(), Constants.ON_RETURN_INSTANCE_KEY)); //not set onreturn callback if (onReturnMethod == null &amp;&amp; onReturnInst == null) &#123; return; &#125; if (onReturnMethod == null || onReturnInst == null) &#123; throw new IllegalStateException(\"service:\" + invoker.getUrl().getServiceKey() + \" has a onreturn callback config , but no such \" + (onReturnMethod == null ? \"method\" : \"instance\") + \" found. url:\" + invoker.getUrl()); &#125; if (!onReturnMethod.isAccessible()) &#123; onReturnMethod.setAccessible(true); &#125; // 原调用方法的入参 Object[] args = invocation.getArguments(); Object[] params; // onreturn 方法的参数列表 Class&lt;?&gt;[] rParaTypes = onReturnMethod.getParameterTypes(); // onreturn 方法的参数多于1个 if (rParaTypes.length &gt; 1) &#123; // onreturn(xx, Object[]) 两个参数：第一个参数与真实方法返回结果类型相同【用来接收返回结果】，第二个接收所有的真实请求参数 if (rParaTypes.length == 2 &amp;&amp; rParaTypes[1].isAssignableFrom(Object[].class)) &#123; params = new Object[2]; params[0] = result; params[1] = args; // onreturn(xx, Object... args) 多个参数：第一个参数与真实方法的返回结果类型相同，后边几个接收所有的真实请求参数 &#125; else &#123; params = new Object[args.length + 1]; params[0] = result; System.arraycopy(args, 0, params, 1, args.length); &#125; // onreturn(xx) 只有一个参数：接收返回执行结果 &#125; else &#123; params = new Object[]&#123;result&#125;; &#125; // 调用方法 try &#123; onReturnMethod.invoke(onReturnInst, params); &#125; catch (InvocationTargetException e) &#123; fireThrowCallback(invoker, invocation, e.getTargetException()); &#125; catch (Throwable e) &#123; fireThrowCallback(invoker, invocation, e); &#125; &#125; onreturn 指定的方法是返回正常结果通知方法，该方法会在调用结果没有异常的情况下执行，且该方法必须至少要有一个入参来接收返回结果。 触发 onthrow123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960+--- FutureFilterprivate void fireThrowCallback(final Invoker&lt;?&gt; invoker, final Invocation invocation, final Throwable exception) &#123; // 获得 onthrow 方法和对象 final Method onthrowMethod = (Method) StaticContext.getSystemContext().get(StaticContext.getKey(invoker.getUrl(), invocation.getMethodName(), Constants.ON_THROW_METHOD_KEY)); final Object onthrowInst = StaticContext.getSystemContext().get(StaticContext.getKey(invoker.getUrl(), invocation.getMethodName(), Constants.ON_THROW_INSTANCE_KEY)); if (onthrowMethod == null &amp;&amp; onthrowInst == null) &#123; return; &#125; if (onthrowMethod == null || onthrowInst == null) &#123; throw new IllegalStateException(\"service:\" + invoker.getUrl().getServiceKey() + \" has a onthrow callback config , but no such \" + (onthrowMethod == null ? \"method\" : \"instance\") + \" found. url:\" + invoker.getUrl()); &#125; if (!onthrowMethod.isAccessible()) &#123; onthrowMethod.setAccessible(true); &#125; // 获取 onthrow 方法的参数列表 Class&lt;?&gt;[] rParaTypes = onthrowMethod.getParameterTypes(); // onthrow 方法的参数第一个值必须为异常类型，所以这里需要构造参数列表 if (rParaTypes[0].isAssignableFrom(exception.getClass())) &#123; try &#123; // 原调用方法的参数列表 Object[] args = invocation.getArguments(); Object[] params; // onthrow 方法的参数个数 &gt; 1 if (rParaTypes.length &gt; 1) &#123; // 原调用方法只有一个参数，而且这个参数是数组类型 // onthrow(xx, Object[]) 两个参数：第一个参数接收 exception，第二个接收所有的真实请求参数 if (rParaTypes.length == 2 &amp;&amp; rParaTypes[1].isAssignableFrom(Object[].class)) &#123; params = new Object[2]; params[0] = exception; params[1] = args; // 原调用方法的参数多于一个 // onthrow(xx, Object... args) 多个参数：第一个参数接收exception，后边几个接收所有的真实请求参数 &#125; else &#123; params = new Object[args.length + 1]; params[0] = exception; System.arraycopy(args, 0, params, 1, args.length); &#125; // 原调用方法没有参数 // onthrow(xx) 只有一个参数：接收exception &#125; else &#123; params = new Object[]&#123;exception&#125;; &#125; // 调用方法 onthrowMethod.invoke(onthrowInst, params); &#125; catch (Throwable e) &#123; logger.error(invocation.getMethodName() + \".call back method invoke error . callback method :\" + onthrowMethod + \", url:\" + invoker.getUrl(), e); &#125; &#125; else &#123; logger.error(invocation.getMethodName() + \".call back method invoke error . callback method :\" + onthrowMethod + \", url:\" + invoker.getUrl(), exception); &#125; &#125;&#125; onthrow 指定的方法是返回异常结果通知方法，该方法会在调用结果有异常的情况下执行，且该方法必须至少有一个入参且第一个入参类型为Throwable或其子类接收返回的异常结果。 小结FutureFilter 用于消费端事件通知，以过滤器的形式统一处理，支持在服务调用之前、调用后以及调用异常的逻辑处理，和切面带来的结果类似。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"Filter","slug":"Filter","permalink":"https://gentryhuang.com/tags/Filter/"}]},{"title":"Dubbo过滤器 - ExceptionFilter","slug":"rpc/Dubbo过滤器-ExceptionFilter","date":"2020-08-08T13:59:38.000Z","updated":"2021-02-19T14:29:14.789Z","comments":false,"path":"posts/c5f1bd62/","link":"","permalink":"https://gentryhuang.com/posts/c5f1bd62/","excerpt":"","text":"概述ExceptionFilter 是服务端的过滤器，它不是一个统一处理异常的过滤器，关注点不在于捕获异常，而是为了找到那些返回的自定义异常，会把异常包装成 RuntimeException 。 因为异常类可能不存在于消费端，避免消费端出现不能反序列化异常的情况。 ExceptionFilter123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687@Activate(group = Constants.PROVIDER)public class ExceptionFilter implements Filter &#123; private final Logger logger; public ExceptionFilter() &#123; this(LoggerFactory.getLogger(ExceptionFilter.class)); &#125; public ExceptionFilter(Logger logger) &#123; this.logger = logger; &#125; @Override public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; try &#123; // 服务调用 Result result = invoker.invoke(invocation); // 1. 泛化调用直接抛出，非泛化调用分类处理 if (result.hasException() &amp;&amp; GenericService.class != invoker.getInterface()) &#123; try &#123; // 获取异常对象 Throwable exception = result.getException(); // 2. 如果是 checked 异常，则直接抛出 if (!(exception instanceof RuntimeException) &amp;&amp; (exception instanceof Exception)) &#123; return result; &#125; // 3. 在方法签名上有声明，直接抛出 try &#123; Method method = invoker.getInterface().getMethod(invocation.getMethodName(), invocation.getParameterTypes()); Class&lt;?&gt;[] exceptionClassses = method.getExceptionTypes(); for (Class&lt;?&gt; exceptionClass : exceptionClassses) &#123; if (exception.getClass().equals(exceptionClass)) &#123; return result; &#125; &#125; &#125; catch (NoSuchMethodException e) &#123; return result; &#125; // 未在方法签名上定义的异常，在服务端打印 错误日志 logger.error(\"Got unchecked and undeclared exception which called by \" + RpcContext.getContext().getRemoteHost() + \". service: \" + invoker.getInterface().getName() + \", method: \" + invocation.getMethodName() + \", exception: \" + exception.getClass().getName() + \": \" + exception.getMessage(), exception); // 4. 异常类和接口类在同一个 jar 包里，直接抛出 String serviceFile = ReflectUtils.getCodeBase(invoker.getInterface()); String exceptionFile = ReflectUtils.getCodeBase(exception.getClass()); if (serviceFile == null || exceptionFile == null || serviceFile.equals(exceptionFile)) &#123; return result; &#125; // 5. 是JDK自带的异常，直接抛出 String className = exception.getClass().getName(); if (className.startsWith(\"java.\") || className.startsWith(\"javax.\")) &#123; return result; &#125; // 6. 是Dubbo中定义异常，直接抛出 if (exception instanceof RpcException) &#123; return result; &#125; // 7. 否则，包装成RuntimeException 抛给客户端 return new RpcResult(new RuntimeException(StringUtils.toString(exception))); &#125; catch (Throwable e) &#123; logger.warn(\"Fail to ExceptionFilter when called by \" + RpcContext.getContext().getRemoteHost() + \". service: \" + invoker.getInterface().getName() + \", method: \" + invocation.getMethodName() + \", exception: \" + e.getClass().getName() + \": \" + e.getMessage(), e); return result; &#125; &#125; // 直接抛出 return result; &#125; catch (RuntimeException e) &#123; logger.error(\"Got unchecked and undeclared exception which called by \" + RpcContext.getContext().getRemoteHost() + \". service: \" + invoker.getInterface().getName() + \", method: \" + invocation.getMethodName() + \", exception: \" + e.getClass().getName() + \": \" + e.getMessage(), e); throw e; &#125; &#125;&#125; Dubbo 内部的异常处理类 ExceptionFilter 的处理逻辑如上面代码所示，其中 1-6 种情况客户端都能反序列化成功，第 7 步是一个兜底操作，为了防止客户端反序列化异常失败。 异常处理Dubbo 官方推荐异常处理方式如下： 1234567* 建议使用异常汇报错误，而不是返回错误码，异常信息能携带更多信息，并且语义更友好。* 如果担心性能问题，在必要时，可以通过 override 掉异常类的 fillInStackTrace() 方法为空方法，使其不拷贝栈信息。* 查询方法不建议抛出 checked 异常，否则调用方在查询时将过多的 try...catch，并且不能进行有效处理。* 服务提供方不应将 DAO 或 SQL 等异常抛给消费方，应在服务实现中对消费方不关心的异常进行包装，否则可能出现消费方无法反序列化相应异常。 自定义异常通过 ExceptionFilter 源码可知，自定义的异常如果不符合前面的 6 种情况，那么最后返回给客户端的异常会被包装成 RuntimeException ，自定义的异常也就无效了。既然如此，能不能剔除掉 ExceptionFilter 过滤器，这样就不会将自定义的异常自动包装了。但是这样的话又回到了最开始的痛点，没有 ExceptionFilter 过滤器处理客户端可能无法正确反序列化自定义的异常。因此，我们就可以自定义一个 Filter 来统一处理这种情况。 BizException一般自定义异常都是unchecked 。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798public class BizException extends RuntimeException &#123; private static final long serialVersionUID = 8056580241015398148L; /** * 异常业务编码 */ private String code; /** * 默认异常构造器. */ public BizException() &#123; super(); &#125; /** * 根据异常信息和原生异常构造对象. * * @param code 错误码 * @param msg 异常信息. * @param cause 原生异常. */ public BizException(final String code, final String msg, final Throwable cause) &#123; super(msg, cause); this.code = code; &#125; /** * 根据异常构造业务对象，设置 编码及 消息 * * @param code * @param msg */ public BizException(final String code, final String msg) &#123; super(msg); this.code = code; &#125; /** * 根据异常信息和原生异常构造对象. * * @param msg 异常信息. * @param cause 原生异常. */ public BizException(final String msg, final Throwable cause) &#123; super(msg, cause); &#125; /** * 根据异常信息构造对象. * * @param msg 异常信息. */ public BizException(final String msg) &#123; super(msg); &#125; /** * 根据异常构造业务对象，设置 编码及 消息 * * @param resultCode */ public BizException(final ResultCode resultCode) &#123; super(resultCode.getMsg()); this.code = resultCode.getCode(); &#125; /** * 根据异常构造业务对象，设置 编码及 消息 * * @param resultCode */ public BizException(final ResultCode resultCode, final Throwable cause) &#123; super(resultCode.getMsg(), cause); this.code = resultCode.getCode(); &#125; public String getCode() &#123; return code; &#125; public void setCode(String code) &#123; this.code = code; &#125; /** * 根据原生异常构造对象. * * @param cause 原生异常. */ public BizException(final Throwable cause) &#123; super(cause); &#125; @Override public synchronized Throwable fillInStackTrace() &#123; return this; &#125;&#125; 自定义 Filter12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@Activate(group = &#123;CommonConstants.PROVIDER&#125;, order = 999999)public class ProviderExceptionFilter implements Filter &#123; private Environment environment; public Environment getEnvironment() &#123; return environment; &#125; public void setEnvironment(Environment environment) &#123; this.environment = environment; &#125; @Override public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; JsonKvFormat kvFormat = makeJsonKvFormat(invoker, invocation); Result result = null; try &#123; long startTime = System.currentTimeMillis(); // invoke result = invoker.invoke(invocation); long endTime = System.currentTimeMillis(); long timeOut = Long.parseLong(environment.getProperty(\"time.out\")); if ((endTime - startTime) &gt; timeOut) &#123; recordTimeOutLog(kvFormat, endTime - startTime); &#125; // 判断调用是否有异常 if (result.hasException() &amp;&amp; GenericService.class != invoker.getInterface()) &#123; Throwable exception = result.getException(); // 是否是自定义异常 if (exception instanceof BizException) &#123; String code = ((BizException) exception).getCode(); recordBizLog(kvFormat, result); result.setValue(com.yunhu.rpc.result.Result.failResult(code, exception.getMessage())); // 是否是不记录日志的自定义异常 &#125; else if (exception instanceof NoRecordException) &#123; String code = ((NoRecordException) exception).getCode(); result.setValue(com.yunhu.rpc.result.Result.failResult(code, exception.getMessage())); // 非自定义异常统一处理 &#125; else &#123; recordErrorLog(kvFormat, exception); result.setValue(com.yunhu.rpc.result.Result.failResult(BizExceptionEnum.SYSTEM_ERROR.getCode(), BizExceptionEnum.SYSTEM_ERROR.getMessage())); &#125; //清除异常，否则调用方会以运行时异常报错！ result.setException(null); return result; &#125; return result; &#125; catch (Exception e) &#123; recordErrorLog(kvFormat, e); result.setException(null); result.setValue(com.yunhu.rpc.result.Result.failResult(BizExceptionEnum.SYSTEM_ERROR.getCode(), BizExceptionEnum.SYSTEM_ERROR.getMessage())); &#125; return result; &#125; 说明： 这里自定义 Filter 的前提是返回结果是以状态码表示的，异常的处理最终也是通过状态码返回。 自定义的 Filter 的优先级相比较 Dubbo 内置的 ExceptionFilter 的优先级要高。即使调用出现异常，自定义 Filter 会清除异常信息，到 ExceptionFilter 时就不会走异常处理流程了。 小结本篇文章对 Dubbo 框架的异常处理过滤器进行了介绍，并实现了自定义的异常处理。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"Filter","slug":"Filter","permalink":"https://gentryhuang.com/tags/Filter/"}]},{"title":"Dubbo过滤器 - TokenFilter","slug":"rpc/Dubbo过滤器-TokenFilter","date":"2020-08-06T12:59:38.000Z","updated":"2021-02-22T03:24:49.937Z","comments":false,"path":"posts/4c117d83/","link":"","permalink":"https://gentryhuang.com/posts/4c117d83/","excerpt":"","text":"概述Dubbo 框架支持通过令牌验证在注册中心控制权限，以决定是否下发令牌给消费者，以防止消费者绕过注册中心访问服务提供者，另外通过注册中心可灵活改变授权方式，而不需修改或升级提供者。 配置 全局开启令牌1234&lt;!--随机token令牌，使用UUID生成--&gt;&lt;dubbo:provider interface=\"com.foo.BarService\" token=\"true\" /&gt;&lt;!--固定token令牌，相当于密码--&gt;&lt;dubbo:provider interface=\"com.foo.BarService\" token=\"123456\" /&gt; 服务级别开启令牌1234&lt;!--随机token令牌，使用UUID生成--&gt;&lt;dubbo:service interface=\"com.foo.BarService\" token=\"true\" /&gt;&lt;!--固定token令牌，相当于密码--&gt;&lt;dubbo:service interface=\"com.foo.BarService\" token=\"123456\" /&gt; Token 流转服务提供端12345678910+--- ServiceConfig#doExportUrlsFor1Protocol // token 【使暴露出去的服务更安全，使用token做安全校验】 if (!ConfigUtils.isEmpty(token)) &#123; // true || default 时，UUID 随机生成 if (ConfigUtils.isDefault(token)) &#123; map.put(Constants.TOKEN_KEY, UUID.randomUUID().toString()); &#125; else &#123; map.put(Constants.TOKEN_KEY, token); &#125; &#125; 服务提供者将设置的 Token 最终会设置到 URL 中，最终写入到注册中心上。 服务消费端服务消费者从注册中心获取服务提供者的 URL ，从而获得该服务的 Token 。在创建 RpcInvocation 时会自动带上 Token，最终会将 Token 发送到服务提供方，而 TokenFilter 就是处理来自服务消费方的 Token 的。 TokenFilter12345678910111213141516171819202122232425262728@Activate(group = Constants.PROVIDER, value = Constants.TOKEN_KEY)public class TokenFilter implements Filter &#123; /** * 对请求的令牌做校验 * * @param invoker service * @param inv * @return * @throws RpcException */ @Override public Result invoke(Invoker&lt;?&gt; invoker, Invocation inv) throws RpcException &#123; // 获得服务提供者配置的Token 值 String token = invoker.getUrl().getParameter(Constants.TOKEN_KEY); if (ConfigUtils.isNotEmpty(token)) &#123; Class&lt;?&gt; serviceType = invoker.getInterface(); // 从 RpcInvocation 的 隐式参数中，获得 Token 值 Map&lt;String, String&gt; attachments = inv.getAttachments(); String remoteToken = attachments == null ? null : attachments.get(Constants.TOKEN_KEY); // 验证消费方【RpcInvocation的信息】传过来的的Token 和 服务提供者配置的Token 释放一致，不一致就抛出异常 if (!token.equals(remoteToken)) &#123; throw new RpcException(\"Invalid token! Forbid invoke remote service \" + serviceType + \" method \" + inv.getMethodName() + \"() from consumer \" + RpcContext.getContext().getRemoteHost() + \" to provider \" + RpcContext.getContext().getLocalHost()); &#125; &#125; return invoker.invoke(inv); &#125;&#125;","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"Filter","slug":"Filter","permalink":"https://gentryhuang.com/tags/Filter/"}]},{"title":"Dubbo过滤器 - EchoFilter","slug":"rpc/Dubbo过滤器-EchoFilter","date":"2020-08-03T14:59:38.000Z","updated":"2021-02-19T02:16:35.529Z","comments":false,"path":"posts/2e2f77b9/","link":"","permalink":"https://gentryhuang.com/posts/2e2f77b9/","excerpt":"","text":"概述回声测试用于检测服务是否可用，回声测试按照正常请求流程执行，能够测试整个调用是否通畅，可用于监控。 EchoService1234567891011public interface EchoService &#123; /** * echo test. * * @param message message. * @return message. */ Object $echo(Object message);&#125; 消费端的服务对象（代理对象）自动实现 EchoService 接口，只需将任意服务引用强制转型为 EchoService 即可使用。关于创建服务消费端的代理对象时，自动实现 EchoService 接口可以参考 回声探测接口实现 。服务提供者是不实现 EchoService 接口，而是通过 EchoFilter 来处理回声探测请求。 EchoFilter1234567891011121314@Activate(group = Constants.PROVIDER, order = -110000)public class EchoFilter implements Filter &#123; @Override public Result invoke(Invoker&lt;?&gt; invoker, Invocation inv) throws RpcException &#123; // 如果是回声探测方法 $echo(message) ,直接返回方法参数。 // 方名为 $echo,方法参数仅有一个 --&gt; 回声探测方法 if (inv.getMethodName().equals(Constants.$ECHO) &amp;&amp; inv.getArguments() != null &amp;&amp; inv.getArguments().length == 1) &#123; return new RpcResult(inv.getArguments()[0]); &#125; // 非回声探测调用，继续走后面的流程 return invoker.invoke(inv); &#125;&#125;","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"Filter","slug":"Filter","permalink":"https://gentryhuang.com/tags/Filter/"}]},{"title":"Dubbo过滤器 - TimeoutFilter","slug":"rpc/Dubbo过滤器-TimeoutFilter","date":"2020-08-02T16:00:00.000Z","updated":"2021-02-19T01:57:04.384Z","comments":false,"path":"posts/8338833e/","link":"","permalink":"https://gentryhuang.com/posts/8338833e/","excerpt":"","text":"概述服务提供端的超时过滤器，即如果服务调用超时，记录告警日志，不干涉服务的运行。 TimeoutFilter1234567891011121314151617181920212223242526272829@Activate(group = Constants.PROVIDER)public class TimeoutFilter implements Filter &#123; private static final Logger logger = LoggerFactory.getLogger(TimeoutFilter.class); @Override public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; // 调用开始时间 long start = System.currentTimeMillis(); // 执行服务调用逻辑 Result result = invoker.invoke(invocation); // 计算调用消耗时长 long elapsed = System.currentTimeMillis() - start; /** * 注意： * 1 这里timeout 是服务提供者的配置，不同于服务消费者的配置。 * 2 服务提供者执行服务即使超时了也不会取消执行，而消费者已经结束了调用，返回调用超时 */ if (invoker.getUrl() != null &amp;&amp; elapsed &gt; invoker.getUrl().getMethodParameter(invocation.getMethodName(), \"timeout\", Integer.MAX_VALUE)) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"invoke time out. method: \" + invocation.getMethodName() + \" arguments: \" + Arrays.toString(invocation.getArguments()) + \" , url is \" + invoker.getUrl() + \", invoke elapsed \" + elapsed + \" ms.\"); &#125; &#125; return result; &#125;&#125; 小结TimeoutFilter 用于记录服务端执行逻辑超时日志，是对 Dubbo 框架中所有服务的监控。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"Filter","slug":"Filter","permalink":"https://gentryhuang.com/tags/Filter/"}]},{"title":"Dubbo过滤器 - TpsLimitFilter","slug":"rpc/Dubbo过滤器-TpsLimitFilter","date":"2020-08-01T16:00:00.000Z","updated":"2021-10-16T02:23:32.796Z","comments":false,"path":"posts/f715f3aa/","link":"","permalink":"https://gentryhuang.com/posts/f715f3aa/","excerpt":"","text":"概述TpsLimitFilter 是服务提供端对 TPS 限流的实现。该过滤器的限流是基于令牌的，本质上是计数器限流的实现方式，即一个时间段内只分配 N 个令牌，每个请求过来都会消耗一个令牌，耗完即止，后面再来的请求都会被拒绝。计数器算法简单粗暴，易于实现。但是缺点也是很大的，容易造成前一个时间段非常忙碌，下一时间段又非常空闲。 配置1234&lt;!-- 每次发放 100 个令牌 --&gt;&lt;dubbo:parameter key=\"tps\" value=\"100\" /&gt;&lt;!-- 令牌刷新的间隔是 1s，如果不配置则默认 60s --&gt;&lt;dubbo:parameter key=\"tps.interval\" value=\"1000\" /&gt; 将以上的配置项添加到 &lt;dubbo:provider/&gt; 或 &lt;dubbo:service/&gt; 或 &lt;dubbo:protocol/&gt; 中开启即可。 注意，目前 Dubbo Filter 的 SPI 配置文件中并没有配置 TpsLimitFilter ，如果需要使用则配置： 12# com.alibaba.dubbo.rpc.Filter 文件tps&#x3D;com.alibaba.dubbo.rpc.filter.TpsLimitFilter TpsLimitFilter123456789101112131415161718192021@Activate(group = Constants.PROVIDER, value = Constants.TPS_LIMIT_RATE_KEY)public class TpsLimitFilter implements Filter &#123; /** * 限流器 */ private final TPSLimiter tpsLimiter = new DefaultTPSLimiter(); @Override public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; // 根据tps限流规则判断是否限制此次调用，如果是就抛出异常。目前使用 TPSLimiter作为限流器的实现类 if (!tpsLimiter.isAllowable(invoker.getUrl(), invocation)) &#123; throw new RpcException( \"Failed to invoke service \" + invoker.getInterface().getName() + \".\" + invocation.getMethodName() + \" because exceed max service tps.\"); &#125; return invoker.invoke(invocation); &#125;&#125; TPSLimiter1234567891011121314public interface TPSLimiter &#123; /** * 根据 tps 限流规则判断是否限制此次调用 * &lt;p&gt; * judge if the current invocation is allowed by TPS rule * * @param url url * @param invocation invocation * @return true allow the current invocation, otherwise, return false */ boolean isAllowable(URL url, Invocation invocation);&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * 默认TPS限制器实现类，以服务为纬度 */public class DefaultTPSLimiter implements TPSLimiter &#123; /** * StatItem 集合，即缓存每个接口的令牌数 * key: 服务键，interface + group + version * value: StatItem */ private final ConcurrentMap&lt;String, StatItem&gt; stats = new ConcurrentHashMap&lt;String, StatItem&gt;(); /** * 是否触发限流 * * @param url url * @param invocation invocation * @return */ @Override public boolean isAllowable(URL url, Invocation invocation) &#123; // 获得 tps 配置项，即令牌数 int rate = url.getParameter(Constants.TPS_LIMIT_RATE_KEY, -1); // 获得 tps.interval 周期配置项，默认60 秒，即令牌刷新时间间隔 long interval = url.getParameter(Constants.TPS_LIMIT_INTERVAL_KEY, Constants.DEFAULT_TPS_LIMIT_INTERVAL); // 获得服务键 String serviceKey = url.getServiceKey(); // 如果设置了令牌数，则开始限流处理 if (rate &gt; 0) &#123; // 获取服务键对应的 StatItem 对象 StatItem statItem = stats.get(serviceKey); // 不存在，则进行创建 if (statItem == null) &#123; stats.putIfAbsent(serviceKey, new StatItem(serviceKey, rate, interval)); statItem = stats.get(serviceKey); &#125; // 根据 tps 限流规则判断是否限制此次调用 return statItem.isAllowable(); // 不进行限流 &#125; else &#123; // 移除当前服务键关联的 StatItem StatItem statItem = stats.get(serviceKey); if (statItem != null) &#123; stats.remove(serviceKey); &#125; &#125; return true; &#125;&#125; TPSLimiter 接口中的核心是 isAllowable() 方法，在 DefaultTPSLimiter 实现中，使用 ConcurrentHashMap 为每个服务健维护了一个相应的 StatItem 对象。在 isAllowable() 方法实现中，会从 URL 中读取 tps 参数值（默认为 -1，即没有限流），对于需要限流的请求，会从 stats 集合中获取（或创建）相应 StatItem 对象，然后调用 StatItem 对象的isAllowable() 方法判断是否被限流。 StatItem12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576class StatItem &#123; /** * 统计名，目前使用服务键 */ private String name; /** * 最后重置时间 */ private long lastResetTime; /** * 令牌刷新时间间隔，即重置 token 值的时间周期，这样就实现了在 interval 时间段内能够通过 rate 个请求的效果。 */ private long interval; /** * 令牌数,初始值为 rate 值，每通过一个请求 token 递减一，当减为 0 时，不再通过任何请求，实现限流的作用。 */ private AtomicInteger token; /** * 一段时间内能通过的 TPS 上限 */ private int rate; /** * 构造方法 * * @param name 服务键 * @param rate 限制大小 * @param interval 限制周期 */ StatItem(String name, int rate, long interval) &#123; this.name = name; this.rate = rate; this.interval = interval; // 记录时间戳 this.lastResetTime = System.currentTimeMillis(); this.token = new AtomicInteger(rate); &#125; /** * 限流规则判断是否限制此次调用 * * @return */ public boolean isAllowable() &#123; // 周期性重置token long now = System.currentTimeMillis(); if (now &gt; lastResetTime + interval) &#123; token.set(rate); // 记录最近一次重置token的时间戳 lastResetTime = now; &#125; // CAS，直到获得一个令牌，或者没有足够的令牌才结束 int value = token.get(); boolean flag = false; while (value &gt; 0 &amp;&amp; !flag) &#123; flag = token.compareAndSet(value, value - 1); value = token.get(); &#125; // 是否允许访问 【取决是否能够拿到令牌】 return flag; &#125; long getLastResetTime() &#123; return lastResetTime; &#125; int getToken() &#123; return token.get(); &#125;&#125; StatItem 包装了令牌刷新的时间间隔、每次发放的令牌数等属性。它的核心是 isAllowable 方法，这也是整个 TPS 限流算法的核心。 它的主要逻辑如下： 判断上次发放令牌的时间点到现在是否超过令牌刷新的时间间隔，如果超过就重新发送令牌，之前没用完的不会叠加，而是重新设置令牌数。 通过 CAS 递减令牌，减掉后令牌数如果小于 0 则会触发限流。 小结TpsLimitFilter 中的限流算法是基于计数器，注意和令牌桶算法的区别。常见的限流算法有计数器、令牌桶、漏桶等。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"Filter","slug":"Filter","permalink":"https://gentryhuang.com/tags/Filter/"}]},{"title":"Dubbo过滤器 - ContextFilter & ConsumerContextFilter","slug":"rpc/Dubbo过滤器-RpcContext","date":"2020-07-30T16:00:00.000Z","updated":"2021-02-26T02:29:28.260Z","comments":false,"path":"posts/c72fde05/","link":"","permalink":"https://gentryhuang.com/posts/c72fde05/","excerpt":"","text":"概述ContextFilter 和 ConsumerContextFilter 分别用来初始化服务提供端和消费端的上下文 RpcContext 。无论是消费端发起的调用，还是服务端收到的调用，从节点的角度看都是一次调用，都可能产生很多中间临时信息，我们不可能要求在每个方法的参数位置都加一个上下文参数，然后一路往下传。通常做法都是放在 ThreadLocal 中，作为一个全局参数，当前线程中的任何一个地方都可以直接操作上下文信息。 RPC 上下文RpcContext 是 Dubbo 的上下文信息，其定义如下： 1 上下文中存放的是当前调用过程中所需的环境信息，如 Invoker信息，Invocation信息、地址信息等。2 RpcContext 是一个 ThreadLocal 的临时状态记录器，该对象维护两个 InternalThreadLocal，分别记录 local 和 server 的上下文。每次收到或发起 RPC 调用的时候，上下文信息都会发生改变。比如：A 调用 B，B 再调用 C，则 B 机器上：在 B 调 C 之前，RpcContext 记录的是 A 调 B 的上下信息，在 B 开始调 C 时 ，RpcContext 记录的是 B 调 C 的上下文信息。发起调用的时候上下文是由 ConsumerContextFilter 实现的，ContextFilter 保存的是收到的请求的上下文。 服务消费方12345678910// 远程调用xxxService.xxx();// 本端是否为消费端，这里会返回trueboolean isConsumerSide = RpcContext.getContext().isConsumerSide();// 获取最后一次调用的提供方IP地址String serverIP = RpcContext.getContext().getRemoteHost();// 获取当前服务配置信息，所有配置信息都将转换为URL的参数String application = RpcContext.getContext().getUrl().getParameter(\"application\");// 注意：每发起RPC调用，上下文状态会变化yyyService.yyy(); 服务停供方123456789101112131415public class XxxServiceImpl implements XxxService &#123; public void xxx() &#123; // 本端是否为提供端，这里会返回true boolean isProviderSide = RpcContext.getContext().isProviderSide(); // 获取调用方IP地址 String clientIP = RpcContext.getContext().getRemoteHost(); // 获取当前服务配置信息，所有配置信息都将转换为URL的参数 String application = RpcContext.getContext().getUrl().getParameter(\"application\"); // 注意：每发起RPC调用，上下文状态会变化 yyyService.yyy(); // 此时本端变成消费端，这里会返回false boolean isProviderSide = RpcContext.getContext().isProviderSide(); &#125; &#125; ConsumerContextFilter在服务消费者中使用，负责发起调用时初始化 RpcContext 。 1234567891011121314151617181920212223242526272829303132@Activate(group = Constants.CONSUMER, order = -10000)public class ConsumerContextFilter implements Filter &#123; @Override public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; RpcContext.getContext() // 记录Invoker .setInvoker(invoker) // 记录服务调用参数 .setInvocation(invocation) // 本地地址 .setLocalAddress(NetUtils.getLocalHost(), 0) // 远端地址 .setRemoteAddress(invoker.getUrl().getHost(), invoker.getUrl().getPort()); // 设置 RpcInvocation 对象的 invoker 属性 if (invocation instanceof RpcInvocation) &#123; ((RpcInvocation) invocation).setInvoker(invoker); &#125; try &#123; RpcResult result = (RpcResult) invoker.invoke(invocation); RpcContext.getServerContext().setAttachments(result.getAttachments()); return result; &#125; finally &#123; /** * 清理隐式参数集合 * 注意：每次服务调用完成，RpcContext设置的隐式参数都会被清理 */ RpcContext.getContext().clearAttachments(); &#125; &#125;&#125; ConsumerContextFilter 通常会和 ContextFilter 配合使用，因为在微服务环境中有很多链式调用。收到请求时，当前节点可以被看作一个服务提供者，由 ContextFilter 设置上下文。当发起请求调用其他服务，当前服务变成一个消费者，由 ConsumerContextFilter 设置上下文。 ContextFilter在服务提供者中使用，负责被调用时初始化 RpcContext 。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667@Activate(group = Constants.PROVIDER, order = -10000)public class ContextFilter implements Filter &#123; @Override public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; /** * 创建新的 attachments 集合，清理公用的隐式参数。公用的隐式参数，设置的地方如下： * @see RpcInvocation#RpcInvocation(com.alibaba.dubbo.rpc.Invocation, com.alibaba.dubbo.rpc.Invoker) */ Map&lt;String, String&gt; attachments = invocation.getAttachments(); // path，group，version，dubbo，token，timeout，async 都是保留字段，不能作为隐式参数的 key if (attachments != null) &#123; attachments = new HashMap&lt;String, String&gt;(attachments); // 清理 path attachments.remove(Constants.PATH_KEY); // 清理 group attachments.remove(Constants.GROUP_KEY); // 清理 version attachments.remove(Constants.VERSION_KEY); // 清理 dubbo attachments.remove(Constants.DUBBO_VERSION_KEY); // 清理 token attachments.remove(Constants.TOKEN_KEY); // 清理 timeout attachments.remove(Constants.TIMEOUT_KEY); // 清除异步属性，防止异步属性传到过滤器下一个环节 attachments.remove(Constants.ASYNC_KEY); &#125; // 这里和 ConsumerContextFilter 不同，没有设置 remoteAddress 的值，做为服务端的过滤器，在收到请求的时候就已经设置了 remoteAddress 的值 // @see com.alibaba.dubbo.remoting.exchange.support.ExchangeHandlerAdapter.reply RpcContext.getContext() .setInvoker(invoker) .setInvocation(invocation)// .setAttachments(attachments) // merged from dubbox .setLocalAddress(invoker.getUrl().getHost(), invoker.getUrl().getPort()); // mreged from dubbox // we may already added some attachments into RpcContext before this filter (e.g. in rest protocol) if (attachments != null) &#123; if (RpcContext.getContext().getAttachments() != null) &#123; RpcContext.getContext().getAttachments().putAll(attachments); &#125; else &#123; RpcContext.getContext().setAttachments(attachments); &#125; &#125; // 设置 RpcInvocation 对象的 'invoker' 属性 if (invocation instanceof RpcInvocation) &#123; ((RpcInvocation) invocation).setInvoker(invoker); &#125; try &#123; // 调用过滤器链的下一个节点 RpcResult result = (RpcResult) invoker.invoke(invocation); // 将 SERVER_LOCAL 这个 RpcContext 中的附加信息添加到 RpcResult 的 attachments 字段中，返回给 Consumer。 result.addAttachments(RpcContext.getServerContext().getAttachments()); return result; &#125; finally &#123; // 清除上下文信息，当前线程处理下一个调用的时候，会创建新的 RpcContext RpcContext.removeContext(); RpcContext.getServerContext().clearAttachments(); &#125; &#125;&#125; 隐式参数Dubbo 中的 Attachment 在服务消费方和提供方之间隐式传递参数，可以通过 RpcContext 上的 setAttachment 和 getAttachment 在服务消费方和提供方之间进行参数的隐式传递，而传递的载体就是 Invocation 对象。Attachment 传递的过程如下图所示： 注意： path, group, version, dubbo, token, timeout,async 几个 key 是保留字段，在设置 Attachment 参数的 key 时需要使用其它名称。 消费端在消费端使用 setAttachment 设置 KV 对，在完成一次远程调用会被清空，即多次远程调用要多次设置。 12345// 隐式传参，后面的远程调用都会隐式将这些参数发送到服务器端，类似cookie，用于框架集成，不建议常规业务使用。RpcContext.getContext().setAttachment(\"index\", \"1\"); // 远程调用Invoker.invoke(); // ... 服务端在服务提供端使用 getAttachment 获取隐式参数。 12// 获取客户端隐式传入的参数，用于框架集成，不建议常规业务使用String index = RpcContext.getContext().getAttachment(\"index\"); 小结本篇文章对 RpcContext 分别在服务提供端和服务消费端的初始化进行了介绍，初始化的时机是每次发起调用和每次被调用。有了 RpcContext 就不需要将调用相关信息通过方法依次传递了。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"Filter","slug":"Filter","permalink":"https://gentryhuang.com/tags/Filter/"}]},{"title":"Dubbo过滤器 - ClassLoaderFilter","slug":"rpc/Dubbo过滤器-ClassLoaderFilter","date":"2020-07-25T16:00:00.000Z","updated":"2021-02-18T09:53:39.254Z","comments":false,"path":"posts/3fc82a32/","link":"","permalink":"https://gentryhuang.com/posts/3fc82a32/","excerpt":"","text":"概述ClassLoaderFilter 是服务提供端的一个 Filter 实现，用于切换当前工作线程的类加载器到接口的类加载器，以便和接口的类加载器的上下文一起工作。 ClassLoaderFilter123456789101112131415161718Activate(group = Constants.PROVIDER, order = -30000)public class ClassLoaderFilter implements Filter &#123; @Override public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; // 获得当前线程的类加载器 ClassLoader ocl = Thread.currentThread().getContextClassLoader(); // 切换当前线程的类加载器为服务接口的类加载器 Thread.currentThread().setContextClassLoader(invoker.getInterface().getClassLoader()); try &#123; // 继续过滤器链的下一个节点 return invoker.invoke(invocation); &#125; finally &#123; // 切换当前线程的类加载器为原来的类加载器 Thread.currentThread().setContextClassLoader(ocl); &#125; &#125;&#125; ClassLoaderFilter 的逻辑：首先获取当前线程关联的 ClassLoader，然后将其 ClassLoader 设置为 invoker.getInterface().getClassLoader()，也就是加载服务接口类的类加载器；之后执行 invoker.invoke() 方法，执行后续的 Filter 逻辑以及业务逻辑；最后，将当前线程关联的 ClassLoader 重置为原来的 ClassLoader ocl 。 双亲委派模型如果 ClassA 和 ClassB 都是同一个类加载器加载的，则它们之间是可以相互访问的。如果 ClassA 和 ClassB 是不同的类加载器加载的，示例图如下： 根据双亲委派模型，如果 ClassA 要访问 ClassB，大致流程如下： ClassA 会从 ClassLoaderA 中查找 ClassB，看是否已经加载。 没有找到 ClassB 则会继续往上层查找，看父类加载器 ParentClassLoader 是否可以查找到 ClassB，如果找不到会继续往上层父类加载器查找。 最终没有找到，会抛出 ClassNotFoundException 异常。 如果要实现违反双亲委派模型来查找 Class，通常会使用上下文类加载器 ContextClassFilter 。 QAQ: ClassLoaderFilter 的具体作用？ A: Dubbo 框架线程的类加载器可能和服务接口的类加载器不是同一个，而当前框架线程中又需要获取服务接口的类加载中的一些 Class，为了避免出现 ClassNotFoundException，此时只需要将框架线程的类加载器切换到加载了接口定义的类加载器，进而就能获得这个类加载中的 Class 。 Extra: Dubbo 中进行序列化优化时，会根据 Invoker 中配置的 optimizer 参数获取扩展的自定义序列化处理类，这些外部引入的序列化类在框架的类加载器中肯定没有，因此需要使用 Invoker 的类加载器获取对应的类。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152+--- DubboProtocol/** * 进行序列化优化，注册需要优化的类 * * @param url * @throws RpcException */ private void optimizeSerialization(URL url) throws RpcException &#123; // 获得 optimizer 序列化优化器 配置项 String className = url.getParameter(Constants.OPTIMIZER_KEY, \"\"); // 如果系统中没有序列化优化器就直接返回 if (StringUtils.isEmpty(className) || optimizers.contains(className)) &#123; return; &#125; logger.info(\"Optimizing the serialization process for Kryo, FST, etc...\"); try &#123; // 根据 序列化优化器名 加载 SerializationOptimizer 实现类。 // 这里的当前线程的 ClassLoader 是处理过的，使用的是 Invoker 的类加载器 Class clazz = Thread.currentThread().getContextClassLoader().loadClass(className); // 是否是 SerializationOptimizer.class，或者 是SerializationOptimizer的子 if (!SerializationOptimizer.class.isAssignableFrom(clazz)) &#123; throw new RpcException(\"The serialization optimizer \" + className + \" isn't an instance of \" + SerializationOptimizer.class.getName()); &#125; // 创建 SerializationOptimizer 对象 SerializationOptimizer optimizer = (SerializationOptimizer) clazz.newInstance(); // 没有要优化的类直接返回 if (optimizer.getSerializableClasses() == null) &#123; return; &#125; // 将要优化的类注册到 SerializableClassRegistry 中 （todo 在使用 Kryo,FST 等序列化算法时，会读取该集合中的类，完成注册） for (Class c : optimizer.getSerializableClasses()) &#123; SerializableClassRegistry.registerClass(c); &#125; // 将 序列化优化器实现类名 加入到缓存中 optimizers.add(className); &#125; catch (ClassNotFoundException e) &#123; throw new RpcException(\"Cannot find the serialization optimizer class: \" + className, e); &#125; catch (InstantiationException e) &#123; throw new RpcException(\"Cannot instantiate the serialization optimizer class: \" + className, e); &#125; catch (IllegalAccessException e) &#123; throw new RpcException(\"Cannot instantiate the serialization optimizer class: \" + className, e); &#125; &#125; 小结本篇文件简单介绍了 Dubbo Filter 之 服务端的 ClassLoader 过滤器，它的作用就是用于切换当前工作线程的类加载器到接口的类加载器，以便和接口的类加载器的上下文一起工作。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"Filter","slug":"Filter","permalink":"https://gentryhuang.com/tags/Filter/"}]},{"title":"Dubbo过滤器 - ExecuteLimitFilter & ActiveLimitFilter","slug":"rpc/Dubbo过滤器-ExecuteLimitFilter","date":"2020-07-19T16:00:00.000Z","updated":"2021-10-16T02:14:59.419Z","comments":false,"path":"posts/bfcb5211/","link":"","permalink":"https://gentryhuang.com/posts/bfcb5211/","excerpt":"","text":"概述ExecuteLimitFilter 是 Dubbo 在服务提供端限流的实现，用于限制每个服务中每个方法的最大并发数（或占用线程池线程数）。ActiveLimitFilter 是 Dubbo 在消费端的限流实现，用于限制一个消费者对一个服务端方法的并发调用量（或占用连接的请求数）。它们都支持接口级别和方法级别的配置。 说明Dubbo 在 2.6 和 2.7 版本的实现中有些许差异，下面我们分别对不同版本的实现进行说明。 Dubbo 2.6 实现ExecuteLimitFilter服务端限流 配置方式1234567&lt;!-- 接口级别配置，每个方法的并发执行数（或占用线程池线程数）不能超过 N 个 --&gt;&lt;dubbo:service interface=\"com.foo.BarService\" executes=\"N\"/&gt;&lt;!-- 方法级别配置，sayHello方法的并发执行数（或占用线程池线程数）不能超过 N 个 --&gt;&lt;dubbo:service interface=\"com.foo.BarService\"&gt; &lt;dubbo:method name=\"sayHello\" executes=\"N\"&gt;&lt;/dubbo:service&gt; 注意，如果不设置，则默认不做限制，如果设置了小于等于0，那么同样是不做任何限制。 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859@Activate(group = Constants.PROVIDER, value = Constants.EXECUTES_KEY)public class ExecuteLimitFilter implements Filter &#123; @Override public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; // 获得URL URL url = invoker.getUrl(); // 获得方法名 String methodName = invocation.getMethodName(); // 信号量 Semaphore executesLimit = null; // 是否获得信号量 boolean acquireResult = false; // 获得服务提供方当前方法最大可并发请求数 int max = url.getMethodParameter(methodName, Constants.EXECUTES_KEY, 0); // 最大可并发请求数大于0 if (max &gt; 0) &#123; // 基于 服务URL + 方法纬度，创建/获取 RpcStatus 计数器 RpcStatus count = RpcStatus.getStatus(url, invocation.getMethodName()); // 创建/获取 RpcStatus 计数器对应的信号量 executesLimit = count.getSemaphore(max); // 尝试获取信号量，获取失败则抛出异常 if (executesLimit != null &amp;&amp; !(acquireResult = executesLimit.tryAcquire())) &#123; throw new RpcException(\"Failed to invoke method \" + invocation.getMethodName() + \" in provider \" + url + \", cause: The service using threads greater than &lt;dubbo:service executes=\\\"\" + max + \"\\\" /&gt; limited.\"); &#125; &#125; long begin = System.currentTimeMillis(); boolean isSuccess = true; // 计数器 +1 RpcStatus.beginCount(url, methodName); try &#123; // 服务调用 Result result = invoker.invoke(invocation); return result; &#125; catch (Throwable t) &#123; // 标记失败 isSuccess = false; if (t instanceof RuntimeException) &#123; throw (RuntimeException) t; &#125; else &#123; throw new RpcException(\"unexpected exception when ExecuteLimitFilter\", t); &#125; &#125; finally &#123; // 计数器-1 [调用失败/成功，看isSuccess的值] RpcStatus.endCount(url, methodName, System.currentTimeMillis() - begin, isSuccess); // 释放信号量 if (acquireResult) &#123; executesLimit.release(); &#125; &#125; &#125;&#125; ExecuteLimitFilter 本质上是利用 RpcStatus 中维护的 Semaphore 进行并发控制，进而达到限流的目的。需要说明的是，ExecuteLimitFilter 虽然使用到了计数器，但是起到限流作用的并不是它，而是计数器对应的信号量 Semaphore 。在 Dubbo 2.7 版本中移除了信号量的实现，使用计数器的原子类操作和CAS机制实现限流。 ActiveLimitFilter客户端限流 配置方式1234567891011&lt;!-- 接口级别配置，每个方法在每个客户端的并发调用数（占用连接的请求数）不能超过 N 个 --&gt;&lt;dubbo:service interface=\"com.foo.BarService\" actives=\"N\"/&gt; &lt;!--在服务端配置--&gt;&lt;dubbo:reference interface=\"com.foo.BarService\" actives=\"N\"/&gt; &lt;!--在客户端配置--&gt;&lt;!-- 方法级别配置，sayHello方法在每个客户端的并发调用数（占用连接的请求数）不能超过 N 个 --&gt;&lt;dubbo:service interface=\"com.foo.BarService\"&gt; &lt;dubbo:method name=\"sayHello\" actives=\"N\"&gt;&lt;!--在服务端配置--&gt;&lt;/dubbo:service&gt;&lt;dubbo:reference interface=\"com.foo.BarService\"&gt; &lt;dubbo:method name=\"sayHello\" actives=\"N\"&gt;&lt;!--在服务端配置--&gt;&lt;/dubbo:reference&gt; 注意，如果服务端侧和消费端侧都配置了 actives，则消费端侧优先。如果设置了 actives 小于等于 0，则不做并发限制。 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283@Activate(group = Constants.CONSUMER, value = Constants.ACTIVES_KEY)public class ActiveLimitFilter implements Filter &#123; @Override public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; // 获取URL URL url = invoker.getUrl(); // 获取方法名 String methodName = invocation.getMethodName(); // 获取当前方法在当前客户端的最大调用量 int max = invoker.getUrl().getMethodParameter(methodName, Constants.ACTIVES_KEY, 0); // 基于服务URL + 方法纬度， 获得 RpcStatus 对象 RpcStatus count = RpcStatus.getStatus(invoker.getUrl(), invocation.getMethodName()); if (max &gt; 0) &#123; /** * 获得超时时间 [注意：这里的超时值不占用调用服务的超时时间] ，是用来控制等待请求释放资源的时间，防止等待时间太久。 * 在极端情况下，调用服务的时间几乎是 2 * timeout */ long timeout = invoker.getUrl().getMethodParameter(invocation.getMethodName(), Constants.TIMEOUT_KEY, 0); long start = System.currentTimeMillis(); long remain = timeout; // 获取当前并发度 int active = count.getActive(); // 如果达到限流阈值，和服务提供者不一样，并不是直接抛出异常，而是先等待直到超时以等待并发度降低，因为请求是允许有超时时间的。 if (active &gt;= max) &#123; // 并发控制 synchronized (count) &#123; /** * * 循环获取当前并发数，如果大于限流阈值则等待 * 会有两种结果： * 1 某个Invoker在调用结束后，并发把计数器原子-1并唤醒等待线程，会有一个等待状态的线程被唤醒并继续执行逻辑 * 2 wait等待超时都没有被唤醒，此时抛出异常 */ while ((active = count.getActive()) &gt;= max) &#123; try &#123; // 等待，直到超时，或者被唤醒 count.wait(remain); &#125; catch (InterruptedException e) &#123; &#125; // 是否超时，超时则抛出异常 long elapsed = System.currentTimeMillis() - start; remain = timeout - elapsed; if (remain &lt;= 0) &#123; throw new RpcException(\"Waiting concurrent invoke timeout in client-side for service: \" + invoker.getInterface().getName() + \", method: \" + invocation.getMethodName() + \", elapsed: \" + elapsed + \", timeout: \" + timeout + \". concurrent invokes: \" + active + \". max concurrent invoke limit: \" + max); &#125; &#125; &#125; &#125; &#125; try &#123; long begin = System.currentTimeMillis(); // 开始计数，并发原子数 + 1 RpcStatus.beginCount(url, methodName); try &#123; // 调用服务 Result result = invoker.invoke(invocation); // 结束计数（调用成功），并发原子数 - 1 RpcStatus.endCount(url, methodName, System.currentTimeMillis() - begin, true); return result; &#125; catch (RuntimeException t) &#123; // 结束计数（调用失败），并发原子数 -1 RpcStatus.endCount(url, methodName, System.currentTimeMillis() - begin, false); throw t; &#125; &#125; finally &#123; // 唤醒等待的相同服务的相同方法的请求 if (max &gt; 0) &#123; synchronized (count) &#123; count.notify(); &#125; &#125; &#125; &#125;&#125; ActiveLimitFilter 依赖 RpcStatus 的 beginCount() 方法和 endCount() 方法来实现 RpcStatus.active 字段的增减来达到限流的目的。 此外，做为消费端的限流过滤器，达到限流的阈值时并不是直接抛出异常，而是充分利用请求超时时间，允许在请求超时时间内等待并发度降低。 RpcStatusRpcStatus 做为 ExecuteLimitFilter 和 ActiveLimitFilter 实现限流的核心类，前者限流使用 RpcStatus 封装的信号量 Semaphore ，后者限流使用 RpcStatus 维护的原子类型的 AtomicInteger active 属性。下面我们对 RpcStatus 的核心代码实现进行分析。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318public class RpcStatus &#123; /** * 服务状态信息 * key: URL * value: RpcStatus 计数器 */ private static final ConcurrentMap&lt;String, RpcStatus&gt; SERVICE_STATISTICS = new ConcurrentHashMap&lt;String, RpcStatus&gt;(); /** * 服务每个方法的状态信息 * key1: URL * key2: 方法名 * RpcStatus 计数器 */ private static final ConcurrentMap&lt;String, ConcurrentMap&lt;String, RpcStatus&gt;&gt; METHOD_STATISTICS = new ConcurrentHashMap&lt;String, ConcurrentMap&lt;String, RpcStatus&gt;&gt;(); private final ConcurrentMap&lt;String, Object&gt; values = new ConcurrentHashMap&lt;String, Object&gt;(); /** * 当前并发度 * * @see com.alibaba.dubbo.rpc.filter.ActiveLimitFilter */ private final AtomicInteger active = new AtomicInteger(); /** * 总调用次数 */ private final AtomicLong total = new AtomicLong(); /** * 总调用失败次数 */ private final AtomicInteger failed = new AtomicInteger(); /** * 总调用时长，单位： 毫秒 */ private final AtomicLong totalElapsed = new AtomicLong(); /** * 总调用失败时长，单位：毫秒 */ private final AtomicLong failedElapsed = new AtomicLong(); /** * 所有调用中最长的耗时，单位：毫秒 */ private final AtomicLong maxElapsed = new AtomicLong(); /** * 所有失败调用中最长的耗时，单位：毫秒 */ private final AtomicLong failedMaxElapsed = new AtomicLong(); /** * 所有成功调用中最长的耗时，单位：毫秒 */ private final AtomicLong succeededMaxElapsed = new AtomicLong(); /** * Semaphore used to control concurrency limit set by `executes` * &lt;p&gt; * 服务执行信号量【包含服务执行信号量大小】 * * @see com.alibaba.dubbo.rpc.filter.ExecuteLimitFilter */ private volatile Semaphore executesLimit; /** * 服务执行信号量大小 */ private volatile int executesPermits; private RpcStatus() &#123; &#125; /** * 根据服务URL为纬度的获得RpcStatus * * @param url * @return status */ public static RpcStatus getStatus(URL url) &#123; // URL的字符串 String uri = url.toIdentityString(); // 是否存在 RpcStatus status = SERVICE_STATISTICS.get(uri); // 不存在则创建，并且放入缓存中 if (status == null) &#123; SERVICE_STATISTICS.putIfAbsent(uri, new RpcStatus()); status = SERVICE_STATISTICS.get(uri); &#125; return status; &#125; /** * 根据 服务URL + 方法 获得RpcStatus * * @param url * @param methodName * @return status */ public static RpcStatus getStatus(URL url, String methodName) &#123; String uri = url.toIdentityString(); // 获得方法集合 ConcurrentMap&lt;String, RpcStatus&gt; map = METHOD_STATISTICS.get(uri); if (map == null) &#123; METHOD_STATISTICS.putIfAbsent(uri, new ConcurrentHashMap&lt;String, RpcStatus&gt;()); map = METHOD_STATISTICS.get(uri); &#125; RpcStatus status = map.get(methodName); if (status == null) &#123; map.putIfAbsent(methodName, new RpcStatus()); status = map.get(methodName); &#125; return status; &#125; /** * 服务调用开始计数 * * @param url URL 对象 * @param methodName 方法名 */ public static void beginCount(URL url, String methodName) &#123; // SERVICE_STATISTICS -&gt; 基于服务URL的计数 beginCount(getStatus(url)); // METHOD_STATISTICS -&gt; 基于服务URL + 方法的计数 beginCount(getStatus(url, methodName)); &#125; /** * 计数 - 调用中的次数 * * @param status */ private static void beginCount(RpcStatus status) &#123; status.active.incrementAndGet(); &#125; /** * 服务调用结束的计数 * * @param url URL对象 * @param methodName 方法名 * @param elapsed 时长，毫秒 * @param succeeded 是否成功 */ public static void endCount(URL url, String methodName, long elapsed, boolean succeeded) &#123; // SERVICE_STATISTICS -&gt; 基于服务URL的计数 endCount(getStatus(url), elapsed, succeeded); // METHOD_STATISTICS -&gt; 基于服务URL + 方法的计数 endCount(getStatus(url, methodName), elapsed, succeeded); &#125; /** * 结束计数 * * @param status * @param elapsed * @param succeeded */ private static void endCount(RpcStatus status, long elapsed, boolean succeeded) &#123; // 调用的次数要递减 status.active.decrementAndGet(); // 总调用次数递增 status.total.incrementAndGet(); // 总调用时长递增 status.totalElapsed.addAndGet(elapsed); // 更新最大调用时长 if (status.maxElapsed.get() &lt; elapsed) &#123; status.maxElapsed.set(elapsed); &#125; // 是否调用成功 if (succeeded) &#123; // 更新最大成功调用时长 if (status.succeededMaxElapsed.get() &lt; elapsed) &#123; status.succeededMaxElapsed.set(elapsed); &#125; &#125; else &#123; // 调用失败次数递增 status.failed.incrementAndGet(); // 总调用失败时长 status.failedElapsed.addAndGet(elapsed); // 更新最大失败调用时长 if (status.failedMaxElapsed.get() &lt; elapsed) &#123; status.failedMaxElapsed.set(elapsed); &#125; &#125; &#125; /** * set value. * * @param key * @param value */ public void set(String key, Object value) &#123; values.put(key, value); &#125; /** * get value. * * @param key * @return value */ public Object get(String key) &#123; return values.get(key); &#125; /** * get active. * * @return active */ public int getActive() &#123; return active.get(); &#125; /** * get total. * * @return total */ public long getTotal() &#123; return total.longValue(); &#125; /** * get total elapsed. * * @return total elapsed */ public long getTotalElapsed() &#123; return totalElapsed.get(); &#125; /** * get failed. * * @return failed */ public int getFailed() &#123; return failed.get(); &#125; /** * get failed elapsed. * * @return failed elapsed */ public long getFailedElapsed() &#123; return failedElapsed.get(); &#125; /** * get succeeded. * * @return succeeded */ public long getSucceeded() &#123; return getTotal() - getFailed(); &#125; /** * get succeeded elapsed. * * @return succeeded elapsed */ public long getSucceededElapsed() &#123; return getTotalElapsed() - getFailedElapsed(); &#125; /** * get succeeded average elapsed. * * @return succeeded average elapsed */ public long getSucceededAverageElapsed() &#123; long succeeded = getSucceeded(); if (succeeded == 0) &#123; return 0; &#125; return getSucceededElapsed() / succeeded; &#125; /** * get succeeded max elapsed. * * @return succeeded max elapsed. */ public long getSucceededMaxElapsed() &#123; return succeededMaxElapsed.get(); &#125; /** * 获取信号量 * &lt;p&gt; * Get the semaphore for thread number. Semaphore's permits is decided by &#123;@link Constants#EXECUTES_KEY&#125; * * @param maxThreadNum value of &#123;@link Constants#EXECUTES_KEY&#125; * @return thread number semaphore */ public Semaphore getSemaphore(int maxThreadNum) &#123; if (maxThreadNum &lt;= 0) &#123; return null; &#125; // 若信号量不存在，或者信号量大小改变，则创建新的信号量 if (executesLimit == null || executesPermits != maxThreadNum) &#123; synchronized (this) &#123; if (executesLimit == null || executesPermits != maxThreadNum) &#123; // 创建信号量 executesLimit = new Semaphore(maxThreadNum); executesPermits = maxThreadNum; &#125; &#125; &#125; // 返回信号量 return executesLimit; &#125;&#125; Dubbo 2.7 实现ExecuteLimitFilter配置方式配置方式同 Dubbo 2.6 版本实现。 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970@Activate(group = CommonConstants.PROVIDER, value = EXECUTES_KEY)public class ExecuteLimitFilter implements Filter, Filter.Listener &#123; private static final String EXECUTE_LIMIT_FILTER_START_TIME = \"execute_limit_filter_start_time\"; @Override public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; // 获取相关参数，为下面的逻辑做准备 URL url = invoker.getUrl(); String methodName = invocation.getMethodName(); int max = url.getMethodParameter(methodName, EXECUTES_KEY, 0); // 尝试增加active的值，当并发度达到executes配置指定的阈值，则直接抛出异常 if (!RpcStatus.beginCount(url, methodName, max)) &#123; throw new RpcException(RpcException.LIMIT_EXCEEDED_EXCEPTION, \"Failed to invoke method \" + invocation.getMethodName() + \" in provider \" + url + \", cause: The service using threads greater than &lt;dubbo:service executes=\\\"\" + max + \"\\\" /&gt; limited.\"); &#125; // 设置限流的开始时间，用于调用完成或调用异常后的消耗时间计算 invocation.put(EXECUTE_LIMIT_FILTER_START_TIME, System.currentTimeMillis()); try &#123; return invoker.invoke(invocation); &#125; catch (Throwable t) &#123; if (t instanceof RuntimeException) &#123; throw (RuntimeException) t; &#125; else &#123; throw new RpcException(\"unexpected exception when ExecuteLimitFilter\", t); &#125; &#125; &#125; /** * 调用结束 - Filter.Listener 接口实现 * * @param appResponse * @param invoker * @param invocation */ @Override public void onResponse(Result appResponse, Invoker&lt;?&gt; invoker, Invocation invocation) &#123; // 减小 active 的值，同时完成对一次调用的统计 RpcStatus.endCount(invoker.getUrl(), invocation.getMethodName(), getElapsed(invocation), true); &#125; /** * 调用失败 - Filter.Listener 接口实现 * * @param t * @param invoker * @param invocation */ @Override public void onError(Throwable t, Invoker&lt;?&gt; invoker, Invocation invocation) &#123; if (t instanceof RpcException) &#123; RpcException rpcException = (RpcException) t; if (rpcException.isLimitExceed()) &#123; return; &#125; &#125; // 减小 active 的值，同时完成对一次调用的统计 RpcStatus.endCount(invoker.getUrl(), invocation.getMethodName(), getElapsed(invocation), false); &#125; private long getElapsed(Invocation invocation) &#123; Object beginTime = invocation.get(EXECUTE_LIMIT_FILTER_START_TIME); return beginTime != null ? System.currentTimeMillis() - (Long) beginTime : 0; &#125;&#125; ExecuteLimitFilter 依赖 RpcStatus 的 beginCount() 方法和 endCount() 方法来实现 RpcStatus.active 字段的增减来达到限流的目的，放弃了 Dubbo 2.6 的信号量限流实现。 ActiveLimitFilter配置方式配置方式同 Dubbo 2.6 版本实现。 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111@Activate(group = CONSUMER, value = ACTIVES_KEY)public class ActiveLimitFilter implements Filter, Filter.Listener &#123; private static final String ACTIVELIMIT_FILTER_START_TIME = \"activelimit_filter_start_time\"; @Override public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; URL url = invoker.getUrl(); String methodName = invocation.getMethodName(); // 获取最大并发度 int max = invoker.getUrl().getMethodParameter(methodName, ACTIVES_KEY, 0); // 获取服务方法的 RpcStatus final RpcStatus rpcStatus = RpcStatus.getStatus(invoker.getUrl(), invocation.getMethodName()); // 尝试增加active的值，当并发度达到 actives 配置指定的阈值时，则根据超时时间进行等待重新获取 if (!RpcStatus.beginCount(url, methodName, max)) &#123; long timeout = invoker.getUrl().getMethodParameter(invocation.getMethodName(), TIMEOUT_KEY, 0); long start = System.currentTimeMillis(); long remain = timeout; // 加锁 synchronized (rpcStatus) &#123; // 再次尝试并发度加一 while (!RpcStatus.beginCount(url, methodName, max)) &#123; try &#123; // 当前线程阻塞，等待并发度降低 rpcStatus.wait(remain); &#125; catch (InterruptedException e) &#123; // ignore &#125; long elapsed = System.currentTimeMillis() - start; remain = timeout - elapsed; // 超时了则抛出限流异常 if (remain &lt;= 0) &#123; throw new RpcException(RpcException.LIMIT_EXCEEDED_EXCEPTION, \"Waiting concurrent invoke timeout in client-side for service: \" + invoker.getInterface().getName() + \", method: \" + invocation.getMethodName() + \", elapsed: \" + elapsed + \", timeout: \" + timeout + \". concurrent invokes: \" + rpcStatus.getActive() + \". max concurrent invoke limit: \" + max); &#125; &#125; &#125; &#125; // 设置调用服务前的时间戳 invocation.put(ACTIVELIMIT_FILTER_START_TIME, System.currentTimeMillis()); return invoker.invoke(invocation); &#125; /** * 调用完成-Filter.Listener 接口实现 * * @param appResponse * @param invoker * @param invocation */ @Override public void onResponse(Result appResponse, Invoker&lt;?&gt; invoker, Invocation invocation) &#123; String methodName = invocation.getMethodName(); URL url = invoker.getUrl(); int max = invoker.getUrl().getMethodParameter(methodName, ACTIVES_KEY, 0); // 减小 active 的值，同时完成对一次调用的统计 RpcStatus.endCount(url, methodName, getElapsed(invocation), true); // 调用 notifyFinish() 方法唤醒阻塞在对应 RpcStatus 对象上的线程 notifyFinish(RpcStatus.getStatus(url, methodName), max); &#125; /** * 调用失败 - Filter.Listener 接口实现 * * @param t * @param invoker * @param invocation */ @Override public void onError(Throwable t, Invoker&lt;?&gt; invoker, Invocation invocation) &#123; String methodName = invocation.getMethodName(); URL url = invoker.getUrl(); int max = invoker.getUrl().getMethodParameter(methodName, ACTIVES_KEY, 0); if (t instanceof RpcException) &#123; RpcException rpcException = (RpcException) t; // 限流异常不处理 if (rpcException.isLimitExceed()) &#123; return; &#125; &#125; // 减小 active 的值，同时完成对一次调用的统计 RpcStatus.endCount(url, methodName, getElapsed(invocation), false); // 调用 notifyFinish() 方法唤醒阻塞在对应 RpcStatus 对象上的线程（所有阻塞等待的线程） notifyFinish(RpcStatus.getStatus(url, methodName), max); &#125; private long getElapsed(Invocation invocation) &#123; Object beginTime = invocation.get(ACTIVELIMIT_FILTER_START_TIME); return beginTime != null ? System.currentTimeMillis() - (Long) beginTime : 0; &#125; /** * 唤醒因限流导致阻塞等待的线程 * * @param rpcStatus * @param max */ private void notifyFinish(final RpcStatus rpcStatus, int max) &#123; if (max &gt; 0) &#123; synchronized (rpcStatus) &#123; rpcStatus.notifyAll(); &#125; &#125; &#125;&#125; ActiveLimitFilter 同样依赖 RpcStatus 的 beginCount() 方法和 endCount() 方法来实现 RpcStatus.active 字段的增减来达到限流的目的。 RpcStatus同样地，RpcStatus 是服务端和消费端实现限流的核心实现，下面对该对象进行说明。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179public class RpcStatus &#123; /** * 服务状态信息 * key: URL * value: RpcStatus */ private static final ConcurrentMap&lt;String, RpcStatus&gt; SERVICE_STATISTICS = new ConcurrentHashMap&lt;String, RpcStatus&gt;(); /** * 服务每个方法的状态信息 * key1: URL * key2: 方法名 * value: RpcStatus */ private static final ConcurrentMap&lt;String, ConcurrentMap&lt;String, RpcStatus&gt;&gt; METHOD_STATISTICS = new ConcurrentHashMap&lt;String, ConcurrentMap&lt;String, RpcStatus&gt;&gt;(); private final ConcurrentMap&lt;String, Object&gt; values = new ConcurrentHashMap&lt;String, Object&gt;(); /** * 当前并发度 */ private final AtomicInteger active = new AtomicInteger(); /** * 调用的总数 */ private final AtomicLong total = new AtomicLong(); /** * 失败的调用数 */ private final AtomicInteger failed = new AtomicInteger(); /** * 所有调用的总耗时 */ private final AtomicLong totalElapsed = new AtomicLong(); /** * 所有失败调用的总耗时 */ private final AtomicLong failedElapsed = new AtomicLong(); /** * 所有调用中最长的耗时 */ private final AtomicLong maxElapsed = new AtomicLong(); /** * 所有失败调用中最长的耗时 */ private final AtomicLong failedMaxElapsed = new AtomicLong(); /** * 所有成功调用中最长的耗时 */ private final AtomicLong succeededMaxElapsed = new AtomicLong(); private RpcStatus() &#123; &#125; /** * @param url * @return status */ public static RpcStatus getStatus(URL url) &#123; String uri = url.toIdentityString(); return SERVICE_STATISTICS.computeIfAbsent(uri, key -&gt; new RpcStatus()); &#125; /** * @param url */ public static void removeStatus(URL url) &#123; String uri = url.toIdentityString(); SERVICE_STATISTICS.remove(uri); &#125; /** * @param url * @param methodName * @return status */ public static RpcStatus getStatus(URL url, String methodName) &#123; String uri = url.toIdentityString(); ConcurrentMap&lt;String, RpcStatus&gt; map = METHOD_STATISTICS.computeIfAbsent(uri, k -&gt; new ConcurrentHashMap&lt;&gt;()); return map.computeIfAbsent(methodName, k -&gt; new RpcStatus()); &#125; /** * @param url */ public static void removeStatus(URL url, String methodName) &#123; String uri = url.toIdentityString(); ConcurrentMap&lt;String, RpcStatus&gt; map = METHOD_STATISTICS.get(uri); if (map != null) &#123; map.remove(methodName); &#125; &#125; public static void beginCount(URL url, String methodName) &#123; beginCount(url, methodName, Integer.MAX_VALUE); &#125; /** * 在远程调用开始之前执行，其中会获取 服务和服务方法 对应的 RpcStatus 对象，然后分别将它们的 active 字段+1 * * @param url * @param methodName * @param max * @return */ public static boolean beginCount(URL url, String methodName, int max) &#123; max = (max &lt;= 0) ? Integer.MAX_VALUE : max; // 获取服务对应的 RpcStatus RpcStatus appStatus = getStatus(url); // 获取服务方法对应的 RpcStatus RpcStatus methodStatus = getStatus(url, methodName); // 是否需要限流 if (methodStatus.active.get() == Integer.MAX_VALUE) &#123; return false; &#125; // 自旋 + CAS 更新服务方法的并发度 for (int i; ; ) &#123; i = methodStatus.active.get(); // 并发度超过 max 上限，直接返回 false if (i + 1 &gt; max) &#123; return false; &#125; if (methodStatus.active.compareAndSet(i, i + 1)) &#123; break; &#125; &#125; // 服务的并发度+1 appStatus.active.incrementAndGet(); return true; &#125; /** * 会对服务和服务方法两个维度的 RpcStatus 中的所有字段进行更新，完成统计. * * @param url * @param elapsed * @param succeeded */ public static void endCount(URL url, String methodName, long elapsed, boolean succeeded) &#123; endCount(getStatus(url), elapsed, succeeded); endCount(getStatus(url, methodName), elapsed, succeeded); &#125; private static void endCount(RpcStatus status, long elapsed, boolean succeeded) &#123; // 降低并发度 status.active.decrementAndGet(); // 调用总次数增加 status.total.incrementAndGet(); // 调用总耗时增加 status.totalElapsed.addAndGet(elapsed); // 更新最大耗时 if (status.maxElapsed.get() &lt; elapsed) &#123; status.maxElapsed.set(elapsed); &#125; // 如果此次调用成功，则会更新成功调用的最大耗时 if (succeeded) &#123; if (status.succeededMaxElapsed.get() &lt; elapsed) &#123; status.succeededMaxElapsed.set(elapsed); &#125; // 如果此次调用失败，则会更新失败调用的最大耗时 &#125; else &#123; status.failed.incrementAndGet(); status.failedElapsed.addAndGet(elapsed); if (status.failedMaxElapsed.get() &lt; elapsed) &#123; status.failedMaxElapsed.set(elapsed); &#125; &#125; &#125; /** * get active. * * @return active */ public int getActive() &#123; return active.get(); &#125; // 省略其它代码&#125; 小结ExecuteLimitFilter 和 ActiveLimitFilter 分别作为服务端和消费端的限流实现，之所以前者是针对服务端的后者是针对消费端的，因为过滤器设置的针对的对象不同而已。我们可以发现 Dubbo 2.7 中两者实现逻辑几乎一致，Dubbo 2.6 中服务端的限流实现借助了信号量，消费端限流实现同样是原子类。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"Filter","slug":"Filter","permalink":"https://gentryhuang.com/tags/Filter/"}]},{"title":"Dubbo过滤器 - AccessLogFilter","slug":"rpc/Dubbo过滤器-AccessLogFilter","date":"2020-07-18T16:00:00.000Z","updated":"2021-02-26T03:40:43.928Z","comments":false,"path":"posts/40c720c7/","link":"","permalink":"https://gentryhuang.com/posts/40c720c7/","excerpt":"","text":"概述AccessLogFilter 是一个日志过滤器，在服务提供端生效，主要用于记录服务每一次的请求日志。虽然 AccessLogFilter 默认会被激活，但还是需要手动配置来开启日志的打印。注意：此日志量比较大，请注意磁盘容量。 配置 标签123&lt;dubbo:protocol accesslog=\"xxx\"&gt;&lt;dubbo:provider accesslog=\"xxx\"&gt;&lt;dubbo:service accesslog=\"xxx\"&gt; 配置方式 accesslog = “true” 或 accesslog=”default” ： 向日志组件 Logger 中输出访问日志，如logbak，将日志输出到应用本身的 log 目录下。 accesslog = “文件路径” ：直接把访问日志输出到指定文件中。 日志打印规则：如果配置的是将日志输出到日志组件，则立即写入。如果配置的是将日志输出到文件中，则将日志放入内存日志集合中，并开启定时任务进行日志持久化。 代码实现属性12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Activate(group = Constants.PROVIDER, value = Constants.ACCESS_LOG_KEY)public class AccessLogFilter implements Filter &#123; private static final Logger logger = LoggerFactory.getLogger(AccessLogFilter.class); //--------------- 使用日志组件输出相关属性 -------------------------/ /** * 日志名前缀，用于获取日志组件。用于 accesslog = true，或 accesslog = default 的情况 */ private static final String ACCESS_LOG_KEY = \"dubbo.accesslog\"; //--------------- 配置输出到指定文件的相关属性 ---------------------/ /** * 日志的文件后缀 */ private static final String FILE_DATE_FORMAT = \"yyyyMMdd\"; /** * 时间格式化 */ private static final String MESSAGE_DATE_FORMAT = \"yyyy-MM-dd HH:mm:ss\"; /** * 队列大小 */ private static final int LOG_MAX_BUFFER = 5000; /** * 日志输出频率，单位：毫秒 */ private static final long LOG_OUTPUT_INTERVAL = 5000; /** * 日志队列 * key: 自定的 accesslog 的值，如： accesslog=\"accesslog.log\" * value: 日志集合 */ private final ConcurrentMap&lt;String, Set&lt;String&gt;&gt; logQueue = new ConcurrentHashMap&lt;String, Set&lt;String&gt;&gt;(); /** * 定时任务线程池 */ private final ScheduledExecutorService logScheduled = Executors.newScheduledThreadPool(2, new NamedThreadFactory(\"Dubbo-Access-Log\", true)); /** * 记录日志任务 */ private volatile ScheduledFuture&lt;?&gt; logFuture = null; // 省略其它代码&#125; invoke 方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475+--- AccessLogFilter@Override public Result invoke(Invoker&lt;?&gt; invoker, Invocation inv) throws RpcException &#123; try &#123; // 记录访问日志的文件名 String accesslog = invoker.getUrl().getParameter(Constants.ACCESS_LOG_KEY); if (ConfigUtils.isNotEmpty(accesslog)) &#123; // dubbo 上下文 RpcContext context = RpcContext.getContext(); // 服务名 String serviceName = invoker.getInterface().getName(); // 版本号 String version = invoker.getUrl().getParameter(Constants.VERSION_KEY); // 分组 String group = invoker.getUrl().getParameter(Constants.GROUP_KEY); // 拼接日志内容 StringBuilder sn = new StringBuilder(); sn.append(\"[\") // 时间 .append(new SimpleDateFormat(MESSAGE_DATE_FORMAT).format(new Date())) // 调用方地址 .append(\"] \").append(context.getRemoteHost()).append(\":\").append(context.getRemotePort()) // 本地地址 .append(\" -&gt; \").append(context.getLocalHost()).append(\":\").append(context.getLocalPort()) .append(\" - \"); // 分组 if (null != group &amp;&amp; group.length() &gt; 0) &#123; sn.append(group).append(\"/\"); &#125; // 服务名 sn.append(serviceName); // 版本 if (null != version &amp;&amp; version.length() &gt; 0) &#123; sn.append(\":\").append(version); &#125; sn.append(\" \"); // 方法名 sn.append(inv.getMethodName()); sn.append(\"(\"); // 参数类型 Class&lt;?&gt;[] types = inv.getParameterTypes(); if (types != null &amp;&amp; types.length &gt; 0) &#123; boolean first = true; for (Class&lt;?&gt; type : types) &#123; if (first) &#123; first = false; &#125; else &#123; sn.append(\",\"); &#125; sn.append(type.getName()); &#125; &#125; sn.append(\") \"); // 参数值 Object[] args = inv.getArguments(); if (args != null &amp;&amp; args.length &gt; 0) &#123; sn.append(JSON.toJSONString(args)); &#125; // 日志信息字符串 String msg = sn.toString(); // 设置 accesslog = true 或 accesslog=default，将日志输出到日志组件Logger，如 logback中 if (ConfigUtils.isDefault(accesslog)) &#123; // 写日志 LoggerFactory.getLogger(ACCESS_LOG_KEY + \".\" + invoker.getInterface().getName()).info(msg); &#125; else &#123; // 异步输出到指定文件 log(accesslog, msg); &#125; &#125; &#125; catch (Throwable t) &#123; logger.warn(\"Exception in AcessLogFilter of service(\" + invoker + \" -&gt; \" + inv + \")\", t); &#125; return invoker.invoke(inv); &#125; 辅助方法仅用于设置日志写入到文件的情况下。 写日志1234567891011121314151617181920212223+--- AccessLogFilter /** * 添加日志内容到日志队列 * * @param accesslog 日志路径 * @param logmessage 日志内容 */ private void log(String accesslog, String logmessage) &#123; // 初始化任务 init(); // 获得日志队列 Set&lt;String&gt; logSet = logQueue.get(accesslog); if (logSet == null) &#123; logQueue.putIfAbsent(accesslog, new ConcurrentHashSet&lt;String&gt;()); logSet = logQueue.get(accesslog); &#125; // 若未超过队列大小，添加到队列中 if (logSet.size() &lt; LOG_MAX_BUFFER) &#123; logSet.add(logmessage); &#125; &#125; 初始化任务1234567891011121314+--- AccessLogFilter /** * 初始化任务 */ private void init() &#123; // 双重检锁机制，防止重复初始化 if (logFuture == null) &#123; synchronized (logScheduled) &#123; if (logFuture == null) &#123; logFuture = logScheduled.scheduleWithFixedDelay(new LogTask(), LOG_OUTPUT_INTERVAL, LOG_OUTPUT_INTERVAL, TimeUnit.MILLISECONDS); &#125; &#125; &#125; &#125; 日志任务1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162+--- AccessLogFilter /** * 日志任务 */ private class LogTask implements Runnable &#123; @Override public void run() &#123; try &#123; if (logQueue != null &amp;&amp; logQueue.size() &gt; 0) &#123; // 遍历日志队列 for (Map.Entry&lt;String, Set&lt;String&gt;&gt; entry : logQueue.entrySet()) &#123; try &#123; // 获得日志文件路径 String accesslog = entry.getKey(); // 获得日志集合 Set&lt;String&gt; logSet = entry.getValue(); // 创建日志文件 File file = new File(accesslog); File dir = file.getParentFile(); if (null != dir &amp;&amp; !dir.exists()) &#123; dir.mkdirs(); &#125; if (logger.isDebugEnabled()) &#123; logger.debug(\"Append log to \" + accesslog); &#125; // 归档历史日志文件，例如： xxx.20191217 if (file.exists()) &#123; String now = new SimpleDateFormat(FILE_DATE_FORMAT).format(new Date()); String last = new SimpleDateFormat(FILE_DATE_FORMAT).format(new Date(file.lastModified())); if (!now.equals(last)) &#123; File archive = new File(file.getAbsolutePath() + \".\" + last); file.renameTo(archive); &#125; &#125; // 输出日志到指定文件 FileWriter writer = new FileWriter(file, true); try &#123; for (Iterator&lt;String&gt; iterator = logSet.iterator(); iterator.hasNext(); iterator.remove()) &#123; // 写入一行日志 writer.write(iterator.next()); // 换行 writer.write(\"\\r\\n\"); &#125; // 刷盘 writer.flush(); &#125; finally &#123; writer.close(); &#125; &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; &#125; &#125; &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; &#125; &#125; 小结 AccessLogFilter 中会开启一个定时线程池，该线程池只有在指定了输出的文件时才会用到，该定时线程池会定时将队列中的日志写入文件中。 如果用户配置了使用应用本身的日志组件，则直接通过封装的 LoggerFactory 打印日志。如果用户配置了日志要输出到自定义的文件中，则会把日志加入到Map缓存中，key 是定义的 accesslog 的值，value 是对应的日志集合。后续等待定时线程不断遍历Map缓存，把日志写入到对应的文件中。 如果是日志输入到文件的情况，会有两个问题： 由于Set集合是无序的，因此日志输出到文件也是无序的 由于是异步刷盘，如果服务突然宕机会导致一部分日志丢失","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"Filter","slug":"Filter","permalink":"https://gentryhuang.com/tags/Filter/"}]},{"title":"Dubbo源码分析 - Dubbo过滤器","slug":"rpc/Dubbo过滤器","date":"2020-07-17T16:00:00.000Z","updated":"2021-02-18T09:02:47.576Z","comments":false,"path":"posts/96cae18/","link":"","permalink":"https://gentryhuang.com/posts/96cae18/","excerpt":"","text":"概述Dubbo 中的过滤器和 Web 应用中的过滤器的概念是一样的，提供了在服务调用前后插入自定义逻辑的途径。过滤器是整个 Dubbo 框架中非常重要的组成部分，Dubbo 中很多功能都是基于过滤器扩展而来的。过滤器提供了服务提供方和消费方调用过程的拦截，虽然拦截器功能强大，但由于每次调用时都会执行，因此在使用的时候需要考虑它对性能的影响。 Dubbo Filter 在 Dubbo 架构中的位置如下： 使用规则Dubbo 中内置了很多过滤器，大多数默认是启用的。使用方自定义的过滤器可以使用以下两种方式启用： 使用 @Activate 注解默认启用1234567@Activate(group = &#123;CommonConstants.PROVIDER&#125;, order = 999999)public class ProviderExceptionFilter implements Filter &#123; @Override public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; //... &#125;&#125; 12# 配置扩展信息providerExceptionFilter&#x3D;com.yunhu.order.system.filter.ProviderExceptionFilter 通过在XML配置文件中配置12345678&lt;!-- 消费方调用过程拦截 --&gt;&lt;dubbo:reference filter=\"xxx,yyy\"/&gt;&lt;!-- 消费方调用过程默认拦截器，将拦截所有 reference --&gt;&lt;dubbo:reference filter=\"xxx,yyy\"/&gt;&lt;!-- 服务提供方调用过程拦截器 --&gt;&lt;dubbo:service filter=\"xxx,yyy\"/&gt;&lt;!-- 服务供方调用过程默认拦截器 --&gt;&lt;dubbo:provider filter=\"xxx,yyy\"/&gt; 特别说明 过滤器顺序 自定义的过滤器的顺序默认会在 Dubbo 内置过滤器之后，使用方可以使用 filter=”xxx,default” 配置方式指定过滤器执行顺序，前面的过滤器会比后面的过滤要靠前。 剔除过滤器 使用方可以使用 “-“ 加过滤器名称来剔除对应的过滤器，如 filter=”-xxFilter” 会使 xxFilter 不生效。如果不想使用Dubbo内置的过滤器，可以配置 filter=”-default” 来剔除，但是一般不这样做，因为内置过滤器会完成特定的功能。 过滤器叠加 如果服务提供方和消费方都配置了过滤器，则两边的过滤器不会相互覆盖，而是相互叠加，都会生效。 过滤器链过滤器实现类会在扩展点初始化时进行加载、排序等，所有的 Filter 会连接成一个过滤器链，每个请求都会经过整个链路中的每一个 Filter。过滤器链的组装发生在服务暴露和服务引用的过程，也就是在服务的暴露和引用过程中，会使用 ProtocolFilterWrapper#buildInvokerChain 方法组装整个过滤器链。 服务暴露和引用过程12345678910111213141516171819202122232425+--- ProtocolFilterWrapper @Override public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; // 如果 Invoker的URL中 protocol=registry,说明不是本地暴露，invoker.url是注册中心的。无需创建Filter过滤器。 if (Constants.REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) &#123; return protocol.export(invoker); &#125; // 建立带有Filter 过滤链的 Invoker，再暴露服务。 // Constants.PROVIDER 标识自己是服务提供者类型的调用链 return protocol.export(buildInvokerChain(invoker, Constants.SERVICE_FILTER_KEY, Constants.PROVIDER)); &#125; @Override public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; // 当invoker.url.protocol=registry就直接执行RegistryProtocol的refer方法。本地引用服务不符合这个判断，远程引用服务符合判断 if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; return protocol.refer(type, url); &#125; /** * 1 引用服务，返回 Invoker 对象 * 2 引用服务完成后，调用 buildInvokerChain(invoker,key,group)方法，创建带有Filter过滤器的Invoker对象。和服务暴露区别在group的值上， * Constants.CONSUMER 标识自己是消费类型的调用链 */ return buildInvokerChain(protocol.refer(type, url), Constants.REFERENCE_FILTER_KEY, Constants.CONSUMER); &#125; 构造过滤器链1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465+--- ProtocolFilterWrapper /** * 创建带Filter链的Invoker 对象 * * @param invoker Invoker对象 * @param key URL中参数名 【如：用于获得ServiceConfig或ReferenceConfig配置的自定义过滤器】 * @param group 分组 【暴露服务时：group=provider; 引用服务时：group=consumer】 * @param &lt;T&gt; * @return 在执行的时候执行Filter */ private static &lt;T&gt; Invoker&lt;T&gt; buildInvokerChain(final Invoker&lt;T&gt; invoker, String key, String group) &#123; // 保存引用，后续用于将真正的Invoker 挂到过滤器链的最后 Invoker&lt;T&gt; last = invoker; // 获取所有的过滤器，包括类上带有@Active注解的和在XML中配置的 List&lt;Filter&gt; filters = ExtensionLoader.getExtensionLoader(Filter.class).getActivateExtension(invoker.getUrl(), key, group); // 倒序循环 Filter，递归包装Invoker，就是一个链表结构： Xx1Filter-&gt;Xx2Filter-&gt;Xx3Filter-&gt;...-&gt;Invoker if (!filters.isEmpty()) &#123; for (int i = filters.size() - 1; i &gt;= 0; i--) &#123; final Filter filter = filters.get(i); final Invoker&lt;T&gt; next = last; //匿名 Invoker 对象 last = new Invoker&lt;T&gt;() &#123; @Override public Class&lt;T&gt; getInterface() &#123; return invoker.getInterface(); &#125; @Override public URL getUrl() &#123; return invoker.getUrl(); &#125; @Override public boolean isAvailable() &#123; return invoker.isAvailable(); &#125; /** * 调用Invoker的invoke方法的时候会执行 * 1 调用Filter#invoke(invoker,invocation)方法，不断执行过滤器逻辑 * 2 在Filter中会调用Invoker#invoker(invocation)方法，最后会执行到Invoker【如：InjvmInvoker,DubboInvoker等】的invoke方法 * * @param invocation * @return * @throws RpcException */ @Override public Result invoke(Invocation invocation) throws RpcException &#123; return filter.invoke(next, invocation); &#125; @Override public void destroy() &#123; invoker.destroy(); &#125; @Override public String toString() &#123; return invoker.toString(); &#125; &#125;; &#125; &#125; return last; &#125; 构建 Invoker 的过器滤链过程如下： 使用装饰者模式，增强原有的 Invoker ，将过滤器一个又一个地套到 Invoker 上。需要注意的是，返回的 Invoker 是一个匿名内部类对象，该对象的 invoke 方法没有其它逻辑，仅用来执行 Filter.invoke 方法。当向该 Invoker 发起调用时，会先执行过滤器链，只有当过滤器链执行完毕后，才会执行真正的 Invoker 的逻辑。 QAQ: 过滤器为什么要倒排？A: 因为过滤器链是从里到外构造匿名Invoke对象的方式构建的，所以只有倒排，最外层的 Invoker 才能是第一个过滤器。说明假设有过滤器 A、B、C 和 Invoker，会按照 C、B、A 倒序遍历，过滤器链的构建顺序为： C-&gt;Invoker （匿名Invoker对象）B-&gt;C-&gt;Invoker （匿名Invoker对象）A-&gt;B-&gt;C-&gt;Invoker （匿名Invoker对象） 最终调用时的顺序就会变成 A 是第一个过滤器。 小结本篇文章对过滤总体进行了简单说明，接下来的几篇文章将对不同的过滤进行分析。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"Dubbo源码分析 - 协议层总览","slug":"rpc/协议层总览","date":"2020-07-09T16:00:00.000Z","updated":"2021-03-09T06:52:52.758Z","comments":false,"path":"posts/3131d6ea/","link":"","permalink":"https://gentryhuang.com/posts/3131d6ea/","excerpt":"","text":"前言在前面的文章中对 Dubbo 架构中的 Dubbo Remoting 层 进行了详细说明，本篇文章将介绍 Dubbo Remoting 层 的使用者 Protocol 层。Protocol 层会通过 Exchangers 门面类创建客户端 ExchangeClient 和服务端 ExchangeServer，此外还会创建通道处理器 ChannelHandler 以及编解码器 Codec2，最后将它们交给 Exchange 层进行装饰。 概述前面已经介绍过了序列化层、传输层、信息交换层以及代理层，它们各自负责 RPC 生命周期中的一环，而协议层则是位于它们之上的一层。Protocol 层在 Dubbo 架构中的位置如下图所示： Protocol 层在 Dubbo 源码中对应的是 dubbo-rpc 模块，该模块的结构如下图所示： 从上图不难看出，dubbo-rpc 和前面介绍过的模块类似，一个抽象模块和多个具体实现模块。dubbo-rpc-api 是对具体协议、服务暴露、服务引用以及代理等的抽象，是整个 Protocol 层的核心。其它模块都是对 dubbo-rpc-api 模块的具体实现，都是 Dubbo 支持的具体协议，在后面的文章中会挑选几个具有代表性的具体协议实现进行详细分析。下面我们对 dubbo-rpc-api 模块进行整体说明。 抽象模块 上图展示了 dubbo-rpc-api 模块的结构，下面我们对其核心包和类进行简单介绍。 核心包 filter 包： 在进行服务暴露和服务引用时，基于 Dubbo SPI Active 机制加载匹配对应的过滤器集合，用于创建带有过滤器链的 Invoker 对象。 listener 包： 在服务暴露和服务引用时，可以通过添加 Listener 来监听相应的事件，与 Listener 相关的接口的 XxxAdapter、XxxWrapper 实现就在这个包中。 protocol 包： 一些实现了 Protocol 接口、Invoker 接口以及 Exporter 接口的抽象类位于该包中，它们主要为具体实现提供一些公共的逻辑。 proxy 包： 提供创建代理的能力，该包中支持 JDK 动态代理以及Javassist 字节码两种方式生成代理类。 service 包： 提供了回声检测接口 EchoServe 和泛化调用接口 GenericService ，在 Dubbo 2.7中已经将此包移除。 support 包： 提供了 RpcUtils 工具类、Mock 相关的 Protocol 实现以及 Invoker 实现。 核心类在 Dubbo Protocol 层中涉及的核心接口有 Exporter、Invoker、Invocation、Result、Protocol、Filter 、ProxyFactory 等，这些接口分别抽象了 Dubbo RPC 层的不同概念，它们相互协同，构建了 Dubbo Protocol 层的骨架。下面我们将逐一介绍这些核心接口的含义。 Invoker 接口Invoker 是实体域，它是 Dubbo 的核心模型，其它模型都向它靠扰，或转换成它，它代表一个可执行体，可向它发起 invoke 调用，它有可能是一个本地的实现，也可能是一个远程的实现，也可能一个集群实现。具体定义如下： 12345678910111213141516171819public interface Invoker&lt;T&gt; extends Node &#123; /** * 服务接口 * * @return service interface. */ Class&lt;T&gt; getInterface(); /** * 一次调用 * * @param invocation * @return result * @throws RpcException */ Result invoke(Invocation invocation) throws RpcException;&#125; Consumer 端在调用 Provider端时，会首先调用本地的 Proxy 代理对象，代理对象会将请求交给本地的 Invoker ，由 Invoker 发起远程调用，然后请求到达 Provider 端的 Invoker ，然后传递给上层的具体的服务实现。简单示意图如下： 在 Consumer 端会持有接口的代理对象，该代理对象会封装一个具有远程通信功能的 *Invoker 对象，代理对象发起调用底层是通过 Invoker 完成网络调用。Provider 端的接口实现会被封装成一个 AbstractProxyInvoker 实例，进一步包装成对应的 Exporter 实例，当 Provider 端接收到一个请求之后会先找到对应的 Exporter 实例，然后调用其对应的 AbstractProxyInvoker 实例，从而完成 Provider 逻辑的调用。 Invocation 接口Invocation 接口作为一次调用的方法参数，是对一次 RPC 调用的目标服务、方法信息、参数信息、具体参数值以及一些附加信息的抽象。具体定义如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public interface Invocation &#123; /** * 调用的方法名称 * * @return method name. * @serial */ String getMethodName(); /** * 参数类型集合 * * @return parameter types. * @serial */ Class&lt;?&gt;[] getParameterTypes(); /** * 此次调用具体的参数值 * * @return arguments. * @serial */ Object[] getArguments(); /** * Invocation可以携带KV信息作为附加信息，一并传递给Provider。 * 注意：attachment 和 attribute 的区别 * * @return attachments. * @serial */ Map&lt;String, String&gt; getAttachments(); /** * get attachment by key. * * @return attachment value. * @serial */ String getAttachment(String key); /** * get attachment by key with default value. * * @return attachment value. * @serial */ String getAttachment(String key, String defaultValue); /** * 此次调用关联的Invoker 对象 * * @return invoker. * @transient */ Invoker&lt;?&gt; getInvoker();&#125; Result 接口Result 接口是一次调用的返回值，抽象了一次调用的返回结果，其中包含了被调用方返回值（或异常）以及附加信息。Result 接口定于如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public interface Result &#123; /** * 获取调用的返回值 * * @return result. if no result return null. */ Object getValue(); /** * 如果此次调用发生异常，用于获取异常信息 * * @return exception. if no exception return null. */ Throwable getException(); /** * Has exception. * * @return has exception. */ boolean hasException(); /** * recreate()方法是一个复合操作，如果此次调用发生异常，则直接抛出异常。如果没有异常，则返回结果 * &lt;p&gt; * &lt;code&gt; * if (hasException()) &#123; * throw getException(); * &#125; else &#123; * return getValue(); * &#125; * &lt;/code&gt; * * @return result. * @throws if has exception throw it. */ Object recreate() throws Throwable; /** * @see com.alibaba.dubbo.rpc.Result#getValue() * @deprecated Replace to getValue() */ @Deprecated Object getResult(); /** * Result中同样可以携带附加信息 * * @return attachments. */ Map&lt;String, String&gt; getAttachments(); /** * get attachment by key. * * @return attachment value. */ String getAttachment(String key); /** * get attachment by key with default value. * * @return attachment value. */ String getAttachment(String key, String defaultValue);&#125; Dubbo 2.7 支持添加回调方法，在 RPC 调用方法结束时会触发这些回调，定义如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public interface Result extends Serializable &#123; // 获取/设置此次调用的返回值 Object getValue(); void setValue(Object value); // 如果此次调用发生异常，则可以通过下面三个方法获取 Throwable getException(); void setException(Throwable t); boolean hasException(); // recreate()方法是一个复合操作，如果此次调用发生异常，则直接抛出异常， // 如果没有异常，则返回结果 Object recreate() throws Throwable; // 添加一个回调，当RPC调用完成时，会触发这里添加的回调 Result whenCompleteWithContext(BiConsumer&lt;Result, Throwable&gt; fn); &lt;U&gt; CompletableFuture&lt;U&gt; thenApply(Function&lt;Result, ? extends U&gt; fn); // 阻塞线程，等待此次RPC调用完成(或是超时) Result get() throws InterruptedException, ExecutionException; Result get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException; // Result中同样可以携带附加信息 Map&lt;String, String&gt; getAttachments(); Map&lt;String, Object&gt; getObjectAttachments(); void addAttachments(Map&lt;String, String&gt; map); void addObjectAttachments(Map&lt;String, Object&gt; map); void setAttachments(Map&lt;String, String&gt; map); void setObjectAttachments(Map&lt;String, Object&gt; map); String getAttachment(String key); Object getObjectAttachment(String key); String getAttachment(String key, String defaultValue); Object getObjectAttachment(String key, Object defaultValue); void setAttachment(String key, String value); void setAttachment(String key, Object value); void setObjectAttachment(String key, Object valu&#125; Exporter 接口通过前文的介绍，我们知道业务接口实现会被包装成一个 AbstractProxyInvoker 实例，然后通过 Exporter 实例暴露出去，以便 Consumer 端可以调用到该服务。Exporter 暴露 Invoker \b的实现，本质上就是让 Provider 端能够根据请求的各种信息找到对应的 Invoker 对象。Dubbo 通过维护一个 Map，其中 key 为服务键，value 为封装服务的 Exporter 实例，这样就可以实现服务的暴露了。 Exporter 接口的定义如下： 123456789101112131415161718public interface Exporter&lt;T&gt; &#123; /** * 获取底层封装的Invoker对象 * * @return invoker */ Invoker&lt;T&gt; getInvoker(); /** * 取消发布底层的Invoker对象 * &lt;p&gt; * &lt;code&gt; * getInvoker().destroy(); * &lt;/code&gt; */ void unexport();&#125; ExporterListener 接口ExporterListener 是一个扩展接口， 该接口用于监听服务的暴露和取消，目前 Dubbo 本身没有提供特别有用的扩展实现，提供该接口主要为使用方提供扩展功能。该接口定义如下： 12345678910111213141516171819202122@SPIpublic interface ExporterListener &#123; /** * 监听 服务暴露 * * @param exporter * @throws RpcException * @see org.apache.dubbo.rpc.Protocol#export(Invoker) */ void exported(Exporter&lt;?&gt; exporter) throws RpcException; /** * 监听 取消服务暴露 * * @param exporter * @throws RpcException * @see org.apache.dubbo.rpc.Exporter#unexport() */ void unexported(Exporter&lt;?&gt; exporter);&#125; InvokerListener 接口InvokerListener 接口是一个扩展接口，用于监听服务引用和销毁引用。同样地，目前 Dubbo 本身没有提供特别有用的扩展实现。该接口定义如下： 123456789101112131415161718192021@SPIpublic interface InvokerListener &#123; /** * 监听服务引用完成 * * @param invoker * @throws RpcException * @see com.alibaba.dubbo.rpc.Protocol#refer(Class, com.alibaba.dubbo.common.URL) */ void referred(Invoker&lt;?&gt; invoker) throws RpcException; /** * 监听销毁引用完成 * * @param invoker * @see com.alibaba.dubbo.rpc.Invoker#destroy() */ void destroyed(Invoker&lt;?&gt; invoker);&#125; Protocol 接口Protocol 接口中主要定义了 export() 和 refer() 方法，分别用于服务暴露和服务引用。具体定义如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@SPI(\"dubbo\")public interface Protocol &#123; /** * 默认端口 * Get default port when user doesn't config the port. * * @return default port */ int getDefaultPort(); /** * 将一个 Invoker 暴露出去 &lt;br&gt; * 1. 接收到请求后，协议应该记录请求源地址: RpcContext.getContext().setRemoteAddress();&lt;br&gt; * 2. export()必须是幂等的，也就是说，在暴露相同的URL时，调用一次和调用两次没有区别 &lt;br&gt; * 3. Invoker 是由框架传入的，协议不需要关心 &lt;br&gt; * * @param &lt;T&gt; Service type * @param invoker Service invoker * @return exporter reference for exported service, useful for unexport the service later * @throws RpcException thrown when error occurs during export the service, for example: port is occupied */ @Adaptive &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException; /** * 引用一个 Invoker &lt;br&gt; * 1. 协议的责任是根据参数返回一个 Invoker 对象，由 refer() 方法返回。&lt;br&gt; * 2. Consumer端可以通过这个Invoker请求到Provider端的服务. &lt;br&gt; * * @param &lt;T&gt; Service type * @param type Service class * @param url URL address for the remote service * @return invoker service's local proxy * @throws RpcException when there's any error while connecting to the service provider */ @Adaptive &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException; /** * 释放当前 Protocol 对象底层占用的资源 &lt;br&gt; * 1. 销毁export()方法以及refer()方法使用到的Invoker对象 &lt;br&gt; * 2. 释放所有占用资源, 如: 连接, 端口, 等等. &lt;br&gt; * 3. 协议可以继续导出和引用新的服务，即使它被销毁。 */ void destroy();&#125; 在 Protocol 接口的实现中，export() 方法并不是简单地将 Invoker 对象包装成 Exporter 对象返回，该过程还会涉及代理对象的创建、底层 Server 的启动等操作。refer() 方法除了根据传入的服务接口以及URL参数查询 Invoker 之外，还会涉及到 Client 的创建等操作。 ProxyFactory 接口ProxyFactory 接口用于在服务暴露时将服务实例封装成 Invoker 对象，在服务引用时为 Invoker 创建代理对象。接口具体定义如下： 1234567891011121314151617181920212223242526272829303132333435363738@SPI(\"javassist\")public interface ProxyFactory &#123; /** * 为传入的 Invoker 创建代理对象，在引用服务的过程会调用该方法 * &lt;p&gt; * create proxy. * * @param invoker 消费者对提供者调用的Invoker * @return proxy 代理对象 */ @Adaptive(&#123;Constants.PROXY_KEY&#125;) &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker) throws RpcException; /** * 支持是否泛型 * * @param invoker * @return proxy */ @Adaptive(&#123;Constants.PROXY_KEY&#125;) &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker, boolean generic) throws RpcException; /** * 将传入的服务实例封装成Invoker，在暴露服务时会调用 * &lt;p&gt; * create invoker. * * @param &lt;T&gt; * @param proxy Service对象 * @param type Service接口类型 * @param url Service对应的Dubbo URL * @return invoker */ @Adaptive(&#123;Constants.PROXY_KEY&#125;) &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) throws RpcException;&#125; FilterDubbo 中的 Filter 用来拦截 Dubbo 请求，Filter 是一个扩展接口。Dubbo 内置了丰富的 Filter 扩展实现，这些内置的扩展实现非常重要，它们可以完成特定的功能。此外，使用方可以根据业务需要来扩展实现 Dubbo 的功能。Filter 接口具体定义如下： 12345678910111213141516171819202122@SPIpublic interface Filter &#123; /** * 将请求传递给后续的 Invoker 处理，注意，后续的 Invoker 对象可能是一个 Filter 封装而成的。 * &lt;p&gt; * &lt;code&gt; * // before filter * Result result = invoker.invoke(invocation); * // after filter * return result; * &lt;/code&gt; * * @param invoker service * @param invocation invocation. * @return invoke result. * @throws RpcException * @see com.alibaba.dubbo.rpc.Invoker#invoke(Invocation) */ Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException;&#125; 小结本篇文章首先介绍了 Dubbo Protocol 在 Dubbo 架构中所处位置，接着简单分析了协议层对应的代码模块，最后对 Protocol 层相关的核心接口进行了说明。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"Dubbo源码分析 - 编解码器","slug":"rpc/编解码器","date":"2020-06-28T16:00:00.000Z","updated":"2020-12-23T08:27:10.332Z","comments":false,"path":"posts/61d79ae/","link":"","permalink":"https://gentryhuang.com/posts/61d79ae/","excerpt":"","text":"前言在 远程通信模块总览 和 网络传输层 中分别介绍了编解码的顶级接口 Codec2 和 Codec ，并对抽象实现类 AbstractCodec 以及 Transport 层的 TransportCodec 进行了介绍。本篇文章将介绍 Exchange 层和 Protocol 层相关的编解码器实现。 概述编解码器主要实现对消息的编码和解码，解决粘包和拆包等问题，是在序列化之上封装的一层逻辑。编码器继承体系如下图所示： 在介绍编解码器之前，我们需要先对 Dubbo 协议进行说明，脱离了 Dubbo 协议编解码器是没有意义的。 Dubbo 协议 Dubbo 协议设计参考了现有的 TCP/IP 协议，一次 RPC 调用包括协议头和协议体两部分。下面对 Dubbo 协议内容进行详细说明： 偏移比特位 表述 含义 0 ～ 7 位和 8 ～ 15 位 Magic High 和 Magic Low 分别是魔数高位和魔数低位，都是固定值，可以通过这 2 个 Byte 判断一个数据包是否为 Dubbo 协议 16 位 Req/Res 数据包类型，标识当前消息是请求还是响应。0 - Response，1 - Request 17 位 2Way 标识当前消息是单向还是双向，仅在第 16 位被设为 1（请求）时有效，0 - 单向，1 - 双向 18 位 Event 标识当前消息是否为事件消息。0 - 请求或响应包，1 - 事件消息 19 ～ 23 位 Serialization ID 序列化器编号，标识当前消息使用哪一种序列化算法。如 2 - Hessian2Serialization … 24 ～ 31 位 Status 记录响应的状态，仅在第 16 位被设为 0（响应）时有效。如 20 - OK … 32 ～ 95 位 RPC Request ID 请求编号，用于记录请求的唯一标识，用来将请求和响应做关联，类型为 long 96 ～ 127 位 Data Length 序列化后的消息体长度，该值按字节计数，类型位 int 128 ～ Body Content 消息体内容，即请求包或响应包通过特定序列化算法序列化后的结果 Dubbo 协议中前 128 位是协议头，之后的内容是消息体，而协议头就是通过 ExchangeCodec 实现编解码的。在消息体中，客户端侧严格按照序列化顺序写入消息，服务端侧会遵循相同的顺序读取消息。 TCP/IP 协议内容如下图所示： 拆包粘包问题TCP 通讯协议是面向流的，包和包之间没有界限。TCP 为了提高性能，发送端会根据缓冲区实际情况进行划分，一个完整的包可能会拆分成多个包进行发送，也可能把多个小包封装成一个大的数据包发送。同理，接收端也会维护缓冲区。这就是 TCP 拆包和粘包。 图片来源 发生原因 应用程序写入的数据大于缓冲区大小，会发生拆包。 应用程序写入的数据小于缓冲区大小，会发生粘包。 接收端不及时读取缓冲区数据，会发生粘包。 解决方案由于 TCP 通讯协议是面向流的，无法分区包的界限，解决拆包粘包问题本质上就是解决包界限的问题。 固定长度 设置定长消息，消息长度不够补充相关默认值，如空格等，接收方每次读取既定长度的内容作为一条完整消息。该方式的缺点是浪费了部分存储空间和带宽。 特殊分隔符 设置数据包的边界，如添加特定符号（回车、换行符号），接收方通过这个边界就可以将不同的数据包拆分开。 消息头 + 固定长度 把消息数据分成消息头和消息体，消息头带消息体的长度，接收方根据消息头中的长度解析数据。 Dubbo 协议解决方案Dubbo 协议使用消息头 + 固定长度的方式处理粘包和拆包问题。消息头存储消息开始标识及消息长度，接收端获取消息头的时候解析出消息长度，然后根据该长度向后读取消息内容。也就是使用编解码处理消息头，使用序列化和反序列化处理消息体。 ExchangeCodecExchangeCodec 继承了 TelnetCodec 类，是信息交换编解码器，关于 TelnetCodec 在本篇文章中暂不展开介绍。该编解码器只处理 Dubbo 协议头，DubboCodec 通过继承的方式在 ExchangeCodec 基础上添加了解析 Dubbo 消息体的功能。 属性123456789101112131415161718192021222324252627282930313233343536373839404142434445464748+--- ExchangeCodec /** * 协议头的字节数: 16Bytes = 128 Bits */ protected static final int HEADER_LENGTH = 16; /** * 协议头前16位，分为 MAGIC_HIGH 和 MAGIC_LOW 2个字节。是个固定值，标志着一个数据包是否是 Dubbo 协议 * * 11011010 10111011 */ protected static final short MAGIC = (short) 0xdabb; // -9541 /** * 魔数高位 * * 11011010 */ protected static final byte MAGIC_HIGH = Bytes.short2bytes(MAGIC)[0]; // -38 /** * 魔数低位 * * 10111011 */ protected static final byte MAGIC_LOW = Bytes.short2bytes(MAGIC)[1]; // -69 /** * 标识是请求还是响应 1 为request请求 0 为响应 * * 10000000 */ protected static final byte FLAG_REQUEST = (byte) 0x80; // -128 /** * 标识是双向传输还是单向传输 1 为双向传输 0 为是单向传输 * * 01000000 */ protected static final byte FLAG_TWOWAY = (byte) 0x40; // 64 /** * 标示是否为事件： 0 - 当前数据包是请求或响应包，1 - 当前数据包是心跳包 * * 00100000 */ protected static final byte FLAG_EVENT = (byte) 0x20; // 32 /** * 用于获取序列化类型 ID的掩码。 * * 00011111 */ protected static final int SERIALIZATION_MASK = 0x1f; // 31 Dubbo 协议头中每一位的值要么直接是上述属性的值，要么是上述属性位运算后的结果。 编码处理Dubbo 中的编码器主要用于将 Java 对象编码成字节流返回给对端，该过程涉及两部分事情，一个是构造协议头，另一个是对消息体进行序列化处理。 ExchangeCodec 编码逻辑主要步骤如下： 创建一个 16 字节的协议头数组。 根据消息包类型确定协议头数组中每一位填充值。 协议头中消息体长度位需要先对消息体进行序列化，然后再将长度设置到协议头中的消息体长度位置。消息体序列化任务交给 DubboCodec 完成（事件消息除外）。 将协议体和协议头先后写入 buffer 中。 123456789101112131415161718192021222324+--- ExchangeCodec /** * 编码 - 请求头 * * @param channel Dubbo 底层 Channel * @param buffer Dubbo 底层 Buffer * @param msg 出站消息 * @throws IOException */ @Override public void encode(Channel channel, ChannelBuffer buffer, Object msg) throws IOException &#123; // 对请求对象进行编码 if (msg instanceof Request) &#123; encodeRequest(channel, buffer, (Request) msg); // 对响应对象进行编码 &#125; else if (msg instanceof Response) &#123; encodeResponse(channel, buffer, (Response) msg); // 提交给父类(Telnet)处理， 编码Telnet命令的结果 &#125; else &#123; super.encode(channel, buffer, msg); &#125; &#125; ExchangeCodec 的 encode() 方法中会根据需要编码的消息类型进行分类，下面我们依次来看对请求对象和响应对象的编码，关于编码 Telnet 命令暂不说明。 请求消息编码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465+--- ExchangeCodec protected void encodeRequest(Channel channel, ChannelBuffer buffer, Request req) throws IOException &#123; // 获取序列化方式，如果没有配置，默认是 hessian2 Serialization serialization = getSerialization(channel); // 创建协议头字节数组，长度为16 byte[] header = new byte[HEADER_LENGTH]; // 设置魔数，占用2个字节: [0-7] -&gt; 魔数高位 -38，【8-15】 -&gt; 魔数低位 -69 Bytes.short2bytes(MAGIC, header); // 设置数据包类型（Request/Response，0 - Response 1- Request）[16] 和序列化器编号 [19,23] header[2] = (byte) (FLAG_REQUEST | serialization.getContentTypeId()); // 设置通信方式 (twoWay)，即是双向传输还是单向，0 - 单向调用，1 - 双向调用 [17] if (req.isTwoWay()) &#123; header[2] |= FLAG_TWOWAY; &#125; // 是否为事件（event）[18] if (req.isEvent()) &#123; header[2] |= FLAG_EVENT; &#125; // 设置请求编号，8个字节，从第5个字节开始设置 [32 - 95] 请求 id 编号，Long 型。 // 注意，字节数组的第4个字节[27- 31]没有设置值，因为status 状态，Request没有，Response才有 Bytes.long2bytes(req.getId(), header, 4); // 获取 buffer 当前的写位置 int savedWriteIndex = buffer.writerIndex(); // 更新 writerIndex，为协议头预留 16 个字节的空间 buffer.writerIndex(savedWriteIndex + HEADER_LENGTH); // 获取序列化器，如 Hessian2ObjectOutput ChannelBufferOutputStream bos = new ChannelBufferOutputStream(buffer); ObjectOutput out = serialization.serialize(channel.getUrl(), bos); // 对事件进行序列化 if (req.isEvent()) &#123; encodeEventData(channel, out, req.getData()); &#125; else &#123; // 对普通请求的数据进行序列化，即将req.data（一般是RpcInvocation） 写入到输出流out中，ChannelBufferOutputStream进行接收，然后存储到ChannelBuffer。 encodeRequestData(channel, out, req.getData(), req.getVersion()); &#125; out.flushBuffer(); if (out instanceof Cleanable) &#123; ((Cleanable) out).cleanup(); &#125; bos.flush(); bos.close(); // 按照字节计数请求的数据序列化后大小，是否超过消息上限。默认最大为 8M，可以通过 payload 参数配置。 int len = bos.writtenBytes(); // 可能会抛出异常，即使抛出异常也无需复位 buffer，每一个请求挂载的 ChannelBuffer 都是新建的。 checkPayload(channel, len); // 将 消息体长度写入到消息头中 [96 - 127]。这也是为什么 ChannelBuffer 要先写入消息体的原因。 Bytes.int2bytes(len, header, 12); // 将 buffer 指针移动到 savedWriteIndex，为写消息头做准备 buffer.writerIndex(savedWriteIndex); // 从 savedWriteIndex 下标处写入消息头 buffer.writeBytes(header); // 调整 ChannelBuffer 写入位置，即writerIndex = 原写下标 + 消息头长度 + 消息体长度 buffer.writerIndex(savedWriteIndex + HEADER_LENGTH + len); &#125; 理解了 Dubbo 的协议后上面的代码就非常简单了。该方法主要逻辑是编码协议头，并且对事件和普通请求消息分别做处理，encodeEventData() 方法没有什么逻辑处理，直接将事件写入到输出流 out 中，encodeRequestData() 方法是对普通请求数据的处理，其实就是对 RpcInvocation 调用进行编码，DubboCode 对 encodeRequestData() 方法进行了重写，主要为了实现对 RpcInvocation 和 RpcResult 作为消息体的编码处理，在 DubboCode 中会详细说明该方法。 事件序列化1234567+--- ExchangeCodec private void encodeEventData(Channel channel, ObjectOutput out, Object data) throws IOException &#123; encodeEventData(out, data); &#125; private void encodeEventData(ObjectOutput out, Object data) throws IOException &#123; out.writeObject(data); &#125; 请求消息序列化1234567+--- ExchangeCodec protected void encodeRequestData(Channel channel, ObjectOutput out, Object data, String version) throws IOException &#123; encodeRequestData(out, data); &#125; protected void encodeRequestData(ObjectOutput out, Object data) throws IOException &#123; out.writeObject(data); &#125; 响应编码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118+--- ExchangeCodec protected void encodeResponse(Channel channel, ChannelBuffer buffer, Response res) throws IOException &#123; // 获取写的位置 int savedWriteIndex = buffer.writerIndex(); try &#123; // 获取序列化器 Serialization serialization = getSerialization(channel); // 创建消息头字节数组，长度为16 byte[] header = new byte[HEADER_LENGTH]; // 设置魔数，占2个字节 [0-15] Bytes.short2bytes(MAGIC, header); // 设置序列化器编号,占header第3个字节的后5位 [19 -23]。 // 数据包类型（Request/Response，0 - Response 1- Request）[16] 这里使用默认 0 ，因为是响应包 header[2] = serialization.getContentTypeId(); // 如果心跳数据包，就设置header第3个字节的第3位 [18] if (res.isHeartbeat()) &#123; header[2] |= FLAG_EVENT; &#125; // 设置响应状态，占1个字节 ，[24-31] byte status = res.getStatus(); header[3] = status; // 设置请求编号，注意Response中的id就是Request的编号，占8个字节 [32-95] Bytes.long2bytes(res.getId(), header, 4); // 更新 writerIndex，为消息头预留 16 个字节的空间 buffer.writerIndex(savedWriteIndex + HEADER_LENGTH); ChannelBufferOutputStream bos = new ChannelBufferOutputStream(buffer); ObjectOutput out = serialization.serialize(channel.getUrl(), bos); // 编码响应数据或错误信息 if (status == Response.OK) &#123; if (res.isHeartbeat()) &#123; // 对心跳响应结果进行序列化 encodeHeartbeatData(channel, out, res.getResult()); &#125; else &#123; // 对响应消息进行序列化，res.getResult() 一般是 Result 对象 encodeResponseData(channel, out, res.getResult(), res.getVersion()); &#125; &#125; else &#123; // 对错误信息进行序列化 out.writeUTF(res.getErrorMessage()); &#125; out.flushBuffer(); if (out instanceof Cleanable) &#123; ((Cleanable) out).cleanup(); &#125; bos.flush(); bos.close(); // 获取消息体长度 int len = bos.writtenBytes(); // 校验消息长度有没有超出当前设置的上限 checkPayload(channel, len); // 将消息体长度写入到消息头中，占4个字节 [96-127] Bytes.int2bytes(len, header, 12); // 将 buffer 指针移动到 savedWriteIndex，为写消息头做准备 buffer.writerIndex(savedWriteIndex); // 从 savedWriteIndex 下标处写入消息头 buffer.writeBytes(header); // 设置新的 writerIndex，writerIndex = 原写下标 + 消息头长度 + 消息体长度 buffer.writerIndex(savedWriteIndex + HEADER_LENGTH + len); // 处理异常 &#125; catch (Throwable t) &#123; // clear buffer 复位 buffer buffer.writerIndex(savedWriteIndex); // send error message to Consumer, otherwise, Consumer will wait till timeout. // 注意和编码请求的不同 if (!res.isEvent() &amp;&amp; res.getStatus() != Response.BAD_RESPONSE) &#123; Response r = new Response(res.getId(), res.getVersion()); r.setStatus(Response.BAD_RESPONSE); // 消息内容过大 if (t instanceof ExceedPayloadLimitException) &#123; logger.warn(t.getMessage(), t); try &#123; r.setErrorMessage(t.getMessage()); channel.send(r); return; &#125; catch (RemotingException e) &#123; logger.warn(\"Failed to send bad_response info back: \" + t.getMessage() + \", cause: \" + e.getMessage(), e); &#125; &#125; else &#123; // FIXME log error message in Codec and handle in caught() of IoHanndler? logger.warn(\"Fail to encode response: \" + res + \", send bad_response info instead, cause: \" + t.getMessage(), t); try &#123; r.setErrorMessage(\"Failed to send response: \" + res + \", cause: \" + StringUtils.toString(t)); channel.send(r); return; &#125; catch (RemotingException e) &#123; logger.warn(\"Failed to send bad_response info back: \" + res + \", cause: \" + e.getMessage(), e); &#125; &#125; &#125; // Rethrow exception if (t instanceof IOException) &#123; throw (IOException) t; &#125; else if (t instanceof RuntimeException) &#123; throw (RuntimeException) t; &#125; else if (t instanceof Error) &#123; throw (Error) t; &#125; else &#123; throw new RuntimeException(t.getMessage(), t); &#125; &#125; &#125; encodeResponse() 方法编码响应的方式与 encodeRequest() 方法编码请求的方式类似，区别点如下: 编码响应会在协议头中 status 保存响应的状态码，编码请求是不具备的。 编码响应不会对 2Way 进行处理，只有是请求包时才会设置。 编码响应会对异常进行处理专门处理 复位 ChannelBuffer，防止缓冲区中数据错乱。 将异常响应返回给对端，防止对端只有等待超时才能返回，尽量避免无效等待。 对异常进行细分，且将异常信息转成字符串防止对端无法正常反序列化异常对象。 此外，编码响应和编码请求类似，对心跳响应的处理也是直接写入到 out 流中，而对响应的编码 encodeResponseData() 方法也被 DubboCodec 进行了重写。 心跳响应序列化123456789101112+--- ExchangeCodec @Deprecated protected void encodeHeartbeatData(Channel channel, ObjectOutput out, Object data) throws IOException &#123; encodeHeartbeatData(out, data); &#125; @Deprecated protected void encodeHeartbeatData(ObjectOutput out, Object data) throws IOException &#123; encodeEventData(out, data); &#125; private void encodeEventData(ObjectOutput out, Object data) throws IOException &#123; out.writeObject(data); &#125; 响应数据序列化1234567+--- ExchangeCodec protected void encodeResponseData(Channel channel, ObjectOutput out, Object data, String version) throws IOException &#123; encodeResponseData(out, data); &#125; protected void encodeResponseData(ObjectOutput out, Object data) throws IOException &#123; out.writeObject(data); &#125; 解码处理Dubbo 的解码器涉及两部分工作，一个是解码协议头，另一个是解码协议体。它是编码的逆过程，会先检查魔数，然后读取协议头和消息的长度，最后根据协议头中的各个标志位进行逻辑处理，以及反序列化消息数据。 ExchangeCodec 解码逻辑主要步骤如下： 从 buffer 中读取一定的字节，可能是 16 个字节也可能小于 16 字节，作为协议头数据。 如果是 Telnet 命令消息，则需要将 buffer 中数据全部读出并调用TelnetCodec的decode方法对数据包进行解码。 如果非 Telnet 命令消息，则属于 Dubbo 协议消息，消息的格式和长度必须遵循 Dubbo 协议。 第 3 步完成的是读取协议头，对协议体的处理则交给 DubboCodec 处理。 消息解码123456789101112+--- ExchangeCodec @Override public Object decode(Channel channel, ChannelBuffer buffer) throws IOException &#123; // 从Buffer 中读取字节数 int readable = buffer.readableBytes(); // 创建协议头字节数组，优先解析 Dubbo 协议，而不是 Telnet 命令 byte[] header = new byte[Math.min(readable, HEADER_LENGTH)]; // 从管道中取出header.length个字节 buffer.readBytes(header); // 解码 return decode(channel, buffer, readable, header); &#125; 注意 buffer.readBytes() 方法用于从 Channel 中读取出 header.length 个字节，可能目前 Channel 中数据不足 16 个字节，也可能大于 16 个字节。下面我们看具体的解码逻辑方法 decode() 。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263+--- ExchangeCodec @Override protected Object decode(Channel channel, ChannelBuffer buffer, int readable, byte[] header) throws IOException &#123; // 通过魔数判断是否Dubbo 消息,不是的情况下目前是Telnet 命令行发出的数据包 if (readable &gt; 0 &amp;&amp; header[0] != MAGIC_HIGH || readable &gt; 1 &amp;&amp; header[1] != MAGIC_LOW) &#123; int length = header.length; // 如果 header.length &lt; readable 成立，说明 buffer 中数据没有读完，因此需要将数据全部读取出来。因为这不是 Dubbo 协议。 if (header.length &lt; readable) &#123; header = Bytes.copyOf(header, readable); buffer.readBytes(header, length, readable - length); &#125; for (int i = 1; i &lt; header.length - 1; i++) &#123; if (header[i] == MAGIC_HIGH &amp;&amp; header[i + 1] == MAGIC_LOW) &#123; buffer.readerIndex(buffer.readerIndex() - header.length + i); header = Bytes.copyOf(header, i); break; &#125; &#125; // 通过telnet命令行发送的数据包不包含消息头，所以这里调用TelnetCodec的decode方法对数据包进行解码 return super.decode(channel, buffer, readable, header); &#125; // 检查可读数据字节数是否少于固定长度 ，若小于则返回需要更多的输入。因为Dubbo协议采用 协议头 + payload 的方式 if (readable &lt; HEADER_LENGTH) &#123; return DecodeResult.NEED_MORE_INPUT; &#125; // 从消息头中获取消息体的长度 - [96 - 127]，通过该长度读取消息体。 int len = Bytes.bytes2int(header, 12); // 检测消息体长度是否超出限制，超出则抛出异常 checkPayload(channel, len); // 检测可读的字节数是否小于实际的字节数【消息头 + 消息体 的字节长度和】，如果是则返回需要更多的输入 int tt = len + HEADER_LENGTH; if (readable &lt; tt) &#123; return DecodeResult.NEED_MORE_INPUT; &#125; // limit input stream. 根据消息体长度创建输入流对象 ChannelBufferInputStream is = new ChannelBufferInputStream(buffer, len); try &#123; // 解析 Header + Body,根据情况，根据具体数据包类型返回 Request 或 Reponse return decodeBody(channel, is, header); &#125; finally &#123; // 跳过未读完的流，并打印错误日志 if (is.available() &gt; 0) &#123; try &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"Skip input stream \" + is.available()); &#125; StreamUtils.skipUnusedStream(is); &#125; catch (IOException e) &#123; logger.warn(e.getMessage(), e); &#125; &#125; &#125; &#125; ExchangeCodec 的 decodeBody() 方法被 DubboCodec 重写了，以支持消息体的编解码功能，就不再对 ExchangeCodec 的该方法进行说明。 ExchangeCodec 中的消息解码和消息编码着重点相同，都是对协议头的编码和解码，对消息体的处理都是交给了子类 DubboCodec 来完成的。接下来就对 DubboCodec 的编码码实现进行分析。 DubboCodecDubboCodec 是 Protocol 层的编解码器，继承了 Exchange 层的 ExchangeCodec 编解码实现类。ExchangeCodec 是基于协议头对 Request 和 Response 的通用解析，Dubbo 协议中 RpcInvocation 和 RpcResult 作为消息体的处理交给了 DubboCodec 来完成，并且 DubboCodec 还支持参数回调等处理。 属性1234567891011121314151617181920212223242526272829303132333435363738394041424344public class DubboCodec extends ExchangeCodec implements Codec2 &#123; private static final Logger log = LoggerFactory.getLogger(DubboCodec.class); /** * 协议名 */ public static final String NAME = \"dubbo\"; /** * 协议版本 */ public static final String DUBBO_VERSION = Version.getProtocolVersion(); /** * 异常响应 */ public static final byte RESPONSE_WITH_EXCEPTION = 0; /** * 正常响应，有结果 */ public static final byte RESPONSE_VALUE = 1; /** * 正常响应，无结果 */ public static final byte RESPONSE_NULL_VALUE = 2; /** * 异常返回包含隐藏参数 */ public static final byte RESPONSE_WITH_EXCEPTION_WITH_ATTACHMENTS = 3; /** * 响应结果包含隐藏参数 */ public static final byte RESPONSE_VALUE_WITH_ATTACHMENTS = 4; /** * 响应空值包含隐藏参数 */ public static final byte RESPONSE_NULL_VALUE_WITH_ATTACHMENTS = 5; /** * 方法参数 */ public static final Object[] EMPTY_OBJECT_ARRAY = new Object[0]; /** * 方法参数类型 */ public static final Class&lt;?&gt;[] EMPTY_CLASS_ARRAY = new Class&lt;?&gt;[0];&#125; DubboCodec 中的属性主要是对 Dubbo 响应标记的定义，外加默认方法参数及类型。 编码消息体DubboCodec 中的编码消息体的方法都是对 ExchangeCodec 方法的重写。 编码请求消息体对 ExchangeCodec 的 encodeRequestData() 方法的重写。 12345+--- DubboCodec @Override protected void encodeRequestData(Channel channel, ObjectOutput out, Object data) throws IOException &#123; encodeRequestData(channel, out, data, DUBBO_VERSION); &#125; 1234567891011121314151617181920212223242526+--- DubboCoec @Override protected void encodeRequestData(Channel channel, ObjectOutput out, Object data, String version) throws IOException &#123; // 将请求消息转成 RpcInvocation 对象 RpcInvocation inv = (RpcInvocation) data; // 写入 `dubbo` `path` `version` out.writeUTF(version); // 写入框架版本 out.writeUTF(inv.getAttachment(Constants.PATH_KEY)); // 写入调用接口 out.writeUTF(inv.getAttachment(Constants.VERSION_KEY)); // 写入接口指定的版本，默认为 0.0.0 // 写入方法名、参数类型、参数值 out.writeUTF(inv.getMethodName()); out.writeUTF(ReflectUtils.getDesc(inv.getParameterTypes())); // 获取方法参数，依次写入方法参数值 Object[] args = inv.getArguments(); if (args != null) &#123; for (int i = 0; i &lt; args.length; i++) &#123; // 调用 CallbackServiceCodec#encodeInvocationArgument(...) 方法编码参数，主要用于参数回调功能 out.writeObject(encodeInvocationArgument(channel, inv, i)); &#125; &#125; // 写入隐式参数 Map out.writeObject(inv.getAttachments()); &#125; 根据 Dubbo 协议的格式编码请求体 RpcInvocation，按照顺序依次将所需字段编码成字节流，对应的解码在 DecodeableRpcInvocation 对象中。需要注意 out 参数，该对象由配置的序列化决定，如配置 &lt;dubbo:protocol serialization=”fastjson”/&gt;，out 就是 FastJsonObjectOutput。 编码响应消息体对 ExchangeCodec 的 encodeResponseData() 方法的重写。 12345+--- DubboCodec @Override protected void encodeResponseData(Channel channel, ObjectOutput out, Object data) throws IOException &#123; encodeResponseData(channel, out, data, DUBBO_VERSION); &#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849+--- DubboCodec @Override protected void encodeResponseData(Channel channel, ObjectOutput out, Object data, String version) throws IOException &#123; // 将响应转为 Result 对象 Result result = (Result) data; // 检测当前协议版本是否支持隐式参数 boolean attach = Version.isSupportResponseAttatchment(version); Throwable th = result.getException(); // 响应结果没有异常信息 if (th == null) &#123; // 提取正常返回结果 Object ret = result.getValue(); // 调用结果为空 if (ret == null) &#123; // 序列化响应类型 out.writeByte(attach ? RESPONSE_NULL_VALUE_WITH_ATTACHMENTS : RESPONSE_NULL_VALUE); // 调用结果非空 &#125; else &#123; // 序列化响应类型 out.writeByte(attach ? RESPONSE_VALUE_WITH_ATTACHMENTS : RESPONSE_VALUE); // 序列化调用结果 out.writeObject(ret); &#125; //响应结果有异常 &#125; else &#123; // 序列化响应类型 out.writeByte(attach ? RESPONSE_WITH_EXCEPTION_WITH_ATTACHMENTS : RESPONSE_WITH_EXCEPTION); // 序列化异常对象 out.writeObject(th); &#125; // 当前协议版本支持Response带有attachments集合 if (attach) &#123; // 记录 Dubbo 协议版本，返回给服务消费端 result.getAttachments().put(Constants.DUBBO_VERSION_KEY, Version.getProtocolVersion()); // 序列化 attachments 集合 out.writeObject(result.getAttachments()); &#125; &#125; 根据 Dubbo 协议的格式编码响应体，主要将 Dubbo 响应状态和响应值编码成字节流，对应的解码在 DecodeableRpcResult 对象中。out 参数注意事项同编码请求消息体。 解码消息体对 ExchangeCodec 的 decodeBody() 方法的重写，用于将数据包解析成 Request 和 Response 模型。 解码请求体将请求包解析成 Request 模型。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384+--- DubboCodec @Override protected Object decodeBody(Channel channel, InputStream is, byte[] header) throws IOException &#123; // 协议头第 3 个字节 byte flag = header[2]; // 获取序列化器编号 byte proto = (byte) (flag &amp; SERIALIZATION_MASK); // 获得调用编号（请求时生成的一个id，用来标识一次调用） long id = Bytes.bytes2long(header, 4); // Req/Res -&gt; 0 ，即响应包 if ((flag &amp; FLAG_REQUEST) == 0) &#123; // 省略解码响应逻辑 // Req/Res -&gt; 0 ，即请求包 &#125; else &#123; // 创建Request Request req = new Request(id); req.setVersion(Version.getProtocolVersion()); // 设置消息单向或双向 req.setTwoWay((flag &amp; FLAG_TWOWAY) != 0); // 设置消息是否为事件消息 if ((flag &amp; FLAG_EVENT) != 0) &#123; // 设置心跳事件到Request对象中 req.setEvent(Request.HEARTBEAT_EVENT); &#125; try &#123; Object data; // 通过序列化器编号间接获取输入流 ObjectInput in = CodecSupport.deserialize(channel.getUrl(), is, proto); // 解码心跳事件，心跳报文没有消息体 if (req.isHeartbeat()) &#123; // 对心跳包进行解码，该方法已经废弃，父类 ExchangeCodec 中的方法 data = decodeHeartbeatData(channel, in); // 对其他事件数据解码，这里是 readonly 事件 &#125; else if (req.isEvent()) &#123; // 父类 ExchangeCodec 中的方法 data = decodeEventData(channel, in); // 解码普通请求 &#125; else &#123; DecodeableRpcInvocation inv; // 根据url参数判断，是否在通信框架（如Netty）的IO线程上对消息体进行解码，默认为 true if (channel.getUrl().getParameter(Constants.DECODE_IN_IO_THREAD_KEY, Constants.DEFAULT_DECODE_IN_IO_THREAD)) &#123; // 创建可解码的 DecodeableRpcInvocation 对象 inv = new DecodeableRpcInvocation(channel, req, is, proto); // 直接调用decode()方法在当前线程，即IO线程上进行解码工作 inv.decode(); // 在 Dubbo ThreadPool 线程上解码，使用 DecodeHandler &#125; else &#123; inv = new DecodeableRpcInvocation(channel, req, new UnsafeByteArrayInputStream(readMessageData(is)), proto); &#125; // 并没有解码，延迟到业务线程池中解码 data = inv; &#125; // 设置data 到 Request 对象中, req.setData(data); &#125; catch (Throwable t) &#123; if (log.isWarnEnabled()) &#123; log.warn(\"Decode request failed: \" + t.getMessage(), t); &#125; // 在解码的过程中出现异常，则设置 broken 字段标识请求异常，并将异常对象设置到Request对象中 req.setBroken(true); req.setData(t); &#125; return req; &#125; &#125; 解码响应体将响应包解析成 Response 模型。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687+--- DubboCodec @Override protected Object decodeBody(Channel channel, InputStream is, byte[] header) throws IOException &#123; // 协议头第 3 个字节 byte flag = header[2]; // 获取序列化器编号 byte proto = (byte) (flag &amp; SERIALIZATION_MASK); // 获得调用编号（请求时生成的一个id，用来标识一次调用） long id = Bytes.bytes2long(header, 4); // Req/Res -&gt; 0 ，即响应包 if ((flag &amp; FLAG_REQUEST) == 0) &#123; // 创建 Response 对象，注意 id Response res = new Response(id); // 设置心跳事件 if ((flag &amp; FLAG_EVENT) != 0) &#123; res.setEvent(Response.HEARTBEAT_EVENT); &#125; // 获取并设置响应状态 byte status = header[3]; res.setStatus(status); try &#123; // 通过序列化器编号间接获取输入流 ObjectInput in = CodecSupport.deserialize(channel.getUrl(), is, proto); // 调用过程正常 if (status == Response.OK) &#123; Object data; // 心跳事件 if (res.isHeartbeat()) &#123; // 反序列化心跳数据，父类 ExchangeCodec 中的方法 data = decodeHeartbeatData(channel, in); // 反序列化其他事件数据 &#125; else if (res.isEvent()) &#123; data = decodeEventData(channel, in); // 解码普通响应 &#125; else &#123; DecodeableRpcResult result; // 根据配置决定是否在当前通信框架（如：Netty）的IO线程上解码，默认true if (channel.getUrl().getParameter(Constants.DECODE_IN_IO_THREAD_KEY, Constants.DEFAULT_DECODE_IN_IO_THREAD)) &#123; // 创建 DecodeableRpcResult 对象 result = new DecodeableRpcResult(channel, res, is, (Invocation) getRequestData(id), proto); // 解码 result.decode(); // 在 Dubbo ThreadPool 线程，解码。会在DecodeHandler中会调用 DecodeableRpcResult#decode()方法 &#125; else &#123; result = new DecodeableRpcResult(channel, res, new UnsafeByteArrayInputStream(readMessageData(is)), (Invocation) getRequestData(id), proto); &#125; data = result; &#125; // 设置 DecodeableRpcResult 对象到 Response 对象中 res.setResult(data); // 响应状态非 OK，表明调用过程出现了异常 &#125; else &#123; // 反序列化异常信息，并设置到 Response 对象中 res.setErrorMessage(in.readUTF()); &#125; &#125; catch (Throwable t) &#123; if (log.isWarnEnabled()) &#123; log.warn(\"Decode response failed: \" + t.getMessage(), t); &#125; // 解码过程中出现了错误，此时设置 CLIENT_ERROR 状态码到 Response 对象中 res.setStatus(Response.CLIENT_ERROR); res.setErrorMessage(StringUtils.toString(t)); &#125; return res; // 请求包 &#125; else &#123; // 省略解码请求逻辑 &#125; &#125; DecodeableRpcInvocationDecodeableRpcInvocation 实现了 Codec 和 Decodeable 接口，并且继承了 RpcInvocation 类，是一个可解码的 Invocation 实现类。服务消费方是对 RpcInvocation 对象的编码，将所需字段编码成字节流。服务提供方将字节流消息解码成 DecodeableRpcInvocation 对象，作为 Request 的请求体数据。 属性12345678910111213141516171819202122232425262728293031323334353637383940414243public class DecodeableRpcInvocation extends RpcInvocation implements Codec, Decodeable &#123; private static final Logger log = LoggerFactory.getLogger(DecodeableRpcInvocation.class); /** * Dubbo 的通道 */ private Channel channel; /** * Serialization 类型编号 */ private byte serializationType; /** * 消息字节流 */ private InputStream inputStream; /** * 请求 */ private Request request; /** * 是否已经解码完成 */ private volatile boolean hasDecoded; /** * 可解码 Invocation * * @param channel Dubbo 底层通道 * @param request 请求 * @param is 字节流消息 * @param id 序列化编号 */ public DecodeableRpcInvocation(Channel channel, Request request, InputStream is, byte id) &#123; Assert.notNull(channel, \"channel == null\"); Assert.notNull(request, \"request == null\"); Assert.notNull(is, \"inputStream == null\"); this.channel = channel; this.request = request; this.inputStream = is; this.serializationType = id; &#125;&#125; 解码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899+--- DecodeableRpcInvocation @Override public void decode() throws Exception &#123; if (!hasDecoded &amp;&amp; channel != null &amp;&amp; inputStream != null) &#123; try &#123; decode(channel, inputStream); &#125; catch (Throwable e) &#123; if (log.isWarnEnabled()) &#123; log.warn(\"Decode rpc invocation failed: \" + e.getMessage(), e); &#125; // 解码失败，设置失败标志 request.setBroken(true); request.setData(e); &#125; finally &#123; hasDecoded = true; &#125; &#125; &#125;+--- DecodeableRpcInvocation @Override public Object decode(Channel channel, InputStream input) throws IOException &#123; // 获取序列化方式，然后通过反序列化得到所需的调用信息 ObjectInput in = CodecSupport.getSerialization(channel.getUrl(), serializationType).deserialize(channel.getUrl(), input); // 框架版本 String dubboVersion = in.readUTF(); request.setVersion(dubboVersion); // 通过反序列化得到 `dubbo` `path` `version`，并保存到 attachments 变量中 setAttachment(Constants.DUBBO_VERSION_KEY, dubboVersion); setAttachment(Constants.PATH_KEY, in.readUTF()); // 读取调用接口 setAttachment(Constants.VERSION_KEY, in.readUTF()); // 读取接口指定的版本，默认为 0.0.0 // 通过反序列化得到调用方法名 setMethodName(in.readUTF()); try &#123; // 参数列表 Object[] args; // 参数类型列表 Class&lt;?&gt;[] pts; // 通过反序列化得到参数类型字符串，如： Ljava/lang/String String desc = in.readUTF(); if (desc.length() == 0) &#123; pts = DubboCodec.EMPTY_CLASS_ARRAY; args = DubboCodec.EMPTY_OBJECT_ARRAY; &#125; else &#123; // 将 desc 解析为参数类型数组 pts = ReflectUtils.desc2classArray(desc); args = new Object[pts.length]; // 一次读取方法参数值 for (int i = 0; i &lt; args.length; i++) &#123; try &#123; // 解析运行时参数 args[i] = in.readObject(pts[i]); &#125; catch (Exception e) &#123; if (log.isWarnEnabled()) &#123; log.warn(\"Decode argument failed: \" + e.getMessage(), e); &#125; &#125; &#125; &#125; // 设置参数类型数组 setParameterTypes(pts); // 通过反序列化得到原 attachments 的内容即隐式参数 Map&lt;String, String&gt; map = (Map&lt;String, String&gt;) in.readObject(Map.class); if (map != null &amp;&amp; map.size() &gt; 0) &#123; Map&lt;String, String&gt; attachment = getAttachments(); if (attachment == null) &#123; attachment = new HashMap&lt;String, String&gt;(); &#125; attachment.putAll(map); setAttachments(attachment); &#125; // 参数回调用 for (int i = 0; i &lt; args.length; i++) &#123; args[i] = decodeInvocationArgument(channel, this, pts, i, args[i]); &#125; // 设置参数列表 setArguments(args); &#125; catch (ClassNotFoundException e) &#123; throw new IOException(StringUtils.toString(\"Read invocation data failed.\", e)); &#125; finally &#123; if (in instanceof Cleanable) &#123; ((Cleanable) in).cleanup(); &#125; &#125; return this; &#125; DecodeableRpcInvocation 是一个支持解码功能的实现类，并不支持编码功能。 在解码请求时，是严格按照写数据顺序来处理的。通过反序列化将诸如 path、version、methodName 以及 参数列表等信息解析出来，并设置到对应的字段中，最终得到一个具有完整调用信息的 DecodeableRpcInvocation 对象。 DecodeableRpcResultDecodeableRpcResult 实现了 Codec 和 Decodeable 接口，且继承了 RpcResult ，可解码的 Result 实现类。和 DecodeableRpcInvocation 类似，服务提供方是对 Result 对象的编码，将响应状态和响应结果编码成字节流。服务消费方将响应消息解码成 DecodeableRpcResult 对象，并作为 Response 的响应结果。 属性123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class DecodeableRpcResult extends RpcResult implements Codec, Decodeable &#123; private static final Logger log = LoggerFactory.getLogger(DecodeableRpcResult.class); /** * Dubbo 底层通道 */ private Channel channel; /** * Serialization 类型编号 */ private byte serializationType; /** * 输入流 */ private InputStream inputStream; /** * 响应 */ private Response response; /** * Invocation 对象 */ private Invocation invocation; /** * 是否已经解码完成 */ private volatile boolean hasDecoded; /** * 可解码 Result * * @param channel Dubbo 底层通道 * @param response 响应 * @param is 字节流响应 * @param invocation 调用信息 * @param id 序列化编号 */ public DecodeableRpcResult(Channel channel, Response response, InputStream is, Invocation invocation, byte id) &#123; Assert.notNull(channel, \"channel == null\"); Assert.notNull(response, \"response == null\"); Assert.notNull(is, \"inputStream == null\"); this.channel = channel; this.response = response; this.inputStream = is; this.invocation = invocation; this.serializationType = id; &#125;&#125; 解码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111+--- DecodeableRpcResult @Override public void decode() throws Exception &#123; if (!hasDecoded &amp;&amp; channel != null &amp;&amp; inputStream != null) &#123; try &#123; // 执行反序列化操作 decode(channel, inputStream); &#125; catch (Throwable e) &#123; if (log.isWarnEnabled()) &#123; log.warn(\"Decode rpc result failed: \" + e.getMessage(), e); &#125; // 反序列化失败，设置 CLIENT_ERROR 状态到 Response 对象中 response.setStatus(Response.CLIENT_ERROR); // 设置异常信息 response.setErrorMessage(StringUtils.toString(e)); &#125; finally &#123; hasDecoded = true; &#125; &#125; &#125;+--- DecodeableRpcResult @Override public Object decode(Channel channel, InputStream input) throws IOException &#123; // 通过序列化器获取输入流 ObjectInput in = CodecSupport.getSerialization(channel.getUrl(), serializationType).deserialize(channel.getUrl(), input); // 反序列化响应类型(编码序列化时设置的) byte flag = in.readByte(); // 匹配响应类型 switch (flag) &#123; // 无返回值 case DubboCodec.RESPONSE_NULL_VALUE: break; // 有返回值 case DubboCodec.RESPONSE_VALUE: try &#123; Type[] returnType = RpcUtils.getReturnTypes(invocation); // 设置结果 setValue(returnType == null || returnType.length == 0 ? in.readObject() : // 返回结果:Type[]&#123;method.getReturnType(), method.getGenericReturnType()&#125; (returnType.length == 1 ? in.readObject((Class&lt;?&gt;) returnType[0]) : in.readObject((Class&lt;?&gt;) returnType[0], returnType[1]))); &#125; catch (ClassNotFoundException e) &#123; throw new IOException(StringUtils.toString(\"Read response data failed.\", e)); &#125; break; // 有异常 case DubboCodec.RESPONSE_WITH_EXCEPTION: try &#123; Object obj = in.readObject(); if (obj instanceof Throwable == false) &#123; throw new IOException(\"Response data error, expect Throwable, but get \" + obj); &#125; setException((Throwable) obj); &#125; catch (ClassNotFoundException e) &#123; throw new IOException(StringUtils.toString(\"Read response data failed.\", e)); &#125; break; // 返回值为空，且携带了 attachments 集合 case DubboCodec.RESPONSE_NULL_VALUE_WITH_ATTACHMENTS: try &#123; // 反序列化 attachments 集合，并存储起来 setAttachments((Map&lt;String, String&gt;) in.readObject(Map.class)); &#125; catch (ClassNotFoundException e) &#123; throw new IOException(StringUtils.toString(\"Read response data failed.\", e)); &#125; break; // 返回值不为空，且携带了 attachments 集合 case DubboCodec.RESPONSE_VALUE_WITH_ATTACHMENTS: try &#123; // 获取返回值类型 Type[] returnType = RpcUtils.getReturnTypes(invocation); // 反序列化调用结果，并保存起来 setValue(returnType == null || returnType.length == 0 ? in.readObject() : (returnType.length == 1 ? in.readObject((Class&lt;?&gt;) returnType[0]) : in.readObject((Class&lt;?&gt;) returnType[0], returnType[1]))); // 反序列化 attachments 集合，并存储起来 setAttachments((Map&lt;String, String&gt;) in.readObject(Map.class)); &#125; catch (ClassNotFoundException e) &#123; throw new IOException(StringUtils.toString(\"Read response data failed.\", e)); &#125; break; // 异常对象不为空，且携带了 attachments 集合 case DubboCodec.RESPONSE_WITH_EXCEPTION_WITH_ATTACHMENTS: try &#123; // 反序列化异常对象 Object obj = in.readObject(); if (obj instanceof Throwable == false) &#123; throw new IOException(\"Response data error, expect Throwable, but get \" + obj); &#125; // 设置异常对象 setException((Throwable) obj); // 反序列化 attachments 集合，并存储起来 setAttachments((Map&lt;String, String&gt;) in.readObject(Map.class)); &#125; catch (ClassNotFoundException e) &#123; throw new IOException(StringUtils.toString(\"Read response data failed.\", e)); &#125; break; default: throw new IOException(\"Unknown result flag, expect '0' '1' '2', get \" + flag); &#125; if (in instanceof Cleanable) &#123; ((Cleanable) in).cleanup(); &#125; return this; &#125; DecodeableRpcResult 是一个支持解码功能的实现类，同样不支持编码功能。 在解码响应时，通过反序列化将 result或exception 以及 attachments 解析出来，并设置到对应的字段中，最终得到一个完整响应结果的 DecodeableRpcResult 对象。 DubboCountCodecDubboCountCodec 实现了 Codec2 顶级接口，编解码的任务都是交给 DubboCodec 对象去完成。DubboProtocol 默认指定的编解码器就是 DubboCountCodec，编码任务直接委托给 DubboCodec 处理，解码支持多消息处理。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public final class DubboCountCodec implements Codec2 &#123; /** * Dubbo的编解码器 */ private DubboCodec codec = new DubboCodec(); /** * 编码直接委托给 DubboCodec 处理 * * @param channel * @param buffer * @param msg * @throws IOException */ @Override public void encode(Channel channel, ChannelBuffer buffer, Object msg) throws IOException &#123; codec.encode(channel, buffer, msg); &#125; /** * 解码 * * @param channel * @param buffer * @return * @throws IOException */ @Override public Object decode(Channel channel, ChannelBuffer buffer) throws IOException &#123; // 记录当前读位置，用于下面计算每条消息的长度 int save = buffer.readerIndex(); // 创建MultiMessage对象，对多消息的封装，MultiMessageHandler处理器会对该消息进行分发处理。 MultiMessage result = MultiMessage.create(); // 循环解码消息 do &#123; // 通过 DubboCodec 解码一条消息 Object obj = codec.decode(channel, buffer); // 字节数不够，重置读指针，然后结束解析 if (Codec2.DecodeResult.NEED_MORE_INPUT == obj) &#123; buffer.readerIndex(save); break; // 将成功解码出的消息添加到 MultiMessage 中 &#125; else &#123; // 添加结果消息 result.addMessage(obj); // 记录消息长度 logMessageLength(obj, buffer.readerIndex() - save); // 记录当前读位置，用于计算下一条消息的长度 save = buffer.readerIndex(); &#125; &#125; while (true); // 没有解码出消息，则返回NEED_MORE_INPUT错误码 if (result.isEmpty()) &#123; return Codec2.DecodeResult.NEED_MORE_INPUT; &#125; // 只解码出来一条消息，则直接返回该条消息 if (result.size() == 1) &#123; return result.get(0); &#125; // 解码出多条消息则将MultiMessage返回 return result; &#125;&#125;","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"Dubbo源码分析 - 信息交换层","slug":"rpc/Exchange层","date":"2020-06-17T16:00:00.000Z","updated":"2021-03-18T08:19:19.178Z","comments":false,"path":"posts/26722deb/","link":"","permalink":"https://gentryhuang.com/posts/26722deb/","excerpt":"","text":"前言前面的几篇文章详细介绍了 Dubbo Remoting 中的 Transport 层，该层只负责单向消息传输，是 Dubbo 中端到端的统一网络传输实现。本篇文章将介绍网络传输层即 Transport 层之上的 Exchange 层，同时它也是 Dubbo Remoting 层的最顶层。 概述信息交换层 Exchange 在传输层之上建立了 Request-Response 模型，实现了在不同传输方式之上都能做到统一的请求-响应处理，实现了同步转异步。以 Request, Response 为中心，扩展接口为 Exchanger, ExchangeChannel, ExchangeClient, ExchangeServer 。 一次 RPC 调用，上层请求 Request 只关注对应的响应 Response，至于是同步请求还是异步请求，又或者使用什么传输根本不关心。而 Transport 层以 Message 为中心提供单向消息传输，是无法满足这项诉求的，因此 Dubbo 基于 Transport 层做了更高层次的封装，构建了 Exchange 层。 Exchange 层代码结构如下图所示： Exchange 层构建于 Transport 层之上，是 Transport 层的使用者，再结合上图中的代码结构不难发现，Exchange 层同样具备端点 Endpoint（Server 和 Client）、通道 Channel、处理器 Handler 以及编解码器 Codec 等组件，区别在于 Exchange 层将 Transport 层的 Message 分成了 Request 和 Response 两种类型，且所有组件都是以这两个模型为中心进行实现。接下来我们从 Request 和 Response 这一对核心类开始，依次介绍 Exchange 层涉及的核心接口和实现类。 Request-Response 模型Exchange 层的 Request 和 Response 是对请求和响应的抽象。 Request 模型对一次 RPC 调用的请求进行抽象。 属性1234567891011121314151617181920212223242526272829303132333435363738394041public class Request &#123; /** * 心跳事件 */ public static final String HEARTBEAT_EVENT = null; /** * 只读事件 */ public static final String READONLY_EVENT = \"R\"; /** * 请求编号自增序列，注意当递增到Long.MAX_VALUE之后，会溢出到Long.MIN_VALUE，但是这不影响继续使用该负数作为消息ID */ private static final AtomicLong INVOKE_ID = new AtomicLong(0); /** * 请求编号 ，注意这个编号用来和该请求对应的响应Response关联，Response中的mId就是该请求的mId */ private final long mId; /** * 请求版本号 */ private String mVersion; /** * 请求是否需要响应： true-&gt; 需要 false-&gt; 不需要 */ private boolean mTwoWay = true; /** * 事件标识，如心跳请求、只读请求。 */ private boolean mEvent = false; /** * 是否异常的请求，主要用于： * 服务端收到请求后，如果使用 DecodeHandler 将二进制数据解码成Request对象，这个解码过程可能会出现异常， * 如果出现异常，那么就用该属性进行标识，其它 ChannelHandler 可以根据该标志做进一步处理。 */ private boolean mBroken = false; /** * 请求体，可以是任何类型的数据，也可以是null */ private Object mData;&#125; 构造方法12345678910111213141516171819202122232425/** * 默认构造方法。 */public Request() &#123; // 对请求编号进行赋值 mId = newId();&#125;/** * 传入请求编号 * * @param id */public Request(long id) &#123; mId = id;&#125;/** * JVM进程内唯一，原子自增 * * @return */private static long newId() &#123; return INVOKE_ID.getAndIncrement();&#125; 核心方法123456789101112131415161718192021222324252627282930313233343536373839404142/** * 判断是否是心跳请求条件： * 1. 需要是事件请求 * 2. 判断请求体是否为 null * * @return */ public boolean isHeartbeat() &#123; return mEvent &amp;&amp; HEARTBEAT_EVENT == mData; &#125; /** * 设置心跳请求信息 * 1. 设置 mEvent = true ，标志是事件 * 2. 设置 mData = null * 3. 以上两者共同确定是心跳请求 * * @param isHeartbeat */ public void setHeartbeat(boolean isHeartbeat) &#123; if (isHeartbeat) &#123; setEvent(HEARTBEAT_EVENT); &#125; &#125; /** * 是否是事件请求 * * @return */ public boolean isEvent() &#123; return mEvent; &#125; /** * 请求体是否不合法（解码请求体失败时会设置 mBroken = true） * * @return */ public boolean isBroken() &#123; return mBroken; &#125; Response 模型对一次 RPC 响应进行抽象。 属性1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class Response &#123; /** * 心跳事件 */ public static final String HEARTBEAT_EVENT = null; /** * 只读事件 */ public static final String READONLY_EVENT = \"R\"; /** * 请求成功 */ public static final byte OK = 20; /** * 客户端侧超时 */ public static final byte CLIENT_TIMEOUT = 30; /** * 服务端超时 */ public static final byte SERVER_TIMEOUT = 31; // ... 省略其它响应状态 /** * 响应编号，和对应的 Request 的 mId 一致。 */ private long mId = 0; /** * 当前协议的版本号，与请求版本号一致 */ private String mVersion; /** * 响应状态码，有 OK、CLIENT_TIMEOUT、SERVER_TIMEOUT 等十多种， 默认是OK。 */ private byte mStatus = OK; /** * 事件标识。注意，只读事件不需要响应，也就不会使用到该属性 */ private boolean mEvent = false; /** * 错误响应消息 */ private String mErrorMsg; /** * 响应体 */ private Object mResult;&#125; 构造方法1234567891011121314151617181920212223/** * 无参构造函数 */ public Response() &#123; &#125; /** * 响应编号，和对应的请求编号一致 * * @param id 响应编号 */ public Response(long id) &#123; mId = id; &#125; /** * @param id 响应编号，和对应的请求编号一致 * @param version 当前协议版本号，和对应的请求版本号一致 */ public Response(long id, String version) &#123; mId = id; mVersion = version; &#125; 核心方法12345678910111213141516171819202122232425262728293031/** * 判断是否是心跳事件 * 1. 需要是事件 * 2. 判断响应体是否为 null * * @return */ public boolean isHeartbeat() &#123; return mEvent &amp;&amp; HEARTBEAT_EVENT == mResult; &#125; /** * 只读请求是不需要响应的，心跳请求需要响应 * * @param isHeartbeat */ @Deprecated public void setHeartbeat(boolean isHeartbeat) &#123; if (isHeartbeat) &#123; setEvent(HEARTBEAT_EVENT); &#125; &#125; /** * 是否是事件 * * @return */ public boolean isEvent() &#123; return mEvent; &#125; Exchange 层为框架引入的 Request 和 Response 语义就介绍到这里，需要再次说明，这两个对象是 Exchange 层的核心，整个 Exchange 层都是围绕这两个对象进行任务的处理，在后面的分析过程中会看到。 MultiMessageMultiMessage 是对多个消息的封装，实现了 Iterable 接口，支持对封装的消息集合进行遍历。 12345678910111213public final class MultiMessage implements Iterable &#123; /** * 多消息的封装 */ private final List messages = new ArrayList(); @Override public Iterator iterator() &#123; return messages.iterator(); &#125; // 省略其它代码...&#125; Exchanger信息交换接口，是 Dubbo 的扩展接口，默认扩展名为 header ，对应的默认扩展实现为 HeaderExchanger ，同时也是 Exchanger 接口的唯一有效实现，该接口主要用来封装请求-响应模式。 1234567891011121314151617181920212223@SPI(HeaderExchanger.NAME)public interface Exchanger &#123; /** * 绑定一个服务器 * * @param url 服务器地址 * @param handler 数据交换处理器 * @return message server 服务器 */ @Adaptive(&#123;Constants.EXCHANGER_KEY&#125;) ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException; /** * 连接服务器，即创建一个客户端 * * @param url 服务器地址 * @param handler 数据交换处理器 * @return message channel 客户端 */ @Adaptive(&#123;Constants.EXCHANGER_KEY&#125;) ExchangeClient connect(URL url, ExchangeHandler handler) throws RemotingException;&#125; 从上面代码可以看出，Exchanger 接口和 Transporter 接口极其相似，因为 Exchanger 是对 Transporter 的封装，接下来通过 HeaderExchanger 就能验证这一点。 HeaderExchanger1234567891011121314151617181920212223242526272829303132public class HeaderExchanger implements Exchanger &#123; /** * 扩展名 */ public static final String NAME = \"header\"; /** * 连接服务，创建客户端。 * * @param url 服务器地址 * @param handler 数据交换处理器 * @return * @throws RemotingException */ @Override public ExchangeClient connect(URL url, ExchangeHandler handler) throws RemotingException &#123; return new HeaderExchangeClient(Transporters.connect(url, new DecodeHandler(new HeaderExchangeHandler(handler))), true); &#125; /** * 绑定服务器 * * @param url 服务器地址 * @param handler 数据交换处理器 * @return * @throws RemotingException */ @Override public ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException &#123; return new HeaderExchangeServer(Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler)))); &#125;&#125; 通过上面代码可以看出，Exchanger 创建的 HeaderExchangeServer 和 HeaderExchangeClient 分别是对 Transporter 创建的 Server 和 Client 的封装，是 Exchange 层的服务器和客户端，下面对这两个过程进行说明： 创建 HeaderExchangeClient 默认启动心跳检测 处理器的顺序为：Transporter层的Handler链 =&gt; DecodeHandler =&gt; HeaderExchangeHandler =&gt; ExchangeHandler 将Transporter创建的客户端封装到HeaderExchangeClient中 创建 HeaderExchangeServer 默认启动心跳检测 处理器的顺序为：Transporter层的Handler链 =&gt; DecodeHandler =&gt; HeaderExchangeHandler =&gt; ExchangeHandler 将Transporter创建的服务封装到HeaderExchangeServer中 需要说明的是，截止到 HeaderExchanger 对服务和客户端的创建，一次 RPC 调用 Remoting 层的通道处理器 Handler 已经全部创建完毕，这些 Handler 在 Dubbo 的整个网络通信中发挥着巨大作用。分析完 Exchanger 数据交换接口后，我们继续看 Exchanger 的访问入口类 Exchangers 。 ExchangersExchangers 是数据交换门面类，属于外观模式的实现。对于 Exchange 的上层来说，Exchange 层的入口正是 Exchangers 这个门面类，其中提供了多个 bind() 和 connect() 方法的重载，这些方法最终会通过 Dubbo SPI 机制获取 Exchanger 接口的扩展实现。整体流程和 Transport 层一致，Transport 层的入口也是要通过 Transports 门面类。下面我们简单看看它的代码实现。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public class Exchangers &#123; static &#123; // check duplicate jar package Version.checkDuplicate(Exchangers.class); &#125; private Exchangers() &#123; &#125; /** * 启动服务 * * @param url URL串 * @param handler 数据交换处理器 * @return 服务 * @throws RemotingException */ public static ExchangeServer bind(String url, ExchangeHandler handler) throws RemotingException &#123; return bind(URL.valueOf(url), handler); &#125; public static ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException &#123; if (url == null) &#123; throw new IllegalArgumentException(\"url == null\"); &#125; if (handler == null) &#123; throw new IllegalArgumentException(\"handler == null\"); &#125; url = url.addParameterIfAbsent(Constants.CODEC_KEY, \"exchange\"); return getExchanger(url).bind(url, handler); &#125; /** * 连接服务 * * @param url URL串 * @param handler 数据交换处理器 * @return 客户端 * @throws RemotingException */ public static ExchangeClient connect(String url, ExchangeHandler handler) throws RemotingException &#123; return connect(URL.valueOf(url), handler); &#125; public static ExchangeClient connect(URL url, ExchangeHandler handler) throws RemotingException &#123; if (url == null) &#123; throw new IllegalArgumentException(\"url == null\"); &#125; if (handler == null) &#123; throw new IllegalArgumentException(\"handler == null\"); &#125; url = url.addParameterIfAbsent(Constants.CODEC_KEY, \"exchange\"); return getExchanger(url).connect(url, handler); &#125; /** * 获取 Exchanger 扩展实现 * * @param url * @return */ public static Exchanger getExchanger(URL url) &#123; // 从 URL 中获取 exchanger 的值，默认为 header String type = url.getParameter(Constants.EXCHANGER_KEY, Constants.DEFAULT_EXCHANGER); return getExchanger(type); &#125; /** * 1 获取Exchanger，默认为 HeaderExchanger。 * 2 紧接着调用 HeaderExchanger的bind方法创建 ExchangeServer实例 * * @param type 扩展名 * @return */ public static Exchanger getExchanger(String type) &#123; return ExtensionLoader.getExtensionLoader(Exchanger.class).getExtension(type); &#125;&#125; 由于目前 Dubbo 的 Exchanger 有效扩展实现只有 HeaderExchanger ，因此 Exchangers 中只保留了和 HeaderExchanger 相关的代码。 了解了 Exchange 层的 Request-Response 模型以及入口后，下面我们分别对 Exchange 层的端点 Endpoint、通道 Channel、处理器 Handler 以及编解码器 Codec2 进行详细说明。 通道Exchange 层通道 Channel 继承关系如下图所示： 在前面的文章中已经详细介绍了 Channel 接口以及 Transport 层对 Channel 接口的实现。Exchange 层基于 Channel 接口抽象出了 ExchangeChannel 接口，表示该层的网路连接，用来发送请求等操作。 ExchangeChannel 接口中的方法如下图所示： 上图中的灰色方法继承自 Endpoint 和 Channel 接口，其中 4 个白色的方法是 Exchange 层定义出的方法，request() 方法负责发送请求，getExchangeHandler() 方法用于获取信息交换处理器，close() 方法用于关闭通道。ExchangeChannel 接口定义如下： 123456789101112131415161718192021222324252627282930313233343536public interface ExchangeChannel extends Channel &#123; /** * 发送请求 * * @param request * @return future * @throws RemotingException */ ResponseFuture request(Object request) throws RemotingException; /** * 发送请求 * * @param request * @param timeout * @return future * @throws RemotingException */ ResponseFuture request(Object request, int timeout) throws RemotingException; /** * 获得信息交换处理器 * * @return message handler */ ExchangeHandler getExchangeHandler(); /** * 优雅关闭 * * @param timeout */ @Override void close(int timeout);&#125; ExchangeChannel 接口本身新定义了请求发送 request() 方法、获得信息交换处理器 getExchangeHandler() 方法以及关闭方法，其它方法分别继承自 Endpoint 和 Channel 接口中的方法。下面我们继续看它的 HeaderExchangeChannel 实现类。 HeaderExchangeChannelHeaderExchangeChannel 实现了 ExchangeChannel 接口，基于消息头的信息交换通道实现类。它本身是 Channel 的装饰器，封装了一个 Channel 对象，send() 和 request() 方法的实现都委托给这个 Channel 对象。 属性1234567891011121314151617181920212223242526272829final class HeaderExchangeChannel implements ExchangeChannel &#123; private static final Logger logger = LoggerFactory.getLogger(HeaderExchangeChannel.class); /** * 作为 channel 的属性 key，value 是 HeaderExchangeChannel 对象 */ private static final String CHANNEL_KEY = HeaderExchangeChannel.class.getName() + \".CHANNEL\"; /** * 被装饰的 Channel，如 NettyChannel、NettyClient */ private final Channel channel; /** * 是否关闭 */ private volatile boolean closed = false; /** * HeaderExchangeChannel 是传入channel的装饰器 * * @param channel 被装饰的 Channel */ HeaderExchangeChannel(Channel channel) &#123; if (channel == null) &#123; throw new IllegalArgumentException(\"channel == null\"); &#125; this.channel = channel; &#125;&#125; HeaderExchangeChannel 中有 3 个属性，这三个属性都有各自的作用： CHANNEL_KEY: 静态常量，作为 Channel 存储 HeaderExchangeChannel 对象的 key，保证了同一个 Channel 创建唯一的 HeaderExchangeChannel 对象。 channel: HeaderExchangeChannel 装饰的 Channel，此 channel 中会存储 HeaderExchangeChannel 对象，key 就是 CHANNEL_KEY 这个常量值。 closed: 用于标记通道是否关闭，request() 和 send() 方法受该值影响。 获取 HeaderExchangeChannel12345678910111213141516171819202122--- HeaderExchangeChannel /** * 创建HeaderExchangeChannel 对象。 * * @param ch Channel * @return */ static HeaderExchangeChannel getOrAddChannel(Channel ch) &#123; if (ch == null) &#123; return null; &#125; // 通过 ch.getAttribute(CHANNEL_KEY) ，保证 ch 绑定唯一的 HeaderExchangeChannel 对象 HeaderExchangeChannel ret = (HeaderExchangeChannel) ch.getAttribute(CHANNEL_KEY); if (ret == null) &#123; ret = new HeaderExchangeChannel(ch); // ch 必须是已连接状态，否则不会绑定对应的 HeaderExchangeChannel 对象 if (ch.isConnected()) &#123; ch.setAttribute(CHANNEL_KEY, ret); &#125; &#125; return ret; &#125; getOrAddChannel() 方法用于获取传入的 Channel 对应的 HeaderExchangeChannel 对象，并且 HeaderExchangeChannel 对象会对传入的 Channel 进行封装、装饰。不难看出两者期望是相互绑定关系，但要求 Channel 一方必须是处于连接状态。 移除 HeaderExchangeChannel1234567--- HeaderExchangeChannel static void removeChannelIfDisconnected(Channel ch) &#123; // ch 断开了连接，则解除邦定的 HeaderExchangeChannel 对象 if (ch != null &amp;&amp; !ch.isConnected()) &#123; ch.removeAttribute(CHANNEL_KEY); &#125; &#125; removeChannelIfDisconnected() 方法用于解除处于断开连接状态的 Channel 绑定的 HeaderExchangeChannel 对象。 关闭12345678910111213141516171819202122232425262728293031323334353637383940414243/** * 优雅关闭 * * @param timeout */ @Override public void close(int timeout) &#123; // 如果已经关闭，就直接返回 if (closed) &#123; return; &#125; // 设置关闭标识，防止发起新的请求 closed = true; // 等待请求完成 if (timeout &gt; 0) &#123; long start = System.currentTimeMillis(); // 请求处理完或者关闭超时，则结束 while (DefaultFuture.hasFuture(channel) &amp;&amp; System.currentTimeMillis() - start &lt; timeout) &#123; try &#123; Thread.sleep(10); &#125; catch (InterruptedException e) &#123; logger.warn(e.getMessage(), e); &#125; &#125; &#125; // 关闭通道 close(); &#125;/** * 关闭通道 */ @Override public void close() &#123; try &#123; // 执行 channel 的关闭动作 channel.close(); &#125; catch (Throwable e) &#123; logger.warn(e.getMessage(), e); &#125; &#125; HeaderExchangeChannel 优雅关闭主要做了三件事： 将自身的关闭标志 closed 设置为 true ，防止发起新的请求。 等待当前 Channel 上的请求被处理完成，除非超时退出。 关闭被装饰的 channel ，即 Transport 层的 Channel 。如 NettyChannel 会先将自身的 closed 字段设置为 true 等其它操作，最后才会关闭底层 Netty 层面的 Channel 。 send 方法12345678910111213141516171819202122232425262728293031323334353637383940/** * Endpoint 方法 * * @param message * @throws RemotingException */ @Override public void send(Object message) throws RemotingException &#123; // 默认不等待消息发出就返回 send(message, getUrl().getParameter(Constants.SENT_KEY, false)); &#125; /** * Endpoint 方法 * * @param message * @param sent true: 会等待消息发出，消息发送失败会抛出异常； false: 不等待消息发出，将消息放入IO队列，即可返回 * @throws RemotingException */ @Override public void send(Object message, boolean sent) throws RemotingException &#123; // 如果处于关闭状态，则抛出异常 if (closed) &#123; throw new RemotingException(this.getLocalAddress(), null, \"Failed to send message \" + message + \", cause: The channel \" + this + \" is closed!\"); &#125; // 如果消息是 Request、Response、String 类型，直接交给 Channel.send() 方法 if (message instanceof Request || message instanceof Response || message instanceof String) &#123; channel.send(message, sent); &#125; else &#123; // 构建 Request 对象，并且不需要响应 Request request = new Request(); request.setVersion(Version.getProtocolVersion()); request.setTwoWay(false); request.setData(message); channel.send(request, sent); &#125; &#125; HeaderExchangeChannel 中的 send() 方法实现是 Endpoint 接口中的方法，该方法比较简单，总体上是直接将消息通过被装饰的 Channel 发送出去，不关心响应结果 。 request 方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * 发送请求 * * @param request * @return * @throws RemotingException */ @Override public ResponseFuture request(Object request) throws RemotingException &#123; // 请求超时时间，默认 1000 return request(request, channel.getUrl().getPositiveParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT)); &#125; /** * 发送请求 * * @param request * @param timeout 请求超时时间 * @return * @throws RemotingException */ @Override public ResponseFuture request(Object request, int timeout) throws RemotingException &#123; // 如果已经关闭，不能发起请求 if (closed) &#123; throw new RemotingException(this.getLocalAddress(), null, \"Failed to send request \" + request + \", cause: The channel \" + this + \" is closed!\"); &#125; // 创建请求，并初始化请求编号 Request req = new Request(); // Dubbo 版本 req.setVersion(Version.getProtocolVersion()); // 需要响应 req.setTwoWay(true); // 具体数据 为 RpcInvocation req.setData(request); // 创建DefaultFuture 对象,该对象表示此次请求-响应是否完成 DefaultFuture future = new DefaultFuture(channel, req, timeout); try &#123; // 使用被装饰的 Channel 发送请求 channel.send(req); &#125; catch (RemotingException e) &#123; // 发送请求失败就取消 DefaultFuture future.cancel(); throw e; &#125; // 返回 DefaultFuture 对象 return future; &#125; request() 方法非常重要，下面对该方法进行说明： 创建 Request 对象，创建的过程会初始化一个请求编号，该编号标志当前请求 该方法需要响应，也就是说服务器收到请求后要给对端发送处理后的结果 创建 DefaultFuture 对象，该对象表示此次请求-响应是否完成 请求的发送交给被装饰的 Channel 请求失败就取消 DefaultFuture，并抛出异常 发送请求的 request() 方法依赖 DefaultFuture ，关心响应结果，这也是和 send() 方法最大的不同。 特别说明： send() 方法本身不关心响应结果; request() 方法关心响应结果，最终是通过 DefaultFuture 对象来传递响应结果。 Dubbo 支持同步和异步两种调用方式，默认使用同步调用方式，若要使用异步调用，需要服务消费方手动进行配置。其中异步调用还可细分为有返回值的异步调用和无返回值的异步调用。 Dubbo 的同步调用发送请求的方法是 request()；无返回值的异步调用发送请求的方法是 send()；有返回值的异步调用发送请求的方法是 request()。 Dubbo 的同步调用和有返回值的异步调用都关心调用结果，因此需要使用关心响应结果的 request() 方法来发送请求。而无返回值的异步调用不关心调用结果，使用不关心响应结果的 send() 方法即可。 综上，是同步调用还是异步调用，需要调用结果还是不需要调用结果，这取决于 Exchange 层的使用方。request() 方法会返回一个 DefaultFuture 对象，该对象并不是请求的结果，而是对此次请求-响应的管理。这意味着可以从 DefaultFuture 对象中获取请求对应的响应信息，只不过在响应结果没有返回之前获取动作会处于阻塞状态（除非超时或结果返回），因此，对于同步调用一般是获取到返回的 DefaultFuture 对象后阻塞等待响应结果，在结果返回之前不会进行其它逻辑处理，对于异步调用业务方可以在合适的时机从 DefaultFuture 中获取响应结果。 有关同步调用和异步调用详细细节会在后面的文章中进行介绍，下面对 Exchange 层的 DefaultFuture 相关体系进行详细分析，它是 Dubbo 内部进行调用转换的核心。 ResponseFuture Dubbo 中的 Future 关联关系如上图所示，DefaultFuture 实现了 ResponseFuture 接口，request() 方法返回值就是 ResponseFuture 类型，这也意味着对于 request() 方法来说无论是同步调用还是异步调用，只有返回 ResponseFuture 才算发送操作完成。需要注意，request() 方法其实是基于 send() 方法的，我们知道 send() 方法是没有返回值的，因此 request() 方法引入了 DefaultFuture 对象来管理 Request 和 Response 关系，从上面的继续关系中就可以明确这一点。 12345678910111213141516171819202122232425262728293031public interface ResponseFuture &#123; /** * 获取响应结果 * * @return result. */ Object get() throws RemotingException; /** * 在指定的时间内获取结果 * * @param timeoutInMillis timeout. * @return result. */ Object get(int timeoutInMillis) throws RemotingException; /** * 设置回调 * * @param callback */ void setCallback(ResponseCallback callback); /** * 是否完成 * * @return done or not. */ boolean isDone();&#125; ResponseFuture 有点类似 JDK 中的 Future 接口，支持获取响应结果、判断响应结果是否返回，其中设置回调方法 setCallback(ResponseCallback callback) 会在 FutureFilter 中使用，主要用于异步调用情况下的事件通知，在后面的文章中会进行介绍，这里不进行展开说明。 DefaultFutureDefaultFuture 表示一次请求-响应的结果，每一个请求（通过request()方法发送的请求）都对应一个 DefaultFuture 对象，DefaultFuture 同时也是所有 DefaultFuture 的管理容器。需要特别说明的是，Dubbo 框架底层数据传输使用的 NIO 组件处理请求理论上是异步的，但是 Dubbo 框架做了异步转同步的处理，DefaultFuture 在这个过程中扮演着重要角色。 静态属性1234567891011121314151617181920212223/** * Request 编号到 Dubbo通道的映射 * key: 请求编号 * value: Dubbo 抽象的通道，用来发送请求 */ private static final Map&lt;Long, Channel&gt; CHANNELS = new ConcurrentHashMap&lt;Long, Channel&gt;(); /** * Request 编号到 DefaultFuture 的映射 * key: 请求编号 * value: DefaultFuture */ private static final Map&lt;Long, DefaultFuture&gt; FUTURES = new ConcurrentHashMap&lt;Long, DefaultFuture&gt;(); /** * 启动扫描响应超时任务 */ static &#123; Thread th = new Thread(new RemotingInvocationTimeoutScan(), \"DubboResponseTimeoutScanTimer\"); // 守护线程 th.setDaemon(true); th.start(); &#125; 前面说到 DefaultFuture 自身就是个管理容器，原因就在 FUTURES 属性上。当 DefaultFuture 加载时会启动扫描响应超时任务线程，下面我们就来看看 RemotingInvocationTimeoutScan 这个任务体的逻辑。 扫描超时请求12345678910111213141516171819202122232425262728293031323334private static class RemotingInvocationTimeoutScan implements Runnable &#123; @Override public void run() &#123; while (true) &#123; try &#123; // 遍历请求关联的 DefaultFuture 集合 for (DefaultFuture future : FUTURES.values()) &#123; // 如果 future 为空，或请求已经响应则进行下一个 if (future == null || future.isDone()) &#123; continue; &#125; // 请求没有响应，判断是否超时（请求时间 - 请求超时时间），超时就进入超时处理流程 if (System.currentTimeMillis() - future.getStartTimestamp() &gt; future.getTimeout()) &#123; // 创建 Request 对应的 超时 Response 对象 Response timeoutResponse = new Response(future.getId()); // 设置响应状态，如果请求已经发送则是服务端超时，否则客户端超时 timeoutResponse.setStatus(future.isSent() ? Response.SERVER_TIMEOUT : Response.CLIENT_TIMEOUT); // 异常信息 timeoutResponse.setErrorMessage(future.getTimeoutMessage(true)); // 响应结果，避免客户端等待 DefaultFuture.received(future.getChannel(), timeoutResponse); &#125; &#125; // 休眠30 ms Thread.sleep(30); &#125; catch (Throwable e) &#123; logger.error(\"Exception when scan the timeout invocation of remoting.\", e); &#125; &#125; &#125; &#125; Dubbo 在 DefaultFuture 类加载时会开启一个守护线程，该线程用于轮询请求关联的 DefaultFuture 集合，及时对超时的请求进行异常结果的响应，尽可能减少客户端的等待时间。需要说明的是，该任务是对所有的 twoway 调用请求进行检测，不管是同步调用还是异步调用，只要超时立即给调用方响应一个超时异常结果，只是一般情况下异步调用不会立刻阻塞等待结果而已。 对象属性12345678910111213141516171819202122232425262728293031323334353637383940414243+--- DefaultFuture /** * 请求 */ private final Request request; /** * invoke id. 请求的编号 */ private final long id; /** * 发送请求的 Channel */ private final Channel channel; /** * 请求-响应的超时时间 */ private final int timeout; /** * 当前 DefaultFuture 创建的开始时间 */ private final long start = System.currentTimeMillis(); /** * 请求发送的时间 */ private volatile long sent; /** * 响应 */ private volatile Response response; /** * 锁 */ private final Lock lock = new ReentrantLock(); /** * 锁的选择器 */ private final Condition done = lock.newCondition(); /** * 回调，适用于异步请求 * * @see com.alibaba.dubbo.rpc.protocol.dubbo.filter.FutureFilter */ private volatile ResponseCallback callback; 对象属性中的 Request、Response、Lock 以及 Condition 是实现异步转同步的必要对象。Dubbo 的异步转同步本质上是利用等待通知机制，等到分析 HeaderExchangeHandler 时还会回过头来看这一块的。 构造方法12345678910111213141516171819/** * 创建 DefaultFuture 时，会把创建的该实例放入 FUTURES 缓存中 * * @param channel 发送请求的 Channel * @param request 请求 * @param timeout 请求-响应的超时时间 */public DefaultFuture(Channel channel, Request request, int timeout) &#123; this.channel = channel; this.request = request; // 设置请求id，这个id是request和response映射的依据，非常重要 this.id = request.getId(); // 设置超时时间，如果传入的 timeout &gt; 0 就取传入的值，否则取 URL 中timeout的值，默认为 1000 this.timeout = timeout &gt; 0 ? timeout : channel.getUrl().getPositiveParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT); // Request 编号到 DefaultFuture 的映射，DefaultFuture 管理每个请求关联的DefaultFuture对象。 FUTURES.put(id, this); // Request 编号到 Dubbo通道的映射 CHANNELS.put(id, channel);&#125; 创建 DefaultFuture 对象时会初始化对象属性，其中 sent 和 response 属性会在 HeaderExchangeHandler 处理方法中进行值的更新。 Request 关联属性123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051+--- DefaultFuture /** * 获取 request 关联的 DefaultFuture 对象 * * @param id 请求id * @return */ public static DefaultFuture getFuture(long id) &#123; return FUTURES.get(id); &#125; /** * 判断通道是否有未响应的请求 * * @param channel 发送请求的 Channel * @return */ public static boolean hasFuture(Channel channel) &#123; return CHANNELS.containsValue(channel); &#125; /** * 发送请求时更新 sent 属性。 * * @param channel * @param request * @see HeaderExchangeHandler#sent(com.alibaba.dubbo.remoting.Channel, java.lang.Object) */ public static void sent(Channel channel, Request request) &#123; // 获取请求关联的 DefaultFuture 对象 DefaultFuture future = FUTURES.get(request.getId()); if (future != null) &#123; future.doSent(); &#125; &#125; /** * 更新 sent 属性，记录请求发送时间戳 */ private void doSent() &#123; sent = System.currentTimeMillis(); &#125; /** * 判断调用结果是否返回，即判断 response 字段是否为空 * * @return */ @Override public boolean isDone() &#123; return response != null; &#125; 获取响应结果12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970@Overridepublic Object get() throws RemotingException &#123; // 超时时间取 timeout 的值 return get(timeout);&#125;@Overridepublic Object get(int timeout) throws RemotingException &#123; if (timeout &lt;= 0) &#123; // 默认 1000 timeout = Constants.DEFAULT_TIMEOUT; &#125; // isDone()方法用来判断Response是否有值，即是否有返回结果 if (!isDone()) &#123; // 等待请求结果，计时开始 long start = System.currentTimeMillis(); lock.lock(); try &#123; // 等待完成或超时 while (!isDone()) &#123; // 等待请求结果，释放锁 done.await(timeout, TimeUnit.MILLISECONDS); // 如果调用结果成功返回，或等待超时，则跳出while循环继续执行后面逻辑 if (isDone() || System.currentTimeMillis() - start &gt; timeout) &#123; break; &#125; &#125; &#125; catch (InterruptedException e) &#123; throw new RuntimeException(e); &#125; finally &#123; // 释放锁 lock.unlock(); &#125; // 未完成，抛出超时异常 if (!isDone()) &#123; throw new TimeoutException(sent &gt; 0, channel, getTimeoutMessage(false)); &#125; &#125; // 返回响应 return returnFromResponse();&#125;/** * 返回响应 * * @return * @throws RemotingException */private Object returnFromResponse() throws RemotingException &#123; Response res = response; if (res == null) &#123; throw new IllegalStateException(\"response cannot be null\"); &#125; // 正常返回结果 if (res.getStatus() == Response.OK) &#123; return res.getResult(); &#125; // 超时，抛出超时异常 if (res.getStatus() == Response.CLIENT_TIMEOUT || res.getStatus() == Response.SERVER_TIMEOUT) &#123; throw new TimeoutException(res.getStatus() == Response.SERVER_TIMEOUT, channel, res.getErrorMessage()); &#125; throw new RemotingException(channel, res.getErrorMessage());&#125; 上面的方法用于在指定的超时时间内获取请求的响应结果，如果在超时时间内响应结果返回则本次请求完成，否则抛出超时异常。需要注意的是，在超时时间内返回的响应结果不一定是成功状态，因此在响应业务线程结果时，在 returnFromResponse() 方法中需要对响应的状态进行判断。上述代码就是等待通知机制中的等待部分。 响应结果12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * 收到响应结果 * * @param channel 通道 * @param response 响应结果 */public static void received(Channel channel, Response response) &#123; try &#123; // 请求与返回结果进行匹配，匹配成功则移除关联的DefaultFuture对象 DefaultFuture future = FUTURES.remove(response.getId()); // 接收结果,更新相关字段标识 if (future != null) &#123; future.doReceived(response); &#125; else &#123; logger.warn(\"The timeout response finally returned at \" + (new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss.SSS\").format(new Date())) + \", response \" + response + (channel == null ? \"\" : \", channel: \" + channel.getLocalAddress() + \" -&gt; \" + channel.getRemoteAddress())); &#125; // 收到结果后，移除关联的的 Channel，它的使命已完成 &#125; finally &#123; CHANNELS.remove(response.getId()); &#125;&#125;/** * 设置响应结果 * * @param res */private void doReceived(Response res) &#123; // 加锁 lock.lock(); try &#123; // 设置结果 response = res; /** * 唤醒等待线程 &#123;@link #get()&#125;，然后执行 returnFromResponse 方法返回结果 */ if (done != null) &#123; done.signal(); &#125; &#125; finally &#123; // 释放锁 lock.unlock(); &#125; // 有事件回调，就执行回调逻辑。 if (callback != null) &#123; invokeCallback(callback); &#125;&#125; 当请求的响应结果返回时，会找到响应关联的 DefaultFuture 对象（根据请求编号从缓存集合中查找）并调用 doReceived() 方法，进而设置响应结果 response 属性的值。上述代码就是等待通知机制中的通知部分。 连接断开异常1234567891011121314151617181920212223242526/** * 当 Channel 断开连接时，应该对其关联的 request 进行异常结果响应，以结束阻塞等待的业务线程。 * * @param channel channel to close */public static void closeChannel(Channel channel) &#123; for (long id : CHANNELS.keySet()) &#123; // 取出断开连接的Channel关联的Request对应的 DefaultFuture if (channel.equals(CHANNELS.get(id))) &#123; DefaultFuture future = getFuture(id); // 如果请求结果还没有返回，则返回异常状态的结果 if (future != null &amp;&amp; !future.isDone()) &#123; // 构造响应 Response ，注意响应编号。 Response disconnectResponse = new Response(future.getId()); disconnectResponse.setStatus(Response.CHANNEL_INACTIVE); disconnectResponse.setErrorMessage(\"Channel \" + channel + \" is inactive. Directly return the unFinished request : \" + future.getRequest()); // 设置响应结果 response DefaultFuture.received(channel, disconnectResponse); &#125; &#125; &#125;&#125; closeChannel() 方法比较简单，用于处理连接断开无法正常响应结果给业务线程的情况，和前文的扫描超时任务 RemotingInvocationTimeoutScan 一致，防止业务线程傻等请求结果。 取消 DefaultFuture12345678910111213+---- DefaultFuture /** * 移除当前请求关联的 Channel、DefaultFuture */ public void cancel() &#123; // 创建响应结果对象 Response errorResult = new Response(id); errorResult.setErrorMessage(\"request future has been canceled.\"); response = errorResult; // 移除请求关联的 DefaultFuture，Channel FUTURES.remove(id); CHANNELS.remove(id); &#125; 用于发送请求失败的情况，由于发送请求之前请求关联了 DefaultFuture 和 Channel ，因此需要移除该请求关联的对象。此外，创建一个异常结果，防止有业务线程还在傻傻地等待请求结果。 设置回调12345678910111213141516171819202122232425262728293031+--- DefaultFuture /** * 设置回调 * * @param callback * @see com.alibaba.dubbo.rpc.protocol.dubbo.filter.FutureFilter#asyncCallback(com.alibaba.dubbo.rpc.Invoker, com.alibaba.dubbo.rpc.Invocation) */ @Override public void setCallback(ResponseCallback callback) &#123; // 如果有响应则立即执行回调 if (isDone()) &#123; invokeCallback(callback); &#125; else &#123; boolean isdone = false; lock.lock(); try &#123; // 如果没有响应，则先保存回调，收到结果再执行回调逻辑 if (!isDone()) &#123; this.callback = callback; &#125; else &#123; isdone = true; &#125; &#125; finally &#123; lock.unlock(); &#125; // 再尝试一次 if (isdone) &#123; invokeCallback(callback); &#125; &#125; &#125; 设置回调是 FutureFilter 处理异步调用时使用的，目的是在返回调用结果时执行事件回调。 执行回调123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 执行回调逻辑 * * @param c */ private void invokeCallback(ResponseCallback c) &#123; ResponseCallback callbackCopy = c; if (callbackCopy == null) &#123; throw new NullPointerException(\"callback cannot be null.\"); &#125; Response res = response; if (res == null) &#123; throw new IllegalStateException(\"response cannot be null. url:\" + channel.getUrl()); &#125; // 正常响应 if (res.getStatus() == Response.OK) &#123; try &#123; // 执行回调 - 处理执行结果 callbackCopy.done(res.getResult()); &#125; catch (Exception e) &#123; logger.error(\"callback invoke error .reasult:\" + res.getResult() + \",url:\" + channel.getUrl(), e); &#125; // 超时处理 TimeoutException 异常 &#125; else if (res.getStatus() == Response.CLIENT_TIMEOUT || res.getStatus() == Response.SERVER_TIMEOUT) &#123; try &#123; TimeoutException te = new TimeoutException(res.getStatus() == Response.SERVER_TIMEOUT, channel, res.getErrorMessage()); // 执行回调 - 处理 TimeoutException 异常 callbackCopy.caught(te); &#125; catch (Exception e) &#123; logger.error(\"callback invoke error ,url:\" + channel.getUrl(), e); &#125; // 处理其他异常 &#125; else &#123; try &#123; RuntimeException re = new RuntimeException(res.getErrorMessage()); // 执行回调 - 处理RuntimeException callbackCopy.caught(re); &#125; catch (Exception e) &#123; logger.error(\"callback invoke error ,url:\" + channel.getUrl(), e); &#125; &#125; &#125; 在设置响应结果后，如果设置了事件回调则执行回调逻辑。 处理器Exchange 层通道处理器继承关系如下图所示： 在 Transport 层已经介绍了大量 ChannelHandler，特别是 ChannelHandlerDelegate 类型的 ChannelHandler ，它们属于处理器装饰者接口，在 Exchange 层新定义了两个该类型的处理器 HeartbeatHandler 和 HeaderExchangeHandler。此外，Exchange 层还定义了一个供上层使用的 ExchangeHandler 接口及其抽象实现类 ExchangeHandlerAdapter。无论是发送请求还是处理响应都会涉及到 ChannelHandler。 HeartbeatHandler专门处理心跳消息的 ChannelHandler 实现，同样是在原有的 ChannelHandler 的基础上添加一些功能。 属性12345678910111213141516171819202122public class HeartbeatHandler extends AbstractChannelHandlerDelegate &#123; private static final Logger logger = LoggerFactory.getLogger(HeartbeatHandler.class); /** * 设置Channel的读时间戳 的 key */ public static String KEY_READ_TIMESTAMP = \"READ_TIMESTAMP\"; /** * 设置Channel的写时间戳 的 key */ public static String KEY_WRITE_TIMESTAMP = \"WRITE_TIMESTAMP\"; /** * 装饰 ChannelHandler * * @param handler */ public HeartbeatHandler(ChannelHandler handler) &#123; super(handler); &#125;&#125; 辅助方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * 设置 Channel 读时间戳 * * @param channel */ private void setReadTimestamp(Channel channel) &#123; channel.setAttribute(KEY_READ_TIMESTAMP, System.currentTimeMillis()); &#125; /** * 设置 Channel 写时间戳 * * @param channel */ private void setWriteTimestamp(Channel channel) &#123; channel.setAttribute(KEY_WRITE_TIMESTAMP, System.currentTimeMillis()); &#125; /** * 清理 Channel 中读时间戳 * * @param channel */ private void clearReadTimestamp(Channel channel) &#123; channel.removeAttribute(KEY_READ_TIMESTAMP); &#125; /** * 清理 Channel 中写时间戳 * * @param channel */ private void clearWriteTimestamp(Channel channel) &#123; channel.removeAttribute(KEY_WRITE_TIMESTAMP); &#125; /** * 是否是心跳请求 * * @param message * @return */ private boolean isHeartbeatRequest(Object message) &#123; return message instanceof Request &amp;&amp; ((Request) message).isHeartbeat(); &#125; /** * 是否是心跳响应 * * @param message * @return */ private boolean isHeartbeatResponse(Object message) &#123; return message instanceof Response &amp;&amp; ((Response) message).isHeartbeat(); &#125; 连接建立12345678910111213/** * 连接完成时，设置通道的最后读写时间 * * @param channel * @throws RemotingException */@Overridepublic void connected(Channel channel) throws RemotingException &#123; setReadTimestamp(channel); setWriteTimestamp(channel); // 设置最后读写时间后，传递给底层的 ChannelHandler 对象进行处理 handler.connected(channel);&#125; HeartbeatHandler 处理连接建立只是记录了通道的最后读写时间。 连接断开12345678910111213/** * 连接断开时，清空通道的最后读写时间 * * @param channel * @throws RemotingException */@Overridepublic void disconnected(Channel channel) throws RemotingException &#123; clearReadTimestamp(channel); clearWriteTimestamp(channel); // 清理读写时间后，传递给底层的 ChannelHandler 对象进行处理 handler.disconnected(channel);&#125; HeartbeatHandler 处理连接断开只是清理了最后读写时间。 发送消息12345678910111213/** * 发送消息后，设置最后写的时间 * * @param channel * @param message * @throws RemotingException */ @Override public void sent(Channel channel, Object message) throws RemotingException &#123; setWriteTimestamp(channel); // 记录最后写时间后，传递给底层的 ChannelHandler 对象进行处理 handler.sent(channel, message); &#125; HeartbeatHandler 处理发送消息只是记录了最后的写时间，然后传递给底层的 ChannelHandler 对象继续处理。 接收消息1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * 收到消息，设置最后读时间 * 1. 收到心跳请求的时候，会生成相应的心跳响应并返回； * 2. 收到心跳响应的时候，会打印相应的日志； * 3. 在收到其他类型的消息时，会传递给底层的 ChannelHandler 对象进行处理 * * @param channel * @param message * @throws RemotingException */ @Override public void received(Channel channel, Object message) throws RemotingException &#123; // 1 设置最后读时间 setReadTimestamp(channel); // 2 收到心跳请求，则生成对应的心跳响应并返回 if (isHeartbeatRequest(message)) &#123; Request req = (Request) message; // 需要响应 if (req.isTwoWay()) &#123; // 设置请求id，为了和请求一一对应 Response res = new Response(req.getId(), req.getVersion()); // 心跳事件 res.setEvent(Response.HEARTBEAT_EVENT); // 心跳响应 channel.send(res); if (logger.isInfoEnabled()) &#123; int heartbeat = channel.getUrl().getParameter(Constants.HEARTBEAT_KEY, 0); if (logger.isDebugEnabled()) &#123; logger.debug(\"Received heartbeat from remote channel \" + channel.getRemoteAddress() + \", cause: The channel has no data-transmission exceeds a heartbeat period\" + (heartbeat &gt; 0 ? \": \" + heartbeat + \"ms\" : \"\")); &#125; &#125; &#125; return; &#125; // 3 收到心跳响应，则打印日志 if (isHeartbeatResponse(message)) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Receive heartbeat response in thread \" + Thread.currentThread().getName()); &#125; return; &#125; // 4 其它类型消息，则传递给底层的 ChannelHandler 对象进行处理 handler.received(channel, message); &#125; HeartbeatHandler 在处理接收消息时有几个点需要注意： 收到消息会记录最后读的时间。 如果收到的是心跳请求消息，则生成该请求的响应并返回给业务线程，不会再往下传递即HeartbeatHandler后面的ChannelHandler没有机会处理这个消息。 如果收到的是心跳响应消息，则打印日志即可，同样不会再往下传递即HeartbeatHandler后面的ChannelHandler没有机会处理这个消息。 如果不是 2、3 步的情况，则直接传递给底层的 ChannelHandler 对象进行处理。 需要注意的是，HeartbeatHandler 定义在 Exchange 层，但是使用是在 transport 层，具体代码如下： 123456789101112131415/** * 无论是Client还是Server，在构造方法中都会将传入的ChannelHandler进行包装，为该 ChannelHandler 增加了 Dubbo 消息派发、心跳处理以及多消息处理的功能。 * @param handler * @param url * @return */ protected ChannelHandler wrapInternal(ChannelHandler handler, URL url) &#123; return new MultiMessageHandler( // 多消息处理 new HeartbeatHandler( // 心跳处理 ExtensionLoader.getExtensionLoader(Dispatcher.class) .getAdaptiveExtension() .dispatch(handler, url) // 返回的是一个 ChannelHandlerDelegate 类型的对象，默认是 AllChannelHandler，确定了具体的线程模型 ) ); &#125; HeaderExchangeHandlerHeaderExchangeHandler 是一个装饰者类型的 ChannelHandler，内部封装了 ExchangeHandler 对象，而 ExchangeHandler 是上层与 Exchange 层交互的重要接口，上层调用方可以实现该接口完成特定功能。经过 HeaderExchangeHandler 装饰的 ExchangeHandler 对象具备 Exchange 层处理请求和响应的能力，最后再经过 Transport 层的 ChannelHandler 装饰而具备 Transport 层处理消息的能力。装饰流程如下图所示： HeaderExchangeHandler 作为一个装饰器，其 对 Channel 中的逻辑处理最终都会委托给被装饰的对象即上层提供的 ExchangeHandler 进行处理，HeaderExchangeHandler 本身关注点在于对 Request 和 Response 的处理逻辑。 下面分析 HeaderExchangeHandler 对 Channel 中的逻辑处理。 属性123456789101112131415161718192021222324252627282930public class HeaderExchangeHandler implements ChannelHandlerDelegate &#123; protected static final Logger logger = LoggerFactory.getLogger(HeaderExchangeHandler.class); /** * 设置Channel的读时间戳 的 key */ public static String KEY_READ_TIMESTAMP = HeartbeatHandler.KEY_READ_TIMESTAMP; /** * 设置Channel的写时间戳 的 key */ public static String KEY_WRITE_TIMESTAMP = HeartbeatHandler.KEY_WRITE_TIMESTAMP; /** * 被装饰的 ChannelHandler,由上层传入 */ private final ExchangeHandler handler; /** * 构造方法 * * @param handler */ public HeaderExchangeHandler(ExchangeHandler handler) &#123; if (handler == null) &#123; throw new IllegalArgumentException(\"handler == null\"); &#125; this.handler = handler; &#125;&#125; HeaderExchangeHandler 实现了 ChannelHandlerDelegate 接口，基于消息头部的信息交换处理器实现类。 获取被装饰的 ChannelHandler1234567891011121314/** * 获取被装饰的 ChannelHandler * * @return */ @Override public ChannelHandler getHandler() &#123; // 如果被装饰的 ChannelHandler 属于装饰者类型就获取其装饰的 handler if (handler instanceof ChannelHandlerDelegate) &#123; return ((ChannelHandlerDelegate) handler).getHandler(); &#125; else &#123; return handler; &#125; &#125; 连接建立12345678910111213141516171819202122/** * 对连接建立的处理 * * @param channel 底层的 Dubbo Channel * @throws RemotingException */ @Override public void connected(Channel channel) throws RemotingException &#123; // 1. 设置读写时间戳 channel.setAttribute(KEY_READ_TIMESTAMP, System.currentTimeMillis()); channel.setAttribute(KEY_WRITE_TIMESTAMP, System.currentTimeMillis()); // 2. 创建 channel 相应的 HeaderExchangeChannel 并将两者绑定. ExchangeChannel exchangeChannel = HeaderExchangeChannel.getOrAddChannel(channel); try &#123; // 3. 通知上层 ExchangeHandler 处理 connect 事件 handler.connected(exchangeChannel); &#125; finally &#123; // 4. 若channel已经断开，则 解绑 channel 与 HeaderExchangeChannel 的联系 HeaderExchangeChannel.removeChannelIfDisconnected(channel); &#125; &#125; 连接断开12345678910111213141516171819202122232425262728/** * 对连接断开的处理 * * @param channel channel. * @throws RemotingException */@Overridepublic void disconnected(Channel channel) throws RemotingException &#123; // 1. 设置读写时间戳 channel.setAttribute(KEY_READ_TIMESTAMP, System.currentTimeMillis()); channel.setAttribute(KEY_WRITE_TIMESTAMP, System.currentTimeMillis()); // 2. 创建 channel 相应的 HeaderExchangeChannel 并将两者绑定. ExchangeChannel exchangeChannel = HeaderExchangeChannel.getOrAddChannel(channel); try &#123; // 3. 通知上层 ExchangeHandler 处理 disconnect handler.disconnected(exchangeChannel); &#125; finally &#123; // 4. 调用 DefaultFuture.closeChannel 方法通知 DefaultFuture 连接断开了，避免连接断开了还在阻塞业务线程。 // DefaultFuture 接到连接断开通知后会先获取连接对应的请求，再通过请求找到关联的 DefaultFuture，判断该请求是否响应，没有响应就创建一个状态码为 CHANNEL_INACTIVE 的 Response 并设置到结果属性。 DefaultFuture.closeChannel(channel); // 5. 解绑 channel 与 HeaderExchangeChannel 的联系 HeaderExchangeChannel.removeChannelIfDisconnected(channel); &#125;&#125; 发送消息12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * 处理发送的数据 * * @param channel 底层的 Dubbo Channel * @param message 可能是请求/响应 消息 * @throws RemotingException */@Overridepublic void sent(Channel channel, Object message) throws RemotingException &#123; Throwable exception = null; try &#123; // 1. 设置写时间 channel.setAttribute(KEY_WRITE_TIMESTAMP, System.currentTimeMillis()); // 2. 创建 channel 相应的 HeaderExchangeChannel 并将两者绑定. ExchangeChannel exchangeChannel = HeaderExchangeChannel.getOrAddChannel(channel); try &#123; // 3. 通知上层 ExchangeHandler 实现的 sent() 方法 handler.sent(exchangeChannel, message); &#125; finally &#123; // 4. 若channel已经断开，则 解绑 channel 与 HeaderExchangeChannel 的联系 HeaderExchangeChannel.removeChannelIfDisconnected(channel); &#125; // 上层 ExchangeHandler 实现的 sent() 方法 执行异常 &#125; catch (Throwable t) &#123; exception = t; &#125; // 5. 如果是请求，则调用 DefaultFuture.sent() 方法更新请求的具体发送时间 if (message instanceof Request) &#123; Request request = (Request) message; DefaultFuture.sent(channel, request); &#125; // 6. 如果发送消息出现异常，则进行处理 if (exception != null) &#123; if (exception instanceof RuntimeException) &#123; throw (RuntimeException) exception; &#125; else if (exception instanceof RemotingException) &#123; throw (RemotingException) exception; &#125; else &#123; throw new RemotingException(channel.getLocalAddress(), channel.getRemoteAddress(), exception.getMessage(), exception); &#125; &#125;&#125; 在 HeaderExchangeChannel.request() 方法中创建了 DefaultFuture 对象，然后将请求通过装饰的 Dubbo Channel 发送出去。请求会通过 Channel 进行传输，在传输的过程中会触发沿途的 ChannelHandler.sent() 等方法，HeaderExchangeHandler 的 sent() 处理逻辑包括调用 DefaultFuture.sent() 方法更新 DefaultFuture 中的 sent 的值即更新请求发送时间。 异常处理123456789101112131415161718192021222324252627282930313233343536373839/** * 捕获到异常 * * @param channel 底层的 Dubbo Channel * @param exception exception. * @throws RemotingException */ @Override public void caught(Channel channel, Throwable exception) throws RemotingException &#123; // 1. 当发生 ExecutionException 异常（线程池处理任务异常） if (exception instanceof ExecutionException) &#123; ExecutionException e = (ExecutionException) exception; Object msg = e.getRequest(); // 1.1 请求消息 if (msg instanceof Request) &#123; Request req = (Request) msg; // 1.2 如果当前请求需要响应且非心跳请求，则发送异常处理结果给调用方 if (req.isTwoWay() &amp;&amp; !req.isHeartbeat()) &#123; // 发送状态码为 SERVER_ERROR 的响应 Response res = new Response(req.getId(), req.getVersion()); res.setStatus(Response.SERVER_ERROR); res.setErrorMessage(StringUtils.toString(e)); channel.send(res); return; &#125; &#125; &#125; // 2. 非线程池处理异常时，将异常交给上层 Handler 处理 ExchangeChannel exchangeChannel = HeaderExchangeChannel.getOrAddChannel(channel); try &#123; // 3. 通知上层 ExchangeHandler 实现的 caught() 方法 handler.caught(exchangeChannel, exception); &#125; finally &#123; // 4. 若channel已经断开，则 解绑 channel 与 HeaderExchangeChannel 的联系 HeaderExchangeChannel.removeChannelIfDisconnected(channel); &#125; &#125; HeaderExchangeHandler 属于 Dubbo 的 ChannelHandler 链的一部分，并且是 Transport 层 ChannelHandler 装饰的对象，Transport 层实现了 Dubbo 的线程模型，但是线程池执行时可能会发生异常，而这个异常类型就是 ExecutionException 。 如果线程池执行任务发生异常就会抛出该异常，HeaderExchangeHandler 最后会捕获到该异常。异常具体位置如下图所示： 接收消息12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970/** * 接收消息 * * @param channel 底层的 Dubbo Channel * @param message message 消息 * @throws RemotingException */ @Override public void received(Channel channel, Object message) throws RemotingException &#123; // 1. 设置最后的读时间 channel.setAttribute(KEY_READ_TIMESTAMP, System.currentTimeMillis()); // 2. 创建 channel 相应的 HeaderExchangeChannel 并将两者绑定. ExchangeChannel exchangeChannel = HeaderExchangeChannel.getOrAddChannel(channel); // 3. 对收到的消息分类 try &#123; // 3.1 处理请求消息 if (message instanceof Request) &#123; Request request = (Request) message; // 3.1.1 只读请求 if (request.isEvent()) &#123; // 在Channel上设置'channel.readonly' 标志，然后往下传即可。 handlerEvent(channel, request); // 处理普通请求 &#125; else &#123; // 3.1.2 需要响应，要将响应写回请求方 if (request.isTwoWay()) &#123; // 处理请求 Response response = handleRequest(exchangeChannel, request); // 将调用结果返回给服务消费端 channel.send(response); // 3.1.3 不需要响应，直接交给上层实现的 ExchangeHandler 进行处理 &#125; else &#123; handler.received(exchangeChannel, request.getData()); &#125; &#125; // 3.2 处理响应响应消息 &#125; else if (message instanceof Response) &#123; // 将关联的 DefaultFuture 设置为完成状态（或是异常完成状态） handleResponse(channel, (Response) message); // 3.3 处理String类型的消息，根据当前服务的角色进行分类处理 &#125; else if (message instanceof String) &#123; // 3.3.1 客户端侧 不支持String if (isClientSide(channel)) &#123; Exception e = new Exception(\"Dubbo client can not supported string message: \" + message + \" in channel: \" + channel + \", url: \" + channel.getUrl()); logger.error(e.getMessage(), e); // 3.3.2 服务端侧，目前仅有 telnet 命令的情况 &#125; else &#123; // 调用 handler 的 telnet方法，处理telnet命令，并将执行命令的结果发送可客户端。【注意：ExchangeHandler实现了TelnetHandler接口】 String echo = handler.telnet(channel, (String) message); if (echo != null &amp;&amp; echo.length() &gt; 0) &#123; channel.send(echo); &#125; &#125; // 3.4 其他情况，直接交给上层实现的 ExchangeHandler 进行处理 &#125; else &#123; handler.received(exchangeChannel, message); &#125; &#125; finally &#123; // 4. 若channel已经断开，则 解绑 channel 与 HeaderExchangeChannel 的联系 HeaderExchangeChannel.removeChannelIfDisconnected(channel); &#125; &#125; 由于收到消息的类型可能有多种，不同类型处理逻辑也不相同，下面对消息分类处理进行说明。 只读请求只读请求由 handlerEvent() 方法进行处理，它会在 Channel 上设置 channel.readonly 标识，客户端收到只读事件请求后，后续不再向对应的服务发送新的请求。 1234567891011121314/** * 处理只读事件请求 * * @param channel 底层 Dubbo 通道 * @param req 请求 * @throws RemotingException */ void handlerEvent(Channel channel, Request req) throws RemotingException &#123; // 如果是只读请求 'R' if (req.getData() != null &amp;&amp; req.getData().equals(Request.READONLY_EVENT)) &#123; // 客户端收到 READONLY_EVENT 事件请求后记录到通道，后续不再向该服务器发送新的请求。[服务调用时会检查服务的状态] channel.setAttribute(Constants.CHANNEL_ATTRIBUTE_READONLY_KEY, Boolean.TRUE); &#125; &#125; 双向请求双向请求即需要响应的请求由 handleRequest() 方法进行处理，该方法会先判断请求是否解码失败，如果解码失败则返回异常响应，如果请求解码成功则会将正常解码的请求交给上层实现的 ExchangeHandler 进行处理。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * 处理普通请求 - 需要响应 * * @param channel 底层 Dubbo 通道 * @param req * @return * @throws RemotingException */ Response handleRequest(ExchangeChannel channel, Request req) throws RemotingException &#123; // 创建响应对象 Response res = new Response(req.getId(), req.getVersion()); // 如果是解码失败的请求，则返回状态为 BAD_REQUEST 的异常结果 if (req.isBroken()) &#123; // 请求数据，转成 msg Object data = req.getData(); String msg; if (data == null) &#123; msg = null; &#125; else if (data instanceof Throwable) &#123; msg = StringUtils.toString((Throwable) data); &#125; else &#123; msg = data.toString(); &#125; res.setErrorMessage(\"Fail to decode request due to: \" + msg); res.setStatus(Response.BAD_REQUEST); // 返回 return res; &#125; // 获取请求数据，这里一般是 RpcInvocation 对象 Object msg = req.getData(); try &#123; // 交给上层实现的 ExchangeHandler 进行处理 Object result = handler.reply(channel, msg); // 封装请求状态和结果 res.setStatus(Response.OK); res.setResult(result); // 上层实现的 ExchangeHandler 处理异常 &#125; catch (Throwable e) &#123; // 若调用过程出现异常，则设置 SERVICE_ERROR，表示服务端异常 res.setStatus(Response.SERVICE_ERROR); res.setErrorMessage(StringUtils.toString(e)); &#125; // 返回响应 return res; &#125; 需要说明的是，在 Dubbo 2.7.x 版本中已经支持服务端的异步处理，通过 Java 8 的 CompletableFuture 来实现。从 2.7.0 开始，Dubbo 的所有异步编程接口开始以 CompletableFuture 为基础 。处理请求的代码如下： 1234567891011121314151617181920212223242526272829303132333435void handleRequest(final ExchangeChannel channel, Request req) throws RemotingException &#123; // 创建响应对象 Response res = new Response(req.getId(), req.getVersion()); // 请求解码失败 if (req.isBroken()) &#123; Object data = req.getData(); // 设置异常信息和响应码，将异常响应返回给对端 res.setErrorMessage(\"Fail to decode request due to: \" + msg); res.setStatus(Response.BAD_REQUEST); channel.send(res); return; &#125; Object msg = req.getData(); // 交给上层实现的ExchangeHandler进行处理。 // DubboProtocol 中的 requestHandler 的 reply 方法返回的类型是 CompletableFuture 。 CompletionStage&lt;Object&gt; future = handler.reply(channel, msg); // 请求处理后的回调 future.whenComplete((appResult, t) -&gt; &#123; // 返回正常响应 if (t == null) &#123; res.setStatus(Response.OK); res.setResult(appResult); // 处理过程发生异常，设置异常信息和错误码 &#125; else &#123; res.setStatus(Response.SERVICE_ERROR); res.setErrorMessage(StringUtils.toString(t)); &#125; // 发送响应 channel.send(res); &#125;);&#125; 单向请求单向请求即调用方不需要返回结果，直接交给上层 ExchangeHandler 实现的 received() 方法进行处理。对于 DubboProtocol 来说，received() 方法会依赖 reply() 方法，单向请求不使用 reply() 方法的返回结果而已。 12345678910111213+--- HeaderExchangeHandler handler.received(exchangeChannel, request.getData());+--- DubboProtocl @Override public void received(Channel channel, Object message) throws RemotingException &#123; // 判断消息类型是不是 Invocation if (message instanceof Invocation) &#123; reply((ExchangeChannel) channel, message); &#125; else &#123; super.received(channel, message); &#125; &#125; 处理响应处理接收到的 Response 消息，也就是返回了结果，只需要 HeaderExchangeHandler 调用 handleResponse() 方法将关联的 DefaultFuture 设置为完成状态（或是异常完成状态），然后向下传递即可。 12345678910111213/** * 处理响应 - 客户端收到服务端的响应 * * @param channel 底层 Dubbo 通道 * @param response 响应 * @throws RemotingException */ static void handleResponse(Channel channel, Response response) throws RemotingException &#123; // 只处理非心跳事件响应，调用DefaultFuture#received(channel, response) 方法设置响应结果以及唤醒等待请求结果的线程。 if (response != null &amp;&amp; !response.isHeartbeat()) &#123; DefaultFuture.received(channel, response); &#125; &#125; 在 HeaderExchangeChannel.request() 方法中完成 DefaultFuture 对象的创建后，会将请求通过装饰的 Dubbo Channel 发送出去，发送的过程会触发 Dubbo Channel 中 ChannelHandler 链，至于是 IO 线程处理请求还是通过线程池来处理请求，需要看具体的消息派发策略。服务端处理完请求后，会将结果发送到对端，消费端读取到完整响应后，同样会触发 Dubbo Channel 中 ChannelHandler 链，当响应传递到 HeaderExchangeHandler 时 received() 方法会触发，执行该方法的内部逻辑，也就是调用 handleResponse() 方法设置响应结果并唤醒等待请求结果的线程。 处理String类型消息对于 String 类型的消息，HeaderExchangeHandler 会根据当前服务的角色进行分类处理，目前仅支持 telnet 命令。 兜底处理如果接收的消息不是以上类型，则直接交给上层实现的 ExchangeHandler 进行处理。 ExchangeHandlerExchangeHandler 是 Exchange 层定义的供上层使用的信息交换处理器接口，该接口继承了 ChannelHandler 和 TelnetHandler 接口，它同样是一个 ChannelHandler 。 123456789101112public interface ExchangeHandler extends ChannelHandler, TelnetHandler &#123; /** * 处理请求 * * @param channel 通道 * @param request 请求 * @return response 返回请求结果 * @throws RemotingException */ Object reply(ExchangeChannel channel, Object request) throws RemotingException;&#125; ExchangeHandler 新定义了 reply() 方法，该方法主要用来处理请求并返回请求结果，上文中的 HeaderExchangeHandler.handleRequest() 方法处理双向请求的过程就是将 reply() 方法返回结果设置到 Response.mResult 属性中。 ExchangeHandlerAdapter信息交换处理器适配器抽象类，实现了 ExchangeHandler 接口并继承了 TelnetHandlerAdapter 类，空实现了 reply 方法。 123456789101112131415public abstract class ExchangeHandlerAdapter extends TelnetHandlerAdapter implements ExchangeHandler &#123; /** * 处理请求 * * @param channel 通道 * @param msg * @return * @throws RemotingException */ @Override public Object reply(ExchangeChannel channel, Object msg) throws RemotingException &#123; return null; &#125;&#125; ExchangeHandler 接口虽然属于 ChannelHandler 类型，但是该接口的定位是供 Exchange 层的上层使用，其实就是 Protocol 层。截止到目前，我们不难发现 ExchangeHandler 的实现就是整个 ChannelHandler 链的最尾的一个节点，这意味着上层逻辑的直接处理对象就是该实现。 由于 ExchangeHandlerAdapter 实现了 ExchangeHandler 接口，在 DubboProtocol、ThirftProtocol 中都会基于 ExchangeHandlerAdapter 实现自己的处理器，处理请求并返回结果，如 DubboProtocol 中的处理器实现，用于将请求最终交给对应的 Invoker 对象处理，简化后的代码如下： 1234567891011121314151617181920212223242526272829private ExchangeHandler requestHandler = new ExchangeHandlerAdapter() &#123; // 用于处理服务消费者的同步调用和异步调用的请求 @Override public Object reply(ExchangeChannel channel, Object message) throws RemotingException &#123; if (message instanceof Invocation) &#123; // 转成 Invocation Invocation inv = (Invocation) message; // 根据调用信息获取 Invoker Invoker&lt;?&gt; invoker = getInvoker(channel, inv); // 执行调用 return invoker.invoke(inv); &#125; &#125; @Override public void received(Channel channel, Object message) throws RemotingException &#123; //... 省略代码 &#125; @Override public void connected(Channel channel) throws RemotingException &#123; //... 省略代码 &#125; @Override public void disconnected(Channel channel) throws RemotingException &#123; //... 省略代码 &#125; &#125; 异步转同步Dubbo 协议下使用的网络通信底层依赖的是 NIO 组件，而这些 NIO 组件是异步通讯机制。此外，TCP 协议本身就是异步的，在 TCP 协议层面发送完 RPC 请求后，线程是不会等待 RPC 的响应结果的。既然底层是异步处理请求，那么 Dubbo 是怎样实现同步调用的呢？其实 Dubbo 异步调用和同步调用差不多，区别在于获取调用结果的时机。在分析异步转同步前，我们先简单说明下 Dubbo 中的同步调用和异步调用。 同步调用同步调用是一种阻塞式的调用方式，消费方发起调用后会处于阻塞等待状态，直到服务提供方返回结果（这里不考虑超时、出错等异常流）。过程如下： 消费方业务线程调用远程服务接口，同时当前业务线程处于阻塞状态即阻塞等待调用结果。 服务提供方收到消费方的请求后会对请求进行处理，处理完毕会将结果发送到对端。 消费方收到调用结果后，阻塞的业务线程继续往下执行。 上述同步调用过程有 3 个点值得关注： 业务线程是怎么进入阻塞状态的 如何定义消费方收到调用结果 业务线程是如何唤醒的 要弄清楚上面的问题需要从源码中找线索，我们先下面的代码。 12345678910111213141516171819202122232425262728+--- DubboInvoker.doInvoke() // 异步无返回值 if (isOneway) &#123; boolean isSent = getUrl().getMethodParameter(methodName, Constants.SENT_KEY, false); // 发送请求 currentClient.send(inv, isSent); // 设置上下文中的 future 为 null RpcContext.getContext().setFuture(null); // 返回一个空的 RpcResult return new RpcResult(); &#125; // 异步有返回值 else if (isAsync) &#123; // 发送请求，获得 ResponseFuture 实例 ResponseFuture future = currentClient.request(inv, timeout); // 设置 future 到上下文中 RpcContext.getContext().setFuture(new FutureAdapter&lt;Object&gt;(future)); // 暂时返回一个空结果 return new RpcResult(); &#125; // 同步调用 else &#123; RpcContext.getContext().setFuture(null); // 发送请求，得到一个 ResponseFuture 实例，并调用该实例的 get 方法进行等待 return (Result) currentClient.request(inv, timeout).get(); &#125; 看到上面的代码后，是不是已经有了结论。关键点在消费方调用后会得到一个 ResponseFuture 对象，该对象在前文已经详细介绍过了。同步调用时，业务线程直接执行 ResponseFuture.get() 方法阻塞等待结果返回，一般消费方会定义超时时间（没有定义则使用默认超时时间）。当服务提供方返回结果后，通过执行 received() 方法将结果设置到 ResponseFuture 中，并唤醒阻塞等待的业务线程。如果超过最大等待时间结果还未返回，则业务线程会抛出异常。 异步调用Dubbo 默认使用的是同步调用，如果要使用异步调用需要消费方自行配置。Dubbo 的异步调用和同步调用类似，区别在于业务线程获取调用结果的时机是可控的。业务线程发起调用后并没有立即获取调用结果，而是将 ResponseFuture 保存到了 Dubbo 的上线文中，然后继续向下执行其它逻辑，当需要调用结果时可以随时从上下文中取出 ResponseFuture 并执行 get() 方法来获取。 转化流程图 上图简单描述了 Dubbo 异步转同步的过程，包括了同步调用和异步调用。需要注意的是，图中设置响应结果是 HeaderExchangeHandler 处理的，其实还有一种处理响应结果的方式，也是前文已经说明的，通过定时任务扫描调用超时的请求以及时响应结果，如果是同步调用则可以尽可能减少业务线程阻塞等待的时间。 客户端Exchange 层的客户端继承关系如下图所示： ExchangeClient12public interface ExchangeClient extends Client, ExchangeChannel &#123;&#125; Exchange 层定义的 Client 接口是个空接口，没有定义任何方法，只是继承了最基本的 Client 和 ExchangeChannel 接口，目前只是充当标记接口角色。为什么说 Client 和 ExchangeChannel 是最基本的接口呢？从 Client 的角度看，Client 接口标识是客户端，这个很好理解。但是继承 ExchangeChannel 接口的目的是什么呢？ 这是因为 ExchangeClient 要使用 ExchangeChannel 来发送消息，因此 ExchangeClient 实例内部会封装一个 ExchangeChannel 实例，基于面向接口开发原则继承 ExchangeChannel 远比自定义发送消息接口要优雅得多。不仅 Exchange 层这样设计，Transport 层的 Client 也是同样的设计方式。 下面我们看 ExchangeClient 的实现类 HeaderExchangeClient 。 HeaderExchangeClient实现了 ExchangeClient 接口，并且间接实现了 ExchangeChannel 和 Client 接口。HeaderExchangeClient 是 Client 的装饰器，主要为装饰的 Client 添加以下功能： 通过定时发送心跳消息来维持与 Server 的长连接状态。 通过定时检查连接状态来实现断线重连功能。 属性12345678910111213141516171819202122232425+--- HeaderExchangeClient /** * 定时任务线程池 */ private static final ScheduledThreadPoolExecutor scheduled = new ScheduledThreadPoolExecutor(2, new NamedThreadFactory(\"dubbo-remoting-client-heartbeat\", true)); /** * Transport 层的 Client 实例 */ private final Client client; /** * 信息交换通道，Client 和 Server 建立的连接 */ private final ExchangeChannel channel; /** * 定时任务Future */ private ScheduledFuture&lt;?&gt; heartbeatTimer; /** * 心跳间隔 */ private int heartbeat; /** * 心跳超时时间 */ private int heartbeatTimeout; HeaderExchangeClient 中的属性字段说明如下： client ：被装饰的 Client 对象，HeaderExchangeClient 中对 Client 接口的实现都会委托给这个被装饰的对象处理。 channel ：HeaderExchangeClient 中对 ExchangeChannel 接口的实现，都会委托给该对象进行处理。 scheduled ：用于定时 发送心跳消息以维持和 Server 的长连接状态和检查连接状态以实现断线重连功能。 heartbeat 和 heartbeatTimeout ：作为心跳相关的时间属性，以此为依据判断是否要发送心跳和重连。 上述属性会在 HeaderExchangeClient 构造方法中完成初始化。 构造方法1234567891011121314151617181920212223242526272829303132/** * @param client Transport 层的 Client 实例 * @param needHeartbeat 是否开启心跳任务 */ public HeaderExchangeClient(Client client, boolean needHeartbeat) &#123; if (client == null) &#123; throw new IllegalArgumentException(\"client == null\"); &#125; // 设置 client 属性 this.client = client; // 创建 HeaderExchangeChannel 对象，对 Transport层的Client进行装饰 this.channel = new HeaderExchangeChannel(client); // 获取 Dubbo 版本 String dubbo = client.getUrl().getParameter(Constants.DUBBO_VERSION_KEY); // 读取心跳相关的配置,默认开启心跳机制 this.heartbeat = client.getUrl().getParameter(Constants.HEARTBEAT_KEY, dubbo != null &amp;&amp; dubbo.startsWith(\"1.0.\") ? Constants.DEFAULT_HEARTBEAT : 0); this.heartbeatTimeout = client.getUrl().getParameter(Constants.HEARTBEAT_TIMEOUT_KEY, heartbeat * 3); // 避免心跳间隔太短 if (heartbeatTimeout &lt; heartbeat * 2) &#123; throw new IllegalStateException(\"heartbeatTimeout &lt; heartbeatInterval * 2\"); &#125; // 是否启动心跳 if (needHeartbeat) &#123; // 启动心跳定时任务 startHeartbeatTimer(); &#125; &#125; 构造方法的第一个参数是 Transport 层的 Client 对象，如 NettyClient 对象，第二参数表示是否开启心跳任务，由前文知该参数在 HeaderExchanger.connect() 方法中传入的是 true，即表示开启客户端侧的心跳定时任务。下面我们重点分析该心跳逻辑。 开启心跳定时任务1234567891011121314151617181920212223242526/** * 开启心跳定时任务 */ private void startHeartbeatTimer() &#123; // 开启一个新的心跳定时任务时，需要停止原有的定时任务 stopHeartbeatTimer(); // 开启新的定时任务 if (heartbeat &gt; 0) &#123; heartbeatTimer = scheduled.scheduleWithFixedDelay( /** * 创建心跳任务 */ new HeartBeatTask(new HeartBeatTask.ChannelProvider() &#123; /** * 每个客户端端侧只有一个通道，这里是 HeaderExchangeClient 对象自己 * @return */ @Override public Collection&lt;Channel&gt; getChannels() &#123; return Collections.&lt;Channel&gt;singletonList(HeaderExchangeClient.this); &#125; &#125;, heartbeat, heartbeatTimeout), heartbeat, heartbeat, TimeUnit.MILLISECONDS); &#125; &#125; 开启心跳定时任务比较简单，主要是创建一个心跳任务 HeartBeatTask 并传入其构造方法所需的参数，Channel(这里是 HeaderExchangeClient 对象)、心跳间隔 heartbeat 和 心跳超时时间 heartbeatTimeout，最后将创建的心跳任务交给定时任务线程池处理。可以看出，不管是心跳检测还是断线重连，核心点是 HeartBeatTask 任务。 关于该任务我们待会详细分析，现在回到 HeaderExchangeClient 类中来。停止心跳定时任务比较简单就不再介绍。下面对剩余的方法分类说明。 其它方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109+--- HeaderExchangeClient //------------------------ ExchangeChannel 接口方法的实现 -------------------/ @Override public ResponseFuture request(Object request) throws RemotingException &#123; return channel.request(request); &#125; @Override public ResponseFuture request(Object request, int timeout) throws RemotingException &#123; return channel.request(request, timeout); &#125; @Override public ExchangeHandler getExchangeHandler() &#123; return channel.getExchangeHandler(); &#125; // ExchangeChannel 对 Endpoint 的 close(int timeout) 方法的重写，HeaderExchangeClient 对其进行实现。 @Override public void close(int timeout) &#123; // Mark the client into the closure process startClose(); // 将 closing 字段设置为true doClose(); // 关闭心跳定时任务 channel.close(timeout); // 关闭 HeaderExchangeChannel &#125; //-------------------------- Endpoint 接口方法的实现 ----------------------/ @Override public URL getUrl() &#123; return channel.getUrl(); &#125; // 获取底层Channel关联的ChannelHandler。 Channel接口继承Endpoint接口是有原因的哟。 @Override public ChannelHandler getChannelHandler() &#123; return channel.getChannelHandler(); &#125; // Channel接口继承Endpoint接口是有原因的哟。 @Override public InetSocketAddress getLocalAddress() &#123; return channel.getLocalAddress(); &#125; @Override public void send(Object message) throws RemotingException &#123; channel.send(message); &#125; @Override public void send(Object message, boolean sent) throws RemotingException &#123; channel.send(message, sent); &#125; @Override public boolean isClosed() &#123; return channel.isClosed(); &#125; @Override public void close() &#123; doClose(); channel.close(); &#125; @Override public void startClose() &#123; channel.startClose(); &#125; //------------------------------- Channel 接口方法的实现 -------------------------/ @Override public InetSocketAddress getRemoteAddress() &#123; return channel.getRemoteAddress(); &#125; @Override public boolean isConnected() &#123; return channel.isConnected(); &#125; @Override public Object getAttribute(String key) &#123; return channel.getAttribute(key); &#125; @Override public void setAttribute(String key, Object value) &#123; channel.setAttribute(key, value); &#125; @Override public void removeAttribute(String key) &#123; channel.removeAttribute(key); &#125; @Override public boolean hasAttribute(String key) &#123; return channel.hasAttribute(key); &#125; //----------------------------- Client 接口方法的实现 ---------------------------/ @Override public void reconnect() throws RemotingException &#123; client.reconnect(); &#125; 对 HeaderExchangeClient 中的其它方法做了简单的分类，分类不是目的，目的是想说明一个现象。Client 和 Server 都是具有语义的端点，两者之间的 TCP 连接抽象为 Channel，端点一般不进行数据传输动作，进行数据传输的动作都是由端点的通道执行的，我们会看到端点有实现数据传输的接口方法，但是具体的动作还是交给了其通道执行。通过上面的代码我们也可以看出，被装饰的Client对象只处理了重连动作，这是端点的动作。其它的方法都是交给了被装饰的 ExchangeChannel 对象。 心跳任务HeartBeatTask 实现了 Runnable 接口，该任务主要进行心跳检测和断线重连。 属性1234567891011121314151617181920212223242526272829303132333435363738394041424344final class HeartBeatTask implements Runnable &#123; private static final Logger logger = LoggerFactory.getLogger(HeartBeatTask.class); /** * 用于获取需要心跳检测的通道数组的对象 */ private ChannelProvider channelProvider; /** * 心跳间隔，单位： 毫秒 */ private int heartbeat; /** * 心跳超时时间，单位：毫秒 */ private int heartbeatTimeout; /** * 获取通道助手内部接口 */ interface ChannelProvider &#123; /** * 获取需要心跳检测的 Channel，Channel 是双向通信的即不仅仅支持客户端连接服务端，还支持服务端发送数据包给客户端 * * @return */ Collection&lt;Channel&gt; getChannels(); &#125; /** * 构造方法 * * @param provider 通道助手对象 * @param heartbeat 心跳间隔 * @param heartbeatTimeout 心跳超时时间 */ HeartBeatTask(ChannelProvider provider, int heartbeat, int heartbeatTimeout) &#123; this.channelProvider = provider; this.heartbeat = heartbeat; this.heartbeatTimeout = heartbeatTimeout; &#125;&#125; 心跳任务有三个核心属性，其中 ChannelProvider 接口是内部接口，供客户端侧和服务端侧实现，以分别获取客户端的通道 Channel 和服务端的通道 Channel 集合。 任务逻辑1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * 任务逻辑 */@Overridepublic void run() &#123; try &#123; // 当前时间 long now = System.currentTimeMillis(); //从ChannelProvider中获取到需要心跳检测的channel for (Channel channel : channelProvider.getChannels()) &#123; // 通道关闭则不需要检测 if (channel.isClosed()) &#123; continue; &#125; try &#123; // 从待处理检测的Channel的附加属性中获取最后一次读、写时间 Long lastRead = (Long) channel.getAttribute(HeaderExchangeHandler.KEY_READ_TIMESTAMP); Long lastWrite = (Long) channel.getAttribute(HeaderExchangeHandler.KEY_WRITE_TIMESTAMP); // 最后一次读/写时间超过心跳间隔，就会发送心跳请求 if ((lastRead != null &amp;&amp; now - lastRead &gt; heartbeat) || (lastWrite != null &amp;&amp; now - lastWrite &gt; heartbeat)) &#123; // 创建心跳请求对象 Request req = new Request(); req.setVersion(Version.getProtocolVersion()); // 需要响应 req.setTwoWay(true); // 是心跳事件 req.setEvent(Request.HEARTBEAT_EVENT); // 发送心跳请求 channel.send(req); if (logger.isDebugEnabled()) &#123; logger.debug(\"Send heartbeat to remote channel \" + channel.getRemoteAddress() + \", cause: The channel has no data-transmission exceeds a heartbeat period: \" + heartbeat + \"ms\"); &#125; &#125; // 最后一次读时间超过心跳超时时间（3 * 心跳时间），则客户端重新连接服务端；服务端直接关闭客户端连接。 if (lastRead != null &amp;&amp; now - lastRead &gt; heartbeatTimeout) &#123; logger.warn(\"Close channel \" + channel + \", because heartbeat read idle time out: \" + heartbeatTimeout + \"ms\"); // 客户端的通道，则重新连接服务端 if (channel instanceof Client) &#123; try &#123; ((Client) channel).reconnect(); &#125; catch (Exception e) &#123; //do nothing &#125; // 服务端通道，则关闭客户端连接 &#125; else &#123; channel.close(); &#125; &#125; &#125; catch (Throwable t) &#123; logger.warn(\"Exception when heartbeat to remote channel \" + channel.getRemoteAddress(), t); &#125; &#125; &#125; catch (Throwable t) &#123; logger.warn(\"Unhandled exception when heartbeat, cause: \" + t.getMessage(), t); &#125;&#125; 心跳任务主要工作如下： 从ChannelProvider中获取不同侧的通道 Channel，客户端侧只有一个 Channel ，服务端侧有多个 Channel，任务只针对未关闭的 Channel 。 从待处理的Channel附加属性中获取最后一次读、写时间，然后计算距离当前的时间，如果大于心跳间隔就会发送一个心跳请求给对端，因为这里既可能是客户端侧通道也可能是服务端侧通道。 根据最后一次读时间，计算距离当前的时间是否大于心跳超时时间，如果大于心跳超时时间，客户端侧会进行重连服务端，服务端侧会立即关闭通道。 其中第 2 个工作是心跳检测，第 3 个工作是断线重连。值得说明的是，Channel 附加属性中的读写时间主要是心跳处理器 HeartbeatHandler 记录的，其 connected() 记录最后一次读写操作时间、sent() 记录最后一次写操作时间、received() 记录最后一次读操作时间，而 disconnected() 会清理通道 Channel 中的读写时间戳 。 服务端Exchange 层的服务继承关系如下图所示： 上图中的 Endpoint、Server 和 Resetable 这三个接口在前面的文章中已经详细介绍过了，这里不再重复，下面对 Exchange 层定义的 Server 进行详细说明。 ExchangeServer 接口1234567891011121314151617public interface ExchangeServer extends Server &#123; /** * 获得信息交换通道集合 * * @return channels */ Collection&lt;ExchangeChannel&gt; getExchangeChannels(); /** * 根据地址获取信息交换通道 * * @param remoteAddress * @return channel */ ExchangeChannel getExchangeChannel(InetSocketAddress remoteAddress);&#125; ExchangeServer 继承了 Server 接口，在其基础之上新增了两个和信息交换层相关的通道方法。 HeaderExchangeServerHeaderExchangeServer 实现了 ExchangeServer 接口，基于消息头的信息交换服务实现类，是 Transport 层 Server 的装饰器，实现自 Server 接口的方法（包括 Server 继承的接口）几乎都是委托给装饰的 Server 对象。HeaderExchangeServer 主要为其修饰的 Server 添加了定时发送心跳消息的实现，用以关闭长时间没有客户端连接的通道。 属性123456789101112131415161718192021222324252627282930public class HeaderExchangeServer implements ExchangeServer &#123; protected final Logger logger = LoggerFactory.getLogger(getClass()); /** * 心跳检测 Schedule */ private final ScheduledExecutorService scheduled = Executors.newScheduledThreadPool(1, new NamedThreadFactory(\"dubbo-remoting-server-heartbeat\", true)); /** * 被装饰的 Transport 层的服务 */ private final Server server; /** * 心跳检测定时器 Future */ private ScheduledFuture&lt;?&gt; heartbeatTimer; /** * 心跳间隔时间，毫秒 */ private int heartbeat; /** * 心跳超时时间，毫秒 */ private int heartbeatTimeout; /** * 是否关闭，默认非关闭状态 */ private AtomicBoolean closed = new AtomicBoolean(false);&#125; 关键属性 Server、heartbeat 以及 heartbeatTimeout 是在 HeaderExchangeServer 构造方法中完成初始化的。 构造方法12345678910111213141516171819202122232425262728/** * 构造方法 * @param server Transport 层的 Server 对象 */public HeaderExchangeServer(Server server) &#123; if (server == null) &#123; throw new IllegalArgumentException(\"server == null\"); &#125; // HeaderExchangeServer 的工作都会委托给该对象 this.server = server; // 在此之前 Constants.HEARTBEAT_KEY 默认已经有值了， 如果手动配置就使用配置的，如果没有配置默认是 60 this.heartbeat = server.getUrl().getParameter(Constants.HEARTBEAT_KEY, 0); // heartbeatTimeout：默认是 heartbeat * 3 this.heartbeatTimeout = server.getUrl().getParameter(Constants.HEARTBEAT_TIMEOUT_KEY, heartbeat * 3); // 检测心跳超时时间是否合法 if (heartbeatTimeout &lt; heartbeat * 2) &#123; throw new IllegalStateException(\"heartbeatTimeout &lt; heartbeatInterval * 2\"); &#125; /** * 默认在 heartbeat（默认是60s）内如果没有收到消息，就会发送心跳消息，如果连着3次（默认180s）没有收到心跳响应，provider会关闭 Channel 。 */ startHeartbeatTimer(); &#125; 构造方法主要的工作如下： 封装 Transport 层的 Server 对象，此后 HeaderExchangeServer 的服务工作都会交给该对象。 读取心跳相关配置，注意心跳间隔和心跳超时时间的关系，以及各自的默认值 启动心跳检测 Schedule 发送消息12345678910111213141516+--- HeaderExchangeServer @Override public void send(Object message) throws RemotingException &#123; if (closed.get()) &#123; throw new RemotingException(this.getLocalAddress(), null, \"Failed to send message \" + message + \", cause: The server \" + getLocalAddress() + \" is closed!\"); &#125; server.send(message); &#125; @Override public void send(Object message, boolean sent) throws RemotingException &#123; if (closed.get()) &#123; throw new RemotingException(this.getLocalAddress(), null, \"Failed to send message \" + message + \", cause: The server \" + getLocalAddress() + \" is closed!\"); &#125; server.send(message, sent); &#125; 发送消息是交给装饰的 server 来完成，底层还是利用 Channel 来发送。 开启心跳定时任务12345678910111213141516171819+--- HeaderExchangeServer private void startHeartbeatTimer() &#123; // 关闭原有定时任务 stopHeartbeatTimer(); // 发起新的定时任务 if (heartbeat &gt; 0) &#123; heartbeatTimer = scheduled.scheduleWithFixedDelay( new HeartBeatTask(new HeartBeatTask.ChannelProvider() &#123; @Override public Collection&lt;Channel&gt; getChannels() &#123; /** * 获取NettyServer中的全部channel连接，Server 持有多个Client 连接的 Channel */ return Collections.unmodifiableCollection(HeaderExchangeServer.this.getChannels()); &#125; &#125;, heartbeat, heartbeatTimeout), heartbeat, heartbeat, TimeUnit.MILLISECONDS); &#125; &#125; 开启心跳定时任务和 HeaderExchangeClient 中的逻辑一样，区别在 HeaderExchangeServer 可以持有多个连接，获取连接代码如下： 12345678910111213141516171819202122232425+--- HeaderExchangeServer @Override @SuppressWarnings(&#123;\"unchecked\", \"rawtypes\"&#125;) public Collection&lt;Channel&gt; getChannels() &#123; return (Collection) getExchangeChannels(); &#125; /** * 获取NettyServer中的全部channel连接 * * @return */ @Override public Collection&lt;ExchangeChannel&gt; getExchangeChannels() &#123; Collection&lt;ExchangeChannel&gt; exchangeChannels = new ArrayList&lt;ExchangeChannel&gt;(); // 获取 server 维护的 Channel 通道集合 Collection&lt;Channel&gt; channels = server.getChannels(); if (channels != null &amp;&amp; !channels.isEmpty()) &#123; for (Channel channel : channels) &#123; // 根据 Channel 获取 Exchange 层的 Channel exchangeChannels.add(HeaderExchangeChannel.getOrAddChannel(channel)); &#125; &#125; return exchangeChannels; &#125; 关于心跳任务已经在前文中详细说明，这里不再重复介绍。 优雅关闭12345678910111213141516171819202122232425262728293031+--- HeaderExchangeServer @Override public void close(final int timeout) &#123; // 将装饰的server的closing设置为 true，表示当前server处于正在关闭状态，不再与Client建立连接 startClose(); if (timeout &gt; 0) &#123; final long max = timeout; final long start = System.currentTimeMillis(); // 发送 READONLY 事件给所有 Client ，表示Server不再接收新的消息 if (getUrl().getParameter(Constants.CHANNEL_SEND_READONLYEVENT_KEY, true)) &#123; // 广播客户端，READONLY_EVENT 事件消息 sendChannelReadOnlyEvent(); &#125; // 等待 Client 与 当前Server 维持的长连接全部断开或超时 while (HeaderExchangeServer.this.isRunning() &amp;&amp; System.currentTimeMillis() - start &lt; max) &#123; try &#123; Thread.sleep(10); &#125; catch (InterruptedException e) &#123; logger.warn(e.getMessage(), e); &#125; &#125; &#125; // 关闭心跳定时任务，且将自身closed设置为true doClose(); // 关闭Transport层的Server server.close(timeout); &#125; 服务关闭流程非常重要，下面对 HeaderExchangeServer 优雅关闭的过程进行详细说明： 调用 startClose() 方法将被装饰的 Server 的 closing 设置为 true，表示该 Server 端处于正在关闭状态不再与 Client 建立连接。1234567891011121314151617+--- HeaderExchangeServer @Override public void startClose() &#123; server.startClose(); &#125;+--- AbstractServer @Override public void connected(Channel ch) throws RemotingException &#123; // 如果 Server 处于正在关闭状态或关闭状态，则不再接收新连接 if (this.isClosing() || this.isClosed()) &#123; logger.warn(\"Close new channel \" + ch + \", cause: server is closing or has been closed. For example, receive a new connect request while in shutdown process.\"); // 关闭新建的 Client ch.close(); return; &#125; &#125; 发送 READONLY 事件给所有 Client ，表示 Server 不再接收新的消息，避免有新的消息发送过来。在收到该消息后，Client 端的 HeaderExchangeHandler 会在 Channel 上添加 key 为 channel.readonly 的附加信息，上层调用方会根据该附加信息判断该连接是否可写。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647+--- HeaderExchangeServerprivate void sendChannelReadOnlyEvent() &#123; // 创建 READONLY_EVENT 请求 Request request = new Request(); request.setEvent(Request.READONLY_EVENT); // 只读请求不需要响应 request.setTwoWay(false); request.setVersion(Version.getProtocolVersion()); // 发送给所有 Client Collection&lt;Channel&gt; channels = getChannels(); for (Channel channel : channels) &#123; try &#123; if (channel.isConnected()) &#123; channel.send(request, getUrl().getParameter(Constants.CHANNEL_READONLYEVENT_SENT_KEY, true)); &#125; &#125; catch (RemotingException e) &#123; logger.warn(\"send cannot write message error.\", e); &#125; &#125; &#125;+--- DubboInvoker /** * 连接是否有效，Server 具有一票否决权 * * @return */ @Override public boolean isAvailable() &#123; if (!super.isAvailable()) &#123; return false; &#125; for (ExchangeClient client : clients) &#123; /** * 即使Client处于连接中，但如果 Server 处于正在关闭中，连接也是不可用的。[channel.readonly 的附加信息的作用在这里] * * &#123;@link HeaderExchangeServer#sendChannelReadOnlyEvent()&#125; */ if (client.isConnected() &amp;&amp; !client.hasAttribute(Constants.CHANNEL_ATTRIBUTE_READONLY_KEY)) &#123; //cannot write == not Available ? return true; &#125; &#125; return false; &#125; 第 2 步完成后，等待所有的 Client 与 当前 Server 维持的长连接断开或超时。12345678910private boolean isRunning() &#123; Collection&lt;Channel&gt; channels = getChannels(); for (Channel channel : channels) &#123; // 存在任意一个Client与当前Server处于连接状态，Server 都不能不关闭 if (channel.isConnected()) &#123; return true; &#125; &#125; return false; &#125; 第 3 步完成后，调用 doClose() 方法关闭心跳定时任务，且将 closed 字段更新为 true。1234567891011private void doClose() &#123; if (!closed.compareAndSet(false, true)) &#123; return; &#125; stopHeartbeatTimer(); try &#123; scheduled.shutdown(); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125;&#125; 真正关闭服务器即Transport层的Server ，如使用 Netty 作为 NIO 组件，关闭的就是 NettyServer 。 NettyServer.close() 方法会先调用 AbstractPeer 的 close() 方法将自身的 closed 字段设置为 true。12345678910111213141516171819@Override public void close() &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Close \" + getClass().getSimpleName() + \" bind \" + getBindAddress() + \", export \" + getLocalAddress()); &#125; ExecutorUtil.shutdownNow(executor, 100); try &#123; // 设置父类中的 closed 字段为true super.close(); &#125; catch (Throwable e) &#123; logger.warn(e.getMessage(), e); &#125; try &#123; // 调用子类实现，关闭具体服务 doClose(); &#125; catch (Throwable e) &#123; logger.warn(e.getMessage(), e); &#125; &#125; 调用 doClose() 方法关闭 boss Channel 即接收客户端连接的 Channel；关闭与 Client 之间的连接并清理 channels 集合；最后，关闭 bossGroup 和 workerGroup 两个线程组。123456789101112131415161718192021222324252627282930313233343536373839404142434445@Overrideprotected void doClose() throws Throwable &#123; try &#123; if (channel != null) &#123; // 关闭服务器通道 channel.close(); &#125; &#125; catch (Throwable e) &#123; logger.warn(e.getMessage(), e); &#125; // 关闭连接到服务器的客户端通道 try &#123; Collection&lt;com.alibaba.dubbo.remoting.Channel&gt; channels = getChannels(); if (channels != null &amp;&amp; channels.size() &gt; 0) &#123; // 依次遍历连接到服务器的客户端通道，然后进行关闭操作 for (com.alibaba.dubbo.remoting.Channel channel : channels) &#123; try &#123; channel.close(); &#125; catch (Throwable e) &#123; logger.warn(e.getMessage(), e); &#125; &#125; &#125; &#125; catch (Throwable e) &#123; logger.warn(e.getMessage(), e); &#125; // 优雅关闭线程组 try &#123; if (bootstrap != null) &#123; bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125; catch (Throwable e) &#123; logger.warn(e.getMessage(), e); &#125; // 清空连接到服务器的客户端通道 try &#123; if (channels != null) &#123; channels.clear(); &#125; &#125; catch (Throwable e) &#123; logger.warn(e.getMessage(), e); &#125;&#125; HeaderExchangeServer 中的其它方法不是很重要就不一一介绍了，至此 Exchange 层的服务实现部分介绍完毕了，魔鬼存在于细节之中。 编解码器Exchange 层编解码器继承关系如下图所示： TransportCodec 及上层编解码器已经在 Transport 层详细说明，TelnetCodec 继承了 TransportCodec 序列化和反序列化的基本能力，同时还提供了对 Telnet 命令处理的能力。而 ExchangeCodec 是在 TelnetCodec 的基础之上添加了处理协议头的能力。考虑到编解码器在 Dubbo 协议的网络传输中扮演着重要角色，并且逻辑相对比较复杂，因此会单独起一篇文章对整个编解码器体系进行详细分析，这里先不进行展开说明，我们下一篇文章见。 小结本篇文章开篇对 Exchange 层产生的背景进行了简单说明，随后从 Exchange 层的核心模型 Request 和 Response 出发，然后以 Exchanger 接口及其实现为中心引出 Exchange 层的核心组件，先是对 Exchange 层的 Channel 进行说明，同时对其关联的 ResponseFuture 进行了分析，它是实现 Dubbo 调用方式转换的关键。接着对 Exchange 层的 ChannelHandler 进行了深入分析，HeartbeatHandler 和心跳任务 HeartBeatTask 是对心跳检测和断线重连的处理，HeaderExchangeHandler 结合 DefaultFuture 对请求-响应统一处理，ExchangeHandler 是 Exchange 层定义的供上层使用的信息交换处理器。最后对 Exchange 层的 Client 和 Server 进行了说明。文章最后，对 Exchange 层的编解码器进行了简单介绍。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"Dubbo源码分析 - 线程池","slug":"rpc/threadpool","date":"2020-06-12T14:42:08.000Z","updated":"2020-12-16T10:02:30.509Z","comments":false,"path":"posts/f3cd85ef/","link":"","permalink":"https://gentryhuang.com/posts/f3cd85ef/","excerpt":"","text":"前言在 网络传输层 中我们介绍 WrappedChannelHandler 类的构造方法时，提到了线程池的创建的，本篇文章我们对线程池部分详细分析。 概述在 Dubbo 的线程模型中，Dubbo 提供了四种线程池的实现，具体如下： fixed 固定大小线程池，启动时建立线程，不关闭，一直持有。(缺省) cached 缓存线程池，空闲一定时间自动删除，需要时重建。 limited 可伸缩线程池，但池中的线程数只会增长不会收缩。只增长不收缩的目的是为了避免收缩时突然来了大流量引起的性能问题。 eager 优先创建Worker线程池。在任务数量大于corePoolSize但是小于maximumPoolSize时，优先创建Worker来处理任务。当任务数量大于maximumPoolSize时，将任务放入阻塞队列中。阻塞队列充满时抛出RejectedExecutionException。(相比于cached:cached在任务数量超过maximumPoolSize时直接抛出异常而不是将任务放入阻塞队列) 一般情况下，Dubbo 线程池和 Dubbo 消息派发策略组合使用，即配置 Dubbo 中的线程模型，以应对不同的场景。如下面的配置案例： 1&lt;dubbo:protocol name=\"dubbo\" dispatcher=\"all\" threadpool=\"fixed\" threads=\"100\" /&gt; 有关消息派发机制部分在 网络传输层 中已经详细说明，这里不再介绍。线程池相关的接口和实现位于 dubbo-common 模块中，下面我们开始介绍 Dubbo 线程模型中的线程池部分。 ThreadPool1234567891011@SPI(\"fixed\")public interface ThreadPool &#123; /** * 线程池执行器 * * @param url URL contains thread parameter * @return thread pool */ @Adaptive(&#123;Constants.THREADPOOL_KEY&#125;) Executor getExecutor(URL url);&#125; ThreadPool 接口被 @SPI 注解修饰，是 Dubbo 的扩展点，默认扩展实现名为 fixed ，对应的扩展实现为 FixedThreadPool 。ThreadPool 接口中的 getExecutor() 方法被 @Adaptive 注解修饰，会动态生成自适应类即适配器类，该类会优先根据 url.threadpool 参数选择 ThreadPool 的扩展实现。线程池 SPI 配置如下： 1234fixed&#x3D;com.alibaba.dubbo.common.threadpool.support.fixed.FixedThreadPoolcached&#x3D;com.alibaba.dubbo.common.threadpool.support.cached.CachedThreadPoollimited&#x3D;com.alibaba.dubbo.common.threadpool.support.limited.LimitedThreadPooleager&#x3D;com.alibaba.dubbo.common.threadpool.support.eager.EagerThreadPool ThreadPool 继承关系 UML 如下图所示： 不同的 ThreadPool 扩展实现会根据 URL 参数创建不同特性的线程池。 FixedThreadPool固定大小线程池，启动时建立线程，不关闭，一直持有，是 Dubbo 默认的线程池。 1234567891011121314151617181920212223242526272829303132333435363738public class FixedThreadPool implements ThreadPool &#123; @Override public Executor getExecutor(URL url) &#123; // 线程名，获取 url.threadname 的值，默认为 Dubbo String name = url.getParameter(Constants.THREAD_NAME_KEY, Constants.DEFAULT_THREAD_NAME); // 线程数，获取 url.threads 的值，默认为 200 int threads = url.getParameter(Constants.THREADS_KEY, Constants.DEFAULT_THREADS); // 队列数，获取 url.queues 的值，默认为 0 int queues = url.getParameter(Constants.QUEUES_KEY, Constants.DEFAULT_QUEUES); // 创建线程池执行器 return new ThreadPoolExecutor( /* 核心线程数*/ threads, /* 最大线程数 */ threads, /* 空闲线程存活时间 */ 0, /* 空闲存活时间单位 */ TimeUnit.MILLISECONDS, /* 阻塞队列,根据配置的队列数，选择对应的队列 * 1 queues == 0 - SynchronousQueue * 2 queues &lt; 0 - LinkedBlockingQueue * 3 queues &gt; 0 - 带队列数的LinkedBlockingQueue */ queues == 0 ? new SynchronousQueue&lt;Runnable&gt;() : (queues &lt; 0 ? new LinkedBlockingQueue&lt;Runnable&gt;() : new LinkedBlockingQueue&lt;Runnable&gt;(queues)), /* 线程工厂 */ new NamedInternalThreadFactory(name, true), /* 拒绝策略 */ new AbortPolicyWithReport(name, url) ); &#125; /** * 配置方式:使用 &lt;dubbo:parameter key=\"xxx\" value=\"yyy\" /&gt; 配置 */&#125; FixedThreadPool 的核心线程数和最大线程数一致，且不会被回收。 CacheThreadPool缓存线程池，空闲一定时间自动删除，需要时重建。 12345678910111213141516171819202122232425262728293031323334353637public class CachedThreadPool implements ThreadPool &#123; @Override public Executor getExecutor(URL url) &#123; // 线程名，获取 url.threadname 的值，默认为 Dubbo String name = url.getParameter(Constants.THREAD_NAME_KEY, Constants.DEFAULT_THREAD_NAME); // 核心线程数，获取 url.corethreads 的值，默认为 0 int cores = url.getParameter(Constants.CORE_THREADS_KEY, Constants.DEFAULT_CORE_THREADS); // 最大线程数，获取 url.threads 的值，默认为 Integer 的最大值 int threads = url.getParameter(Constants.THREADS_KEY, Integer.MAX_VALUE); // 队列数，获取 url.queues 的值，默认为 0 int queues = url.getParameter(Constants.QUEUES_KEY, Constants.DEFAULT_QUEUES); // 线程存活时长，获取 url.alive 的值，默认为 60 * 1000 int alive = url.getParameter(Constants.ALIVE_KEY, Constants.DEFAULT_ALIVE); // 创建执行器 return new ThreadPoolExecutor( cores, threads, alive, TimeUnit.MILLISECONDS, /* 阻塞队列,根据配置的队列数，选择对应的队列 * 1 queues == 0 - SynchronousQueue * 2 queues &lt; 0 - LinkedBlockingQueue * 3 queues &gt; 0 - 带队列数的LinkedBlockingQueue */ queues == 0 ? new SynchronousQueue&lt;Runnable&gt;() : (queues &lt; 0 ? new LinkedBlockingQueue&lt;Runnable&gt;() : new LinkedBlockingQueue&lt;Runnable&gt;(queues)), /* 线程工厂 */ new NamedInternalThreadFactory(name, true), /* 拒绝策略 */ new AbortPolicyWithReport(name, url) ); /** * 配置方式:使用 &lt;dubbo:parameter key=\"xxx\" value=\"yyy\" /&gt; 配置 */ &#125;&#125; CacheThreadPool 缓存线程池，可以指定核心线程数、最大线程数、缓冲队列长度空以及空闲时间，空闲一定时间非核心线程会被回收，需要时重建。 LimitedThreadPool可伸缩线程池，但池中的线程数只会增长不会收缩。只增长不收缩的目的是为了避免收缩时突然来了大流量引起的性能问题。 123456789101112131415161718192021222324252627282930313233343536373839public class LimitedThreadPool implements ThreadPool &#123; @Override public Executor getExecutor(URL url) &#123; // 线程名，获取 url.threadname 的值，默认为 Dubbo String name = url.getParameter(Constants.THREAD_NAME_KEY, Constants.DEFAULT_THREAD_NAME); // 核心线程数，获取 url.corethreads 的值，默认为 0 int cores = url.getParameter(Constants.CORE_THREADS_KEY, Constants.DEFAULT_CORE_THREADS); // 最大线程数，获取 url.threads 的值，默认为 200 int threads = url.getParameter(Constants.THREADS_KEY, Constants.DEFAULT_THREADS); // 队列数，获取 url.queues 的值，默认为 0 int queues = url.getParameter(Constants.QUEUES_KEY, Constants.DEFAULT_QUEUES); // 创建执行器 return new ThreadPoolExecutor( cores, threads, /** 空闲时间无限大，即不会自动删除 */ Long.MAX_VALUE, TimeUnit.MILLISECONDS, /* 阻塞队列,根据配置的队列数，选择对应的队列 * 1 queues == 0 - SynchronousQueue * 2 queues &lt; 0 - LinkedBlockingQueue * 3 queues &gt; 0 - 带队列数的LinkedBlockingQueue */ queues == 0 ? new SynchronousQueue&lt;Runnable&gt;() : (queues &lt; 0 ? new LinkedBlockingQueue&lt;Runnable&gt;() : new LinkedBlockingQueue&lt;Runnable&gt;(queues)), /* 线程工厂 */ new NamedInternalThreadFactory(name, true), /* 拒绝策略 */ new AbortPolicyWithReport(name, url) ); &#125; /** * 配置方式: 使用 &lt;dubbo:parameter /&gt; 配置 */&#125; LimitedThreadPool 可伸缩线程池，可以指定核心线程数、最大线程数以及缓冲队列长度，LimitedThreadPool 创建的线程池的非核心线程不会被回收。 以上三种类型的线程池都是基于 JDK ThreadPoolExecutor 线程池，在核心线程全部被占用的时候会先把任务放到缓冲队列中，当缓冲队列满了之后，才会尝试创建新线程来处理任务。EagerThreadPool 则有很大差异，具体我们接着分析。 EagerThreadPool123456789101112131415161718192021222324252627282930313233343536373839public class EagerThreadPool implements ThreadPool &#123; @Override public Executor getExecutor(URL url) &#123; // 线程名，获取 url.threadname 的值，默认为 Dubbo String name = url.getParameter(Constants.THREAD_NAME_KEY, Constants.DEFAULT_THREAD_NAME); // 核心线程数，获取 url.corethreads 的值，默认为 0 int cores = url.getParameter(Constants.CORE_THREADS_KEY, Constants.DEFAULT_CORE_THREADS); // 最大线程数，获取 url.threads 的值，默认为 Integer 的最大值 int threads = url.getParameter(Constants.THREADS_KEY, Integer.MAX_VALUE); // 队列数，获取 url.queues 的值，默认为 0 int queues = url.getParameter(Constants.QUEUES_KEY, Constants.DEFAULT_QUEUES); // 线程存活时长，获取 url.alive 的值，默认为 60 * 1000 int alive = url.getParameter(Constants.ALIVE_KEY, Constants.DEFAULT_ALIVE); // 创建任务队列，注意虽然是 LinkedBlockingQueue 类型，但由于设置大小了，因此变成了有界队列。 TaskQueue&lt;Runnable&gt; taskQueue = new TaskQueue&lt;Runnable&gt;(queues &lt;= 0 ? 1 : queues); // 创建 EagerThreadPoolExecutor 对象 EagerThreadPoolExecutor executor = new EagerThreadPoolExecutor( cores, threads, alive, TimeUnit.MILLISECONDS, /* TaskQueue 队列*/ taskQueue, new NamedInternalThreadFactory(name, true), new AbortPolicyWithReport(name, url)); // 将创建的 eager 线程池对象设置到 taskQueue 中 taskQueue.setExecutor(executor); return executor; &#125; /** * 配置方式：使用 &lt;dubbo:parameter /&gt; 配置 */&#125; EagerThreadPool 并没有直接使用 JDK ThreadPoolExecutor 线程池，而是使用了继承 ThreadPoolExecutor 的 EagerThreadPoolExecutor 线程池。而且使用的队列 TaskQueue ，继承了 LinkedBlockingQueue。EagerThreadPool 的不同就体现在这两个对象上。 TaskQueue123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/** * LinkedBlockingQueue 内部由单链表实现的阻塞队列，只能从head取元素，从tail添加元素。 * 1 take() 取数据，当队列为空时阻塞 * 2 poll() 取数据，弹出队列头部元素，队列为空时返回空 * 3 offer() 添加数据，当队列满时返回 false * 4 put() 添加数据，当队列满时阻塞 */public class TaskQueue&lt;R extends Runnable&gt; extends LinkedBlockingQueue&lt;Runnable&gt; &#123; private static final long serialVersionUID = -2635853580887179627L; /** * eager 线程池 */ private EagerThreadPoolExecutor executor; public TaskQueue(int capacity) &#123; super(capacity); &#125; public void setExecutor(EagerThreadPoolExecutor exec) &#123; executor = exec; &#125; /** * 重写 LinkedBlockingQueue 的 offer() 方法。 * 主要实现： * 1 在任务数量大于corePoolSize但是小于maximumPoolSize时，优先创建Worker来处理任务 * 2 当任务数量大于maximumPoolSize时，将任务放入阻塞队列中。阻塞队列充满时抛出RejectedExecutionException * * @param runnable * @return */ @Override public boolean offer(Runnable runnable) &#123; if (executor == null) &#123; throw new RejectedExecutionException(\"The task queue does not have executor!\"); &#125; // 获取当前线程池中的活跃线程数(注意非核心线程数可能被回收) int currentPoolThreadSize = executor.getPoolSize(); // 当前有线程空闲，直接将任务提交到队列中，空闲线程会直接从中获取任务执行 if (executor.getSubmittedTaskCount() &lt; currentPoolThreadSize) &#123; // 将任务入队 return super.offer(runnable); &#125; // return false to let executor create new worker. // 当前没有空闲线程，但活跃线程数小于最大线程数即还可以创建线程，则返回 false，让线程池创建新的线程来执行任务 if (currentPoolThreadSize &lt; executor.getMaximumPoolSize()) &#123; return false; &#125; // currentPoolThreadSize &gt;= max // 当前活跃线程达到上线，则只能将任务放入缓冲队列 return super.offer(runnable); &#125; /** * 再次将任务加入队列 * * @param o task * @return offer success or not * @throws RejectedExecutionException if executor is terminated. */ public boolean retryOffer(Runnable o, long timeout, TimeUnit unit) throws InterruptedException &#123; if (executor.isShutdown()) &#123; throw new RejectedExecutionException(\"Executor is shutdown!\"); &#125; return super.offer(o, timeout, unit); &#125;&#125; TaskQueue 继承了 LinkedBlockingQueue 阻塞队列，它复写了 LinkedBlockingQueue 的 offer() 方法，会判断线程池 EagerThreadPoolExecutor 的 submittedTaskCount 值是否已经达到最大线程数，如果没有超过则返回 false，线程池会创建新线程来执行任务。这点非常重要，eager 线程池优先创建线程执行任务的逻辑判断就这这里。 EagerThreadPoolExecutor12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public class EagerThreadPoolExecutor extends ThreadPoolExecutor &#123; /** * 记录当前在线程池中的任务总数（正在线程中执行的任务数+队列中等待的任务数） */ private final AtomicInteger submittedTaskCount = new AtomicInteger(0); public EagerThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, TaskQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, handler); &#125; /** * 返回当前线程池的任务总数 * * @return current tasks which are executed */ public int getSubmittedTaskCount() &#123; return submittedTaskCount.get(); &#125; /** * 复写 ThreadPoolExecutor 的 afterExecute() 方法 * * @param r * @param t */ @Override protected void afterExecute(Runnable r, Throwable t) &#123; // 任务执行结束，递减 submittedTaskCount submittedTaskCount.decrementAndGet(); &#125; /** * 复写 ThreadPoolExecutor 的 execute() 方法 * * @param command */ @Override public void execute(Runnable command) &#123; if (command == null) &#123; throw new NullPointerException(); &#125; // 任务提交之前，递增submittedTaskCount submittedTaskCount.incrementAndGet(); try &#123; // 提交任务 （当线程池中线程数达到核心线程数，ThreadPoolExecutor 底层会执行 TaskQueue 的 poll() 方法） super.execute(command); // 提交任务被拒绝 &#125; catch (RejectedExecutionException rx) &#123; // 获取缓存队列 final TaskQueue queue = (TaskQueue) super.getQueue(); try &#123; // 尝试将被拒绝的任务再次交给线程池处理，如果线程池关闭或队列满了，则递减 submittedTaskCount if (!queue.retryOffer(command, 0, TimeUnit.MILLISECONDS)) &#123; submittedTaskCount.decrementAndGet(); throw new RejectedExecutionException(\"Queue capacity is full.\"); &#125; // 中断异常，递减 submittedTaskCount &#125; catch (InterruptedException x) &#123; submittedTaskCount.decrementAndGet(); throw new RejectedExecutionException(x); &#125; // 提交任务发生其它异常，递减 submittedTaskCount &#125; catch (Throwable t) &#123; // decrease any way submittedTaskCount.decrementAndGet(); &#125; &#125;&#125; 当活跃线程数没有达到最大线程数时且无空闲线程，EagerThreadPoolExecutor 会优先创建线程来执行任务，而不是放到缓冲队列中，当活跃线程数达到最大值时，EagerThreadPoolExecutor 会将任务放入缓冲队列中等待空闲线程执行，阻塞队列充满时抛出异常。 AbortPolicyWithReport123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125/** * 拒绝策略实现类，继承了 ThreadPoolExecutor.AbortPolicy，这里打印JStack，分析线程状态 * &lt;p&gt; * Abort Policy. * Log warn info when abort. */public class AbortPolicyWithReport extends ThreadPoolExecutor.AbortPolicy &#123; protected static final Logger logger = LoggerFactory.getLogger(AbortPolicyWithReport.class); /** * 线程 */ private final String threadName; /** * URL对象 */ private final URL url; /** * 最后打印时间 */ private static volatile long lastPrintTime = 0; /** * 信号量 */ private static Semaphore guard = new Semaphore(1); public AbortPolicyWithReport(String threadName, URL url) &#123; this.threadName = threadName; this.url = url; &#125; /** * 复写了 rejectedExecution 方法 * * @param r * @param e */ @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; // 打印告警日志 String msg = String.format(\"Thread pool is EXHAUSTED!\" + \" Thread Name: %s, Pool Size: %d (active: %d, core: %d, max: %d, largest: %d), Task: %d (completed: %d),\" + \" Executor status:(isShutdown:%s, isTerminated:%s, isTerminating:%s), in %s://%s:%d!\", threadName, e.getPoolSize(), e.getActiveCount(), e.getCorePoolSize(), e.getMaximumPoolSize(), e.getLargestPoolSize(), e.getTaskCount(), e.getCompletedTaskCount(), e.isShutdown(), e.isTerminated(), e.isTerminating(), url.getProtocol(), url.getIp(), url.getPort()); logger.warn(msg); // 打印JStack，分析线程状态 dumpJStack(); // 抛出 RejectedExecutionException 异常 throw new RejectedExecutionException(msg); &#125; /** * 打印JStack，用来分析线程状态 */ private void dumpJStack() &#123; // 当前时间 long now = System.currentTimeMillis(); //10分钟打印一次 if (now - lastPrintTime &lt; 10 * 60 * 1000) &#123; return; &#125; // 获得信号量 ,用以保证同一时间有且仅有一个线程执行打印 if (!guard.tryAcquire()) &#123; return; &#125; // 创建线程池，后台执行打印逻辑 Executors.newSingleThreadExecutor().execute(new Runnable() &#123; @Override public void run() &#123; // 获得系统 String dumpPath = url.getParameter(Constants.DUMP_DIRECTORY, System.getProperty(\"user.home\")); SimpleDateFormat sdf; // 获得路径 String OS = System.getProperty(\"os.name\").toLowerCase(); // window system don't support \":\" in file name if (OS.contains(\"win\")) &#123; sdf = new SimpleDateFormat(\"yyyy-MM-dd_HH-mm-ss\"); &#125; else &#123; sdf = new SimpleDateFormat(\"yyyy-MM-dd_HH:mm:ss\"); &#125; String dateStr = sdf.format(new Date()); // 输出流 FileOutputStream jstackStream = null; try &#123; jstackStream = new FileOutputStream(new File(dumpPath, \"Dubbo_JStack.log\" + \".\" + dateStr)); // 打印JStack 信息 JVMUtil.jstack(jstackStream); &#125; catch (Throwable t) &#123; logger.error(\"dump jstack error\", t); &#125; finally &#123; // 释放信号量 guard.release(); if (jstackStream != null) &#123; try &#123; jstackStream.flush(); jstackStream.close(); &#125; catch (IOException e) &#123; &#125; &#125; &#125; // 记录最后打印时间 lastPrintTime = System.currentTimeMillis(); &#125; &#125;); &#125;&#125; 小结本篇文章对 Dubbo 线程模型中的线程池部分进行了介绍，Dubbo 目前支持四种线程池，其中 eager 线程池比较特别，使用的缓冲队列 TaskQueue 重写了 LinkedBlockingQueue 的 offer() 方法，该方法的逻辑是判断线程池的中的任务（执行中的和队列中的）是否已经达到最大线程数，如果没有超过就使线程池创建新线程来执行任务。其它三个线程的是基于 JDK ThreadPoolExecutor 线程池，在核心线程全部被占用的时候会先把任务放到缓冲队列中，当缓冲队列满了之后，才会尝试创建新线程来处理任务。最后，介绍了这四个线程池使用的拒绝策略，用于打印JStack，分析线程状态。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"Dubbo源码分析 - Mina网络通信","slug":"rpc/Mina网络通信","date":"2020-06-06T16:00:00.000Z","updated":"2020-12-01T01:45:15.779Z","comments":false,"path":"posts/543ee8c5/","link":"","permalink":"https://gentryhuang.com/posts/543ee8c5/","excerpt":"","text":"前言在 网络传输层 中对 Transport 通用层或者说是抽象层进行了详细分析。上一篇文章 Netty4网络通信 中我们详细分析了 Dubbo 接入 Netty4 实现的网络通信，本篇文章将分析 Dubbo 如何接入 Mina 库。 概述Dubbo 为了集成不同优秀开源的 NIO 库，专门实现了一个抽象层，对应的模块是 dubbo-remoting-api，在 远程通信模块总览 中介绍了该模块核心的接口和类。针对每一个 NIO 框架的接入，Dubbo 都构建一个单独的模块，该模块只需实现抽象模块 dubbo-remoting-api 即可，结合 Dubbo SPI 机制可以灵活切换到不同的 NIO 库。下面我们开始介绍实现层 dubbo-remoting-mina 模块，UML 图如下： 通过上面的 UML 图可以很清晰看出各个类之间的关系，和 Netty4 实现通信几乎一致。下面我们依然根据 UML 图的依赖关系逐个分析。 MinaTransporter123456789101112131415161718192021222324252627282930public class MinaTransporter implements Transporter &#123; public static final String NAME = \"mina\"; /** * 绑定一个服务器 * * @param url 服务器地址 * @param handler 通道处理器 * @return * @throws RemotingException */ @Override public Server bind(URL url, ChannelHandler handler) throws RemotingException &#123; return new MinaServer(url, handler); &#125; /** * 连接服务器，级创建一个客户端 * * @param url 服务器地址 * @param handler 通道处理器 * @return * @throws RemotingException */ @Override public Client connect(URL url, ChannelHandler handler) throws RemotingException &#123; return new MinaClient(url, handler); &#125;&#125; MinaTransporter 实现了 Transporter 扩展接口，关于 Transporter 扩展接口已经在 远程通信模块总览 中进行了介绍，默认扩展实现是 netty 即 Netty3 实现。bind() 和 connect() 方法分别用于创建 MinaServer 和 MinaClient 对象。一般 Transport 扩展实现会由 Transport 的门面 Transports 统一向上层提供，这个上层就是 Exchange 信息交互层。下面我们继续分析 MinaTransporter 创建的服务器和客户端。 MinaServer属性12345678910111213public class MinaServer extends AbstractServer &#123; private static final Logger logger = LoggerFactory.getLogger(MinaServer.class); /** * 用于同客户端建立连接 */ private SocketAcceptor acceptor; public MinaServer(URL url, ChannelHandler handler) throws RemotingException &#123; super(url, ChannelHandlers.wrap(handler, ExecutorUtil.setThreadName(url, SERVER_THREAD_POOL_NAME))); &#125;&#125; MinaServer 继承了 AbstractServer 抽象服务类，是 Mina 服务实现类。MinaServer 通过层层继承拥有了很多类的职能，如 端点（Endpoint）、通道处理（ChannelHandler）、(服务端)Server ，其中间接关联了 ChannelHandler（AbstractPeer中的属性）和 Codec2（AbstractEndpoint中的）对象 。剩下的不再说明，和 Netty4 实现一致。 启动服务方法 doOpen1234567891011121314@Override protected void doOpen() throws Throwable &#123; // set thread pool. acceptor = new SocketAcceptor(getUrl().getPositiveParameter(Constants.IO_THREADS_KEY, Constants.DEFAULT_IO_THREADS), Executors.newCachedThreadPool(new NamedThreadFactory(\"MinaServerWorker\", true))); // 配置项 SocketAcceptorConfig cfg = acceptor.getDefaultConfig(); cfg.setThreadModel(ThreadModel.MANUAL); //编写过滤器链，通过过滤器执行编解码器 acceptor.getFilterChain().addLast(\"codec\", new ProtocolCodecFilter(new MinaCodecAdapter(getCodec(), getUrl(), this))); // 绑定端口，并设置 handler acceptor.bind(getBindAddress(), new MinaHandler(getUrl(), this)); &#125; 启动服务的方法是父类的一个模版方法，代码实现是 Mina 的标准化流程。简单概括下： 创建 SocketAcceptor 对象，URL 对象从父类 AbstractPeer 中获取。 设置 Mina 服务的配置项。 设置 Mina 的过滤器，在 Mina 中编解码器是通过过滤器职能实现的，Mina 的过滤器对 Codec2 实现进行了封装。 设置处理，绑定端口，启动服务 除了标准化流程不同外，其它方面都和 NettyServer 一致，都需要把 Codec2 编解码器和通道处理器 ChannelHandler 关联到服务上。 关闭服务 doClose1234567891011@Override protected void doClose() throws Throwable &#123; try &#123; if (acceptor != null) &#123; // 解绑端口，关闭服务 acceptor.unbind(getBindAddress()); &#125; &#125; catch (Throwable e) &#123; logger.warn(e.getMessage(), e); &#125; &#125; NettyServer 关闭时需要考虑到多个对象，如服务 Channel、客户端连接到服务的Channel、以及循环线程组。 MinaServer 只需要考虑关闭 SocketAcceptor 对象即可。 获取客户端通道1234567891011121314@Override public Collection&lt;Channel&gt; getChannels() &#123; // 获取Mina 连接集合 Set&lt;IoSession&gt; sessions = acceptor.getManagedSessions(getBindAddress()); Collection&lt;Channel&gt; channels = new HashSet&lt;Channel&gt;(); for (IoSession session : sessions) &#123; // 连接处于连接状态 if (session.isConnected()) &#123; // 获取Mina 连接对应的 Dubbo MinaChannel channels.add(MinaChannel.getOrAddChannel(session, getUrl(), this)); &#125; &#125; return channels; &#125; 和 NettyServer 类似，都需要获取处于连接状态的通道，最终映射到 Dubbo 层面的通道 MinaChannel。 是否启动成功123456789/** * 服务是否启动 * * @return */ @Override public boolean isBound() &#123; return acceptor.isManaged(getBindAddress()); &#125; 调用 Mina API 判断服务是否开启，和 NettyServer 类似。 MinaChannelMinaChannel 继承了 AbstractChannel 抽象类，是对 org.apache.mina.common.IoSession 的装饰，使用了装饰者模式，与 IoSession 是一对一的关系，这一点和 NettyChannel 一致。 属性1234567891011121314151617181920212223final class MinaChannel extends AbstractChannel &#123; private static final Logger logger = LoggerFactory.getLogger(MinaChannel.class); /** * IoSession 存储数据的key，value 是 MinaChannel 对象 */ private static final String CHANNEL_KEY = MinaChannel.class.getName() + \".CHANNEL\"; /** * 对底层连接的封装（服务器与客户端的特定连接） */ private final IoSession session; // 私有构造方法 private MinaChannel(IoSession session, URL url, ChannelHandler handler) &#123; super(url, handler); if (session == null) &#123; throw new IllegalArgumentException(\"mina session == null\"); &#125; this.session = session; &#125;&#125; MinaChannel 和 NettyChannel 有所不同，MinaChannel 内部装饰的 Mina 的连接 IoSession 直接存储数据，将对应的 MinaChannel 存储到 IoSession 中，而 NettyChannel 采用单独使用集合处理的方式。同样的，获取 MinaChannel 只能通过内部方法创建。 核心方法创建/获取 MinaChannel1234567891011121314151617181920static MinaChannel getOrAddChannel(IoSession session, URL url, ChannelHandler handler) &#123; if (session == null) &#123; return null; &#125; // IoSession 中取出对应的 MinaChannel 对象 MinaChannel ret = (MinaChannel) session.getAttribute(CHANNEL_KEY); if (ret == null) &#123; // 创建 MinaChannel 对象 ret = new MinaChannel(session, url, handler); // 判断连接是处于连接中 if (session.isConnected()) &#123; MinaChannel old = (MinaChannel) session.setAttribute(CHANNEL_KEY, ret); if (old != null) &#123; session.setAttribute(CHANNEL_KEY, old); ret = old; &#125; &#125; &#125; return ret; &#125; 和 NettyChannel 类似，都是使用NIO的连接作为映射的标识，getOrAddChannel() 方法不仅创建了 MinaChannel，也设置了 AbstractPeer 类中的 ChannelHandler 和 URL 属性的值，这意味着 AbstractPeer 当前子类对象关联了这两个属性的值。 发送消息该方法是 Endpoint 接口中的方法，并非 Channel 接口中的方法，Channel接口没有发送消息的方法。它会通过装饰的 Mina 框架的 IoSession 将数据发送到对端，并且支持等待发送完成。 123456789101112131415161718192021222324@Override public void send(Object message, boolean sent) throws RemotingException &#123; // 检查连接是否可用 super.send(message, sent); boolean success = true; int timeout = 0; try &#123; // 通过 IoSession 发送消息到对端 WriteFuture future = session.write(message); // 支持等待消息发送成功或者超时 if (sent) &#123; timeout = getUrl().getPositiveParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT); success = future.join(timeout); &#125; &#125; catch (Throwable e) &#123; throw new RemotingException(this, \"Failed to send message \" + message + \" to \" + getRemoteAddress() + \", cause: \" + e.getMessage(), e); &#125; if (!success) &#123; throw new RemotingException(this, \"Failed to send message \" + message + \" to \" + getRemoteAddress() + \"in timeout(\" + timeout + \"ms) limit\"); &#125; &#125; 操作附加属性12345678910111213141516171819@Override public boolean hasAttribute(String key) &#123; return session.containsAttribute(key); &#125; @Override public Object getAttribute(String key) &#123; return session.getAttribute(key); &#125; @Override public void setAttribute(String key, Object value) &#123; session.setAttribute(key, value); &#125; @Override public void removeAttribute(String key) &#123; session.removeAttribute(key); &#125; MinaChannel 使用了 IoSession 直接操作附加属性，而 NettyChannel 维护了一个集合来存放附加属性。 关闭连接12345678910111213141516171819202122232425@Override public void close() &#123; try &#123; // 标记连接关闭 super.close(); &#125; catch (Exception e) &#123; logger.warn(e.getMessage(), e); &#125; try &#123; // 移除处于断开连接的连接对应的 MinaChanenl removeChannelIfDisconnected(session); &#125; catch (Exception e) &#123; logger.warn(e.getMessage(), e); &#125; try &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"CLose mina channel \" + session); &#125; // 关闭 Mina 连接 session.close(); &#125; catch (Exception e) &#123; logger.warn(e.getMessage(), e); &#125; &#125; 和 NettyChannel 逻辑一致。 清理 MinaChannel123456static void removeChannelIfDisconnected(IoSession session) &#123; if (session != null &amp;&amp; !session.isConnected()) &#123; // 直接使用 Mina API 移除 session.removeAttribute(CHANNEL_KEY); &#125; &#125; 获取地址123456789@Override public InetSocketAddress getLocalAddress() &#123; return (InetSocketAddress) session.getLocalAddress(); &#125; @Override public InetSocketAddress getRemoteAddress() &#123; return (InetSocketAddress) session.getRemoteAddress(); &#125; 和 NettyChannel 类似，都是使用各自NIO库API 获取对应的地址。 编解码通过前文的 UML 关系图以及 MinaServer 启动服务方法，我们不难看出 MinaCodecAdapter 充当适配器角色，严格来说属于对象适配器模式，即 将 Dubbo 的 Codec2 编解码器适配成 Mina 层面的编码器和解码器，Mina 会把编解码工作委托给 Dubbo 的 Codec2 编解码器去处理。相关关系如下图所示： 在 网络传输层 中已经详细介绍过了 AbstractEndpoint 抽象类，该抽象类中的 codec 属性正是 Codec2 类型，该属性在 AbstractEndpoint 构造方法中被初始化，而 MinaServer 间接继承了 AbstractEndpoint 抽象类，在创建 MinaServer 对象时该编解码属性也进行了初始化。 属性12345678910111213141516171819202122232425262728293031323334353637383940414243final class MinaCodecAdapter implements ProtocolCodecFactory &#123; /** * Mina 编码器 */ private final ProtocolEncoder encoder = new InternalEncoder(); /** * Mina 解码器 */ private final ProtocolDecoder decoder = new InternalDecoder(); /** * 关联的 Dubbo Codec2 */ private final Codec2 codec; /** * url */ private final URL url; /** * 关联的 ChannelHandler */ private final ChannelHandler handler; private final int bufferSize; public MinaCodecAdapter(Codec2 codec, URL url, ChannelHandler handler) &#123; this.codec = codec; this.url = url; this.handler = handler; int b = url.getPositiveParameter(Constants.BUFFER_KEY, Constants.DEFAULT_BUFFER_SIZE); this.bufferSize = b &gt;= Constants.MIN_BUFFER_SIZE &amp;&amp; b &lt;= Constants.MAX_BUFFER_SIZE ? b : Constants.DEFAULT_BUFFER_SIZE; &#125; @Override public ProtocolEncoder getEncoder() &#123; return encoder; &#125; @Override public ProtocolDecoder getDecoder() &#123; return decoder; &#125;&#125; MinaCodecAdapter 和 NettyCodecAdapter 有一点差别，因为各自NIO库实现不同，MinaCodecAdapter 需要实现 Mina 的接口 ProtocolCodecFactory 。 编码器实现1234567891011121314151617181920212223/** * 实现Mina的编码器接口 ProtocolEncoder */ private class InternalEncoder implements ProtocolEncoder &#123; @Override public void dispose(IoSession session) throws Exception &#123; &#125; @Override public void encode(IoSession session, Object msg, ProtocolEncoderOutput out) throws Exception &#123; ChannelBuffer buffer = ChannelBuffers.dynamicBuffer(1024); MinaChannel channel = MinaChannel.getOrAddChannel(session, url, handler); try &#123; // 编码委托给 Codec2 实现去完成 codec.encode(channel, buffer, msg); &#125; finally &#123; MinaChannel.removeChannelIfDisconnected(session); &#125; out.write(ByteBuffer.wrap(buffer.toByteBuffer())); out.flush(); &#125; &#125; 解码器实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374/** * 实现Mina的解码器接口 ProtocolDecoder */ private class InternalDecoder implements ProtocolDecoder &#123; private ChannelBuffer buffer = ChannelBuffers.EMPTY_BUFFER; @Override public void decode(IoSession session, ByteBuffer in, ProtocolDecoderOutput out) throws Exception &#123; int readable = in.limit(); if (readable &lt;= 0) return; ChannelBuffer frame; if (buffer.readable()) &#123; if (buffer instanceof DynamicChannelBuffer) &#123; buffer.writeBytes(in.buf()); frame = buffer; &#125; else &#123; int size = buffer.readableBytes() + in.remaining(); frame = ChannelBuffers.dynamicBuffer(size &gt; bufferSize ? size : bufferSize); frame.writeBytes(buffer, buffer.readableBytes()); frame.writeBytes(in.buf()); &#125; &#125; else &#123; frame = ChannelBuffers.wrappedBuffer(in.buf()); &#125; Channel channel = MinaChannel.getOrAddChannel(session, url, handler); Object msg; int savedReadIndex; try &#123; do &#123; savedReadIndex = frame.readerIndex(); try &#123; // 解码委托给 Codec2 实现 msg = codec.decode(channel, frame); &#125; catch (Exception e) &#123; buffer = ChannelBuffers.EMPTY_BUFFER; throw e; &#125; if (msg == Codec2.DecodeResult.NEED_MORE_INPUT) &#123; frame.readerIndex(savedReadIndex); break; &#125; else &#123; if (savedReadIndex == frame.readerIndex()) &#123; buffer = ChannelBuffers.EMPTY_BUFFER; throw new Exception(\"Decode without read data.\"); &#125; if (msg != null) &#123; out.write(msg); &#125; &#125; &#125; while (frame.readable()); &#125; finally &#123; if (frame.readable()) &#123; frame.discardReadBytes(); buffer = frame; &#125; else &#123; buffer = ChannelBuffers.EMPTY_BUFFER; &#125; MinaChannel.removeChannelIfDisconnected(session); &#125; &#125; @Override public void dispose(IoSession session) throws Exception &#123; &#125; @Override public void finishDecode(IoSession session, ProtocolDecoderOutput out) throws Exception &#123; &#125; &#125; MinaHandlerMinaHandler 继承了 org.apache.mina.common.IoHandlerAdapter ，这是 Mina 提供的处理请求或事件的处理类。 属性123456789101112131415161718public class MinaHandler extends IoHandlerAdapter &#123; private final URL url; // Dubbo ChannelHandler。MinaHandler 中几乎所有方法都会触发该对象。 private final ChannelHandler handler; public MinaHandler(URL url, ChannelHandler handler) &#123; if (url == null) &#123; throw new IllegalArgumentException(\"url == null\"); &#125; if (handler == null) &#123; throw new IllegalArgumentException(\"handler == null\"); &#125; this.url = url; this.handler = handler; &#125;&#125; 请求或事件处理方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485//--------- MinaHandler 中以下所有方法都会触发装饰的 ChannelHandler 对象 ------------/ /** * 连接服务 * * @param session 客户端与服务器的通道 * @throws Exception */ @Override public void sessionOpened(IoSession session) throws Exception &#123; MinaChannel channel = MinaChannel.getOrAddChannel(session, url, handler); try &#123; handler.connected(channel); &#125; finally &#123; MinaChannel.removeChannelIfDisconnected(session); &#125; &#125; /** * 断开连接 * * @param session 客户端与服务器的通道 * @throws Exception */ @Override public void sessionClosed(IoSession session) throws Exception &#123; MinaChannel channel = MinaChannel.getOrAddChannel(session, url, handler); try &#123; handler.disconnected(channel); &#125; finally &#123; MinaChannel.removeChannelIfDisconnected(session); &#125; &#125; /** * 接收消息 * * @param session 客户端与服务器的通道 * @param message 消息 * @throws Exception */ @Override public void messageReceived(IoSession session, Object message) throws Exception &#123; MinaChannel channel = MinaChannel.getOrAddChannel(session, url, handler); try &#123; handler.received(channel, message); &#125; finally &#123; MinaChannel.removeChannelIfDisconnected(session); &#125; &#125; /** * 发送消息 * * @param session 客户端与服务器的通道 * @param message 消息 * @throws Exception */ @Override public void messageSent(IoSession session, Object message) throws Exception &#123; MinaChannel channel = MinaChannel.getOrAddChannel(session, url, handler); try &#123; handler.sent(channel, message); &#125; finally &#123; MinaChannel.removeChannelIfDisconnected(session); &#125; &#125; /** * 异常处理 * * @param session 客户端与服务器的通道 * @param cause * @throws Exception */ @Override public void exceptionCaught(IoSession session, Throwable cause) throws Exception &#123; MinaChannel channel = MinaChannel.getOrAddChannel(session, url, handler); try &#123; handler.caught(channel, cause); &#125; finally &#123; MinaChannel.removeChannelIfDisconnected(session); &#125; &#125; MinaServer &amp; MinaHandler在 MinaServer 创建 MinaHandler 代码如下： 123// 绑定端口，并设置 handler// MinaHandler 构造方法第二个参数是 MinaServer 本身acceptor.bind(getBindAddress(), new MinaHandler(getUrl(), this)); 第一个参数是调用间接父类 AbstractPeer#getUrl() 方法获取上层传入的 URL对象。第二个参数正是 MinaServer 对象本身，通过之前的介绍，我们知道 MinaServer 继承关系，它的父类 AbstractPeer 实现了 ChannelHandler 接口，并且将所有方法都委托给了其装饰的 ChannelHandler 对象。因此，MinaHandler 中的通道方法都是交给 MinaServer 关联的 ChannelHandler 对象本身。 MinaClientMinaClient 是基于 Mina 实现的客户端，下面我们对它的属性、构造方法以及基本方法进行详细说明。 属性1234567891011121314151617181920212223242526public class MinaClient extends AbstractClient &#123; private static final Logger logger = LoggerFactory.getLogger(MinaClient.class); /** * SocketConnector 缓存 * key: URL 串 * value: SocketConnector 对象 */ private static final Map&lt;String, SocketConnector&gt; connectors = new ConcurrentHashMap&lt;String, SocketConnector&gt;(); /** * 缓存 key */ private String connectorKey; /** * 用于连接Mina服务 */ private SocketConnector connector; /** * 对底层连接的封装（服务器与客户端的特定连接） */ private volatile IoSession session;&#125; 构造方法1234public MinaClient(final URL url, final ChannelHandler handler) throws RemotingException &#123; // wrapChannelHandler方法用于包装ChannelHandler，其中实现了 Dubbo 线程模型的功能。 super(url, wrapChannelHandler(url, handler)); &#125; 和 NettyClient 本质一摸一样，不再说明。 启动客户端 doOpen1234567891011121314151617181920212223@Override protected void doOpen() throws Throwable &#123; // URL 串 connectorKey = getUrl().toFullString(); SocketConnector c = connectors.get(connectorKey); if (c != null) &#123; connector = c; &#125; else &#123; // set thread pool. connector = new SocketConnector(Constants.DEFAULT_IO_THREADS, Executors.newCachedThreadPool(new NamedThreadFactory(\"MinaClientWorker\", true))); // config SocketConnectorConfig cfg = (SocketConnectorConfig) connector.getDefaultConfig(); cfg.setThreadModel(ThreadModel.MANUAL); cfg.getSessionConfig().setTcpNoDelay(true); cfg.getSessionConfig().setKeepAlive(true); int timeout = getConnectTimeout(); cfg.setConnectTimeout(timeout &lt; 1000 ? 1 : timeout / 1000); // set codec. 编解码器支持 connector.getFilterChain().addLast(\"codec\", new ProtocolCodecFilter(new MinaCodecAdapter(getCodec(), getUrl(), this))); connectors.put(connectorKey, connector); &#125; &#125; 连接服务器 doConnect12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667@Override protected void doConnect() throws Throwable &#123; // 根据服务地址连接服务 ConnectFuture future = connector.connect(getConnectAddress(), new MinaHandler(getUrl(), this)); long start = System.currentTimeMillis(); final AtomicReference&lt;Throwable&gt; exception = new AtomicReference&lt;Throwable&gt;(); final CountDownLatch finish = new CountDownLatch(1); // resolve future.awaitUninterruptibly() dead lock // 添加监听器 future.addListener(new IoFutureListener() &#123; @Override public void operationComplete(IoFuture future) &#123; try &#123; // 服务准备好了 if (future.isReady()) &#123; // 获取连接通道 IoSession newSession = future.getSession(); try &#123; // Close old channel 对旧的通道处理 IoSession oldSession = MinaClient.this.session; // copy reference if (oldSession != null) &#123; try &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Close old mina channel \" + oldSession + \" on create new mina channel \" + newSession); &#125; oldSession.close(); &#125; finally &#123; MinaChannel.removeChannelIfDisconnected(oldSession); &#125; &#125; &#125; finally &#123; // 如果关闭 if (MinaClient.this.isClosed()) &#123; try &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Close new mina channel \" + newSession + \", because the client closed.\"); &#125; newSession.close(); &#125; finally &#123; MinaClient.this.session = null; MinaChannel.removeChannelIfDisconnected(newSession); &#125; &#125; else &#123; MinaClient.this.session = newSession; &#125; &#125; &#125; &#125; catch (Exception e) &#123; exception.set(e); &#125; finally &#123; finish.countDown(); &#125; &#125; &#125;); try &#123; finish.await(getConnectTimeout(), TimeUnit.MILLISECONDS); &#125; catch (InterruptedException e) &#123; throw new RemotingException(this, \"client(url: \" + getUrl() + \") failed to connect to server \" + getRemoteAddress() + \" client-side timeout \" + getConnectTimeout() + \"ms (elapsed: \" + (System.currentTimeMillis() - start) + \"ms) from netty client \" + NetUtils.getLocalHost() + \" using dubbo version \" + Version.getVersion() + \", cause: \" + e.getMessage(), e); &#125; Throwable e = exception.get(); if (e != null) &#123; throw e; &#125; &#125; 连接服务流程和 NettyClient 一致。 断开连接 doDisConnect123456789@Override protected void doDisConnect() throws Throwable &#123; try &#123; // 直接使用 Mina API 移除关闭的通道 MinaChannel.removeChannelIfDisconnected(session); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage()); &#125; &#125; 断开连接仅仅是在客户端连接服务的通道处于关闭状态时，把对应的通道缓存清除。 获取连接到服务的通道 getChannel12345678@Override protected Channel getChannel() &#123; IoSession s = session; if (s == null || !s.isConnected()) &#123; return null; &#125; return MinaChannel.getOrAddChannel(s, getUrl(), this); &#125; 获取连接到服务的通道是父类的模版方法，用于返回具体NIO的通道对应的 Dubbo 通道，这里是返回Mina的通道对应的Dubbo 层面的MinaChanel 。 小结无论是 远程通信模块总览 ，还是 网络传输层 都是为具体实现服务的，具体实现依赖上层抽象，在 Mina 这个 NIO 框架的实现角度来看依赖的上层（dubbo-remoting-api）是透明的即通用的逻辑模版。整个 Transport 层相关的核心继承关系如下图： 至此，Dubbo 接入 Mina 实现网络通信就介绍完了，其实这篇文章是对 Netty4网络通信 的删剪版，为什么接入Netty库和接入Mina库实现起来的差异如此之小，我们可以发现两者的流程基本一致，如果非要说区别那就是两者的 API 和实现机制不同。这得益于 Dubbo 的优秀设计，它把 NIO库的共性全都进行了抽象，进而屏蔽不同 NIO 库之间的差异，扩展性大大增强。包括没有介绍到的 dubbo-remoting-grizzly 模块，实现模式也是一样的。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"Mina","slug":"Mina","permalink":"https://gentryhuang.com/tags/Mina/"}]},{"title":"Dubbo源码分析 - Netty4网络通信","slug":"rpc/Netty4实现","date":"2020-05-29T16:00:00.000Z","updated":"2020-12-01T01:45:15.786Z","comments":false,"path":"posts/4468445c/","link":"","permalink":"https://gentryhuang.com/posts/4468445c/","excerpt":"","text":"前言在 网络传输层 中对 Transport 通用层或者说是抽象层进行了详细分析。接下来会继续分析 Transport 层的 NIO库实现，本篇文章将分析 Dubbo 如何将 Neety4 接入实现。 概述在 NIO 库的选型上，有很多优秀的开源框架，如 Netty、Mina、Grizzy 等，Dubbo 的选择是分别对这些框架进行集成。对上层进行抽象以屏蔽不同 NIO 库的差异，抽象对应的模块是 dubbo-remoting-api，在 远程通信模块总览 中介绍了核心的接口和类。针对每一个 NIO 框架的接入，Dubbo 都构建一个单独的模块，该模块只需实现抽象模块 dubbo-remoting-api 即可，结合 Dubbo SPI 机制可以灵活切换到不同的 NIO 库。下面我们开始介绍实现层 dubbo-remoting-netty4 模块，代码结构如下： 上面的代码结构诠释了 “麻雀虽小五脏俱全”，作为一个通信框架该有的基本元素都具备了。注意，在当前分析的 Dubbo 版本中默认使用的是 Netty3 实现，考虑到现在主流 Netty4 而且 Dubbo 最新版本已经默认切换成了 Netty4 实现，另一方面 Netty3 接入和 Netty4 基本一致，因此就不再分析 Netty3 实现。 通过下面的 UML 图会更加清晰看到 Netty4 实现中各个功能类之间的关联关系。下面我们就根据 UML 图的依赖关系逐个分析。 NettyTransporter1234567891011121314151617181920212223242526272829303132public class NettyTransporter implements Transporter &#123; /** * 拓展名 */ public static final String NAME = \"netty4\"; /** * 绑定一个服务器 * * @param url 服务器地址 * @param listener 通道处理器 * @return server 返回服务器 * @throws RemotingException */ @Override public Server bind(URL url, ChannelHandler listener) throws RemotingException &#123; return new NettyServer(url, listener); &#125; /** * 连接一个服务器，即创建一个客户端 * * @param url 服务器地址 * @param listener 通道处理器 * @return client 客户端 * @throws RemotingException */ @Override public Client connect(URL url, ChannelHandler listener) throws RemotingException &#123; return new NettyClient(url, listener); &#125;&#125; NettyTransporter 实现了 Transporter 扩展接口，关于 Transporter 扩展接口已经在 远程通信模块总览 中进行了介绍，默认扩展实现是 netty 即 Netty3 实现。bind() 和 connect() 方法分别用于创建 NettyServer 和 NettyClient 对象。一般 Transport 扩展实现会由 Transport 的门面 Transports 统一向上层提供，这个上层就是 Exchange 信息交互层。下面我们继续分析 NettyTransporter 创建的服务和客户端。 NettyServerNettyServer 是基于 Netty4 实现的服务，下面我们对它的属性、构造方法以及基本方法进行详细说明。 属性123456789101112131415161718192021222324252627282930public class NettyServer extends AbstractServer implements Server &#123; private static final Logger logger = LoggerFactory.getLogger(NettyServer.class); /** * 通道集合,这里是连接到服务器的客户端通道集合 * key: ip:port * value: Dubbo 的 Channel */ private Map&lt;String, Channel&gt; channels; /** * Netty 服务端的引导类 */ private ServerBootstrap bootstrap; /** * Netty 的 Channel */ private io.netty.channel.Channel channel; /** * boss 线程组 */ private EventLoopGroup bossGroup; /** * worker 线程组 */ private EventLoopGroup workerGroup;&#125; NettyServer 继承了 AbstractServer，并实现了 Server 接口，是 Netty 服务实现类。NettyServer 通过层层继承拥有了很多类的职能，如 端点（Endpoint）、通道处理（ChannelHandler）、(服务端)Server ，其中间接关联了 ChannelHandler（AbstractPeer中的属性）和 Codec2（AbstractEndpoint中的）对象 。 构造方法1234567891011121314public class NettyServer extends AbstractServer implements Server &#123; /** * 创建 NettyServer 时，会对传入的 ChannelHandler 进行层层包装。 * 其中在包装过程中， Dispatcher创建的ChanglHandler的过程都要创建一个线程池，然后保存到Datasource 中。 todo 2.7.7 对次做了优化 * * @param url * @param handler * @throws RemotingException */ public NettyServer(URL url, ChannelHandler handler) throws RemotingException &#123; // ChannelHandlers.wrap方法，用来包装 ChannelHandler，实现Dubbo 线程模型的功能。 SERVER_THREAD_POOL_NAME -&gt; 'DubboServerHandler' super(url, ChannelHandlers.wrap(handler, ExecutorUtil.setThreadName(url, SERVER_THREAD_POOL_NAME))); &#125;&#125; NettyServer 的构造方法主要两个工作，但这两个工作信息量非常大。对上层传入的 ChannelHandler 进行包装，调用父类 AbstractServer 的构造方法。包装 ChannelHandler 的方法在 网络传输层 中已经详细说明，会自动为传入的 ChannelHandler 外面包裹三层 ChannelHandler，即 MultiMessageHandler(HeartbeatHandler(线程模型Handler(传入的ChannelHandler))) ，其中线程模型Handler默认为 AllChannelHandler，线程模型Handler进行创建的时候会初始化线程池并存放到 DataSource 中（是父类 WrappedChannelHandler 的职能） 。下面对这两件事整体概括： 对传入的 ChannelHandler 进行包装，最终得到一个增强的 ChannelHandler。注意，它不再是传入进来的 ChannelHandler 。 执行 super(URL,ChannelHandler) ，调用父类 AbstractServer 的构造方法。 将增强后的 ChannelHandler 和 上层传入的 URL 通过父类构造方法层层向下传递，直到 AbstractPeer 抽象类，该类将 ChannelHandler 和 URL 保存起来。 第 3 步向上调用父类构造方法时，执行到 AbstractEndpoint 抽象类时，会通过传递的 URL 获取 Codec2 的扩展实现类以及超时时间和连接超时时间。 执行到 AbstractServer 构造方法时，分别获取服务地址、绑定地址、最大可接受连接数、空闲超时时间以及从 DataSource 中获取当前服务端口对应的线程池。 第 5 步还有最重要的一个过程，调用模版方法启动服务，而这个模版方法每个子类服务都会进行实现，这里就是 NettyServer 的 doOpen 方法。 NettyServer 构造方法中 ExecutorUtil.setThreadName(url, SERVER_THREAD_POOL_NAME) 方法用于设置线程名到 URL 参数中，该个线程名包含 URL 的地址信息，代码如下： 12345678--- ExecutorUtil public static URL setThreadName(URL url, String defaultName) &#123; // 从URL中获取 threadname 的值作为线程名，没有就使用defaultName String name = url.getParameter(Constants.THREAD_NAME_KEY, defaultName); name = name + \"-\" + url.getAddress(); url = url.addParameter(Constants.THREAD_NAME_KEY, name); return url; &#125; 启动服务方法 doOpen12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758--- NettyServer /** * 启动服务器 * * @throws Throwable */ @Override protected void doOpen() throws Throwable &#123; // 创建引导类 bootstrap = new ServerBootstrap(); // 分别创建Boss线程组和Worker线程组 bossGroup = new NioEventLoopGroup(1, new DefaultThreadFactory(\"NettyServerBoss\", true)); workerGroup = new NioEventLoopGroup(getUrl().getPositiveParameter(Constants.IO_THREADS_KEY, Constants.DEFAULT_IO_THREADS), new DefaultThreadFactory(\"NettyServerWorker\", true)); // 创建NettyServerHandler对象，注意传入的第二个参数是 NettyServer 对象本身，因为NettyServer是ChannelHander的子类。 // 由于 NettyServerHandler 继承了 ChannelDuplexHandler，因此它是 Netty 层面的 ChannelHanlder。 final NettyServerHandler nettyServerHandler = new NettyServerHandler(getUrl(), this); // 获取当前NettyServer创建的所有Channel channels = nettyServerHandler.getChannels(); bootstrap // 设置线程组 .group(bossGroup, workerGroup) // 服务端使用NioServerSocketChannel 作为传输通道 .channel(NioServerSocketChannel.class) // 配置可选项，Netty 优化相关 .childOption(ChannelOption.TCP_NODELAY, Boolean.TRUE) .childOption(ChannelOption.SO_REUSEADDR, Boolean.TRUE) .childOption(ChannelOption.ALLOCATOR, PooledByteBufAllocator.DEFAULT) // 设置出入站通道处理器链 .childHandler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123; @Override protected void initChannel(NioSocketChannel ch) throws Exception &#123; // 创建编解码适配器,NettyCodecAdapter中会创建Decoder和Encoder NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec(), getUrl(), NettyServer.this); // ChannelPipeline ch.pipeline() //.addLast(\"logging\",new LoggingHandler(LogLevel.INFO)) // 打印日志，方便debug // 注册解码器 .addLast(\"decoder\", adapter.getDecoder()) // 注册编码器 .addLast(\"encoder\", adapter.getEncoder()) // 注册NettyServerHandler .addLast(\"handler\", nettyServerHandler); &#125; &#125;); // 服务器绑定指定地址和端口 ，启动 Netty ChannelFuture channelFuture = bootstrap.bind(getBindAddress()); // 等待绑定完成 channelFuture.syncUninterruptibly(); // 获取服务通道，即用来接收客户端连接的 Channel channel = channelFuture.channel(); &#125; 启动服务的方法是父类的一个模版方法，该方法的信息量很大，从 Netty 角度看就是使用的标准化流程并没有什么特别的地方，但是从 Dubbo 的角度看涉及很多核心组件。下面对主要的过程进行概括： 初始化 ServerBootstrap 、创建 Boss 线程组和 Worker 线程组。 创建 Dubbo 层面的 NettyServerHandler 对象，因其继承了 ChannelDuplexHandler 类，因此它又属于 Netty 层面的 ChannelHandler，这给出了一个非常重要的信息，那就是该对象有处理 Netty 通道消息或事件的能力。 获取 NettyServerHandler 中维护的 channels 缓存集合，该集合是 io.netty.channel.Channel.remoteAddress 到 Dubbo层面的 NettyChannel 的映射，而 NettyChannel 内部封装了 Netty的Channel，NettyChannel 和 Netty的Channel 是一一对应的关系。从代码中不难看出 NettyServer 和 NettyServerHandler 共用一个 channels 缓存集合。当有连接创建时，先是创建该Netty连接对应的Dubbo层面的NettyChannel（不存在的情况下），然后 channels 就会把该NettyChannel缓存起来。当有连接断开时，就根据当前Netty连接的 remoteAddress 从 channels 中移除对应的NettyChannel。 设置服务侧 Channel 类型为 NioServerSocketChannel，并设置一些可选项用来优化Netty。 创建 ChannelInitializer 并指定如何初始化 Channel 上的 ChannelHandler 等一系列 Netty 使用的标准化流程，其中注册了编解码器和 NettyServerHandler 对象。 在第 5 步中，会分别创建Netty的编码器和解码器，NettyCodecAdapter 只是一个适配对象，其两个内部类才是真正的 Netty 的编解码器。 下文会对该过程涉及的接口及实现类分别说明，接下来我们继续分析 NettyServer 中的方法，此后我们要时刻牢记 NettyServer 通过层层继承拥有了很多类的职能。 关闭服务方法 doClose1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253--- NettyServer /** * 关闭服务器 * * @throws Throwable */ @Override protected void doClose() throws Throwable &#123; try &#123; if (channel != null) &#123; // 关闭服务器通道 channel.close(); &#125; &#125; catch (Throwable e) &#123; logger.warn(e.getMessage(), e); &#125; // 关闭连接到服务器的客户端通道 try &#123; Collection&lt;com.alibaba.dubbo.remoting.Channel&gt; channels = getChannels(); if (channels != null &amp;&amp; channels.size() &gt; 0) &#123; // 依次遍历连接到服务器的客户端通道，然后进行关闭操作 for (com.alibaba.dubbo.remoting.Channel channel : channels) &#123; try &#123; channel.close(); &#125; catch (Throwable e) &#123; logger.warn(e.getMessage(), e); &#125; &#125; &#125; &#125; catch (Throwable e) &#123; logger.warn(e.getMessage(), e); &#125; // 优雅关闭线程组 try &#123; if (bootstrap != null) &#123; bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125; catch (Throwable e) &#123; logger.warn(e.getMessage(), e); &#125; // 清空连接到服务器的客户端通道 try &#123; if (channels != null) &#123; channels.clear(); &#125; &#125; catch (Throwable e) &#123; logger.warn(e.getMessage(), e); &#125; &#125; 关闭服务主要工作如下： 关闭服务通道 channel 关闭连接到服务的客户端通道集合们 关闭线程组 清空连接到服务的客户端通道缓存 获得客户端通道集合12345678910111213141516--- NettyServer @Override public Collection&lt;Channel&gt; getChannels() &#123; Collection&lt;Channel&gt; chs = new HashSet&lt;Channel&gt;(); for (Channel channel : this.channels.values()) &#123; // 已连接，则加入结果集 if (channel.isConnected()) &#123; chs.add(channel); // 未连接，移除 &#125; else &#123; channels.remove(NetUtils.toAddressString(channel.getRemoteAddress())); &#125; &#125; return chs; &#125; 以上代码用于获取连接到服务的客户端通道集合，注意只会筛选目前连接到服务的通道。 是否启动成功1234@Overridepublic boolean isBound() &#123; return channel.isActive();&#125; 调用 Netty API 判断服务通道是否开启。 NettyChannelNettyChannel 继承了 AbstractChannel，是对 io.netty.channel.Channel 的装饰，使用了装饰者模式，与 io.netty.channel.Channel 是一对一的关系。 属性123456789101112131415161718192021222324252627282930313233343536final class NettyChannel extends AbstractChannel &#123; private static final Logger logger = LoggerFactory.getLogger(NettyChannel.class); /** * Netty的Channel 到 Dubbo的Channel 映射集合 * key: Netty 的 Channel * value: NettyChannel */ private static final ConcurrentMap&lt;Channel, NettyChannel&gt; channelMap = new ConcurrentHashMap&lt;Channel, NettyChannel&gt;(); /** * Netty的Channel，和当前的 Dubbo Channel对象一一对应 */ private final Channel channel; /** * 当前Channel 中附加属性集合 */ private final Map&lt;String, Object&gt; attributes = new ConcurrentHashMap&lt;String, Object&gt;(); /** * 装饰 Netty的Channel * * @param channel Netty的Channel * @param url URL * @param handler handler */ private NettyChannel(Channel channel, URL url, ChannelHandler handler) &#123; super(url, handler); if (channel == null) &#123; throw new IllegalArgumentException(\"netty channel == null;\"); &#125; this.channel = channel; &#125;&#125; NettyChannel 中的属性已经详细标注，其中它的构造方法是私有的，调用入口只有一个，是该类内部方法 – getOrAddChannel() 。 核心方法创建 NettyChannel1234567891011121314151617181920--- NettyChannel static NettyChannel getOrAddChannel(Channel ch, URL url, ChannelHandler handler) &#123; if (ch == null) &#123; return null; &#125; NettyChannel ret = channelMap.get(ch); if (ret == null) &#123; // 创建 NettyChannel，封装 Netty的 Channel NettyChannel nettyChannel = new NettyChannel(ch, url, handler); // 处于连接中 if (ch.isActive()) &#123; // 添加到 通道集合缓存中 ret = channelMap.putIfAbsent(ch, nettyChannel); &#125; if (ret == null) &#123; ret = nettyChannel; &#125; &#125; return ret; &#125; 优先从缓存中找，找不到则创建 NettyChannel 对象，NettyChannel 对象封装了 io.netty.channel.Channel 对象、传入的 ChannelHandler 和 URL，如果封装的 Netty 通道是连接状态，则加入缓存。需要特别说明的是，NettyChannel 继承了 AbstractChannel，而 AbstractChannel 又继承了 AbstractPeer 抽象类，在 网络传输层 中已经详细介绍过了AbstractPeer 抽象类，它是整个 Remoting 层链路最底层，上层传入的 ChannelHandler 会最终保存在该类中。因此，getOrAddChannel() 方法不仅创建了 NettyChannel，也设置了 AbstractPeer 类中的 ChannelHandler 和 URL 属性的值，这意味着 AbstractPeer 当前子类对象关联了这两个属性的值。 发送消息该方法是 Endpoint 接口中的方法，并非 Channel 接口中的方法，Channel接口没有发送消息的方法。它会通过装饰的 Netty 框架 Channel 将数据发送到对端，并且支持等待发送完成。 12345678910111213141516171819202122232425262728293031323334--- NettyChannel @Override public void send(Object message, boolean sent) throws RemotingException &#123; // 检查连接是否可用 super.send(message, sent); // 是否执行成功。 如果不需要等待发送成功（sent = false），默认就是成功状态 boolean success = true; int timeout = 0; try &#123; // 使用Netty 的 Channel 发送消息 ChannelFuture future = channel.writeAndFlush(message); // 为true的话，会等待消息发送成功或者超时 if (sent) &#123; timeout = getUrl().getPositiveParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT); success = future.await(timeout); &#125; // 发生异常就抛出 Throwable cause = future.cause(); if (cause != null) &#123; throw cause; &#125; &#125; catch (Throwable e) &#123; throw new RemotingException(this, \"Failed to send message \" + message + \" to \" + getRemoteAddress() + \", cause: \" + e.getMessage(), e); &#125; // 发送失败，抛出异常 if (!success) &#123; throw new RemotingException(this, \"Failed to send message \" + message + \" to \" + getRemoteAddress() + \"in timeout(\" + timeout + \"ms) limit\"); &#125; &#125; 操作通道附加属性123456789101112131415161718192021222324--- NettyChannel @Override public boolean hasAttribute(String key) &#123; return attributes.containsKey(key); &#125; @Override public Object getAttribute(String key) &#123; return attributes.get(key); &#125; @Override public void setAttribute(String key, Object value) &#123; if (value == null) &#123; // The null value unallowed in the ConcurrentHashMap. attributes.remove(key); &#125; else &#123; attributes.put(key, value); &#125; &#125; @Override public void removeAttribute(String key) &#123; attributes.remove(key); &#125; 关闭通道123456789101112131415161718192021222324252627282930313233--- NettyChannel @Override public void close() &#123; try &#123; // 标记关闭 ，设置 com.alibaba.dubbo.remoting.transport.AbstractPeer.closed 的值为 true super.close(); &#125; catch (Exception e) &#123; logger.warn(e.getMessage(), e); &#125; try &#123; // 移除断开连接的Channel对应的Dubbo NettyChannel removeChannelIfDisconnected(channel); &#125; catch (Exception e) &#123; logger.warn(e.getMessage(), e); &#125; try &#123; // 清空属性 attributes attributes.clear(); &#125; catch (Exception e) &#123; logger.warn(e.getMessage(), e); &#125; try &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Close netty channel \" + channel); &#125; // 关闭Netty 的 Channel，注意在关闭前对一些其它资源进行清理工作。 channel.close(); &#125; catch (Exception e) &#123; logger.warn(e.getMessage(), e); &#125; &#125; 清理 NettyChannel 缓存123456static void removeChannelIfDisconnected(Channel ch) &#123; // Netty的Channel 未连接 if (ch != null &amp;&amp; !ch.isActive()) &#123; channelMap.remove(ch); &#125; &#125; 获取地址12345678910111213141516171819/** * 获取本机地址 - Endpoint 接口中的方法 * * @return */ @Override public InetSocketAddress getLocalAddress() &#123; return (InetSocketAddress) channel.localAddress(); &#125; /** * 获取远程地址 - Channel 接口中的方法 * * @return */ @Override public InetSocketAddress getRemoteAddress() &#123; return (InetSocketAddress) channel.remoteAddress(); &#125; 编解码通过前文的 UML 关系图以及 NettyServer 启动服务方法，我们不难看出 NettyCodecAdapter 充当适配器角色，严格来说属于对象适配器模式，即 将 Dubbo 的 Codec2 编解码器适配成 Netty 层面的编码器和解码器，Netty 会把编解码工作委托给 Dubbo 的 Codec2 编解码器去处理。相关关系如下图所示： 在 网络传输层 中已经详细介绍过了 AbstractEndpoint 抽象类，该抽象类中的 codec 属性正是 Codec2 类型，该属性在 AbstractEndpoint 构造方法中被初始化，而 NettyServer 间接继承了 AbstractEndpoint 抽象类，在创建 NettyServer 对象时该编解码属性也进行了初始化。 属性及方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152final class NettyCodecAdapter &#123; /** * Netty 的 编码器。内部封装的Codec2 ，是在 &#123;@link com.alibaba.dubbo.remoting.transport.AbstractEndpoint&#125; 中创建的 */ private final ChannelHandler encoder = new InternalEncoder(); /** * Netty 的 解码器。内部封装的Codec2 ，是在 &#123;@link com.alibaba.dubbo.remoting.transport.AbstractEndpoint&#125; 中创建的 */ private final ChannelHandler decoder = new InternalDecoder(); /** * Dubbo 的 编解码器 */ private final Codec2 codec; /** * Dubbo URL */ private final URL url; /** * Dubbo 的 ChannelHandler */ private final com.alibaba.dubbo.remoting.ChannelHandler handler; public NettyCodecAdapter(Codec2 codec, URL url, com.alibaba.dubbo.remoting.ChannelHandler handler) &#123; this.codec = codec; this.url = url; this.handler = handler; &#125; /** * 获取编码器 * * @return */ public ChannelHandler getEncoder() &#123; return encoder; &#125; /** * 获取解码器 * * @return */ public ChannelHandler getDecoder() &#123; return decoder; &#125;&#125; 编码器实现123456789101112131415161718192021222324252627282930--- NettyCodecAdapter /** * 编码器 - MessageToByteEncoder：编码器抽象类 */ private class InternalEncoder extends MessageToByteEncoder &#123; /** * @param ctx ChannelHandler 的上下文 * @param msg msg * @param out 缓冲区 * @throws Exception */ @Override protected void encode(ChannelHandlerContext ctx, Object msg, ByteBuf out) throws Exception &#123; // 创建 NettyBackedChannelBuffer com.alibaba.dubbo.remoting.buffer.ChannelBuffer buffer = new NettyBackedChannelBuffer(out); // 从当前ChannelHandlerContext中获取对应的 Channel 对象 // Channel : pipeline : ChannelHandler : ChannelHandlerContext = 1:1:n:n Channel ch = ctx.channel(); // 获取 Netty 通道对应的 Dubbo Channel NettyChannel channel = NettyChannel.getOrAddChannel(ch, url, handler); try &#123; // 编码，将解码任务委托给 Codec2 实现去完成 codec.encode(channel, buffer, msg); &#125; finally &#123; // 移除 Netty的Channel关联的缓存 NettyChannel.removeChannelIfDisconnected(ch); &#125; &#125; &#125; 解码器实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051--- NettyCodecAdapter /** * 解码器 - ByteToMessageDecoder： 解码器抽象类 */ private class InternalDecoder extends ByteToMessageDecoder &#123; @Override protected void decode(ChannelHandlerContext ctx, ByteBuf input, List&lt;Object&gt; out) throws Exception &#123; // 创建Dubbo 对 Netty 的缓存区封装的 NettyBackedChannelBuffer 对象 ChannelBuffer message = new NettyBackedChannelBuffer(input); // 获取 Netty 通道对应的 Dubbo Channel NettyChannel channel = NettyChannel.getOrAddChannel(ctx.channel(), url, handler); Object msg; int saveReaderIndex; try &#123; // 循环解析数据，直到结束 do &#123; // 记录当前读进度 saveReaderIndex = message.readerIndex(); try &#123; // 将解码任务委托给 Codec2 完成 msg = codec.decode(channel, message); &#125; catch (IOException e) &#123; throw e; &#125; // 需要更多的输入，即消息不完整，标记回原有读进度，并结束 if (msg == Codec2.DecodeResult.NEED_MORE_INPUT) &#123; message.readerIndex(saveReaderIndex); break; // 解码到消息，添加到 out集合中，即 将读取到的消息传递给后面的Handler处理 &#125; else &#123; //is it possible to go here ? todo if (saveReaderIndex == message.readerIndex()) &#123; throw new IOException(\"Decode without read data.\"); &#125; if (msg != null) &#123; out.add(msg); &#125; &#125; &#125; while (message.readable()); &#125; finally &#123; // 移除 Netty的Channel 关联的缓存 NettyChannel.removeChannelIfDisconnected(ctx.channel()); &#125; &#125; &#125;&#125; NettyServerHandlerNettyServerHandler 继承了 io.netty.channel.ChannelDuplexHandler ，这是 Netty 提供的一个同时处理入站数据和出站数据的 ChannelHandler ，作为 Netty4 的通道处理器。 属性12345678910111213141516171819202122232425262728293031@io.netty.channel.ChannelHandler.Sharablepublic class NettyServerHandler extends ChannelDuplexHandler &#123; /** * Dubbo Channel 集合,即连接到当前服务的Dubbo Channel集合 * key: Netty 通道的 remoteAddress * value: Dubbo 的 Channel */ private final Map&lt;String, Channel&gt; channels = new ConcurrentHashMap&lt;String, Channel&gt;(); /** * URL */ private final URL url; /** * Dubbo ChannelHandler。NettyServerHandler 中几乎所有方法都会触发该对象。 */ private final ChannelHandler handler; public NettyServerHandler(URL url, ChannelHandler handler) &#123; if (url == null) &#123; throw new IllegalArgumentException(\"url == null\"); &#125; if (handler == null) &#123; throw new IllegalArgumentException(\"handler == null\"); &#125; this.url = url; this.handler = handler; &#125;&#125; 在 NettyServerHandler 中有 channels、handler 以及 url 属性。下面分别说明对应属性： channels 属性：保存当前 Server 创建的所有 Dubbo Channel，连接创建、连接断开都会操作 channels 集合进行相应的增删。其中 ServerHandler 也会使用该属性值。 url 属性： 通过构造方法传入。 handler属性：通道处理器，是 NettyServer 对象。NettyServerHandler 中几乎所有方法都会触发该 ChannelHandler 对象。 通道处理方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108--- NettyServerHandler //--------- NettyServerHandler 中以下所有方法都会触发装饰的 ChannelHandler 对象 ------------/ /** * 连接创建触发该方法 * * @param ctx * @throws Exception */ @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; // 交给下一个节点处理 ctx.fireChannelActive(); // 创建Dubbo 的NettyChannel 对象 NettyChannel channel = NettyChannel.getOrAddChannel(ctx.channel(), url, handler); try &#123; // 加入到 连接到服务的 Dubbo Channel集合 中 if (channel != null) &#123; channels.put(NetUtils.toAddressString((InetSocketAddress) ctx.channel().remoteAddress()), channel); &#125; // 交给 handler 处理，处理连接事件 handler.connected(channel); &#125; finally &#123; /** 如果已经断开，就移除NettyChannel对象 &#123;@link com.alibaba.dubbo.remoting.transport.netty4.NettyChannel.channelMap &#125;*/ NettyChannel.removeChannelIfDisconnected(ctx.channel()); &#125; &#125; /** * 连接断开触发该方法 * * @param ctx * @throws Exception */ @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123; NettyChannel channel = NettyChannel.getOrAddChannel(ctx.channel(), url, handler); try &#123; // 从缓存中移除 Netty Channel 对应的 Dubbo Channel channels.remove(NetUtils.toAddressString((InetSocketAddress) ctx.channel().remoteAddress())); // 将断开连接事件交给 handler处理 handler.disconnected(channel); &#125; finally &#123; NettyChannel.removeChannelIfDisconnected(ctx.channel()); &#125; &#125; @Override public void disconnect(ChannelHandlerContext ctx, ChannelPromise future) throws Exception &#123; &#125; /** * 读取数据 * * @param ctx * @param msg * @throws Exception */ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; NettyChannel channel = NettyChannel.getOrAddChannel(ctx.channel(), url, handler); try &#123; handler.received(channel, msg); &#125; finally &#123; NettyChannel.removeChannelIfDisconnected(ctx.channel()); &#125; &#125; /** * 写入数据 * * @param ctx * @param msg * @param promise * @throws Exception */ @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception &#123; // 将发送的数据继续向下传递 super.write(ctx, msg, promise); NettyChannel channel = NettyChannel.getOrAddChannel(ctx.channel(), url, handler); try &#123; handler.sent(channel, msg); &#125; finally &#123; NettyChannel.removeChannelIfDisconnected(ctx.channel()); &#125; &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; NettyChannel channel = NettyChannel.getOrAddChannel(ctx.channel(), url, handler); try &#123; handler.caught(channel, cause); &#125; finally &#123; NettyChannel.removeChannelIfDisconnected(ctx.channel()); &#125; &#125; NettyServer &amp; NettyServerHandler在 NettyServer 创建 NettyServerHandler 时，代码如下： 123// 创建NettyServerHandler对象，注意传入的第二个参数是 NettyServer 对象本身，因为NettyServer是ChannelHandler的子类。// 由于 NettyServerHandler 继承了 ChannelDuplexHandler，因此它是 Netty 层面的 ChannelHandler。final NettyServerHandler nettyServerHandler = new NettyServerHandler(getUrl(), this); 第一个参数是调用间接父类 AbstractPeer#getUrl() 方法获取上层传入的 URL对象。第二个参数正是 NettyServer 对象本身，通过之前的介绍，我们知道 NettyServer 继承关系，它的父类 AbstractPeer 实现了 ChannelHandler 接口，并且将所有方法都委托给了其装饰的 ChannelHandler 对象。因此，NettyServerHandler 中的通道方法都是交给 NettyServer 关联的 ChannelHandler 对象本身。 NettyServer 结构如下图所示： 由上图可知，Dubbo 接入 Netty4 这个 NIO 框架服务器部分具体实现还是很直观的，图中有四个元素：端点（NettyServer）、通道（NettyChannel）、编码器（InternalEncoder）和解码器（InternalDecoder）、通道处理器（NettyServerHandler）。从 Transporter 层来看，功能的不同其实就是注册在 Channel 上的 ChannelHandler 不同，对于 Netty 来说编解码器也属于通道处理器，而端点和通道这两个元素是必须存在的。 至此，我们可以看到 Dubbo 通过装饰者模式层层包装 ChannelHandler，从而不需要将每个 ChannelHandler 都挂载到 Pipeline 中，在 NettyServer 以及下面介绍的 NettyClient 中最多有 3 个 ChannelHandler，分别是编码器、解码器以及 NettyServerHandler(或 NettyClientHandler)。不仅是 Netty 实现的网络通信是这样的，Mina 等实现也是一样的，这在一定程度上避免了低效和浪费资源。 服务小结无论是 远程通信模块总览 ，还是 网络传输层 都是为具体实现服务的，具体实现依赖上层抽象，在 Netty4 这个 NIO 框架的实现角度来看依赖的上层（dubbo-remoting-api）是透明的即通用的逻辑模版。整个 Transport 层和服务相关的核心继承关系如下图： 至此，Dubbo 接入 Netty4 的服务部分就介绍完了。从 AbstractPeer 开始一路继承下来，NettyServer 拥有了多个核心类的职能，关联了两个核心的对象，分别是 ChannelHandler 对象以及 Codec2 对象，这两个对象非常重要，到达服务底层的所有任务 NettyServer 最终都是委托给这两个对象进行处理的。等等，好像漏了通道这个核心对象，尽管它很重要，但是它毕竟是两个端点之间的TCP连接的抽象，对于上层来说一般是非可控的，Dubbo 层面的 Channel 最终是通对 Netty Channel 的装饰来完成工作的。通过前面的介绍，我们知道 NettyServer 关联的 ChannelHandler 是上层传入并经过包装后的对象，包装过程中的功能性对象可由上层通过配置进行管控的，如线程模型中的派发策略和线程池都是可指定的。NettyServer 关联的 Codec2 对象是根据上层传入的 URL 通过 Dubbo SPI 机制初始化的，而 URL 是 Dubbo 中的配置载体，同样是上层可控的。最后的结论是，上层只需要根据业务场景需要，实现 ChannelHandler 和 Codec2 这两个扩展接口即可。 下面我们开始分析 Dubbo 接入 Netty4 的客户端部分。这部分涉及的很多接口和类都是服务部分介绍过的，在下面介绍的客户端部分就不再重复说明。 NettyClientNettyClient 是基于 Netty4 实现的客户端，下面我们对它的属性、构造方法以及基本方法进行详细说明。 属性12345678910111213141516171819public class NettyClient extends AbstractClient &#123; private static final Logger logger = LoggerFactory.getLogger(NettyClient.class); /** * 线程组 */ private static final NioEventLoopGroup nioEventLoopGroup = new NioEventLoopGroup(Constants.DEFAULT_IO_THREADS, new DefaultThreadFactory(\"NettyClientWorker\", true)); /** * 引导类 */ private Bootstrap bootstrap; /** * Netty 的通道。使用volatitle 修饰符。因为客户端可能会和服务端断开连接，需要保证多线程的可见性 */ private volatile Channel channel;&#125; NettyClient 继承了 AbstractClient 抽象类，是 Dubbo 的 Netty 客户端实现类。Channel 属性只有一个，是因为作为客户端同一时间只会连接一个服务。其它两个属性是 Netty 层相关类。 构造方法1234public NettyClient(final URL url, final ChannelHandler handler) throws RemotingException &#123; // wrapChannelHandler方法用于包装ChannelHandler，其中实现了 Dubbo 线程模型的功能。 super(url, wrapChannelHandler(url, handler)); &#125; NettyClient 构造方法流程和 NettyServer 构造方法流程大体一致，区别在 NettyServer 初始化服务器并启动，NettyClient 初始化客户端并连接服务器，其它流程一摸一样，无论是服务端还是客户端，都需要通道处理器，都需要编解码器。下面对构造方法流程简单总结： 对传入的 ChannelHandler 进行包装，最终得到一个增强的 ChannelHandler。对传入的 URL 进行线程池类型和线程名配置赋值。 调用父类 AbstractClient 构造方法及上层父类方法，初始化编解码器 Codec2。 第 2 步执行 AbstractClient 构造方法时，根据 URL 参数配置依次初始化： 发送消息时连接断开是否重连 url.send.reconnect（默认false） 关闭超时时间 url.shutdown.timeout（默认15min） 重连告警间隔时间即重连n次告警一次 url.reconnect.waring.period（默认1800） 调用父类模版方法 doOpen() 启动客户端，启动过程出现异常则调用父类的 close() 方法并抛出异常。 连接服务器，先启动断线重连机制再调用父类模版方法 doConnect() 方法进行连接服务器，其中断线重连机制是父类方法。同样的，连接服务器失败则调用父类的 close() 方法并抛出异常。 从 DataSource 中获取当前客户端对应的线程池。 NettyClient 构造方法中 wrapChannelHandler(url,handler) 方法用于设置线程名并设置线程池类型，相比 NettyServer 构造方法多了设置线程池类型步骤，代码如下： 123456789--- AbstractClient protected static ChannelHandler wrapChannelHandler(URL url, ChannelHandler handler) &#123; // 设置线程名，即 URL.threadname 配置参数值，默认为 'DubboClientHandler' url = ExecutorUtil.setThreadName(url, CLIENT_THREAD_POOL_NAME); // 设置使用的线程池类型，即 URL.threadpool 配置参数值，默认值为 'cached' url = url.addParameterIfAbsent(Constants.THREADPOOL_KEY, Constants.DEFAULT_CLIENT_THREADPOOL); // 包装通道处理器 return ChannelHandlers.wrap(handler, url); &#125; 启动客户端 doOpen12345678910111213141516171819202122232425262728293031323334353637383940414243@Overrideprotected void doOpen() throws Throwable &#123; // 创建 NettyClientHandler 对象，第二个参数是 NettyClient 对象本身，因为 NettyClient 是 ChannelHander的实现类。 final NettyClientHandler nettyClientHandler = new NettyClientHandler(getUrl(), this); // 创建 Netty 客户端引导对象 bootstrap = new Bootstrap(); bootstrap // 设置它的线程组 .group(nioEventLoopGroup) // 设置可选项 .option(ChannelOption.SO_KEEPALIVE, true) .option(ChannelOption.TCP_NODELAY, true) .option(ChannelOption.ALLOCATOR, PooledByteBufAllocator.DEFAULT) //.option(ChannelOption.CONNECT_TIMEOUT_MILLIS, getTimeout()) // 设置 客户端对应的Channel类型 .channel(NioSocketChannel.class); // 设置连接超时时间，这里使用到 AbstractEndpoint 中的 connectTimeout 字段 if (getConnectTimeout() &lt; 3000) &#123; bootstrap.option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 3000); &#125; else &#123; bootstrap.option(ChannelOption.CONNECT_TIMEOUT_MILLIS, getConnectTimeout()); &#125; // 设置处理器执行链 bootstrap.handler(new ChannelInitializer() &#123; @Override protected void initChannel(Channel ch) throws Exception &#123; // 创建 NettyCoderAdapter 对象 NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec(), getUrl(), NettyClient.this); // 获取Pipeline ch.pipeline() //.addLast(\"logging\",new LoggingHandler(LogLevel.INFO)) // 设置日志，方便调试 // 注册解码器 .addLast(\"decoder\", adapter.getDecoder()) // 注册编码器 .addLast(\"encoder\", adapter.getEncoder()) // 注册处理器 .addLast(\"handler\", nettyClientHandler); &#125; &#125;);&#125; NettyClient 的启动客户端方法是父类的一个模版方法，和 NettyServer 的启动服务方法类似，下面简单概括： 创建 Dubbo 层面的 NettyClientHandler 对象，因其继承了 Netty 中的 ChannelDuplexHandler 类，因此它又属于 Netty 层面的 ChannelHandler，直接参与 Netty 通道消息或事件的处理。 初始化客户端引导对象，设置参数项。其中不需要boss线程组，通道类型是 NioSocketChannel，连接超时时间是从父类 AbstractEndpoint 中获取 。 创建 ChannelInitializer 初始化器，指定如何初始化 Channel 上的 ChannelHandler 等系列 Netty 使用的标准化流程，这里就是注册通道处理器（包括编解码器）。 客户端初始化完毕后，进入连接服务的流程。 连接服务器 doConnect12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667@Overrideprotected void doConnect() throws Throwable &#123; // 记录连接开始时间 long start = System.currentTimeMillis(); // 连接指定地址的服务，地址从 URL 配置总线中获取 （URL从AbstractPeer中取） ChannelFuture future = bootstrap.connect(getConnectAddress()); try &#123; // 等待连接成功或者超时 boolean ret = future.awaitUninterruptibly(getConnectTimeout(), TimeUnit.MILLISECONDS); // 连接成功 if (ret &amp;&amp; future.isSuccess()) &#123; // 取出连接服务的通道 Channel newChannel = future.channel(); try &#123; // 如果已经存在连接服务的通道了，就把老的关闭，使用新的 Channel oldChannel = NettyClient.this.channel; if (oldChannel != null) &#123; try &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Close old netty channel \" + oldChannel + \" on create new netty channel \" + newChannel); &#125; // 关闭老的通道 oldChannel.close(); &#125; finally &#123; // 移除老的通道对应的缓存（即对应的 Dubbo 的通道 NettyChannel） NettyChannel.removeChannelIfDisconnected(oldChannel); &#125; &#125; &#125; finally &#123; // 若客户端关闭了，则关闭新的连接 if (NettyClient.this.isClosed()) &#123; try &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Close new netty channel \" + newChannel + \", because the client closed.\"); &#125; newChannel.close(); &#125; finally &#123; NettyClient.this.channel = null; NettyChannel.removeChannelIfDisconnected(newChannel); &#125; // 更新连接服务的通道 &#125; else &#123; NettyClient.this.channel = newChannel; &#125; &#125; // 连接服务发生异常，则抛出 &#125; else if (future.cause() != null) &#123; throw new RemotingException(this, \"client(url: \" + getUrl() + \") failed to connect to server \" + getRemoteAddress() + \", error message is:\" + future.cause().getMessage(), future.cause()); // 连接超时，抛出RemotingException异常 &#125; else &#123; throw new RemotingException(this, \"client(url: \" + getUrl() + \") failed to connect to server \" + getRemoteAddress() + \" client-side timeout \" + getConnectTimeout() + \"ms (elapsed: \" + (System.currentTimeMillis() - start) + \"ms) from netty client \" + NetUtils.getLocalHost() + \" using dubbo version \" + Version.getVersion()); &#125; &#125; finally &#123; // 没有连接 if (!isConnected()) &#123; //future.cancel(true); &#125; &#125;&#125; 客户端连接服务主要做了以下工作： 调用 Netty 的 Bootstrap#connect(remoteAddress) 方法连接服务器，返回连接结果对象 ChannelFuture 。 调用 Netty 的 ChannelFuture#awaitUninterruptibly(getConnectTimeout(), TimeUnit.MILLISECONDS) 方法，等待连接成功或超时。 如果连接服务成功，先判断是否存在旧的连接通道，有则关闭旧的通道并删除对应的通道缓存，再判断当前客户端是否关闭（通道、线程池等资源），关闭则新的连接作废并删除对应的通道缓存。前置检测完成后，最后更新连接服务的通道。 连接失败，可能是连接服务异常，也可能是连接超时异常。 finally 块中的逻辑，当没有连接时什么也不做，可以看到官方把取消连接任务方法调用注释了，这里应该是前面判断失败的分支逻辑已经处理过了，没有连接无非就是连接失败或超时。 断开连接 doDisConnect12345678@Overrideprotected void doDisConnect() throws Throwable &#123; try &#123; NettyChannel.removeChannelIfDisconnected(channel); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage()); &#125;&#125; 断开连接仅仅是在客户端连接服务的通道关闭时，把对应的通道缓存清除。 获取连接到服务的通道 getChannel12345678@Override protected com.alibaba.dubbo.remoting.Channel getChannel() &#123; Channel c = channel; if (c == null || !c.isActive()) &#123; return null; &#125; return NettyChannel.getOrAddChannel(c, getUrl(), this); &#125; 获取连接到服务的通道是父类的模版方法，用于返回具体NIO的通道对应的 Dubbo 通道，这里是返回Netty的Channel对应的Dubbo 层面的NettyChanel 。 NettyClientHandlerNettyClientHandler 的实现和 NettyServerHandler 类似，同样实现了 Netty 的 ChannelDuplexHandler。NettyClientHandler 会将所有方法委托给 NettyClient 关联的 ChannelHandler 对象进行处理。 属性123456789101112131415161718192021222324252627282930@io.netty.channel.ChannelHandler.Sharablepublic class NettyClientHandler extends ChannelDuplexHandler &#123; /** * URL */ private final URL url; /** * ChannelHandler，NettyClient 对象 */ private final ChannelHandler handler; /** * 构造方法 * * @param url url * @param handler NettyClient */ public NettyClientHandler(URL url, ChannelHandler handler) &#123; if (url == null) &#123; throw new IllegalArgumentException(\"url == null\"); &#125; if (handler == null) &#123; throw new IllegalArgumentException(\"handler == null\"); &#125; this.url = url; this.handler = handler; &#125;&#125; 在 NettyClientHandler 中有两个属性，url 和 handler 。属性说明如下： url 属性：通过构造方法传入。 handler 属性：通道处理器，是 NettyClient 对象。NettyClientHandler 中几乎所有方法都会委托给该对象处理。 通道处理方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899/** * 处理连接事件 * &lt;p&gt; * 说明：不同于NettyServerHandler的该方法会提交给handler处理，客户端不会被连接，因此无需做连接处理。 * * @param ctx * @throws Exception */ @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; ctx.fireChannelActive(); &#125; /** * 处理断开连接事件 * &lt;p&gt; * 说明： 不同于NettyServerHandler的该方法会提交给handler处理，客户端无需处理断开连接事件，因此无需做连接处理。 * * @param ctx * @throws Exception */ @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123; ctx.fireChannelInactive(); &#125; //--------- 以下断开连接、读取数据、写数据以及异常处理，都是直接委托给ClientHandler装饰的ChannelHandler进行处理，所需的通道是 Netty通道对应Dubbo通道 --------------/ /** * 断开连接 * * @param ctx * @param future * @throws Exception */ @Override public void disconnect(ChannelHandlerContext ctx, ChannelPromise future) throws Exception &#123; NettyChannel channel = NettyChannel.getOrAddChannel(ctx.channel(), url, handler); try &#123; handler.disconnected(channel); &#125; finally &#123; NettyChannel.removeChannelIfDisconnected(ctx.channel()); &#125; &#125; /** * 读取消息 * * @param ctx * @param msg * @throws Exception */ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; NettyChannel channel = NettyChannel.getOrAddChannel(ctx.channel(), url, handler); try &#123; handler.received(channel, msg); &#125; finally &#123; NettyChannel.removeChannelIfDisconnected(ctx.channel()); &#125; &#125; /** * 写数据 * * @param ctx * @param msg * @param promise * @throws Exception */ @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception &#123; super.write(ctx, msg, promise); NettyChannel channel = NettyChannel.getOrAddChannel(ctx.channel(), url, handler); try &#123; handler.sent(channel, msg); &#125; finally &#123; NettyChannel.removeChannelIfDisconnected(ctx.channel()); &#125; &#125; /** * 异常处理 * * @param ctx * @param cause * @throws Exception */ @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; NettyChannel channel = NettyChannel.getOrAddChannel(ctx.channel(), url, handler); try &#123; handler.caught(channel, cause); &#125; finally &#123; NettyChannel.removeChannelIfDisconnected(ctx.channel()); &#125; &#125; NettyClientHandler 对 io.netty.channel.ChannelDuplexHandler 重写的方法，在需要处理的时候都是委托给 NettyClient 关联的 ChannelHandler 对象，所需通道是 Netty通道对应的 Dubbo 通道，在前面的 NettyChannel 类中已经说明，它是对 Netty 通道的装饰，实际操作还是由 Netty 通道处理。 NettyClient &amp; NettyClientHandlerNettyClient 创建 NettyClientHandler 代码如下： 12// 创建 Dubbo NettyClientHandler 对象。注意传入的第二个参数是 NettyClient 对象本身，因为 NettyClient 是ChannelHander的实现类。final NettyClientHandler nettyClientHandler = new NettyClientHandler(getUrl(), this); 由于继承关系，NettyClient 继承了 AbstractPeer 抽象类，该类是将数据全部直接委托给装饰的 ChannelHandler 对象，因此 NettyClient 同样是将数据委托给其关联的 ChannelHandler 对象。 NettyClient 结构如下图所示： 总结本篇文章重点介绍了 Dubbo Transporter 层中基于 Netty4 实现的 Server 和 Client 实现以及相关的核心类，如 NettyTransporter 、 NettyChannel 通道、NettyServerHandler 和 NettyClientHandler 通道处理器、NettyCodecAdapter 编解码器，它们都是最低层的实现。前面文章也提到，dubbo-remoting-api 模块对于 dubbo-remoting-netty4 模块来说是透明的即通用的逻辑模版，其中 NettyServer 和 NettyClient 通过继承及实现，拥有了 Endpoint、ChannelHandler等多个接口的职能，关联了 ChannelHandler 对象和 Codec2 对象，并最终将数据委托给这两个对象去处理。上层只需要根据业务场景需要，配置功能参数到配置总线 URL 并实现 ChannelHandler 和 Codec2 这两个扩展接口即可，Codec2 的实现是在 AbstractEndpoint 抽象类的构造方法中根据 Dubbo SPI 获取的。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"Netty","slug":"Netty","permalink":"https://gentryhuang.com/tags/Netty/"}]},{"title":"Dubbo源码分析 - 网络传输层","slug":"rpc/Transport层","date":"2020-05-22T16:00:00.000Z","updated":"2021-03-15T02:10:06.551Z","comments":false,"path":"posts/53cd7ee7/","link":"","permalink":"https://gentryhuang.com/posts/53cd7ee7/","excerpt":"","text":"前言在 远程通信模块总览 中对 Remoting 层进行了总体说明，下面我们开始详细介绍 Remoting 层的 Transport 网络传输层。本文会从 Transporter 层的 Server、Client、Channel、ChannelHandler、Dispatcher 以及 Codec2 等核心接口出发，分别介绍这些核心接口的实现。 概述有很多网络库可以实现网络传输的功能，如 Netty、Mina、Grizzly等。但这些 NIO 库对外接口和使用方式不一样，如果使用方直接使用 Netty 或其它通信组件，那么就依赖了具体的NIO库实现，而不是依赖一个有传输能力的抽象，后续要切换其它NIO库实现的话就需要修改依赖和接入的相关代码，这既容易出错也不符合设计模式中的开放-封闭原则。因此，Dubbo Transporter 层就被抽象出来了，它屏蔽了不同的通信框架的异同，封装了统一的对外接口。有了 Transporter 层之后，我们可以通过 Dubbo SPI 动态切换具体的 Transporter 扩展实现，从而切换到不同的 Client 和 Server 实现，达到底层 NIO 库切换的目的。需要注意的是，Dubbo Transporter 层不等于 Transport 扩展接口及其实现，它是对网络传输层的抽象即在NIO库之上的抽象，以 Message 为中心，扩展接口为 Channel, Transporter, Client, Server, Codec, ChannelHandler, Dispatcher 等。 Transport 抽象层代码结构如下： 注意， Dubbo 接入具体 NIO 库的代码散落在 dubbo-remoting-* 实现模块中，会在后面的文章中介绍。 Transporter 扩展接口12345678910111213141516171819202122232425262728@SPI(\"netty\")public interface Transporter &#123; /** * 创建一个服务器，监听来自客户端的请求。根据 'server'，'transporter' 确定 Server 扩展实现 * * @param url 服务器地址 * @param handler 通道处理器 * @return server 返回服务器 * @throws RemotingException * @see com.alibaba.dubbo.remoting.Transporters#bind(URL, ChannelHandler...) */ @Adaptive(&#123;Constants.SERVER_KEY, Constants.TRANSPORTER_KEY&#125;) Server bind(URL url, ChannelHandler handler) throws RemotingException; /** * 连接服务器，即创建一个客户端。根据 'client','transporter' 确定 Client 扩展实现 * * @param url 服务器地址 * @param handler 通道处理器 * @return client 客户端 * @throws RemotingException * @see com.alibaba.dubbo.remoting.Transporters#connect(URL, ChannelHandler...) */ @Adaptive(&#123;Constants.CLIENT_KEY, Constants.TRANSPORTER_KEY&#125;) Client connect(URL url, ChannelHandler handler) throws RemotingException;&#125; Transporter 是在 Client 和 Server 之上封装的统一的对外接口，针对每个支持的NIO库，都有一个 Transporter 接口实现，它们是 Dubbo 接入具体NIO库的实现入口，在各个 dubbo-remoting-* 实现模块中。如，Dubbo 接入 Mina 网络通信库，就会有对应的 dubbo-remoting-mina 模块对抽象api模块的实现，该模块提供了 Transporter、Server、Client、Channel、ChannelHandler 等核心接口的实现。 这些 Transporter 接口实现返回的 Client 和 Server 具体实现如下图所示，它们是Dubbo 接入的NIO库对应的 Server和Client实现。 具体NIO库Server的实现 具体NIO库Client的实现 在 远程通信模块总览 中已经介绍过 Transporter 接口以及该接口的门面类 Transporters ，这里不再重复介绍。关于通信具体实现模块会在后面的文章中介绍，它们也是 Transporter 层的一部分，本篇文章着重分析 Transport 层公用组件及抽象概念。 AbstractPeer 抽象类123456789101112131415161718192021222324252627282930313233343536373839public abstract class AbstractPeer implements Endpoint, ChannelHandler &#123; /** * 通道处理器,AbstractPeer 对 ChannelHandler 接口的所有实现，都是委托给了这个 ChannelHandler 对象来处理 */ private final ChannelHandler handler; /** * 端点自身的 URL 类型的字段 */ private volatile URL url; /** * 正在关闭 */ private volatile boolean closing; /** * 关闭完成 */ private volatile boolean closed; /** * handler 属性，通道处理器，通过构造方法传入。使用 '装饰者模式' * * @param url * @param handler */ public AbstractPeer(URL url, ChannelHandler handler) &#123; if (url == null) &#123; throw new IllegalArgumentException(\"url == null\"); &#125; if (handler == null) &#123; throw new IllegalArgumentException(\"handler == null\"); &#125; this.url = url; this.handler = handler; &#125; // $&#123;省略其它代码&#125;&#125; AbstractPeer 这个抽象类，它同时实现了 Endpoint 接口和 ChannelHandler 接口，AbstractPeer 对 ChannelHandler 接口的所有实现都是委托给维护的 ChannelHandler 属性来处理。对 Endpoint 接口的实现，包括和Channel有关的，如关闭Channel、开始关闭Channel(做标记关闭)、检查Channel是否关闭，这些都是对其维护的 closing 和 closed 属性进行操作；发送消息 send 方法的实现交给其子类去完成；获取端点自身的 URL；获取 ChannelHandler。需要特别说明的是，上层的 ChannelHandler 在链路的最底层保存的位置就是在 AbstractPeer 这个抽象类中。 AbstractPeer 也是 AbstractChannel、AbstractEndpoint 抽象类的父类，继承关系如下图： 红框中的实现类是 Dubbo 接入的具体NIO库实现相关的 Server、Client 和 Channel 实现类，通过继承关系以及前面的描述，我们可以知道 AbstractChannel、AbstractServer、AbstractClient 都会关联一个 ChannelHandler 对象，这个对象很重要，后面会慢慢揭开它的面纱。 AbstractEndpoint 抽象类上文也提到了，AbstractEndpoint 继承了 AbstractPeer 这个抽象类，因为继承关系因此也会关联一个 ChannelHandler。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public abstract class AbstractEndpoint extends AbstractPeer implements Resetable &#123; private static final Logger logger = LoggerFactory.getLogger(AbstractEndpoint.class); /** * 编解码器 */ private Codec2 codec; /** * 超时时间 */ private int timeout; /** * 连接超时时间 (用于具体子类客户端连接超时时间) */ private int connectTimeout; public AbstractEndpoint(URL url, ChannelHandler handler) &#123; // 调用父类 AbstractPeer 的构造方法 super(url, handler); // 根据URL中的 codec 参数值 获取Codec2的实现类 this.codec = getChannelCodec(url); // 根据 URL 中的 timeout 参数确定 timeout 字段的值，默认 1000 this.timeout = url.getPositiveParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT); // 根据URL中的connect.timeout 参数确定connectTimeout 字段值，默认 3000 this.connectTimeout = url.getPositiveParameter(Constants.CONNECT_TIMEOUT_KEY, Constants.DEFAULT_CONNECT_TIMEOUT); &#125; /** * 基于Dubbo SPI机制，加载对应的Codec实现对象，如：在DubboProtocol中会获得DubboCodec对象 * * @param url * @return */ protected static Codec2 getChannelCodec(URL url) &#123; String codecName = url.getParameter(Constants.CODEC_KEY, \"telnet\"); if (ExtensionLoader.getExtensionLoader(Codec2.class).hasExtension(codecName)) &#123; return ExtensionLoader.getExtensionLoader(Codec2.class).getExtension(codecName); &#125; else &#123; // 注意： Codec接口已经废弃了 return new CodecAdapter(ExtensionLoader.getExtensionLoader(Codec.class).getExtension(codecName)); &#125; &#125; // $&#123;省略其它代码&#125;&#125; 通过上面的代码可以看到，AbstractEndpoint 中维护了一个编解码对象 Codec2 ，该对象是在 AbstractEndpoint 构造方法中根据传入的URL完成初始化，这个非常重要。除了维护 Codec2 编解码对象外，还维护了超时时间（timeout）和连接超时时间（connectTimeout），它们也是在构造方法中根据传入的URL进行初始化的。 此外，AbstractEndpoint 还实现了 Resetable 接口用来支持重置 AbstractEndpoint 中维护的三个属性，代码实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940--- AbstractEndpoint /** * 重置属性, 即使用新的 url 重置 codec、timeout、connectTimeout 属性 * * @param url */ @Override public void reset(URL url) &#123; if (isClosed()) &#123; throw new IllegalStateException(\"Failed to reset parameters \" + url + \", cause: Channel closed. channel: \" + getLocalAddress()); &#125; try &#123; if (url.hasParameter(Constants.TIMEOUT_KEY)) &#123; int t = url.getParameter(Constants.TIMEOUT_KEY, 0); if (t &gt; 0) &#123; this.timeout = t; &#125; &#125; &#125; catch (Throwable t) &#123; logger.error(t.getMessage(), t); &#125; try &#123; if (url.hasParameter(Constants.CONNECT_TIMEOUT_KEY)) &#123; int t = url.getParameter(Constants.CONNECT_TIMEOUT_KEY, 0); if (t &gt; 0) &#123; this.connectTimeout = t; &#125; &#125; &#125; catch (Throwable t) &#123; logger.error(t.getMessage(), t); &#125; try &#123; if (url.hasParameter(Constants.CODEC_KEY)) &#123; this.codec = getChannelCodec(url); &#125; &#125; catch (Throwable t) &#123; logger.error(t.getMessage(), t); &#125; &#125; 抽象的服务端和客户端由上面的继承关系图可知，AbstractServer 和 AbstractClient 都继承自 AbstractEndpoint 抽象类，下面我们先来分析 AbstractServer 这个抽象服务的实现。 AbstractServer属性1234567891011121314151617181920212223242526public abstract class AbstractServer extends AbstractEndpoint implements Server &#123; protected static final String SERVER_THREAD_POOL_NAME = \"DubboServerHandler\"; private static final Logger logger = LoggerFactory.getLogger(AbstractServer.class); /** * 当前Server关联的线程池，是从 DataStore 中取的 */ ExecutorService executor; /** * 当前Server本地地址 */ private InetSocketAddress localAddress; /** * 绑定地址 （默认值与 localAddress 一致） */ private InetSocketAddress bindAddress; /** * 服务器最大可接受连接数 */ private int accepts; /** * 空闲超时时间 */ private int idleTimeout = 600; //600 seconds &#125; AbstractServer 在继承 AbstractEndpoint 的同时，还实现了 Server 接口，是服务抽象类，重点实现了服务的公用逻辑，Server 接口在 在 远程通信模块总览 中已经介绍，其中的属性已经在代码中详细标注。下面我们接着看它的构造方法，上述的属性字段都是在构造方法中进行初始化的。 构造方法123456789101112131415161718192021222324252627282930313233343536--- AbstractServer public AbstractServer(URL url, ChannelHandler handler) throws RemotingException &#123; // 调用父类构造方法 super(url, handler); // 服务地址: 本机地址 如：-&gt; /192.168.0.100:20880 localAddress = getUrl().toInetSocketAddress(); // 获取ip和端口 String bindIp = getUrl().getParameter(Constants.BIND_IP_KEY, getUrl().getHost()); int bindPort = getUrl().getParameter(Constants.BIND_PORT_KEY, getUrl().getPort()); if (url.getParameter(Constants.ANYHOST_KEY, false) || NetUtils.isInvalidLocalHost(bindIp)) &#123; // 设置ip 为 0.0.0.0 bindIp = NetUtils.ANYHOST; &#125; // 绑定地址 如： /0.0.0.0:20880 bindAddress = new InetSocketAddress(bindIp, bindPort); // 获取最大可接受连接数 this.accepts = url.getParameter(Constants.ACCEPTS_KEY, Constants.DEFAULT_ACCEPTS); // 空闲超时时间 this.idleTimeout = url.getParameter(Constants.IDLE_TIMEOUT_KEY, Constants.DEFAULT_IDLE_TIMEOUT); try &#123; // 调用模版方法 doOpen 启动服务 doOpen(); if (logger.isInfoEnabled()) &#123; logger.info(\"Start \" + getClass().getSimpleName() + \" bind \" + getBindAddress() + \", export \" + getLocalAddress()); &#125; &#125; catch (Throwable t) &#123; throw new RemotingException(url.toInetSocketAddress(), null, \"Failed to bind \" + getClass().getSimpleName() + \" on \" + getLocalAddress() + \", cause: \" + t.getMessage(), t); &#125; /** 从DataStore中获得线程池 ,来源 &#123;@link com.alibaba.dubbo.remoting.transport.dispatcher.WrappedChannelHandler.WrappedChannelHandler&#125;*/ DataStore dataStore = ExtensionLoader.getExtensionLoader(DataStore.class).getDefaultExtension(); executor = (ExecutorService) dataStore.get(Constants.EXECUTOR_SERVICE_COMPONENT_KEY, Integer.toString(url.getPort())); &#125; 构造方法会根据传入的URL初始化 AbstractServer 中的属性，这也是为了其子类的初始化做准备，其中在构造方法中调用了一个模版方法 doOpen，这个方法就是初始化其子类的关键入口，即启动具体的NIO服务，下篇文章分析具体NIO库是如何接入的就会清晰了。当前Server关联的线程池 executor 是从 DataStore 中取的，下文会对 DataStore 进行介绍并说明线程池的来源。 模版方法用于子类实现，完成服务的开启和关闭工作。 123protected abstract void doOpen() throws Throwable;protected abstract void doClose() throws Throwable; 发送消息发送消息方法是对 Endpoint 接口的实现 1234567891011121314151617181920--- AbstractServer /** * 发送消息 * * @param message * @param sent true: 会等待消息发出，消息发送失败会抛出异常； false: 不等待消息发出，将消息放入IO队列，即可返回 * @throws RemotingException */ @Override public void send(Object message, boolean sent) throws RemotingException &#123; // 获取连接上服务器的通道列表 【客户端列表】 Collection&lt;Channel&gt; channels = getChannels(); // 群发消息 for (Channel channel : channels) &#123; // 如果是已经连接的就发送 if (channel.isConnected()) &#123; channel.send(message, sent); &#125; &#125; &#125; 客户端请求连接用于客户端连接当前服务，是对父类 AbstractPeer 方法的重写，对 ChannelHandler 的实现，AbstractPeer 中的实现很简单，只是判断服务是否关闭，关闭就不会处理客户端连接请求，没有关闭则会把连接请求交给维护的 ChannelHandler 处理。 1234567891011121314151617181920212223242526--- AbstractServer @Override public void connected(Channel ch) throws RemotingException &#123; // If the server has entered the shutdown process, reject any new connection // 调用父类AbstractPeer 中的方法，判读当前这个 Server 端是否正在关闭或关闭了。如果不是启动状态则直接关闭新建的 Client 连接。 if (this.isClosing() || this.isClosed()) &#123; logger.warn(\"Close new channel \" + ch + \", cause: server is closing or has been closed. For example, receive a new connect request while in shutdown process.\"); ch.close(); return; &#125; //1 超过上限，关闭新的连接 //1.1 获取连接上服务器的通道列表 【客户端列表】 Collection&lt;Channel&gt; channels = getChannels(); //1.2 判断服务器上连接数是否超过上限 if (accepts &gt; 0 &amp;&amp; channels.size() &gt; accepts) &#123; logger.error(\"Close channel \" + ch + \", cause: The server \" + ch.getLocalAddress() + \" connections greater than max config \" + accepts); // 服务器上的连接数超过上上限的话，就关闭新的连接 ch.close(); return; &#125; // 处理连接事件，AbstractPeer 中的方法，本质还是委托内部装饰的 ChannelHandler 来处理 super.connected(ch); &#125; 客户端断开连接用于客户端断开连接当前服务，是对父类 AbstractPeer 方法的重写，对 ChannelHandler 的实现，AbstractPeer 中的实现很简单，直接把断开连接请求交给装饰的 ChannelHandler 处理。 12345678910--- AbstractServer @Override public void disconnected(Channel ch) throws RemotingException &#123; Collection&lt;Channel&gt; channels = getChannels(); if (channels.isEmpty()) &#123; logger.warn(\"All clients has discontected from \" + ch.getLocalAddress() + \". You can graceful shutdown now.\"); &#125; // 处理断开连接请求 super.disconnected(ch); &#125; 服务关闭1234567891011121314151617181920@Override public void close() &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Close \" + getClass().getSimpleName() + \" bind \" + getBindAddress() + \", export \" + getLocalAddress()); &#125; // 关闭关联的线程池 ExecutorUtil.shutdownNow(executor, 100); try &#123; // 标记关闭 super.close(); &#125; catch (Throwable e) &#123; logger.warn(e.getMessage(), e); &#125; try &#123; // 子类关闭动作 doClose(); &#125; catch (Throwable e) &#123; logger.warn(e.getMessage(), e); &#125; &#125; 还有一些不是很重要的其它方法就不分析了，下面继续分析抽象客户端实现。 AbstractClientAbstractClient 同样继承了 AbstractEndpoint 抽象类，并且实现了 Client 接口，是客户端的抽象类，实现了公用的逻辑。Client 接口在 在 远程通信模块总览 中已经介绍过，就不再重复说明。 属性123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public abstract class AbstractClient extends AbstractEndpoint implements Client &#123; private static final Logger logger = LoggerFactory.getLogger(AbstractClient.class); /** * 连接线程池名 */ protected static final String CLIENT_THREAD_POOL_NAME = \"DubboClientHandler\"; /** * 连接线程池id */ private static final AtomicInteger CLIENT_THREAD_POOL_ID = new AtomicInteger(); /** * 重连定时任务执行器，在客户端连接服务端时，会创建后台任务，定时检查连接，若断开会进行重新连 */ private static final ScheduledThreadPoolExecutor reconnectExecutorService = new ScheduledThreadPoolExecutor(2, new NamedThreadFactory(\"DubboClientReconnectTimer\", true)); /** * 连接锁，用于实现发起连接和断开连接互斥，避免并发。 */ private final Lock connectLock = new ReentrantLock(); /** * 发送消息时，若断开，是否重连 */ private final boolean send_reconnect; /** * 重连次数 */ private final AtomicInteger reconnect_count = new AtomicInteger(0); /** * 重连时，是否已经打印过错误日志。默认没有打印过 */ private final AtomicBoolean reconnect_error_log_flag = new AtomicBoolean(false); /** * 重连warning的间隔，warning多少次之后warning一次 */ private final int reconnect_warning_period; /** * 关闭超时时间 */ private final long shutdown_timeout; /** * 当前客户端对应的线程池 * 在调用 &#123;@link #wrapChannelHandler(URL, ChannelHandler)&#125; 时，会调用 &#123;@link com.alibaba.dubbo.remoting.transport.dispatcher.WrappedChannelHandler&#125; 创建 */ protected volatile ExecutorService executor; /** * 重连执行任务 Future */ private volatile ScheduledFuture&lt;?&gt; reconnectExecutorFuture = null; /** * 最后成功连接时间 */ private long lastConnectedTime = System.currentTimeMillis();&#125; AbstractClient 中的相关属性已经详细标注，因为是客户端，会涉及到重连服务的情况，属性相对比服务端要多些，但是这些属性都是很有用的 。 构造方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455--- AbstractClient public AbstractClient(URL url, ChannelHandler handler) throws RemotingException &#123; super(url, handler); // 从URL中，获得重连相关配置，即 send.reconnect 配置属性 send_reconnect = url.getParameter(Constants.SEND_RECONNECT_KEY, false); // 从URL中获得关闭超时时间 即 shutdown.timeout 配置属性 shutdown_timeout = url.getParameter(Constants.SHUTDOWN_TIMEOUT_KEY, Constants.DEFAULT_SHUTDOWN_TIMEOUT); // The default reconnection interval is 2s, 1800 means warning interval is 1 hour. reconnect_warning_period = url.getParameter(\"reconnect.waring.period\", 1800); // 初始化客户端 try &#123; doOpen(); &#125; catch (Throwable t) &#123; // 初始化失败，则关闭，并抛出异常 close(); throw new RemotingException(url.toInetSocketAddress(), null, \"Failed to start \" + getClass().getSimpleName() + \" \" + NetUtils.getLocalAddress() + \" connect to the server \" + getRemoteAddress() + \", cause: \" + t.getMessage(), t); &#125; // 连接服务器 try &#123; connect(); if (logger.isInfoEnabled()) &#123; logger.info(\"Start \" + getClass().getSimpleName() + \" \" + NetUtils.getLocalAddress() + \" connect to the server \" + getRemoteAddress()); &#125; &#125; catch (RemotingException t) &#123; // 如果连接失败，并且配置了启动检查，则进行对应的逻辑 if (url.getParameter(Constants.CHECK_KEY, true)) &#123; // 关闭连接 close(); throw t; &#125; else &#123; logger.warn(\"Failed to start \" + getClass().getSimpleName() + \" \" + NetUtils.getLocalAddress() + \" connect to the server \" + getRemoteAddress() + \" (check == false, ignore and retry later!), cause: \" + t.getMessage(), t); &#125; &#125; catch (Throwable t) &#123; close(); throw new RemotingException(url.toInetSocketAddress(), null, \"Failed to start \" + getClass().getSimpleName() + \" \" + NetUtils.getLocalAddress() + \" connect to the server \" + getRemoteAddress() + \", cause: \" + t.getMessage(), t); &#125; // 从DataStore中获得线程池，这里的线程池就是线程模型中的涉及的线程池 /** * &#123;@link WrappedChannelHandler#WrappedChannelHandler(com.alibaba.dubbo.remoting.ChannelHandler, com.alibaba.dubbo.common.URL)&#125; */ executor = (ExecutorService) ExtensionLoader.getExtensionLoader(DataStore.class).getDefaultExtension().get(Constants.CONSUMER_SIDE, Integer.toString(url.getPort())); ExtensionLoader.getExtensionLoader(DataStore.class).getDefaultExtension().remove(Constants.CONSUMER_SIDE, Integer.toString(url.getPort())); &#125; 构造方法中不仅初始化了属性，还调用了模版方法，用于完成子类的初始化工作，即完成客户端的初始化并连接上服务。具体的客户端实现同样在后面的文章中说明。 模版方法12345678910111213141516171819202122232425262728293031323334--- AbstractClient /** * Open client. * * @throws Throwable */ protected abstract void doOpen() throws Throwable; /** * Close client. * * @throws Throwable */ protected abstract void doClose() throws Throwable; /** * Connect to server. * * @throws Throwable */ protected abstract void doConnect() throws Throwable; /** * disConnect to server. * * @throws Throwable */ protected abstract void doDisConnect() throws Throwable; /** * Get the connected channel. * * @return channel */ protected abstract Channel getChannel(); 与 AbstractServer 类似，AbstractClient 定义了 doOpen()、doClose()、doConnect()、 doDisConnect() 和 getChannel() 抽象方法给子类实现以完成特定的功能。其中 doClose() 方法在 Netty 实现中是个空方法。 连接服务的通用逻辑123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051--- AbstractClient/** * 连接服务器 * * @throws RemotingException */ protected void connect() throws RemotingException &#123; // 获得锁 connectLock.lock(); try &#123; // 判断连接状态，若已经连接就不重复连接。 if (isConnected()) &#123; return; &#125; // 初始化重连线程 【断线重连机制】 initConnectStatusCheckCommand(); // 执行连接 doConnect(); // 是否已经连接，如过连接失败则抛出异常 if (!isConnected()) &#123; throw new RemotingException(this, \"Failed connect to server \" + getRemoteAddress() + \" from \" + getClass().getSimpleName() + \" \" + NetUtils.getLocalHost() + \" using dubbo version \" + Version.getVersion() + \", cause: Connect wait timeout: \" + getConnectTimeout() + \"ms.\"); // 连接成功，打印日志 &#125; else &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Successed connect to server \" + getRemoteAddress() + \" from \" + getClass().getSimpleName() + \" \" + NetUtils.getLocalHost() + \" using dubbo version \" + Version.getVersion() + \", channel is \" + this.getChannel()); &#125; &#125; // 设置重连次数归零 reconnect_count.set(0); // 设置未打印过重连错误日志 reconnect_error_log_flag.set(false); &#125; catch (RemotingException e) &#123; throw e; &#125; catch (Throwable e) &#123; throw new RemotingException(this, \"Failed connect to server \" + getRemoteAddress() + \" from \" + getClass().getSimpleName() + \" \" + NetUtils.getLocalHost() + \" using dubbo version \" + Version.getVersion() + \", cause: \" + e.getMessage(), e); &#125; finally &#123; // 释放锁 connectLock.unlock(); &#125; &#125; 连接服务通用逻辑主要做了以下工作： 获得锁，用于实现在连接和断开连接同时操作时，通过加锁以防止并发问题。 判断是否连接，如果连接了就无需再连接，是否连接逻辑是对Channel接口方法的实现。1234567891011121314--- AbstractClient /** * Dubbo的Channel 接口中的方法。方法内部调用的是Channel对象 * * @return */ @Override public boolean isConnected() &#123; Channel channel = getChannel(); if (channel == null) &#123; return false; &#125; return channel.isConnected(); &#125; 开启断线重连机制，即初始化重连线程，定时检查连接状态。 调用具体客户端实现的连接服务的方法去连接对应的服务。 连接失败抛出异常，连接成功则打印日志并归零重连次数。 断线重连机制1234567891011121314151617181920212223242526272829303132333435363738394041424344454647--- AbstractClient /** * 初始化重连线程 【以一定频率尝试重连任务】 */ private synchronized void initConnectStatusCheckCommand() &#123; // 获得重连频率 【注意：默认是开启的，2000毫秒】 int reconnect = getReconnectParam(getUrl()); // 若开启重连功能，创建重连线程 if (reconnect &gt; 0 &amp;&amp; (reconnectExecutorFuture == null || reconnectExecutorFuture.isCancelled())) &#123; // 创建重连任务体 Runnable connectStatusCheckCommand = new Runnable() &#123; @Override public void run() &#123; try &#123; // 判断是否连接，未连接就重连 if (!isConnected()) &#123; connect(); // 已连接则记录最后连接时间（确保是连接状态的时间） &#125; else &#123; lastConnectedTime = System.currentTimeMillis(); &#125; &#125; catch (Throwable t) &#123; // 符合条件时，打印错误或告警日志。 如果不加节制打印日志，很容易打出满屏日志，严重的可能造成JVM崩溃 // 超过一定时间未连接上，才打印异常日志。并且，仅打印一次。默认15分钟 String errorMsg = \"client reconnect to \" + getUrl().getAddress() + \" find error . url: \" + getUrl(); // wait registry sync provider list if (System.currentTimeMillis() - lastConnectedTime &gt; shutdown_timeout) &#123; if (!reconnect_error_log_flag.get()) &#123; reconnect_error_log_flag.set(true); logger.error(errorMsg, t); return; &#125; &#125; // 按照一定的重连次数，打印告警日志 if (reconnect_count.getAndIncrement() % reconnect_warning_period == 0) &#123; logger.warn(errorMsg, t); &#125; &#125; &#125; &#125;; // 发起重连定时任务，定时检查是否需要重连 [默认两秒检查一次] reconnectExecutorFuture = reconnectExecutorService.scheduleWithFixedDelay(connectStatusCheckCommand, reconnect, reconnect, TimeUnit.MILLISECONDS); &#125; &#125; 断线重连机制就是在客户端连接服务端时，会创建后台任务，定时检查连接，若断开会进行重连。 发送消息1234567891011121314151617181920212223--- AbstractClient /** * 发送消息 * * @param message * @param sent true: 会等待消息发出，消息发送失败会抛出异常； false: 不等待消息发出，将消息放入IO队列，即可返回 * @throws RemotingException */ @Override public void send(Object message, boolean sent) throws RemotingException &#123; // 未连接时，并且开启了发送消息断开重连功能，则先发起连接 if (send_reconnect &amp;&amp; !isConnected()) &#123; connect(); &#125; // 获取通道，如 NettyChannel 实例，该实例内部channel实例就是 NioClientSocketChannel。 Channel channel = getChannel(); //TODO Can the value returned by getChannel() be null? need improvement. if (channel == null || !channel.isConnected()) &#123; throw new RemotingException(this, \"message can not send, because channel is closed . url:\" + getUrl()); &#125; // 发送消息 channel.send(message, sent); &#125; 客户端连接服务时只会有对应的一个 Channel 通道，客户端发送消息时使用的是 Dubbo 接入具体NIO库的 Channel 实例，如 NettyChannel 实例，它内部封装的 Channel 实例是 Netty 的通道实例 NioClientSocketChannel 。这个在后面的文章中详细说明。 断开连接该方法目前用在 reconnect() 重连方法和 close() 关闭方法中。 12345678910111213141516171819202122232425public void disconnect() &#123; // 加锁 connectLock.lock(); try &#123; // 1 关闭断线重连任务 destroyConnectStatusCheckCommand(); try &#123; // 2 关闭连接服务的通道 Channel channel = getChannel(); if (channel != null) &#123; channel.close(); &#125; &#125; catch (Throwable e) &#123; logger.warn(e.getMessage(), e); &#125; try &#123; // 3 清除通道缓存(Dubbo 层面的 Channel，该Channel 内部封装了NIO库的Channel，它们是一对一关系) doDisConnect(); &#125; catch (Throwable e) &#123; logger.warn(e.getMessage(), e); &#125; &#125; finally &#123; connectLock.unlock(); &#125; &#125; 重连先断开连接，在进行连接。 1234567@Overridepublic void reconnect() throws RemotingException &#123; // 1 先断开连接 disconnect(); // 2 连接 connect();&#125; 关闭12345678910111213141516171819202122232425262728293031@Override public void close() &#123; try &#123; // 1 关闭线程池 if (executor != null) &#123; ExecutorUtil.shutdownNow(executor, 100); &#125; &#125; catch (Throwable e) &#123; logger.warn(e.getMessage(), e); &#125; try &#123; // 2 标记通道关闭完成 super.close(); &#125; catch (Throwable e) &#123; logger.warn(e.getMessage(), e); &#125; try &#123; // 3 断开连接 disconnect(); &#125; catch (Throwable e) &#123; logger.warn(e.getMessage(), e); &#125; try &#123; //4 执行关闭 doClose(); &#125; catch (Throwable e) &#123; logger.warn(e.getMessage(), e); &#125; &#125; 超时关闭对线程池超时关闭 12345@Override public void close(int timeout) &#123; ExecutorUtil.gracefulShutdown(executor, timeout); close(); &#125; 抽象通道 AbstractChannelAbstractChannel 同样继承了 AbstractPeer 这个抽象类，同时还实现了 Channel 接口。AbstractChannel 实现非常简单，只是在 send() 方法中检测了底层连接的状态，没有实现具体的发送消息的逻辑。注意，一般情况下 Dubbo 层面的 Channel 和 具体NIO库的通道是一对一的关系，前者会对后者进行装饰，前者的功能本质上是后者的职能。 1234567891011121314151617181920public abstract class AbstractChannel extends AbstractPeer implements Channel &#123; // 关联了 ChannelHandler public AbstractChannel(URL url, ChannelHandler handler) &#123; super(url, handler); &#125; /** * 发送消息，在这里只做底层连接状态检查，没有实现具体的发送消息的逻辑，具体的发送逻辑由子类实现 * @param message * @param sent true: 会等待消息发出，消息发送失败会抛出异常； false: 不等待消息发出，将消息放入IO队列，即可返回 * @throws RemotingException */ @Override public void send(Object message, boolean sent) throws RemotingException &#123; if (isClosed()) &#123; throw new RemotingException(this, \"Failed to send message \" + (message == null ? \"\" : message.getClass().getName()) + \":\" + message + \", cause: Channel closed. channel: \" + getLocalAddress() + \" -&gt; \" + getRemoteAddress()); &#125; &#125;&#125; 继承关系图如下： 各子类实现会对 send 方法进行重写。 ChannelHandler前文介绍的 AbstractEndpoint、AbstractChannel 都是通过对 AbstractPeer 继承间接实现了 ChannelHandler 接口并关联了 ChannelHandler 对象，仅仅是对 ChannelHandler 的装饰，方法都是委托给底层关联的这个 ChannelHandler 对象。下面我们对 Transporter 层相关的 ChannelHandler 进行详细分析。继承关系如下图所示： ChannelHandlerAdapterChannelHandlerAdapter 是 ChannelHandler 的一个空实现，TelnetHandlerAdapter 继承了它并实现了 TelnetHandler 接口，用于支持 Dubbo 命令行的服务治理。关于 Telnet 的实现，会在后面单独进行介绍，这里就不展开说明了。 1234567891011121314151617181920212223242526/** * ChannelHandlerAdapter. 实现ChannelHandler接口，通道处理器适配器，每个方法都是空实现。子类可根据具体场景选择性实现所需方法。 */public class ChannelHandlerAdapter implements ChannelHandler &#123; @Override public void connected(Channel channel) throws RemotingException &#123; &#125; @Override public void disconnected(Channel channel) throws RemotingException &#123; &#125; @Override public void sent(Channel channel, Object message) throws RemotingException &#123; &#125; @Override public void received(Channel channel, Object message) throws RemotingException &#123; &#125; @Override public void caught(Channel channel, Throwable exception) throws RemotingException &#123; &#125;&#125; ChannelHandlerDispatcher在前面的文章中有提到过 ChannelHandlerDispatcher，它维护了一个 CopyOnWriteArraySet 集合，负责将多个 ChannelHandler 对象聚合成一个 ChannelHandler 对象。 123456789101112131415161718192021222324public class ChannelHandlerDispatcher implements ChannelHandler &#123; private static final Logger logger = LoggerFactory.getLogger(ChannelHandlerDispatcher.class); /** * 通道处理器集合 */ private final Collection&lt;ChannelHandler&gt; channelHandlers = new CopyOnWriteArraySet&lt;ChannelHandler&gt;(); public ChannelHandlerDispatcher() &#123; &#125; public ChannelHandlerDispatcher(ChannelHandler... handlers) &#123; this(handlers == null ? null : Arrays.asList(handlers)); &#125; public ChannelHandlerDispatcher(Collection&lt;ChannelHandler&gt; handlers) &#123; if (handlers != null &amp;&amp; !handlers.isEmpty()) &#123; this.channelHandlers.addAll(handlers); &#125; &#125; // 省略对 ChannelHandler 接口方法的实现&#125; ChannelHandlerDispatcher 实现了 ChannelHandler 接口中的所有方法，每个方法都是循环通道集合调用相应的方法。 ChannelHandlerDelegate实现 ChannelHandler 接口，通道处理器装饰者接口，即是对其它 ChannelHandler 进行装饰的接口，这个接口非常重要。 12345678public interface ChannelHandlerDelegate extends ChannelHandler &#123; /** * 获取装饰的ChannelHandler * * @return */ ChannelHandler getHandler();&#125; ChannelHandlerDelegate 有三个直接的实现类，分别是 AbstractChannelHandlerDelegate、WrappedChannelHandler 和 HeaderExchangeHandler ，它们就是对其它 ChannelHandler 的装饰。其中 HeaderExchangeHandler 是 Exchange 层涉及的对象，我们先不讨论。我们先来分析 AbstractChannelHandlerDelegate 继承体系。 AbstractChannelHandlerDelegate123456789101112131415161718192021222324252627282930313233343536373839404142public abstract class AbstractChannelHandlerDelegate implements ChannelHandlerDelegate &#123; // 装饰的 ChannelHandler protected ChannelHandler handler; protected AbstractChannelHandlerDelegate(ChannelHandler handler) &#123; Assert.notNull(handler, \"handler == null\"); this.handler = handler; &#125; @Override public ChannelHandler getHandler() &#123; if (handler instanceof ChannelHandlerDelegate) &#123; return ((ChannelHandlerDelegate) handler).getHandler(); &#125; return handler; &#125; @Override public void connected(Channel channel) throws RemotingException &#123; handler.connected(channel); &#125; @Override public void disconnected(Channel channel) throws RemotingException &#123; handler.disconnected(channel); &#125; @Override public void sent(Channel channel, Object message) throws RemotingException &#123; handler.sent(channel, message); &#125; @Override public void received(Channel channel, Object message) throws RemotingException &#123; handler.received(channel, message); &#125; @Override public void caught(Channel channel, Throwable exception) throws RemotingException &#123; handler.caught(channel, exception); &#125;&#125; 实现 ChannelHandlerDelegate 接口，在每个实现的方法里都是直接调用被装饰的 ChannelHandler 对象对应的方法，没有其它逻辑。它的三个子类都是在被装饰的 ChannelHandler 的基础上添加了一些增强的功能，使用的是装饰者模式。因为 HeartbeatHandler 属于 Exchange 层的 ChannelHandler ，在分析 Exchange 层时再进行分析，这里不再展开说明。 DecodeHandler123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class DecodeHandler extends AbstractChannelHandlerDelegate &#123; private static final Logger log = LoggerFactory.getLogger(DecodeHandler.class); public DecodeHandler(ChannelHandler handler) &#123; super(handler); &#125; /** * 覆写了 received(channel,message)方法 * * @param channel * @param message RpcInvocation 或 RpcResult * @throws RemotingException * @see com.alibaba.dubbo.rpc.protocol.dubbo.DubboCodec#decodeBody(com.alibaba.dubbo.remoting.Channel, java.io.InputStream, byte[]) */ @Override public void received(Channel channel, Object message) throws RemotingException &#123; // 当消息是 Decodeable 类型时 进行解码 if (message instanceof Decodeable) &#123; decode(message); &#125; // 当消息是Request类型时，对 data 字段进行解码 if (message instanceof Request) &#123; decode(((Request) message).getData()); &#125; // 当消息是Response类型时，对 result 字段进行解码 if (message instanceof Response) &#123; decode(((Response) message).getResult()); &#125; // 解码后，调用ChannelHandler#received(channel,message)方法，将消息交给委托的handler继续处理 handler.received(channel, message); &#125; /** * 解析消息 * * @param message */ private void decode(Object message) &#123; /** * Decodeable 接口目前有两个实现类： * 1 DecodeableRpcInvocation * 2 DecodeableRpcResult */ if (message != null &amp;&amp; message instanceof Decodeable) &#123; try &#123; // 解析消息 ((Decodeable) message).decode(); if (log.isDebugEnabled()) &#123; log.debug(\"Decode decodeable message \" + message.getClass().getName()); &#125; &#125; catch (Throwable e) &#123; if (log.isWarnEnabled()) &#123; log.warn(\"Call Decodeable.decode failed: \" + e.getMessage(), e); &#125; &#125; // ~ end of catch &#125; // ~ end of if &#125; // ~ end of method decode&#125; DecodeHandler 是一个解码处理器，专门用于处理 Decodeable 类型消息的 ChannelHandler实现类，因此该实现类只重写了 received() 接收消息的方法，它的作用和含义如下： 请求解码可在IO线程上执行，也可在线程池中执行，取决于配置。DecodeHandler 存在的意义就是保证请求体或响应体可在线程池中被解码。 在Codec2解码器实现中，如果请求体和响应结果需要在线程池中进行解码，那么就不进行直接解码，而是把解码任务最终交给线程池来处理，最后由 DecodeHandler来处理，因为 DecodeHandler 也参与了对上层 ChannelHandler 的包装。 实现了 Decodeable 接口的类都会提供了一个 decode() 方法实现对自身的解码，DecodeHandler.received() 方法就是通过该方法得到解码后的消息，然后传递给底层的 ChannelHandler 对象继续处理。 MultiMessageHandler1234567891011121314151617181920212223242526272829public class MultiMessageHandler extends AbstractChannelHandlerDelegate &#123; public MultiMessageHandler(ChannelHandler handler) &#123; super(handler); &#125; /** * 覆写了 received方法 * * @param channel * @param message * @throws RemotingException */ @SuppressWarnings(\"unchecked\") @Override public void received(Channel channel, Object message) throws RemotingException &#123; // 消息类型是MultiMessage，即多消息 if (message instanceof MultiMessage) &#123; MultiMessage list = (MultiMessage) message; // 循环提交给handler处理 for (Object obj : list) &#123; handler.received(channel, obj); &#125; // 如果是单消息时，直接提交给handler处理 &#125; else &#123; handler.received(channel, message); &#125; &#125;&#125; MultiMessageHandler 是专门处理 MultiMessage 类型消息的 ChannelHandler 实现类。MultiMessage 是 Exchange 层的一种消息类型，它其中封装了多个消息。在 MultiMessageHandler 收到 MultiMessage 消息的时候，received() 方法会遍历其中的所有消息，并交给底层的 ChannelHandler 对象进行处理。 至此，Transport 层的 AbstractChannelHandlerDelegate 继承体系分析完毕。下面我们继续看 ChannelHandlerDelegate 的另一条继承体系分支。 WrappedChannelHandlerWrappedChannelHandler 也实现了 ChannelHandlerDelegate 接口，也是对其它 ChannelHandler 装饰的类。WrappedChannelHandler 在 ChannelHandler 接口方法实现上和 AbstractChannelHandlerDelegate 基本一致，那为什么又要搞一个新的继承体系而不是直接继承 AbstractChannelHandlerDelegate 呢？因为 WrappedChannelHandler 继承体系不仅是对其它 ChannelHandler 的装饰而且还决定了 Dubbo 的线程模型，有关 Dubbo 中的线程池会单独分析，这里先不展开说明。WrappedChannelHandler 关联体系如下图所示： 从上图可知，每个 WrappedChannelHandler 的子类都有一个对应的 Dispatcher 实现类，这些实现类就是用来创建 WrappedChannelHandler 的子类们。 Dispatcher 接口已经在 远程通信模块总览 中已经介绍过，它主要支持了 Dubbo 的线程模型，通过它的实现类可以创建不同的 ChannelHandler 来决定消息是交给线程池处理还是IO线程处理。 WrappedChannelHandler 实现了 ChannelHandlerDelegate 接口，其子类实现了消息派发功能，即决定了 Dubbo 以哪种线程模型处理收到的事件和消息。每个子类都由对应的Dispatcher 实现类创建。 属性 12345678910111213141516171819202122public class WrappedChannelHandler implements ChannelHandlerDelegate &#123; protected static final Logger logger = LoggerFactory.getLogger(WrappedChannelHandler.class); /** * 共享线程池 */ protected static final ExecutorService SHARED_EXECUTOR = Executors.newCachedThreadPool(new NamedThreadFactory(\"DubboSharedHandler\", true)); /** * 当前端点关联的线程池 */ protected final ExecutorService executor; /** * 被装饰的通道处理器 */ protected final ChannelHandler handler; /** * URL */ protected final URL url;&#125; WrappedChannelHandler 中有四个核心的属性，因为是对 ChannelHandler 的装饰，因此 ChannelHandler 是必须的。需要说明的是共享线程池和当前端点关联的线程池，共享线程池对每个子类公用，当前端点关联的线程池属于每个子类对象独有，它是在构造方法中初始化的。 构造方法 123456789101112131415161718192021222324--- WrappedChannelHandler public WrappedChannelHandler(ChannelHandler handler, URL url) &#123; // 赋值 this.handler = handler; this.url = url; // 基于SPI机制创建线程池 executor = (ExecutorService) ExtensionLoader.getExtensionLoader(ThreadPool.class).getAdaptiveExtension().getExecutor(url); // 默认是 ExecutorService 的名称 String componentKey = Constants.EXECUTOR_SERVICE_COMPONENT_KEY; // 如果是消费端，则 componentKey 为 'consumer' if (Constants.CONSUMER_SIDE.equalsIgnoreCase(url.getParameter(Constants.SIDE_KEY))) &#123; componentKey = Constants.CONSUMER_SIDE; &#125; // 基于SPI机制创建线程池存储对象 DataStore dataStore = ExtensionLoader.getExtensionLoader(DataStore.class).getDefaultExtension(); // 添加线程池到 DataStore中 dataStore.put(componentKey, Integer.toString(url.getPort()), executor); &#125; 通过 WrappedChannelHandler 的构造方法可知，每个子类对象都会创建一个线程池并添加到 DataStore 缓存起来，我们上面介绍的 AbstractClient 和 AbstractServer 是从 DataStore 获得线程池的，而数据来源正是这里。关于线程池的介绍，会在后面的文章中详细分析，这里先不展开说明。 DataSource 核心就是一个 Map 结构缓存，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142// SimpleDataStore 是 DataStore 唯一扩展实现public class SimpleDataStore implements DataStore &#123; /** * key1: ExecutorService 的名称 或 'consumer' * key2: port * value: ExecutorService */ private ConcurrentMap&lt;String, ConcurrentMap&lt;String, Object&gt;&gt; data = new ConcurrentHashMap&lt;String, ConcurrentMap&lt;String, Object&gt;&gt;(); @Override public Map&lt;String, Object&gt; get(String componentName) &#123; ConcurrentMap&lt;String, Object&gt; value = data.get(componentName); if (value == null) return new HashMap&lt;String, Object&gt;(); return new HashMap&lt;String, Object&gt;(value); &#125; @Override public Object get(String componentName, String key) &#123; if (!data.containsKey(componentName)) &#123; return null; &#125; return data.get(componentName).get(key); &#125; @Override public void put(String componentName, String key, Object value) &#123; Map&lt;String, Object&gt; componentData = data.get(componentName); if (null == componentData) &#123; data.putIfAbsent(componentName, new ConcurrentHashMap&lt;String, Object&gt;()); componentData = data.get(componentName); &#125; componentData.put(key, value); &#125; @Override public void remove(String componentName, String key) &#123; if (!data.containsKey(componentName)) &#123; return; &#125; data.get(componentName).remove(key); &#125;&#125; 获取线程池 获取线程池，供子类使用调用。 1234567891011121314--- WrappedChannelHandler/** * 获取当前端点关联的公共线程池，部分子类会使用 * * @return */ public ExecutorService getExecutorService() &#123; ExecutorService cexecutor = executor; // 当前端点关联的线程池为空或关闭就使用共享的 if (cexecutor == null || cexecutor.isShutdown()) &#123; cexecutor = SHARED_EXECUTOR; &#125; return cexecutor; &#125; WrappedChannelHandler 实现 ChannelHandler 接口的方法都是直接调用装饰的 ChannelHandler 对应的方法，就不再进行分析。 线程模型如果事件处理的逻辑能迅速完成，并且不会发起新的 IO 请求，比如只是在内存中记个标识，则直接在 IO 线程上处理更快，因为减少了线程池调度。但如果事件处理逻辑较慢，或者需要发起新的 IO 请求，比如需要查询数据库，则必须派发到线程池，否则 IO 线程阻塞，将导致不能接收其它请求。因此，需要通过不同的派发策略和不同的线程池配置的组合来应对不同的场景: 1&lt;dubbo:protocol name=\"dubbo\" dispatcher=\"all\" threadpool=\"fixed\" threads=\"100\" /&gt; Dubbo 的线程模型需要具有线程派发能力的 ChannelHandler 和 定制化的线程池来支撑。Dispatcher 的职责就是用来创建具有线程派发能力的 ChannelHandler，其本身并不具备线程派发能力。关于 Dispatcher 在 远程通信模块总览 中已经介绍，这里不再重复说明。 Dispatcher 派发策略： all: 所有消息都派发到线程池，包括请求，响应，连接事件，断开事件，心跳等。 direct: 所有消息都不派发到线程池，全部在 IO 线程上直接执行。 message: 只有请求响应消息派发到线程池，其它连接断开事件，心跳等消息，直接在 IO 线程上执行。 execution: 只有请求消息派发到线程池，不含响应，响应和其它连接断开事件，心跳等消息，直接在 IO 线程上执行。 connection: 在 IO 线程上，将连接断开事件放入队列，有序逐个执行，其它消息派发到线程池。 关于线程池部分在后面的文章中详细说明，先不在这里展开介绍。 Dispatcher 实现类用来创建 WrappedChannelHandler 的子类对象，每个子类对象代表不同的派发策略，同时子类对象在创建的时候会初始化一个线程池。下面我们来分析 Dispatcher 扩展实现和对应的 WrappedChannelHandler 的子类。 AllDispatcher &amp; AllChannelHandlerAllDispatcher 用来创建 AllChannelHandler 对象，代码如下： 12345678910111213public class AllDispatcher implements Dispatcher &#123; public static final String NAME = \"all\"; /** * 创建 AllChannelHandler 对象 * @param handler * @param url * @return */ @Override public ChannelHandler dispatch(ChannelHandler handler, URL url) &#123; return new AllChannelHandler(handler, url); &#125;&#125; AllChannelHandler 实现 WrappedChannelHandler 抽象类，所有消息都派发到线程池，包括请求，响应，连接事件，断开事件，心跳等，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293public class AllChannelHandler extends WrappedChannelHandler &#123; // 构造方法调用父类方法，创建独享的线程池 public AllChannelHandler(ChannelHandler handler, URL url) &#123; super(handler, url); &#125; /** * 处理连接事件 * * @param channel * @throws RemotingException */ @Override public void connected(Channel channel) throws RemotingException &#123; // 获取线程池 ExecutorService cexecutor = getExecutorService(); try &#123; // 将CONNECTED 事件的处理封装成ChannelEventRunnable提交到线程池中执行 cexecutor.execute(new ChannelEventRunnable(channel, handler, ChannelState.CONNECTED)); &#125; catch (Throwable t) &#123; throw new ExecutionException(\"connect event\", channel, getClass() + \" error when process connected event .\", t); &#125; &#125; /** * 处理断开连接事件 * * @param channel * @throws RemotingException */ @Override public void disconnected(Channel channel) throws RemotingException &#123; // 获取线程池 ExecutorService cexecutor = getExecutorService(); try &#123; // 创建ChannelEventRunnable对象，用于将断开连接事件任务派发到线程池执行 cexecutor.execute(new ChannelEventRunnable(channel, handler, ChannelState.DISCONNECTED)); &#125; catch (Throwable t) &#123; throw new ExecutionException(\"disconnect event\", channel, getClass() + \" error when process disconnected event .\", t); &#125; &#125; /** * 接收到的所有消息都派发到线程池。注意这里的message 可能是 Request也可能是 Response。 * 流程大概是：消息先由IO线程（Netty 中的EventLoopGroup ）从二进制流中解码出来，然后执行到该方法会把请求提交给线程池处理，处理完后调用send 方法用于向对端写回结果。 * * @param channel * @param message * @throws RemotingException */ @Override public void received(Channel channel, Object message) throws RemotingException &#123; ExecutorService cexecutor = getExecutorService(); try &#123; // 将请求/响应消息派发到线程池中处理，ChannelEventRunnable对象作为任务体 cexecutor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message)); &#125; catch (Throwable t) &#123; // 如果是请求消息，并且出现了线程池满了的异常 if (message instanceof Request &amp;&amp; t instanceof RejectedExecutionException) &#123; Request request = (Request) message; // 如果通信方式为双向通信，将错误信息封装到Response 中，并返回给服务消费方。防止消费端等待超时 if (request.isTwoWay()) &#123; String msg = \"Server side(\" + url.getIp() + \",\" + url.getPort() + \") threadpool is exhausted ,detail msg:\" + t.getMessage(); Response response = new Response(request.getId(), request.getVersion()); response.setStatus(Response.SERVER_THREADPOOL_EXHAUSTED_ERROR); response.setErrorMessage(msg); // 返回包含错误信息的 Response 对象 channel.send(response); return; &#125; &#125; throw new ExecutionException(message, channel, getClass() + \" error when process received event .\", t); &#125; &#125; /** * 处理异常信息 * * @param channel * @param exception * @throws RemotingException */ @Override public void caught(Channel channel, Throwable exception) throws RemotingException &#123; ExecutorService cexecutor = getExecutorService(); try &#123; cexecutor.execute(new ChannelEventRunnable(channel, handler, ChannelState.CAUGHT, exception)); &#125; catch (Throwable t) &#123; throw new ExecutionException(\"caught event\", channel, getClass() + \" error when process caught event .\", t); &#125; &#125;&#125; AllChannelHandler 重写了 WrappedChannelHandler 中除了发送消息的 sent() 方法之外的其它方法，执行底层的 ChannelHandler 的逻辑都交给线程池处理，请求执行完毕后发送消息 AllChannelHandler 会直接在 IO 线程中进行处理。 ExecutionDispatcher &amp; AllChannelHandlerExecutionDispatcher 用来创建 ExecutionChannelHandler 对象，代码如下： 123456789101112131415public class ExecutionDispatcher implements Dispatcher &#123; public static final String NAME = \"execution\"; /** * 创建 ExecutionChannelHandler 对象 * * @param handler 通道处理 * @param url url * @return */ @Override public ChannelHandler dispatch(ChannelHandler handler, URL url) &#123; return new ExecutionChannelHandler(handler, url); &#125;&#125; ExecutionChannelHandler 实现 WrappedChannelHandler 抽象类，只会将请求消息派发到线程池进行处理。对于响应消息以及其他网络事件（例如，连接建立事件、连接断开事件、心跳消息等），ExecutionChannelHandler 会直接在 IO 线程中进行处理，代码如下： 12345678910111213141516171819202122232425262728293031323334public class ExecutionChannelHandler extends WrappedChannelHandler &#123; // 构造方法调用父类方法，创建独享的线程池 public ExecutionChannelHandler(ChannelHandler handler, URL url) &#123; super(handler, url); &#125; @Override public void received(Channel channel, Object message) throws RemotingException &#123; ExecutorService cexecutor = getExecutorService(); // 请求消息 if (message instanceof Request) &#123; try &#123; cexecutor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message)); &#125; catch (Throwable t) &#123; if (t instanceof RejectedExecutionException) &#123; Request request = (Request) message; if (request.isTwoWay()) &#123; String msg = \"Server side(\" + url.getIp() + \",\" + url.getPort() + \") thread pool is exhausted, detail msg:\" + t.getMessage(); Response response = new Response(request.getId(), request.getVersion()); response.setStatus(Response.SERVER_THREADPOOL_EXHAUSTED_ERROR); response.setErrorMessage(msg); channel.send(response); return; &#125; &#125; throw new ExecutionException(message, channel, getClass() + \" error when process received event.\", t); &#125; &#125; else &#123; // 直接交给装饰的 ChannelHandler 处理 handler.received(channel, message); &#125; &#125;&#125; 由上面代码可知，ExecutionChannelHandler 只重写了 received() 方法并且只处理请求消息，其它方法的调用直接调用父类的，是直接在 IO 线程中进行处理。 DirectDispatcher &amp; DirectChannelHandlerdirect 类型，所有消息都不派发到线程池，全部在 IO 线程上直接执行，相关代码如下： 12345678public class DirectDispatcher implements Dispatcher &#123; public static final String NAME = \"direct\"; @Override public ChannelHandler dispatch(ChannelHandler handler, URL url) &#123; return handler; &#125;&#125; MessageOnlyDispatcher &amp; MessageOnlyChannelHandlerMessageOnlyDispatcher 用来创建 MessageOnlyChannelHandler 对象，代码如下： 123456789101112131415public class MessageOnlyDispatcher implements Dispatcher &#123; public static final String NAME = \"message\"; /** * 创建 MessageOnlyChannelHandler * @param handler 通道处理 * @param url url * @return */ @Override public ChannelHandler dispatch(ChannelHandler handler, URL url) &#123; return new MessageOnlyChannelHandler(handler, url); &#125;&#125; MessageOnlyChannelHandler 实现 WrappedChannelHandler 抽象类，会将所有收到的消息（请求/响应）提交到线程池处理，其他网络事件（连接断开事件，心跳等消息）则是由 IO 线程直接处理，代码如下： 123456789101112131415161718192021222324public class MessageOnlyChannelHandler extends WrappedChannelHandler &#123; // 构造方法调用父类方法，创建独享的线程池 public MessageOnlyChannelHandler(ChannelHandler handler, URL url) &#123; super(handler, url); &#125; /** * 处理读取到的数据 * * @param channel * @param message request/response * @throws RemotingException */ @Override public void received(Channel channel, Object message) throws RemotingException &#123; ExecutorService cexecutor = getExecutorService(); try &#123; cexecutor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message)); &#125; catch (Throwable t) &#123; throw new ExecutionException(message, channel, getClass() + \" error when process received event .\", t); &#125; &#125;&#125; 由上面代码可知，ExecutionChannelHandler 只重写了 received() 方法，其它方法的调用是直接调用父类的方法，直接在 IO 线程中进行处理。 ConnectionOrderedDispatcher &amp; ConnectionOrderedChannelHandlerConnectionOrderedDispatcher 用来创建 ConnectionOrderedChannelHandler 对象，代码如下： 12345678910111213141516public class ConnectionOrderedDispatcher implements Dispatcher &#123; public static final String NAME = \"connection\"; /** * 创建 ConnectionOrderedChannelHandler 对象 * * @param handler 通道处理 * @param url url * @return */ @Override public ChannelHandler dispatch(ChannelHandler handler, URL url) &#123; return new ConnectionOrderedChannelHandler(handler, url); &#125;&#125; ConnectionOrderedChannelHandler 实现 WrappedChannelHandler 抽象类，会将收到的消息交给线程池进行处理，对于连接建立以及断开事件是通过 IO 线程将连接、断开事件交给 connectionExecutor 线程池排队处理的，代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788public class ConnectionOrderedChannelHandler extends WrappedChannelHandler &#123; /** * 处理连接建立和断开事件的线程池，线程池线程数只有一个，因此任务多的情况会先堆积到阻塞队列进行排队，有序执行 */ protected final ThreadPoolExecutor connectionExecutor; /** * 线程池阻塞队列告警阈值 */ private final int queuewarninglimit; public ConnectionOrderedChannelHandler(ChannelHandler handler, URL url) &#123; // 调用父类构造方法，创建独享的线程池 super(handler, url); // 从 'threadname' 配置项获取线程池名，默认为 Dubbo String threadName = url.getParameter(Constants.THREAD_NAME_KEY, Constants.DEFAULT_THREAD_NAME); // 该线程池只有一个线程，并且阻塞队列的长度也是固定的，由配置参数决定 connectionExecutor = new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(url.getPositiveParameter(Constants.CONNECT_QUEUE_CAPACITY, Integer.MAX_VALUE)), new NamedThreadFactory(threadName, true), new AbortPolicyWithReport(threadName, url) ); // 从 'connect.queue.warning.size' 配置项获取线程池阻塞队列告警阈值，默认大小为 1000 queuewarninglimit = url.getParameter(Constants.CONNECT_QUEUE_WARNING_SIZE, Constants.DEFAULT_CONNECT_QUEUE_WARNING_SIZE); &#125; @Override public void connected(Channel channel) throws RemotingException &#123; try &#123; checkQueueLength(); connectionExecutor.execute(new ChannelEventRunnable(channel, handler, ChannelState.CONNECTED)); &#125; catch (Throwable t) &#123; throw new ExecutionException(\"connect event\", channel, getClass() + \" error when process connected event .\", t); &#125; &#125; @Override public void disconnected(Channel channel) throws RemotingException &#123; try &#123; checkQueueLength(); connectionExecutor.execute(new ChannelEventRunnable(channel, handler, ChannelState.DISCONNECTED)); &#125; catch (Throwable t) &#123; throw new ExecutionException(\"disconnected event\", channel, getClass() + \" error when process disconnected event .\", t); &#125; &#125; @Override public void received(Channel channel, Object message) throws RemotingException &#123; ExecutorService cexecutor = getExecutorService(); try &#123; cexecutor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message)); &#125; catch (Throwable t) &#123; //fix, reject exception can not be sent to consumer because thread pool is full, resulting in consumers waiting till timeout. if (message instanceof Request &amp;&amp; t instanceof RejectedExecutionException) &#123; Request request = (Request) message; if (request.isTwoWay()) &#123; String msg = \"Server side(\" + url.getIp() + \",\" + url.getPort() + \") threadpool is exhausted ,detail msg:\" + t.getMessage(); Response response = new Response(request.getId(), request.getVersion()); response.setStatus(Response.SERVER_THREADPOOL_EXHAUSTED_ERROR); response.setErrorMessage(msg); channel.send(response); return; &#125; &#125; throw new ExecutionException(message, channel, getClass() + \" error when process received event .\", t); &#125; &#125; @Override public void caught(Channel channel, Throwable exception) throws RemotingException &#123; ExecutorService cexecutor = getExecutorService(); try &#123; cexecutor.execute(new ChannelEventRunnable(channel, handler, ChannelState.CAUGHT, exception)); &#125; catch (Throwable t) &#123; throw new ExecutionException(\"caught event\", channel, getClass() + \" error when process caught event .\", t); &#125; &#125; // 检查阈值 private void checkQueueLength() &#123; // 排队任务超过阈值打印告警日志 if (connectionExecutor.getQueue().size() &gt; queuewarninglimit) &#123; logger.warn(new IllegalThreadStateException(\"connectionordered channel handler `queue size: \" + connectionExecutor.getQueue().size() + \" exceed the warning limit number :\" + queuewarninglimit)); &#125; &#125;&#125; 和 AllChannelHandler 一样，发送消息由 ConnectionOrderedChannelHandler 直接在 IO 线程中进行处理，区别在于后者的连接建立、断开事件不是通过父类中创建的线程池处理，而是创建了一个排队线程池。之所以叫它排队线程池，是该线程池只有一个线程，并且使用的阻塞队列是有序的。 ChannelEventRunnable 线程派发任务体实现Runnable接口，该任务体被不同的线程派发机制使用。 属性123456789101112131415161718192021222324252627282930313233343536373839404142434445public class ChannelEventRunnable implements Runnable &#123; private static final Logger logger = LoggerFactory.getLogger(ChannelEventRunnable.class); /** * 装饰的通道处理器，会在线程池中处理消息 */ private final ChannelHandler handler; /** * 通道 */ private final Channel channel; /** * 通道状态 */ private final ChannelState state; /** * 消息（可能为空，如连接断开事件） */ private final Object message; /** * 处理异常时，捕获的异常 */ private final Throwable exception; public ChannelEventRunnable(Channel channel, ChannelHandler handler, ChannelState state) &#123; this(channel, handler, state, null); &#125; public ChannelEventRunnable(Channel channel, ChannelHandler handler, ChannelState state, Object message) &#123; this(channel, handler, state, message, null); &#125; public ChannelEventRunnable(Channel channel, ChannelHandler handler, ChannelState state, Throwable t) &#123; this(channel, handler, state, null, t); &#125; public ChannelEventRunnable(Channel channel, ChannelHandler handler, ChannelState state, Object message, Throwable exception) &#123; this.channel = channel; this.handler = handler; this.state = state; this.message = message; this.exception = exception; &#125;&#125; ChannelEventRunnable 中的属性都是由线程派发相关的 ChannelHandler 传入的，不同的派发策略传入的属性不同，通过不同的构造方法也可以看出。 任务体12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091public class ChannelEventRunnable implements Runnable &#123; @Override public void run() &#123; // 检测通道状态，如果是请求或响应消息， 那么state = RECEIVED if (state == ChannelState.RECEIVED) &#123; try &#123; // 将 channel 和 message 传递给 ChannelHandler 对象用于后续的调用。 handler.received(channel, message); &#125; catch (Exception e) &#123; logger.warn(\"ChannelEventRunnable handle \" + state + \" operation error, channel is \" + channel + \", message is \" + message, e); &#125; // 其它通道状态 &#125; else &#123; switch (state) &#123; // 连接事件 case CONNECTED: try &#123; handler.connected(channel); &#125; catch (Exception e) &#123; logger.warn(\"ChannelEventRunnable handle \" + state + \" operation error, channel is \" + channel, e); &#125; break; // 断开连接事件 case DISCONNECTED: try &#123; handler.disconnected(channel); &#125; catch (Exception e) &#123; logger.warn(\"ChannelEventRunnable handle \" + state + \" operation error, channel is \" + channel, e); &#125; break; // 发送消息 case SENT: try &#123; handler.sent(channel, message); &#125; catch (Exception e) &#123; logger.warn(\"ChannelEventRunnable handle \" + state + \" operation error, channel is \" + channel + \", message is \" + message, e); &#125; // 异常处理 case CAUGHT: try &#123; handler.caught(channel, exception); &#125; catch (Exception e) &#123; logger.warn(\"ChannelEventRunnable handle \" + state + \" operation error, channel is \" + channel + \", message is: \" + message + \", exception is \" + exception, e); &#125; break; default: logger.warn(\"unknown state: \" + state + \", message is \" + message); &#125; &#125; &#125; /** * 通道状态 */ public enum ChannelState &#123; /** * CONNECTED - 连接 */ CONNECTED, /** * DISCONNECTED - 断开连接 */ DISCONNECTED, /** * SENT - 发送消息 */ SENT, /** * RECEIVED - 接收请求/响应消息 */ RECEIVED, /** * CAUGHT - 异常 */ CAUGHT &#125;&#125; 该任务体功能和作用如下： 1 请求和响应消息出现频率比其他类型消息高，因此这里对消息类型进行了针对性判断，便于提前处理。2 ChannelEventRunnable 仅是一个中转站，它的 run 方法中并不包含具体的调用逻辑，只是判断对应的通道状态，然后将参数传给装饰的 ChannelHandler 对象进行针对性处理。 至此，ChannelHandlerDelegate 的另一条继承体系分析完毕，Transport 层的主要 ChannelHandler 分析到此结束。 ChannelHandlersChannelHandler 的工具类，主要是对传入的 ChannelHandler 进行层层包装，具体怎么包装的我们看下面的代码。 123456789101112131415161718192021222324252627282930313233343536373839public class ChannelHandlers &#123; /** * 单例 */ private static ChannelHandlers INSTANCE = new ChannelHandlers(); protected ChannelHandlers() &#123; &#125; /** * 包装 * * @param handler * @param url * @return */ public static ChannelHandler wrap(ChannelHandler handler, URL url) &#123; return ChannelHandlers.getInstance().wrapInternal(handler, url); &#125; protected static ChannelHandlers getInstance() &#123; return INSTANCE; &#125; /** * 无论是Client还是Server，在构造方法中都会将传入的ChannelHandler进行包装，为该 ChannelHandler 增加了 Dubbo 消息派发、心跳处理以及多消息处理的功能。 * @param handler * @param url * @return */ protected ChannelHandler wrapInternal(ChannelHandler handler, URL url) &#123; return new MultiMessageHandler( // 多消息处理 new HeartbeatHandler( // 心跳处理 ExtensionLoader.getExtensionLoader(Dispatcher.class) .getAdaptiveExtension() .dispatch(handler, url) // 返回的是一个 ChannelHandlerDelegate 类型的对象，默认是 AllChannelHandler，确定了具体的线程模型 ) ); &#125;&#125; 很容易发现，包装器其实就是前文介绍的 ChannelHandlerDelegate 类型的 ChannelHandler。该包装逻辑无论在 Client 端还是 Server 端都会使用，也就意味着上层传入的 ChannelHandler 会增加很多的逻辑，即支持多消息处理、心跳处理以及支持 Dubbo 线程模型机制。我们在下一篇文章中还会再次介绍，这里先以 netty4 实现的网络通信简单说明。 NettyServer123456public class NettyServer extends AbstractServer implements Server &#123; public NettyServer(URL url, ChannelHandler handler) throws RemotingException &#123; // ChannelHandlers.wrap方法，用来包装 ChannelHandler，实现Dubbo 线程模型等功能 super(url, ChannelHandlers.wrap(handler, ExecutorUtil.setThreadName(url, SERVER_THREAD_POOL_NAME))); &#125;&#125; NettyClient123456public class NettyClient extends AbstractClient &#123; public NettyClient(final URL url, final ChannelHandler handler) throws RemotingException &#123; // wrapChannelHandler方法，用来包装 ChannelHandler，实现Dubbo 线程模型等功能 super(url, wrapChannelHandler(url, handler)); &#125;&#125; 编解码关于 Codec2 扩展接口已经在 远程通信模块总览 中进行了介绍，下面介绍在 Transport 层相关的实现和扩展。 编解码工具类 CodecSupport1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798public class CodecSupport &#123; private static final Logger logger = LoggerFactory.getLogger(CodecSupport.class); /** * 序列化对象集合 * key: 序列化类型编号 &#123;@link Serialization#getContentTypeId()&#125; * value: 序列化对象，如： Hessian2Serialization */ private static Map&lt;Byte, Serialization&gt; ID_SERIALIZATION_MAP = new HashMap&lt;Byte, Serialization&gt;(); /** * 序列化名集合 * key: 序列化类型编号 &#123;@link Serialization#getContentTypeId()&#125; * value: 序列化拓展名，如：hessian2 */ private static Map&lt;Byte, String&gt; ID_SERIALIZATIONNAME_MAP = new HashMap&lt;Byte, String&gt;(); static &#123; // 基于 Dubbo SPI，获取 Serialization 的扩展名列表 Set&lt;String&gt; supportedExtensions = ExtensionLoader.getExtensionLoader(Serialization.class).getSupportedExtensions(); for (String name : supportedExtensions) &#123; // 根据扩展名获取对应的扩展实现 Serialization serialization = ExtensionLoader.getExtensionLoader(Serialization.class).getExtension(name); // 内容类型编号 byte idByte = serialization.getContentTypeId(); if (ID_SERIALIZATION_MAP.containsKey(idByte)) &#123; logger.error(\"Serialization extension \" + serialization.getClass().getName() + \" has duplicate id to Serialization extension \" + ID_SERIALIZATION_MAP.get(idByte).getClass().getName() + \", ignore this Serialization extension\"); continue; &#125; // 以内容编号作为 key,分别缓存序列化扩展实现和扩展实现名 ID_SERIALIZATION_MAP.put(idByte, serialization); ID_SERIALIZATIONNAME_MAP.put(idByte, name); &#125; &#125; private CodecSupport() &#123; &#125; /** * 从缓存中，根据序列化号查找Serialization对象 * * @param id * @return */ public static Serialization getSerializationById(Byte id) &#123; return ID_SERIALIZATION_MAP.get(id); &#125; /** * 通过URL根据SPI机制查找Serialization对象，默认使用 hessian2 * * @param url * @return */ public static Serialization getSerialization(URL url) &#123; return ExtensionLoader.getExtensionLoader(Serialization.class).getExtension(url.getParameter(Constants.SERIALIZATION_KEY, Constants.DEFAULT_REMOTING_SERIALIZATION)); &#125; /** * 查找Serialization对象 * * @param url * @param id * @return * @throws IOException */ public static Serialization getSerialization(URL url, Byte id) throws IOException &#123; Serialization serialization = getSerializationById(id); // 序列化扩展名 String serializationName = url.getParameter(Constants.SERIALIZATION_KEY, Constants.DEFAULT_REMOTING_SERIALIZATION); // 出于安全的目的，针对 JDK 类型的序列化方式，检查连接到服务器的 URL 和实际传输的数据协议是否一致。 if (serialization == null || ((id == 3 || id == 7 || id == 4) &amp;&amp; !(serializationName.equals(ID_SERIALIZATIONNAME_MAP.get(id))))) &#123; throw new IOException(\"Unexpected serialization id:\" + id + \" received from network, please check if the peer send the right id.\"); &#125; return serialization; &#125; /** * 获取反序列化对应的 ObjectInput * * @param url * @param is * @param proto * @return * @throws IOException */ public static ObjectInput deserialize(URL url, InputStream is, byte proto) throws IOException &#123; Serialization s = getSerialization(url, proto); return s.deserialize(url, is); &#125;&#125; 上面代码已经详细注释，整个逻辑分为两点，Dubbo 应用启动时缓存序列化并提供获取序列化的方法。 关于序列化在之前的文章中已经详细介绍过，这里就不再重复说明。 编解码适配器123456789101112131415161718192021222324252627282930313233343536373839public class CodecAdapter implements Codec2 &#123; /** * 被适配的对象 */ private Codec codec; /** * 通过构造方法设置被适配的对象 * * @param codec */ public CodecAdapter(Codec codec) &#123; Assert.notNull(codec, \"codec == null\"); this.codec = codec; &#125; @Override public void encode(Channel channel, ChannelBuffer buffer, Object message) throws IOException &#123; UnsafeByteArrayOutputStream os = new UnsafeByteArrayOutputStream(1024); codec.encode(channel, os, message); buffer.writeBytes(os.toByteArray()); &#125; @Override public Object decode(Channel channel, ChannelBuffer buffer) throws IOException &#123; byte[] bytes = new byte[buffer.readableBytes()]; int savedReaderIndex = buffer.readerIndex(); buffer.readBytes(bytes); UnsafeByteArrayInputStream is = new UnsafeByteArrayInputStream(bytes); Object result = codec.decode(channel, is); buffer.readerIndex(savedReaderIndex + is.position()); return result == Codec.NEED_MORE_INPUT ? DecodeResult.NEED_MORE_INPUT : result; &#125; public Codec getCodec() &#123; return codec; &#125;&#125; CodecAdapter 使用对象适配模式完成对 Codec 类型的适配工作，即将 Codec 适配成 Codec2 。关于适配器模式可以参考 适配器模式 。 编解码继承关系编解码 Codec2 的继承关系如下图所示： 继承关系中包含了各层的编解码实现，本篇文章只介绍 Transport 层相关的实现，其它层相关的实现会在对应的层进行介绍。需要注意的是，Exchange 层的编解码实现依赖了 Transport 层的编解码实现，Protocol 层又依赖了 Exchange 层的编解码实现。可以发现，编解码器的实现通过继承的方式以获得更多的功能，每个编码器实现类编解码消息的逻辑都不一样。 AbstractCodec1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public abstract class AbstractCodec implements Codec2 &#123; private static final Logger logger = LoggerFactory.getLogger(AbstractCodec.class); /** * 静态方法，校验消息长度 * * @param channel * @param size * @throws IOException */ protected static void checkPayload(Channel channel, long size) throws IOException &#123; // 8M int payload = Constants.DEFAULT_PAYLOAD; if (channel != null &amp;&amp; channel.getUrl() != null) &#123; // 获取配置允许最大的消息大小，默认 为 8 * 1024 * 1024; 8M payload = channel.getUrl().getParameter(Constants.PAYLOAD_KEY, Constants.DEFAULT_PAYLOAD); &#125; // 超过允许最大的消息大小，则抛出异常 if (payload &gt; 0 &amp;&amp; size &gt; payload) &#123; ExceedPayloadLimitException e = new ExceedPayloadLimitException(\"Data length too large: \" + size + \", max payload: \" + payload + \", channel: \" + channel); logger.error(e); throw e; &#125; &#125; /** * 获得Serialization对象 * * @param channel * @return */ protected Serialization getSerialization(Channel channel) &#123; return CodecSupport.getSerialization(channel.getUrl()); &#125; /** * 是否为客户端的通道 * * @param channel * @return */ protected boolean isClientSide(Channel channel) &#123; String side = (String) channel.getAttribute(Constants.SIDE_KEY); if (\"client\".equals(side)) &#123; return true; &#125; else if (\"server\".equals(side)) &#123; return false; &#125; else &#123; InetSocketAddress address = channel.getRemoteAddress(); URL url = channel.getUrl(); boolean client = url.getPort() == address.getPort() &amp;&amp; NetUtils.filterLocalHost(url.getIp()).equals( NetUtils.filterLocalHost(address.getAddress() .getHostAddress())); channel.setAttribute(Constants.SIDE_KEY, client ? \"client\" : \"server\"); return client; &#125; &#125; /** * 是否为服务端的通道 * * @param channel * @return */ protected boolean isServerSide(Channel channel) &#123; return !isClientSide(channel); &#125;&#125; 是 Codec2 的抽象实现，提供了公用的一些方法，如校验消息长度是否超过阈值，根据URL获取 Serialization 扩展实现，判断当前通道属于客户端侧还是服务端侧。 TransportCodecTransportCodec 的逻辑简单、粗暴，使用 Serialize 对所有消息直接序列化或者反序列化。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class TransportCodec extends AbstractCodec &#123; @Override public void encode(Channel channel, ChannelBuffer buffer, Object message) throws IOException &#123; // 对 ChannelBuffer 进行装饰获得 Dubbo 输出流 OutputStream output = new ChannelBufferOutputStream(buffer); // 获得用于序列化的ObjectOutput对象 ObjectOutput objectOutput = getSerialization(channel).serialize(channel.getUrl(), output); // 将消息写入 ObjectOutput encodeData(channel, objectOutput, message); objectOutput.flushBuffer(); // 释放，kryo 的 KryoObjectInput 和 KryoObjectOutput 实现了 Cleanable 接口，需要释放资源。 if (objectOutput instanceof Cleanable) &#123; ((Cleanable) objectOutput).cleanup(); &#125; &#125; @Override public Object decode(Channel channel, ChannelBuffer buffer) throws IOException &#123; // 对 ChannelBuffer 进行装饰获得 Dubbo 输入流 InputStream input = new ChannelBufferInputStream(buffer); // 获得用于反序列的 ObjectInput 对象 ObjectInput objectInput = getSerialization(channel).deserialize(channel.getUrl(), input); // 从 ObjectInput 读取消息并反序列化为 对象 Object object = decodeData(channel, objectInput); if (objectInput instanceof Cleanable) &#123; ((Cleanable) objectInput).cleanup(); &#125; return object; &#125; protected void encodeData(Channel channel, ObjectOutput output, Object message) throws IOException &#123; encodeData(output, message); &#125; protected Object decodeData(Channel channel, ObjectInput input) throws IOException &#123; return decodeData(input); &#125; protected void encodeData(ObjectOutput output, Object message) throws IOException &#123; output.writeObject(message); &#125; protected Object decodeData(ObjectInput input) throws IOException &#123; try &#123; return input.readObject(); &#125; catch (ClassNotFoundException e) &#123; throw new IOException(\"ClassNotFoundException: \" + StringUtils.toString(e)); &#125; &#125;&#125; 小结本篇文章简单介绍了 Transport 层及其必要性，然后从端点抽象类 AbstractPeer、AbstractEndpoint，语义端点抽象类 AbstractServer、AbstractServer，抽象通道 AbstractChannel 以及 通道关联的 ChannelHandler 多方面介绍了 Transport 层的实现，最后介绍了编解码的继承体系。不难发现，作为底层的 Transport，支持了消息/事件发送、处理、响应以及编解码，涉及的接口和类在功能层面上已经是一个闭环了。后面两篇文章会对本篇文章的抽象进行具体化。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"Dubbo源码分析 - Buffer缓冲区","slug":"rpc/Buffer缓冲区","date":"2020-05-17T16:00:00.000Z","updated":"2020-11-21T08:23:29.506Z","comments":false,"path":"posts/e79185fb/","link":"","permalink":"https://gentryhuang.com/posts/e79185fb/","excerpt":"","text":"前言本篇文章继续说明 Remoting 层中的 buffer 包相关抽象及实现。在序列化层中虽然不会直接和 Buffer 缓冲区交互，但是序列化和反序列化方法所需的参数底层一般都是 Buffer 缓冲区。 概述缓冲区在NIO框架中是一个必要的角色，在各个 NIO 框架中都有自己的缓冲区实现。如，Java NIO 的 ByteBuffer、Mina 的 IoBuffer 以及 Netty4 的 ByteBuf等。Dubbo 抽象出了 ChannelBuffer 接口用于对底层 NIO 框架的缓冲区进行统一。相关的 UML 图如下： Dubbo 不仅抽象出了 ChannelBuffer 接口，还抽象出了对应的工厂 ChannelBufferFactory。 ChannelBuffer 接口ChannelBuffer 接口的设计与 Netty 的 ByteBuf 设计基本一致，也定义了 readerIndex 和 writeIndex 指针。 下面对方法大致归类说明： getBytes()、setBytes() 方法：读/写当前 ChannelBuffer，但是不会修改 readerIndex 和 writerIndex 指针的位置。 readBytes() 、writeBytes() 方法：读/写当前 ChannelBuffer，readBytes() 方法会从 readerIndex 指针开始读取数据，并移动 readerIndex 指针；writeBytes() 方法会从 writerIndex 指针位置开始写入数据，并移动 writerIndex 指针。 markReaderIndex()、markWriterIndex() 方法：分别记录当前 readerIndex 指针和 writerIndex 指针的位置，一般会和 resetReaderIndex()、resetWriterIndex() 方法配合使用，resetReaderIndex() 方法用于将 readerIndex 指针重置到被 markedReaderIndex() 方法标记时的位置，resetwriterIndex() 方法同理。 capacity()、clear()、copy() 等辅助方法用来获取 ChannelBuffer 容量以及实现清理、拷贝数据的功能。 factory() 方法：是 Dubbo 独有的方法，该方法返回创建 ChannelBuffer 的工厂对象。 AbstractChannelBuffer实现了 ChannelBuffer 接口的大部分方法，但是在 AbstractChannelBuffer 实现的方法都是重载的方法，具体功能的方法需要子类实现。 AbstractChannelBuffer 主要维护了四个核心属性： 1234567891011121314151617181920public abstract class AbstractChannelBuffer implements ChannelBuffer &#123; /** * 读取位置 */ private int readerIndex; /** * 写入位置 */ private int writerIndex; /** * 标记的读取位置 */ private int markedReaderIndex; /** * 标记的写入位置 */ private int markedWriterIndex;&#125; readerIndex：通过 readBytes() 方法及其重载读取数据时，会后移该指针。 writerIndex：通过 writeBytes() 方法及其重载写入数据的时候，会后移该指针。 markedReaderIndex：实现记录 readerIndex 指针以及用于回滚 readerIndex 指针的功能。 markedWriterIndex：实现记录 writerIndex 指针以及用于回滚 writerIndex 指针的功能。 其中，AbstractChannelBuffer 中还定义了用于动态扩容的 ensureWritableBytes 方法，目前只有 DynamicChannelBuffer 、NettyBackedChannelBuffer（Dubbo 的 Netty3 和 Netty4 ChannelBuffer实现）实现。 需要注意，AbstractChannelBuffer 中 readBytes() 和 writeBytes() 方法的各个重载最终会通过 getBytes() 方法和 setBytes() 方法实现数据的读写，这些方法需要在 AbstractChannelBuffer 的子类中实现。下面以读写一个 byte 数组为例进行说明，其它都类似。 1234567891011121314151617181920--- AbstractChannelBuffer // 从 buffer 中读取长度为 length 的字节放到 dst字节数组中 @Override public void readBytes(byte[] dst, int dstIndex, int length) &#123; // 检测读取字节长度是否超过可读长度，超过则抛出异常 checkReadableBytes(length); // 将readerIndex之后的length个字节数读取到dst数组中，从 dst数组的 dstIndex 位置开始，长度为 length getBytes(readerIndex, dst, dstIndex, length); // 将readerIndex后移length个字节 readerIndex += length; &#125; // 将 src 字节数组中 [scrIndex-scrIndex+leng] 范围数据写入到 buffer 中 @Override public void writeBytes(byte[] src, int srcIndex, int length) &#123; setBytes(writerIndex, src, srcIndex, length); // 将writerIndex 后移 length个字节 writerIndex += length; &#125; 下面简单使用图示说明 ChannelBuffer 中的四个核心属性和容量，图片来源 初始状态 写入 5 个字节后 读取 3 个字节后 ChannelBufferFactory12345678910111213141516171819202122232425public interface ChannelBufferFactory &#123; /** * 获取指定容量的 ChannelBuffer * @param capacity * @return */ ChannelBuffer getBuffer(int capacity); /** * 获取指定偏移量的数据的 ChannelBuffer * @param array * @param offset * @param length * @return */ ChannelBuffer getBuffer(byte[] array, int offset, int length); /** * 根据 java.nio.ByteBuffer 数据获取ChannelBuffer * @param nioBuffer * @return */ ChannelBuffer getBuffer(ByteBuffer nioBuffer);&#125; ChannelBuffer 工厂 DirectChannelBufferFactory123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class DirectChannelBufferFactory implements ChannelBufferFactory &#123; /** * 单例 */ private static final DirectChannelBufferFactory INSTANCE = new DirectChannelBufferFactory(); public DirectChannelBufferFactory() &#123; super(); &#125; public static ChannelBufferFactory getInstance() &#123; return INSTANCE; &#125; @Override public ChannelBuffer getBuffer(int capacity) &#123; if (capacity &lt; 0) &#123; throw new IllegalArgumentException(\"capacity: \" + capacity); &#125; if (capacity == 0) &#123; return ChannelBuffers.EMPTY_BUFFER; &#125; // 使用 ChannelBuffers 工具类创建 ByteBufferBackedChannelBuffer return ChannelBuffers.directBuffer(capacity); &#125; @Override public ChannelBuffer getBuffer(byte[] array, int offset, int length) &#123; if (array == null) &#123; throw new NullPointerException(\"array\"); &#125; if (offset &lt; 0) &#123; throw new IndexOutOfBoundsException(\"offset: \" + offset); &#125; if (length == 0) &#123; return ChannelBuffers.EMPTY_BUFFER; &#125; if (offset + length &gt; array.length) &#123; throw new IndexOutOfBoundsException(\"length: \" + length); &#125; // 调用 getBuffer 方法，使用 ChannelBuffers 工具类创建 ByteBufferBackedChannelBuffer ChannelBuffer buf = getBuffer(length); // 向 buf 中写入数据 buf.writeBytes(array, offset, length); return buf; &#125; @Override public ChannelBuffer getBuffer(ByteBuffer nioBuffer) &#123; if (!nioBuffer.isReadOnly() &amp;&amp; nioBuffer.isDirect()) &#123; return ChannelBuffers.wrappedBuffer(nioBuffer); &#125; // 调用 getBuffer 方法，使用 ChannelBuffers 工具类创建 ByteBufferBackedChannelBuffer ChannelBuffer buf = getBuffer(nioBuffer.remaining()); int pos = nioBuffer.position(); // 向buf中写入数据 buf.writeBytes(nioBuffer); nioBuffer.position(pos); return buf; &#125;&#125; 实现 ChannelBufferFactory 接口，创建 ByteBufferBackedChannelBuffer 的工厂类。 HeapChannelBufferFactory12345678910111213141516171819202122232425262728293031323334353637383940public class HeapChannelBufferFactory implements ChannelBufferFactory &#123; /** * 单例 */ private static final HeapChannelBufferFactory INSTANCE = new HeapChannelBufferFactory(); public HeapChannelBufferFactory() &#123; super(); &#125; public static ChannelBufferFactory getInstance() &#123; return INSTANCE; &#125; //----------- 通过 ChannelBuffers 工具类创建 HeapChannelBuffer 对象 ------/ @Override public ChannelBuffer getBuffer(int capacity) &#123; return ChannelBuffers.buffer(capacity); &#125; @Override public ChannelBuffer getBuffer(byte[] array, int offset, int length) &#123; return ChannelBuffers.wrappedBuffer(array, offset, length); &#125; @Override public ChannelBuffer getBuffer(ByteBuffer nioBuffer) &#123; if (nioBuffer.hasArray()) &#123; return ChannelBuffers.wrappedBuffer(nioBuffer); &#125; ChannelBuffer buf = getBuffer(nioBuffer.remaining()); int pos = nioBuffer.position(); buf.writeBytes(nioBuffer); nioBuffer.position(pos); return buf; &#125;&#125; 实现 ChannelBufferFactory 接口，创建 HeapChannelBufferFactory 的工厂。 NettyBackedChannelBufferFactory12345678910111213141516171819202122232425262728293031323334353637public class NettyBackedChannelBufferFactory implements ChannelBufferFactory &#123; /** * 单例 */ private static final NettyBackedChannelBufferFactory INSTANCE = new NettyBackedChannelBufferFactory(); public static ChannelBufferFactory getInstance() &#123; return INSTANCE; &#125; @Override public ChannelBuffer getBuffer(int capacity) &#123; // 使用 Netty 的 ChannelBuffers 方法创建 org.jboss.netty.buffer.ChannelBuffer return new NettyBackedChannelBuffer(ChannelBuffers.dynamicBuffer(capacity)); &#125; @Override public ChannelBuffer getBuffer(byte[] array, int offset, int length) &#123; // 创建 Netty3 ChannelBuffer 对象 org.jboss.netty.buffer.ChannelBuffer buffer = ChannelBuffers.dynamicBuffer(length); // 写入数据 buffer.writeBytes(array, offset, length); // 创建 NettyBackedChannelBuffer 对象 return new NettyBackedChannelBuffer(buffer); &#125; @Override public ChannelBuffer getBuffer(ByteBuffer nioBuffer) &#123; // 1 使用 Netty 的 ChannelBuffers 方法创建 org.jboss.netty.buffer.ChannelBuffer // 2 创建 NettyBackedChannelBuffer return new NettyBackedChannelBuffer(ChannelBuffers.wrappedBuffer(nioBuffer)); &#125;&#125; 实现 ChannelBufferFactory 接口，创建 NettyBackedChannelBuffer 的工厂。目前 Dubbo 框架中，Netty3 通信框架在使用这个工厂，Netty4 不再使用工厂。 ChannelBuffers123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153import java.nio.ByteBuffer;/** * Buffer 工具类，提供创建，比较 ChannelBuffer 等公用方法 */public final class ChannelBuffers &#123; public static final ChannelBuffer EMPTY_BUFFER = new HeapChannelBuffer(0); private ChannelBuffers() &#123; &#125; //------------------------------ 创建 DynamicChannelBuffer 对象 -------------------------/ public static ChannelBuffer dynamicBuffer() &#123; // 默认大小为 256 return dynamicBuffer(256); &#125; public static ChannelBuffer dynamicBuffer(int capacity) &#123; return new DynamicChannelBuffer(capacity); &#125; public static ChannelBuffer dynamicBuffer(int capacity, ChannelBufferFactory factory) &#123; return new DynamicChannelBuffer(capacity, factory); &#125; //----------------------------- 创建 HeapChannelBuffer 对象 -----------------------------/ public static ChannelBuffer buffer(int capacity) &#123; if (capacity &lt; 0) &#123; throw new IllegalArgumentException(\"capacity can not be negative\"); &#125; if (capacity == 0) &#123; return EMPTY_BUFFER; &#125; return new HeapChannelBuffer(capacity); &#125; public static ChannelBuffer wrappedBuffer(byte[] array, int offset, int length) &#123; if (array == null) &#123; throw new NullPointerException(\"array == null\"); &#125; byte[] dest = new byte[length]; System.arraycopy(array, offset, dest, 0, length); return wrappedBuffer(dest); &#125; public static ChannelBuffer wrappedBuffer(byte[] array) &#123; if (array == null) &#123; throw new NullPointerException(\"array == null\"); &#125; if (array.length == 0) &#123; return EMPTY_BUFFER; &#125; return new HeapChannelBuffer(array); &#125; public static ChannelBuffer wrappedBuffer(ByteBuffer buffer) &#123; if (!buffer.hasRemaining()) &#123; return EMPTY_BUFFER; &#125; // ByteBuffer 中的字节数组是否可访问，可访问就创建 HeapChannelBuffer if (buffer.hasArray()) &#123; return wrappedBuffer(buffer.array(), buffer.arrayOffset() + buffer.position(), buffer.remaining()); // 不可访问就 创建 ByteBufferBackedChannelBuffer &#125; else &#123; return new ByteBufferBackedChannelBuffer(buffer); &#125; &#125; //--------------------------- 创建 ByteBufferBackedChannelBuffer 对象 ------------------------/ public static ChannelBuffer directBuffer(int capacity) &#123; if (capacity == 0) &#123; return EMPTY_BUFFER; &#125; ChannelBuffer buffer = new ByteBufferBackedChannelBuffer(ByteBuffer.allocateDirect(capacity)); buffer.clear(); return buffer; &#125; /** * 用于比较两个 ChannelBuffer 是否相同。 * 注意该方法不能完全确定两个 ChannelBuffer 是否相等，但是可以快速确定两个 ChannelBuffer 不相同。 * * @param bufferA * @param bufferB * @return */ public static boolean equals(ChannelBuffer bufferA, ChannelBuffer bufferB) &#123; // 比较两个ChannelBuffer的可读字节数 final int aLen = bufferA.readableBytes(); if (aLen != bufferB.readableBytes()) &#123; return false; &#125; // aLen &amp; 0111，最大为 7 final int byteCount = aLen &amp; 7; // 获取读取索引 int aIndex = bufferA.readerIndex(); int bIndex = bufferB.readerIndex(); // 最多比较前 7 个字节 for (int i = byteCount; i &gt; 0; i--) &#123; if (bufferA.getByte(aIndex) != bufferB.getByte(bIndex)) &#123; return false; &#125; aIndex++; bIndex++; &#125; return true; &#125; /** * 用于比较两个 ChannelBuffer 的大小，方法中会逐个比较两个 ChannelBuffer 中的全部可读字节 * * @param bufferA * @param bufferB * @return */ public static int compare(ChannelBuffer bufferA, ChannelBuffer bufferB) &#123; final int aLen = bufferA.readableBytes(); final int bLen = bufferB.readableBytes(); final int minLength = Math.min(aLen, bLen); int aIndex = bufferA.readerIndex(); int bIndex = bufferB.readerIndex(); for (int i = minLength; i &gt; 0; i--) &#123; byte va = bufferA.getByte(aIndex); byte vb = bufferB.getByte(bIndex); if (va &gt; vb) &#123; return 1; &#125; else if (va &lt; vb) &#123; return -1; &#125; aIndex++; bIndex++; &#125; return aLen - bLen; &#125;&#125; ChannelBuffers 用来创建 ChannelBuffer 和 比较 ChannelBuffer 。创建的 ChannelBuffer 包括 DynamicChannelBuffer、HeapChannelBuffer、ByteBufferBackedChannelBuffer，不包括 NettyBackedChannelBuffer，Netty 3 的 NettyBackedChannelBuffer 可由工厂创建，Netty 4 的 NettyBackedChannelBuffer 没有工厂，在 Dubbo 中直接使用构造方法创建。 Buffer 实现类前面介绍了 ChannelBuffer 接口以及对应的工厂，并对 ChannelBuffers 工具类进行了介绍，下面我们来分析 ChannelBuffer 的具体实现类。 ByteBufferBackedChannelBuffer1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class ByteBufferBackedChannelBuffer extends AbstractChannelBuffer &#123; /** * 基于 nio 的 Buffer 实现类 */ private final ByteBuffer buffer; /** * 容量 */ private final int capacity; public ByteBufferBackedChannelBuffer(ByteBuffer buffer) &#123; if (buffer == null) &#123; throw new NullPointerException(\"buffer\"); &#125; this.buffer = buffer.slice(); // 设置容量 capacity = buffer.remaining(); // 设置 writerIndex writerIndex(capacity); &#125; public ByteBufferBackedChannelBuffer(ByteBufferBackedChannelBuffer buffer) &#123; this.buffer = buffer.buffer; // 设置容量 capacity = buffer.capacity; // 设置 writerIndex,readerIndex setIndex(buffer.readerIndex(), buffer.writerIndex()); &#125; /** * 创建 ChannelBuf 工厂 * @return */ @Override public ChannelBufferFactory factory() &#123; if (buffer.isDirect()) &#123; return DirectChannelBufferFactory.getInstance(); &#125; else &#123; return HeapChannelBufferFactory.getInstance(); &#125; &#125; // $&#123;省略其它代码&#125;&#125; ByteBufferBackedChannelBuffer 继承了 AbstractChannelBuffer， 是基于 Java NIO 中 ByteBuffer 的 ChannelBuffer 实现类。其中的方法基本都是基于 Java NIO 的 ByteBuffer 的 API 实现的。以 getBytes() 方法和 setBytes() 方法的一个重载为例，进行说明： 123456789101112131415161718192021--- ByteBufferBackedChannelBuffer @Override public void getBytes(int index, byte[] dst, int dstIndex, int length) &#123; // ByteBuffer 的 API ByteBuffer data = buffer.duplicate(); try &#123; data.limit(index + length).position(index); &#125; catch (IllegalArgumentException e) &#123; throw new IndexOutOfBoundsException(); &#125; data.get(dst, dstIndex, length); &#125; @Override public void setBytes(int index, byte[] src, int srcIndex, int length) &#123; // ByteBuffer 的 API ByteBuffer data = buffer.duplicate(); data.limit(index + length).position(index); data.put(src, srcIndex, length); &#125; ByteBufferBackedChannelBuffer 对应的 ChannelBufferFactory 实现有两个，DirectChannelBufferFactory 和 HeapChannelBufferFactory 。DirectChannelBufferFactory 主要用来创建 ByteBufferBackedChannelBuffer 对象的，兜底时才会创建 HeapChannelBuffer；HeapChannelBufferFactory 兜底时会创建 ByteBufferBackedChannelBuffer 对象。 HeapChannelBuffer1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class HeapChannelBuffer extends AbstractChannelBuffer &#123; /** * 字节数组 * * The underlying heap byte array that this buffer is wrapping. */ protected final byte[] array; /** * Creates a new heap buffer with a newly allocated byte array. * * @param length the length of the new byte array */ public HeapChannelBuffer(int length) &#123; this(new byte[length], 0, 0); &#125; /** * Creates a new heap buffer with an existing byte array. * * @param array the byte array to wrap */ public HeapChannelBuffer(byte[] array) &#123; this(array, 0, array.length); &#125; /** * Creates a new heap buffer with an existing byte array. * * @param array the byte array to wrap * @param readerIndex the initial reader index of this buffer * @param writerIndex the initial writer index of this buffer */ protected HeapChannelBuffer(byte[] array, int readerIndex, int writerIndex) &#123; if (array == null) &#123; throw new NullPointerException(\"array\"); &#125; this.array = array; // 设置 readerIndex 和 writerIndex setIndex(readerIndex, writerIndex); &#125; /** * 创建 HeapChannelBufferFactory 工厂 * * @return */ @Override public ChannelBufferFactory factory() &#123; return HeapChannelBufferFactory.getInstance(); &#125; // $&#123;省略其它方法&#125;&#125; HeapChannelBuffer 是基于字节数组的 ChannelBuffer 实现类，数据的存储都是放在 array 字节数组中。读取和写入都是调用 System.arraycopy() 方法完成操作的。 12345678--- HeapChannelBufferpublic void setBytes(int index, byte[] src, int srcIndex, int length) &#123; System.arraycopy(src, srcIndex, array, index, length);&#125;public void getBytes(int index, byte[] dst, int dstIndex, int length) &#123; System.arraycopy(array, index, dst, dstIndex, length);&#125; HeapChannelBuffer 对应的 ChannelBufferFactory 实现是 HeapChannelBufferFactory，前面已经介绍过，内部是使用 ChannelBuffers 工具类来完成创建任务。 DynamicChannelBuffer12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class DynamicChannelBuffer extends AbstractChannelBuffer &#123; /** * ChannelBuffer 工厂，用于创建 ChannelBuffer */ private final ChannelBufferFactory factory; /** * 被修饰的 ChannelBuffer，默认为 HeapChannelBuffer。 */ private ChannelBuffer buffer; /** * 默认 HeapChannelBufferFactory * * @param estimatedLength */ public DynamicChannelBuffer(int estimatedLength) &#123; this(estimatedLength, HeapChannelBufferFactory.getInstance()); &#125; /** * 根据传入的 factory 创建 ChannelBuffer * @param estimatedLength * @param factory */ public DynamicChannelBuffer(int estimatedLength, ChannelBufferFactory factory) &#123; if (estimatedLength &lt; 0) &#123; throw new IllegalArgumentException(\"estimatedLength: \" + estimatedLength); &#125; if (factory == null) &#123; throw new NullPointerException(\"factory\"); &#125; // 设置 factory this.factory = factory; // 创建 buffer buffer = factory.getBuffer(estimatedLength); &#125; @Override public ChannelBufferFactory factory() &#123; return factory; &#125; // $&#123;省略其它代码&#125;&#125; DynamicChannelBuffer 是其他 ChannelBuffer 的装饰器，并且可以为其他 ChannelBuffer 动态扩展容量。扩容时机是，在每次写入数据之前，都需要调用该方法确定当前可用空间是否足够，我们可以看到在 DynamicChannelBuffer 中调用的位置： DynamicChannelBuffer 的 ensureWritableBytes 方法会检查底层 ChannelBuffer 对象的空间是否需要扩容，如果空间不足则创建一个新的 ChannelBuffer（空间扩大为原来的两倍），然后将原来 ChannelBuffer 中的数据拷贝到新 ChannelBuffer 中，最后将 buffer 字段指向新 ChannelBuffer 对象以完成整个扩容操作。方法具体逻辑如下： 1234567891011121314151617181920212223242526272829303132333435--- DynamicChannelBuffer @Override public void ensureWritableBytes(int minWritableBytes) &#123; // 剩余空间充足 if (minWritableBytes &lt;= writableBytes()) &#123; return; &#125; int newCapacity; // 判断当前 ChannelBuffer 容量大小是否为 0 if (capacity() == 0) &#123; newCapacity = 1; &#125; else &#123; // 获取 ChannelBuffer 容量大小 newCapacity = capacity(); &#125; // 计算预计容量大小 int minNewCapacity = writerIndex() + minWritableBytes; // 如果预计容量大于当前 ChannelBuffer 的容量大小，则进行 2 倍容量扩容 while (newCapacity &lt; minNewCapacity) &#123; newCapacity &lt;&lt;= 1; &#125; // 通过工厂创建容量大小为 newCapacity 的 ChannelBuffer ChannelBuffer newBuffer = factory().getBuffer(newCapacity); // 将原来ChannelBuffer 中的数据拷贝到新的 ChannelBuffer 中 newBuffer.writeBytes(buffer, 0, writerIndex()); // 将 buffer 字段指向新 ChannelBuffer 对象 buffer = newBuffer; &#125; NettyBackedChannelBufferNettyBackedChannelBuffer 是基于 Netty 中 ByteBuf 的 ChannelBuffer 实现类，因为 Netty 中的 ByteBuf 内部维护了 readerIndex 、writerIndex 、 markedReaderIndex 、markedWriterIndex 指针，因此该实现类没有继承 AbstractChannelBuffer 抽象类，而是直接实现了 ChannelBuffer 接口。NettyBackedChannelBuffer 操作缓存区的任务都是委托给 Netty 的 ByteBuf 来完成。 下面是 Dubbo 的 Netty 4 模块缓冲区构造方法。 12345678910111213141516171819202122public class NettyBackedChannelBuffer implements ChannelBuffer &#123; /** * Netty 的 ByteBuf - 字节数容器 */ private ByteBuf buffer; public NettyBackedChannelBuffer(ByteBuf buffer) &#123; Assert.notNull(buffer, \"buffer == null\"); this.buffer = buffer; &#125; @Override public ChannelBufferFactory factory() &#123; return null; &#125; // ---------------------------- 该类的实现方法都是直接调用 Netty 的 ByteBuf 对应的方法 -----------------------/ // $&#123;省略其它方法&#125;&#125; 注意，该实现类无需工厂创建，因此 factory() 方法返回为 null 。对于 Netty 3 模块，是有对应的工厂的。 JDK Stream 和 ChannelBufferDubbo 框架的序列化和反序列化是基于 JDK 的 InputStream 和 OutputStream 。 1234567891011121314151617181920212223242526--- Serialization /** * create serializer * &lt;p&gt; * 创建ObjectOutput对象，实现序列化功能，序列化输出到 OutputStream * * @param url URL * @param output 输出流 * @return serializer * @throws IOException */ @Adaptive ObjectOutput serialize(URL url, OutputStream output) throws IOException; /** * create deserializer * &lt;p&gt; * 创建 ObjectInput 对象，实现反序列化，从 InputStream 反序列化 * * @param url URL * @param input 输入流 * @return deserializer * @throws IOException */ @Adaptive ObjectInput deserialize(URL url, InputStream input) throws IOException; 直接使用 JDK Stream 虽然可行，但是效率上有待提升。因此，在 ChannelBuffer 基础上，Dubbo 提供了一套输入输出流，对 ChannelBufer 进行装饰，如下图所示： ChannelBufferInputStream12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * 实现 InputStream 接口 */public class ChannelBufferInputStream extends InputStream &#123; /** * Buffer */ private final ChannelBuffer buffer; /** * 开始位置 */ private final int startIndex; /** * 结束位置 */ private final int endIndex; public ChannelBufferInputStream(ChannelBuffer buffer) &#123; this(buffer, buffer.readableBytes()); &#125; public ChannelBufferInputStream(ChannelBuffer buffer, int length) &#123; if (buffer == null) &#123; throw new NullPointerException(\"buffer\"); &#125; if (length &lt; 0) &#123; throw new IllegalArgumentException(\"length: \" + length); &#125; if (length &gt; buffer.readableBytes()) &#123; throw new IndexOutOfBoundsException(); &#125; // 设置 ChannelBuffer this.buffer = buffer; // 设置 开始位置 为 ChannelBuffer 的读取索引位置 startIndex = buffer.readerIndex(); // 设置 结束位置 endIndex = startIndex + length; // 标记 读取索引位置 buffer.markReaderIndex(); &#125; // $&#123;省略其它代码&#125;&#125; ChannelBufferInputStream 底层装饰了一个 ChannelBuffer，其实现 InputStream 接口的 readXxx() 方法都是从装饰的 ChannelBuffer 中读取数据。ChannelBufferInputStream 中还维护了一个 startIndex 和一个 endIndex 属性，用来记录读取数据的起止位置。 ChannelBufferOutputStream1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class ChannelBufferOutputStream extends OutputStream &#123; /** * 被装饰的 ChannelBuffer */ private final ChannelBuffer buffer; /** * 开始位置 */ private final int startIndex; public ChannelBufferOutputStream(ChannelBuffer buffer) &#123; if (buffer == null) &#123; throw new NullPointerException(\"buffer\"); &#125; // 设置 ChannelBuffer this.buffer = buffer; // 设置 开始位置 为 ChannelBuffer 的写入索引位置 startIndex = buffer.writerIndex(); &#125; /** * 获取装饰的 ChannelBuffer * * @return */ public ChannelBuffer buffer() &#123; return buffer; &#125; /** * 获取写入字节数 * * @return */ public int writtenBytes() &#123; return buffer.writerIndex() - startIndex; &#125; //------------ 写入数据都是委托给被装饰的 ChannelBuffer -------------/ @Override public void write(byte[] b, int off, int len) throws IOException &#123; if (len == 0) &#123; return; &#125; buffer.writeBytes(b, off, len); &#125; @Override public void write(byte[] b) throws IOException &#123; buffer.writeBytes(b); &#125; @Override public void write(int b) throws IOException &#123; buffer.writeByte((byte) b); &#125;&#125; ChannelBufferOutputStream 底层装饰了一个 ChannelBuffer，其实现 OutputStream 接口的 writeXxx() 方法都向被装饰的 ChannelBuffer 中写入数据。ChannelBufferInputStream 中还维护了一个 startIndex 属性，用来记录最初的写入数据的位置。 小结本篇文章介绍了 Remoting 层中的 buffer 包相关抽象及实现。先是介绍 ChannelBuffer 这一缓冲区抽象接口，并说明了其核心方法和属性以及工作原理。接着介绍了其工厂和实现类，并说明了每个实现类的特点。最后分析了 ChannelBuffer 和 JDK 的 InputStream/OutputStream 的联系，结合 Dubbo 中的序列化层进行了说明。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"Dubbo源码分析 - 远程通信模块总览","slug":"rpc/远程通信模块总览","date":"2020-05-09T16:00:00.000Z","updated":"2020-12-17T01:33:48.593Z","comments":false,"path":"posts/95ab077/","link":"","permalink":"https://gentryhuang.com/posts/95ab077/","excerpt":"","text":"前言前面的几篇文章对 Dubbo 的 Serialize 层进行了介绍，它属于 Remoting 层的一部分，相比较同属于 Remoting 层的 Transport 层 和 Exchange 层，Serialize 层在单独的一个模块中，Transport 层 和 Exchange 层在 dubbo-remoting 模块中， 接下来我们对该模块进行总体说明。需要说明的是，整个 Remoting 层实现是 Dubbo 协议的实现，如果选择 RMI 协议，那整个 Remoting 层都不会用上。 概述dubbo-remoting 模块提供了多种客户端和服务端通信的功能，该模块内部可以再划分为 Transport 传输层和 Exchange 信息交换层，Transport 层只负责单向消息传输，是对 Mina, Netty 等网络传输组件的抽象，它也可以扩展 UDP 传输，而 Exchange 层是在传输层之上封装了 Request-Response 语义。 dubbo-remoting 模块结构如下： Dubbo 框架并没有自己实现一套完整的网络库，而是使用第三方开源网络库。dubbo-remoting-api 子模块中定义了远程通信的抽象概念，具体通信功能需要 dubbo-remoting-* 模块来实现，它们依赖第三方 NIO 库实现 dubbo-remoting-api 模块。如 dubbo-remoting-netty 模块依赖 Netty 3 实现 Dubbo 的远程通信。需要说明的是，dubbo-remoting-zookeeper 模块是实现注册中心功能的模块。 远程通信的抽象dubbo-remoting-api 模块是对远程通信的抽象，结构如下图所示： 下面对各个包进行简单说明： buffer 包定义了缓冲区相关的接口、抽象类以及实现。缓存区对于通信框架是一个不可或缺的功能，几乎每个通信框架都有自己的缓存区实现。Dubbo 中的该包是对各个通信框架的缓存区进行了统一的抽象，同时实现了一些基础能力。 exchange 包建立Request-Response模型，封装请求响应模式，以 Request, Response 为中心。 telnet 包Dubbo 支持通过 telnet 命令进行服务治理。 transport 包将网络传输抽象为统一接口，屏蔽了不同网络库的差异，只负责抽象单向消息的传输，以 Message 为中心。即请求消息由 Client 端发出，Server 端接收；响应消息由 Server 端发出，Client端接收。 其它接口顶层接口放到了 remoting 包下，这些接口是 Dubbo Remoting 的核心接口。 远程通信抽象相关UML图如下： 端点 Endpoint12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public interface Endpoint &#123; /** * 关联的 URL 信息 * * @return url */ URL getUrl(); /** * 底层 Channel 关联的 ChannelHandler * * @return channel handler */ ChannelHandler getChannelHandler(); /** * 获取本地地址 * * @return local address. */ InetSocketAddress getLocalAddress(); /** * 发送消息 * * @param message * @throws RemotingException */ void send(Object message) throws RemotingException; /** * 发送消息 * * @param message * @param sent true: 会等待消息发出，消息发送失败会抛出异常； false: 不等待消息发出，将消息放入IO队列，即可返回 */ void send(Object message, boolean sent) throws RemotingException; /** * 关闭底层Channel */ void close(); /** * 优雅关闭底层Channel */ void close(int timeout); /** * 开始关闭 */ void startClose(); /** * 检测底层Channel是否已经关闭 * * @return closed */ boolean isClosed();&#125; Dubbo 中抽象了端点（Endpoint)的概念，通过 ip + port 能够唯一确定一个端点，两个端点之间可以建立 TCP 连接，用于双向传输数据。Dubbo 将 Endpoint 之间的 TCP 连接抽象为通道（Channel），将发起请求的 Endpoint 抽象为客户端（Client），将接收请求的 Endpoint 抽象为服务端（Server）。本质上 Client 和 Server 都是一个端点。 通道 Channel12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public interface Channel extends Endpoint &#123; /** * 获取远程地址 (注意，父类中是获取本地地址) * * @return remote address. */ InetSocketAddress getRemoteAddress(); /** * 是否已经链接 * * @return connected */ boolean isConnected(); //------------- Channel 中属性相关接口，可以对Channel 中属性进行操作 -----------------/ /** * has attribute. * * @param key key. * @return has or has not. */ boolean hasAttribute(String key); /** * get attribute. * * @param key key. * @return value. */ Object getAttribute(String key); /** * set attribute. * * @param key key. * @param value value. */ void setAttribute(String key, Object value); /** * remove attribute. * * @param key key. */ void removeAttribute(String key);&#125; Channel 是对两个 Endpoint 连接的抽象，消息发送端会往 Channel 写入消息，而接收端会从 Channel 读取消息。 Channel 接口继承了 Endpoint 接口，也具备开关 Channel 以及发送数据的能力。此外，Channel 支持附加键值对属性。Dubbo 的 Channel 和 Netty 中的 Channel 一致，是通信的载体，Dubbo 的 Channel 的工作最终是要委托给底层 NIO 连接完成，如 Netty 的 Channel 来完成的 。 通道处理器 ChannelHandler1234567891011121314151617181920212223242526272829303132333435363738394041@SPIpublic interface ChannelHandler &#123; /** * 处理 Channel 的连接建立事件 - Channel 已经被创建 * * @param channel channel. */ void connected(Channel channel) throws RemotingException; /** * 处理 Channel 的连接断开事件 - Channel 已经被断开 * * @param channel channel. */ void disconnected(Channel channel) throws RemotingException; /** * 处理发送的数据 - 消息被发送 * * @param channel channel. * @param message message. */ void sent(Channel channel, Object message) throws RemotingException; /** * 处理读取到的数据 - 消息被接收 * * @param channel channel. * @param message message. */ void received(Channel channel, Object message) throws RemotingException; /** * 处理捕获到的异常 * * @param channel channel. * @param exception exception. */ void caught(Channel channel, Throwable exception) throws RemotingException;&#125; ChannelHandler 是注册在 Channel 上的消息处理器，和 Netty 的 ChannelHandler 一致，负责 Channel 中的逻辑处理，如连接、断开、发送消息、收到消息和出现异常等。需要说明的是，ChannelHandler 被 @SPI注解标注，表示是一个 Dubbo 扩展点。ChannelHandler 中定义了 5 个方法，对应着它的 5 种状态： connected - Channel 已经被创建 disconnected - Channel 已经被断开 sent - 消息被发送 received - 消息被接收 caught - 捕获到异常 Dubbo 中提供了大量的 ChannelHandler 去承载特性和扩展，这些 Handler 最终会和底层通信框架进行关联，如 Netty、Mina 等。一次完整的 RPC 调用贯穿了一系列的 ChannelHandler，如果直接挂载到 Netty 这样的底层通信框架，因为整个调用链路比较长，需要触发大量链式查找和事件，不仅效率低而且消耗资源。因此，Dubbo 框架内部使用了大量的 ChannelHandler 组成链式结构（类似过滤器Filter链），根据 ChannelHandler 的特性依次处理具体的逻辑，Dubbo 这种将多个 ChannelHandler 聚合成一个 ChannelHandler 使用的是装饰者模式，在后面的具体实现中可以看到大量装饰者模式的使用。 语义端点Dubbo 中抽象了端点 Endpoint 的概念，将发起请求的 Endpoint 抽象为客户端（Client），将接收请求的 Endpoint 抽象为服务端（Server），Client 和 Server 本身都是 Endpoint，只不过在语义上区分了请求和响应的职责，两者都具备发送消息的能力，所以都继承了 Endpoint 接口。UML 图如下： 客户端 Client1234567891011121314151617public interface Client extends Endpoint, Channel, Resetable &#123; /** * 重连 * * @throws RemotingException */ void reconnect() throws RemotingException; /** * 重置 * * @param parameters */ @Deprecated void reset(com.alibaba.dubbo.common.Parameters parameters);&#125; 服务端 Server123456789101112131415161718192021222324252627282930313233public interface Server extends Endpoint, Resetable &#123; /** * 是否绑定本地端口，即是否启动成功，可连接、接收消息 * * @return bound */ boolean isBound(); /** * 获取连接上服务的通道列表。 多个Client 可以连接同一个Server * * @return channels */ Collection&lt;Channel&gt; getChannels(); /** * 根据地址获取连接上服务的通道 * * @param remoteAddress * @return channel */ Channel getChannel(InetSocketAddress remoteAddress); /** * 重置，已废弃 * * @param parameters */ @Deprecated void reset(com.alibaba.dubbo.common.Parameters parameters);&#125; Client 和 Server 的主要区别是 Client 只能关联一个 Channel，而 Server 可以接收多个 Client 发起的 Channel 连接。 网络传输 Transporter由远程通信抽象相关UML图可知，网络传输 Transporter 是在 Client 和 Server 之上封装的接口。 12345678910111213141516171819202122232425262728@SPI(\"netty\")public interface Transporter &#123; /** * 创建一个服务器。根据 'server'，'transporter' 确定 Server 扩展实现 * * @param url 服务器地址 * @param handler 通道处理器 * @return server 返回服务器 * @throws RemotingException * @see com.alibaba.dubbo.remoting.Transporters#bind(URL, ChannelHandler...) */ @Adaptive(&#123;Constants.SERVER_KEY, Constants.TRANSPORTER_KEY&#125;) Server bind(URL url, ChannelHandler handler) throws RemotingException; /** * 连接服务器，即创建一个客户端。根据 'client','transporter' 确定 Client 扩展实现 * * @param url 服务器地址 * @param handler 通道处理器 * @return client 客户端 * @throws RemotingException * @see com.alibaba.dubbo.remoting.Transporters#connect(URL, ChannelHandler...) */ @Adaptive(&#123;Constants.CLIENT_KEY, Constants.TRANSPORTER_KEY&#125;) Client connect(URL url, ChannelHandler handler) throws RemotingException;&#125; Transporter 接口上标注 @SPI 注解，表示它是一个扩展点，默认扩展名为 netty ，bind 方法 和 connect 方法 都使用 @Adaptive 注解标注，表示会生成自适应扩展实现。 网络传输门面 Transporters1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class Transporters &#123; static &#123; // check duplicate jar package Version.checkDuplicate(Transporters.class); Version.checkDuplicate(RemotingException.class); &#125; private Transporters() &#123; &#125; /** * 静态方法，创建一个服务器 * * @param url * @param handler * @return * @throws RemotingException */ public static Server bind(String url, ChannelHandler... handler) throws RemotingException &#123; return bind(URL.valueOf(url), handler); &#125; public static Server bind(URL url, ChannelHandler... handlers) throws RemotingException &#123; if (url == null) &#123; throw new IllegalArgumentException(\"url == null\"); &#125; if (handlers == null || handlers.length == 0) &#123; throw new IllegalArgumentException(\"handlers == null\"); &#125; // 创建handler ChannelHandler handler; if (handlers.length == 1) &#123; handler = handlers[0]; &#125; else &#123; // 如果handlers 元素数量大于1，则创建分发器 ChannelHandlerDispatcher【分发器会循环调用handlers】 handler = new ChannelHandlerDispatcher(handlers); &#125; // 获取自适应 Transporter 实例，由具体的Transporter 来创建Server 。默认是NettyTransporter创建NettyServer return getTransporter().bind(url, handler); &#125; /** * 静态方法，连接服务器，即创建一个客户端 * * @param url * @param handler * @return * @throws RemotingException */ public static Client connect(String url, ChannelHandler... handler) throws RemotingException &#123; return connect(URL.valueOf(url), handler); &#125; public static Client connect(URL url, ChannelHandler... handlers) throws RemotingException &#123; if (url == null) &#123; throw new IllegalArgumentException(\"url == null\"); &#125; ChannelHandler handler; // 没有传入通道处理器 ChannelHandler，则会创建ChannelHandlerAdapter 作为通道处理器 if (handlers == null || handlers.length == 0) &#123; handler = new ChannelHandlerAdapter(); &#125; else if (handlers.length == 1) &#123; handler = handlers[0]; &#125; else &#123; // 传入多个 ChanenlHandler，则会创建分发器 ChannelHandlerDispatcher【分发器会循环调用handlers】 handler = new ChannelHandlerDispatcher(handlers); &#125; //获取自适应 Transporter 实例，由具体的Transporter 来创建 Client 。默认是NettyTransporter创建 NettyClient return getTransporter().connect(url, handler); &#125; /** * 获取自适应 Transporter 实例 * * @return */ public static Transporter getTransporter() &#123; return ExtensionLoader.getExtensionLoader(Transporter.class).getAdaptiveExtension(); &#125;&#125; Transporters 是一个门面类，其中封装了通过 Dubbo SPI 获取 Transporter 对象、ChannelHandler 的处理、服务器 Sever 的创建以及客户端 Client 的创建。属于外观模式。 编解码器Codec2相比较Codec的变化是，将OutputStream和InputStream，替换成了ChannelBuffer，更好的以 ChannelBuffer 为核心，与其他框架整合。 Codec212345678910111213141516171819202122232425262728293031323334353637383940@SPIpublic interface Codec2 &#123; /** * 编码 * * @param channel 通道 * @param buffer Buffer * @param message 消息 * @throws IOException */ @Adaptive(&#123;Constants.CODEC_KEY&#125;) void encode(Channel channel, ChannelBuffer buffer, Object message) throws IOException; /** * 解码 * * @param channel 通道 * @param buffer Buffer * @return 消息 * @throws IOException */ @Adaptive(&#123;Constants.CODEC_KEY&#125;) Object decode(Channel channel, ChannelBuffer buffer) throws IOException; /** * 解码过程中，需要解决TCP拆包，粘包的场景。解码结果如下： */ enum DecodeResult &#123; /** * 需要更多输入 */ NEED_MORE_INPUT, /** * 忽略一些输入 */ SKIP_SOME_INPUT &#125;&#125; Codec123456789101112131415161718192021222324252627282930313233@Deprecated@SPIpublic interface Codec &#123; /** * Need more input poison. * * @see #decode(Channel, InputStream) */ Object NEED_MORE_INPUT = new Object(); /** * Encode message. * * @param channel channel. * @param output output stream. * @param message message. */ @Adaptive(&#123;Constants.CODEC_KEY&#125;) void encode(Channel channel, OutputStream output, Object message) throws IOException; /** * Decode message. * * @param channel channel. * @param input input stream. * @return message or &lt;code&gt;NEED_MORE_INPUT&lt;/code&gt; poison. * @see #NEED_MORE_INPUT */ @Adaptive(&#123;Constants.CODEC_KEY&#125;) Object decode(Channel channel, InputStream input) throws IOException;&#125; Codec 是老的编解码器接口，目前已经被Codec2取代，可以通过CodecAdapter将Codec适配成Codec2。 可解码接口 Decodeable12345678public interface Decodeable &#123; /** * 解码接口 * * @throws Exception */ public void decode() throws Exception;&#125; 该接口在消息解码的过程中扮演重要角色，是对 Dubbo 协议下的请求和响应消息体解码的支持。在后面的文章中会详细说明其作用。 派发器 Dispatcher1234567891011121314151617181920212223242526272829303132/** * ChannelHandlerWrapper (SPI, Singleton, ThreadSafe) * &lt;span&gt;说明：&lt;/span&gt; * 1 调度器接口，被 @SPI(AllDispatcher.NAME)注解标注，是Dubbo 的拓展点，默认扩展名为 'all' * 2 如果事件处理的逻辑能迅速完成，并且不会发起新的 IO 请求，比如只是在内存中记个标识，则直接在 IO 线程上处理更快，因为减少了线程池调度。 * 如果事件处理逻辑较慢，或者需要发起新的 IO 请求，比如需要查询数据库，则必须派发到线程池，否则 IO 线程阻塞，将导致不能接收其它请求。 * 3 通过不同的派发策略和不同的线程池配置的组合来应对不同的场景。注意，派发策略和线程池的联系 * * &lt;span&gt;在dubbo 中，有多种Dispatcher的实现&lt;/span&gt; * &lt;ul&gt; * &lt;li&gt;all: 所有消息都派发到线程池，包括请求，响应，连接事件，断开事件，心跳等&lt;/li&gt; * &lt;li&gt;direct: 所有消息都不派发到线程池，全部在IO线程上直接执行&lt;/li&gt; * &lt;li&gt;message: 只有请求/响应消息派发到线程池，其他的消息直接在IO线程上执行&lt;/li&gt; * &lt;li&gt;execution: 只有请求消息派发到线程池，其他的消息直接在IO线程上执行&lt;/li&gt; * &lt;li&gt;connection: 在IO线程上，将连接/断开事件放入队列，有序逐个执行。其他消息派发到线程池&lt;/li&gt; * &lt;/ul&gt; * 注意：每个Dispatcher实现类，都对应一个ChannelHandler实现类。默认情况下，使用AllDispatcher调度 */@SPI(AllDispatcher.NAME)public interface Dispatcher &#123; /** * 派发消息到线程池处理还是IO线程直接处理 * * @param handler 通道处理 * @param url url * @return channel handler */ @Adaptive(&#123;Constants.DISPATCHER_KEY, \"dispather\", \"channel.handler\"&#125;) ChannelHandler dispatch(ChannelHandler handler, URL url);&#125; Dispatcher 主要支持了 Dubbo 的线程模型，可以创建不同的 ChannelHandler 来决定消息是交给线程池处理还是IO线程处理，因此我们可以在不同的场景中选择不同的派发策略实现消息或者事件的处理。 异常类 小结本篇文章主要介绍了 dubbo-remoting-api 中核心接口以及类，重点介绍了 端点 Endpoint、通道 Channel、通道处理器 ChannelHandler 、以及编解码器 。在语义上将端点 Endpoint 区分为 Client 和 Server。接着又介绍了 Server 和 Client 之上的 网络传输层Transporter 以及其门面类 Transporters 。 总结起来，上层使用方通过 Transporters 门面获取具体的 Transporter 实现，然后通过该 Transporter 创建相应的 Server 和 Client 实现，接着 Client 和 Server 之间建立连接即通道 Channel，并使用 ChannelHandler 处理 Channel相关事件和消息，这个过程还会涉及到编解码的处理，Codec2 正是用来解决编解码问题的。需要注意的是，这里上层指的其实就是信息交互层 Exchange ，我们会在之后的文章中介绍。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"Dubbo源码分析 - FST序列化","slug":"rpc/fst序列化","date":"2020-05-04T16:00:00.000Z","updated":"2020-11-07T16:20:28.343Z","comments":false,"path":"posts/cfaae53/","link":"","permalink":"https://gentryhuang.com/posts/cfaae53/","excerpt":"","text":"概述在 序列化总览 中介绍了 Dubbo 序列化抽象API相关接口，本篇文章将介绍 Dubbo 的 FST 序列化实现。 相关的代码结构如下图所示： FST 工厂12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class FstFactory &#123; /** * 单例 */ private static final FstFactory factory = new FstFactory(); /** * FST 配置对象 */ private final FSTConfiguration conf = FSTConfiguration.createDefaultConfiguration(); /** * 静态方法，获取FST默认工厂 * * @return */ public static FstFactory getDefaultFactory() &#123; return factory; &#125; public FstFactory() &#123; // 将要序列化优化的类 注册到 FSTConfiguration 配置对象中 for (Class clazz : SerializableClassRegistry.getRegisteredClasses()) &#123; conf.registerClass(clazz); &#125; &#125; /** * 获得 FSTObjectOutput 对象，被 FstObjectOutput 调用 * * @param outputStream * @return */ public FSTObjectOutput getObjectOutput(OutputStream outputStream) &#123; return conf.getObjectOutput(outputStream); &#125; /** * 获得 FSTObjectInput 对象，被 FstObjectInput 调用 * * @param inputStream * @return */ public FSTObjectInput getObjectInput(InputStream inputStream) &#123; return conf.getObjectInput(inputStream); &#125;&#125; 值得注意的是，FST 工厂的构造方法中会将 SerializableClassRegistry 注册表中的待序列化优化类，注册到 FSTConfiguration 中。 FstSerialization1234567891011121314151617181920212223242526public class FstSerialization implements Serialization &#123; @Override public byte getContentTypeId() &#123; return 9; &#125; /** * 内容类型 * @return */ @Override public String getContentType() &#123; return \"x-application/fst\"; &#125; @Override public ObjectOutput serialize(URL url, OutputStream out) throws IOException &#123; return new FstObjectOutput(out); &#125; @Override public ObjectInput deserialize(URL url, InputStream is) throws IOException &#123; return new FstObjectInput(is); &#125;&#125; 实现 Serialization 接口，FST 序列化实现类，将序列化任务交给 FstObjectOutput 对象完成，将反序列化任务交给 FstObjectInput 对象完成。 FstObjectOutputFstObjectOutput 实现序列化抽象API模块的 ObjectOutput 接口。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public class FstObjectOutput implements ObjectOutput &#123; private FSTObjectOutput output; public FstObjectOutput(OutputStream outputStream) &#123; // 通过工厂创建 FSTObjectOutput 对象 output = FstFactory.getDefaultFactory().getObjectOutput(outputStream); &#125; //--------------------- 序列化方法直接委托给 FSTObjectOutput 对应的方法 ---------- / @Override public void writeBool(boolean v) throws IOException &#123; output.writeBoolean(v); &#125; @Override public void writeByte(byte v) throws IOException &#123; output.writeByte(v); &#125; @Override public void writeShort(short v) throws IOException &#123; output.writeShort(v); &#125; @Override public void writeInt(int v) throws IOException &#123; output.writeInt(v); &#125; @Override public void writeLong(long v) throws IOException &#123; output.writeLong(v); &#125; @Override public void writeFloat(float v) throws IOException &#123; output.writeFloat(v); &#125; @Override public void writeDouble(double v) throws IOException &#123; output.writeDouble(v); &#125; @Override public void writeBytes(byte[] v) throws IOException &#123; if (v == null) &#123; output.writeInt(-1); &#125; else &#123; writeBytes(v, 0, v.length); &#125; &#125; @Override public void writeBytes(byte[] v, int off, int len) throws IOException &#123; if (v == null) &#123; output.writeInt(-1); &#125; else &#123; output.writeInt(len); output.write(v, off, len); &#125; &#125; @Override public void writeUTF(String v) throws IOException &#123; output.writeUTF(v); &#125; @Override public void writeObject(Object v) throws IOException &#123; output.writeObject(v); &#125; @Override public void flushBuffer() throws IOException &#123; output.flush(); &#125;&#125; FstObjectOutput 中的序列化方法直接委托给 FSTObjectOutput 中对应的方法。 FstObjectInputFstObjectInput 实现序列化抽象API模块的 ObjectInput 接口。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091public class FstObjectInput implements ObjectInput &#123; private FSTObjectInput input; public FstObjectInput(InputStream inputStream) &#123; input = FstFactory.getDefaultFactory().getObjectInput(inputStream); &#125; // ----------- 所有的实现方法委托给 FSTObjectInput 对应的方法 ---------------/ @Override public boolean readBool() throws IOException &#123; return input.readBoolean(); &#125; @Override public byte readByte() throws IOException &#123; return input.readByte(); &#125; @Override public short readShort() throws IOException &#123; return input.readShort(); &#125; @Override public int readInt() throws IOException &#123; return input.readInt(); &#125; @Override public long readLong() throws IOException &#123; return input.readLong(); &#125; @Override public float readFloat() throws IOException &#123; return input.readFloat(); &#125; @Override public double readDouble() throws IOException &#123; return input.readDouble(); &#125; @Override public String readUTF() throws IOException &#123; return input.readUTF(); &#125; @Override public Object readObject() throws IOException, ClassNotFoundException &#123; return input.readObject(); &#125; @Override @SuppressWarnings(\"unchecked\") public &lt;T&gt; T readObject(Class&lt;T&gt; clazz) throws IOException, ClassNotFoundException &#123; try &#123; return (T) input.readObject(clazz); &#125; catch (Exception e) &#123; throw new IOException(e); &#125; &#125; @Override @SuppressWarnings(\"unchecked\") public &lt;T&gt; T readObject(Class&lt;T&gt; clazz, Type type) throws IOException, ClassNotFoundException &#123; try &#123; return (T) input.readObject(clazz); &#125; catch (Exception e) &#123; throw new IOException(e); &#125; &#125; @Override public byte[] readBytes() throws IOException &#123; int len = input.readInt(); if (len &lt; 0) &#123; return null; &#125; else if (len == 0) &#123; return new byte[]&#123;&#125;; &#125; else &#123; byte[] b = new byte[len]; input.readFully(b); return b; &#125; &#125;&#125; 每个实现方法，直接委托给 FSTObjectInput 对应的方法。 小结Dubbo 的 FST 序列化方式特殊点在于可以指定要序列化优化的类，然注册到 FSTConfiguration 配置对象中，用以发挥出 FST 的高性能。其中 Kryo 序列化方式和 FST 类似。其它没有分析到的序列化方式套路都是一样的。Dubbo 的序列化到此结束。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"Dubbo源码分析 - Hessian序列化","slug":"rpc/hessian序列化","date":"2020-05-03T16:00:00.000Z","updated":"2020-11-07T16:00:54.930Z","comments":false,"path":"posts/4fd38523/","link":"","permalink":"https://gentryhuang.com/posts/4fd38523/","excerpt":"","text":"概述在 序列化总览 中介绍了 Dubbo 序列化抽象API相关接口，本篇文章将介绍 Dubbo 的 Hessian 序列化实现，它是 Dubbo 的默认序列化实现。 相关的代码结构如下图所示： Hessian 有自己的序列化实现，Dubbo 对 Hessian2 进行了改进，形成了一套自己的序列化方式。 Hessian2Serialization123456789101112131415161718192021222324public class Hessian2Serialization implements Serialization &#123; public static final byte ID = 2; @Override public byte getContentTypeId() &#123; return ID; &#125; @Override public String getContentType() &#123; return \"x-application/hessian2\"; &#125; @Override public ObjectOutput serialize(URL url, OutputStream out) throws IOException &#123; return new Hessian2ObjectOutput(out); &#125; @Override public ObjectInput deserialize(URL url, InputStream is) throws IOException &#123; return new Hessian2ObjectInput(is); &#125;&#125; Hessian2Serialization 实现并没有什么不同，同样是使用 serialize 方法创建 ObjectOutput 对象，该对象类型为 Hessian2ObjectOutput，负责序列化工作。使用 deserialize 方法创建 ObjectInput 对象，该对象类型为 Hessian2ObjectInput，负责反序列化工作。 Hessian2ObjectOutputHessian2ObjectOutput 实现了抽象API模块中的 ObjectOutput 接口。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public class Hessian2ObjectOutput implements ObjectOutput &#123; private final Hessian2Output mH2o; public Hessian2ObjectOutput(OutputStream os) &#123; // 创建 Hessian2Output 对象 mH2o = new Hessian2Output(os); // 设置对应的工厂 mH2o.setSerializerFactory(Hessian2SerializerFactory.SERIALIZER_FACTORY); &#125; //---------------- 最终序列化任务都委托给 Hessian2Output 对象来完成 ------------/ @Override public void writeBool(boolean v) throws IOException &#123; mH2o.writeBoolean(v); &#125; @Override public void writeByte(byte v) throws IOException &#123; mH2o.writeInt(v); &#125; @Override public void writeShort(short v) throws IOException &#123; mH2o.writeInt(v); &#125; @Override public void writeInt(int v) throws IOException &#123; mH2o.writeInt(v); &#125; @Override public void writeLong(long v) throws IOException &#123; mH2o.writeLong(v); &#125; @Override public void writeFloat(float v) throws IOException &#123; mH2o.writeDouble(v); &#125; @Override public void writeDouble(double v) throws IOException &#123; mH2o.writeDouble(v); &#125; @Override public void writeBytes(byte[] b) throws IOException &#123; mH2o.writeBytes(b); &#125; @Override public void writeBytes(byte[] b, int off, int len) throws IOException &#123; mH2o.writeBytes(b, off, len); &#125; @Override public void writeUTF(String v) throws IOException &#123; mH2o.writeString(v); &#125; @Override public void writeObject(Object obj) throws IOException &#123; mH2o.writeObject(obj); &#125; @Override public void flushBuffer() throws IOException &#123; mH2o.flushBuffer(); &#125;&#125; Hessian2ObjectOutput 中封装一个 Hessian2Output 对象，由上面代码可知，Hessian2Output 对 java.io.OutputStream 进行了封装，并且序列化各类数据的方法都会委托给 Hessian2Output 对象的相应方法完成。需要注意的是，对于基本类型数据的序列化，Hessian2Output 使用字节数组来处理的。 12345678910111213141516171819202122232425262728293031public class Hessian2Output extends AbstractHessianOutput implements Hessian2Constants &#123; public final static int SIZE = 4096; // 字节数组 private final byte[] _buffer = new byte[SIZE]; // the output stream/ protected OutputStream _os; // map of references private IdentityIntMap _refs = new IdentityIntMap(); private boolean _isCloseStreamOnClose; // map of classes private HashMap _classRefs; // map of types private HashMap _typeRefs; private int _offset; private boolean _isStreaming; /** * Creates a new Hessian output stream, initialized with an * underlying output stream. * * @param os the underlying output stream. */ public Hessian2Output(OutputStream os) &#123; _os = os; &#125; // ... 省略其它代码&#125; Hessian2ObjectInputHessian2ObjectInput 实现了抽象API模块中的 ObjectInput 接口。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public class Hessian2ObjectInput implements ObjectInput &#123; private final Hessian2Input mH2i; public Hessian2ObjectInput(InputStream is) &#123; // 创建 Hessian2Input 对象 mH2i = new Hessian2Input(is); // 设置序列化工厂 mH2i.setSerializerFactory(Hessian2SerializerFactory.SERIALIZER_FACTORY); &#125; @Override public boolean readBool() throws IOException &#123; return mH2i.readBoolean(); &#125; @Override public byte readByte() throws IOException &#123; return (byte) mH2i.readInt(); &#125; @Override public short readShort() throws IOException &#123; return (short) mH2i.readInt(); &#125; @Override public int readInt() throws IOException &#123; return mH2i.readInt(); &#125; @Override public long readLong() throws IOException &#123; return mH2i.readLong(); &#125; @Override public float readFloat() throws IOException &#123; return (float) mH2i.readDouble(); &#125; @Override public double readDouble() throws IOException &#123; return mH2i.readDouble(); &#125; @Override public byte[] readBytes() throws IOException &#123; return mH2i.readBytes(); &#125; @Override public String readUTF() throws IOException &#123; return mH2i.readString(); &#125; @Override public Object readObject() throws IOException &#123; return mH2i.readObject(); &#125; @Override @SuppressWarnings(\"unchecked\") public &lt;T&gt; T readObject(Class&lt;T&gt; cls) throws IOException, ClassNotFoundException &#123; return (T) mH2i.readObject(cls); &#125; @Override public &lt;T&gt; T readObject(Class&lt;T&gt; cls, Type type) throws IOException, ClassNotFoundException &#123; return readObject(cls); &#125;&#125; Hessian2ObjectInput 中封装一个 Hessian2Input 对象，由上面代码可知，Hessian2Input 对 java.io.InputStream 进行了封装，并且将所有反序列化的实现都委托给 Hessian2Input 对象。同样的，Hessian2Input 对基本数据类型的数据进行反序列化是读取字节数组内容。 小结Dubbo 的 Hessian 序列化也是同样的套路，Hessian2Serialization 要进行序列化操作就把任务交给创建的 Hessian2ObjectOutput 对象去完成，要进行反序列化操作就把任务交给 Hessian2ObjectInput 对象去完成。只不过，Hessian2ObjectOutput 和 Hessian2ObjectInput 又会把任务委托给 Hessian类的Hessian2Output对象和Hessian2Input对象去完成。下一篇文章中分析 Dubbo 的 FST 序列化实现，它代表了一种类型，支持将那些需要被序列化的类注册到dubbo系统中。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"Dubbo源码分析 - JDK序列化","slug":"rpc/JDK序列化","date":"2020-05-02T16:00:00.000Z","updated":"2021-01-04T10:57:13.531Z","comments":false,"path":"posts/5898e8ff/","link":"","permalink":"https://gentryhuang.com/posts/5898e8ff/","excerpt":"","text":"概述在 序列化总览 中介绍了 Dubbo 序列化抽象API相关接口，本篇文章将介绍JDK的序列化实现。 相关的代码结构如下图所示： JDK 序列化是基于Java原生的序列化实现，从不同的方面考虑，具体有三种实现方式： java=com.alibaba.dubbo.common.serialize.java.JavaSerializationcompactedjava=com.alibaba.dubbo.common.serialize.java.CompactedJavaSerializationnativejava=com.alibaba.dubbo.common.serialize.nativejava.NativeJavaSerialization NativeJavaSerialization 是原生的 Java 序列化的实现方式。CompactedJavaSerialization 是在原生的 Java 序列化的基础上做了压缩，实现了自定义的类描述符的写入和读取，在序列化时只需写入类名而不是完整的类信息，可以有效压缩体积。JavaSerialization 是对原生 Java 序列化和压缩的组合实现，并且支持对空字符串及空对象的处理。三者的UML图如下： Java 原生序列化NativeJavaSerialization123456789101112131415161718192021222324public class NativeJavaSerialization implements Serialization &#123; public static final String NAME = \"nativejava\"; @Override public byte getContentTypeId() &#123; return 7; &#125; @Override public String getContentType() &#123; return \"x-application/nativejava\"; &#125; @Override public ObjectOutput serialize(URL url, OutputStream output) throws IOException &#123; return new NativeJavaObjectOutput(output); &#125; @Override public ObjectInput deserialize(URL url, InputStream input) throws IOException &#123; return new NativeJavaObjectInput(input); &#125;&#125; 基于原生的Java序列化实现，即使用 java.io.ObjectOutputSteam 进行序列化，使用 java.io.ObjectInputStream 进行反序列化。在 NativeJavaObjectOutput 和 NativeJavaObjectInput 会分别对传入的流进行包装。 NativeJavaObjectOutputNativeJavaObjectOutput 实现了抽象API模块中的 ObjectOutput 接口。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889public class NativeJavaObjectOutput implements ObjectOutput &#123; /** * java原生的 输出流对象 */ private final ObjectOutputStream outputStream; public NativeJavaObjectOutput(OutputStream os) throws IOException &#123; this(new ObjectOutputStream(os)); &#125; protected NativeJavaObjectOutput(ObjectOutputStream out) &#123; Assert.notNull(out, \"output == null\"); this.outputStream = out; &#125; protected ObjectOutputStream getObjectOutputStream() &#123; return outputStream; &#125; @Override public void writeObject(Object obj) throws IOException &#123; outputStream.writeObject(obj); &#125; @Override public void writeBool(boolean v) throws IOException &#123; outputStream.writeBoolean(v); &#125; @Override public void writeByte(byte v) throws IOException &#123; outputStream.writeByte(v); &#125; @Override public void writeShort(short v) throws IOException &#123; outputStream.writeShort(v); &#125; @Override public void writeInt(int v) throws IOException &#123; outputStream.writeInt(v); &#125; @Override public void writeLong(long v) throws IOException &#123; outputStream.writeLong(v); &#125; @Override public void writeFloat(float v) throws IOException &#123; outputStream.writeFloat(v); &#125; @Override public void writeDouble(double v) throws IOException &#123; outputStream.writeDouble(v); &#125; @Override public void writeUTF(String v) throws IOException &#123; outputStream.writeUTF(v); &#125; @Override public void writeBytes(byte[] v) throws IOException &#123; if (v == null) &#123; outputStream.writeInt(-1); &#125; else &#123; writeBytes(v, 0, v.length); &#125; &#125; @Override public void writeBytes(byte[] v, int off, int len) throws IOException &#123; if (v == null) &#123; outputStream.writeInt(-1); &#125; else &#123; outputStream.writeInt(len); outputStream.write(v, off, len); &#125; &#125; @Override public void flushBuffer() throws IOException &#123; outputStream.flush(); &#125;&#125; Java 原生的序列化，无论是基本数据类型还是引用数据类型，进行序列化时都直接使用 java.io.ObjectOutputStream API来完成。 NativeJavaObjectInputNativeJavaObjectInput 实现了抽象API模块中的 ObjectInput接口。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091public class NativeJavaObjectInput implements ObjectInput &#123; /** * Java原生的 ObjectInputStream 输入流 */ private final ObjectInputStream inputStream; public NativeJavaObjectInput(InputStream is) throws IOException &#123; this(new ObjectInputStream(is)); &#125; protected NativeJavaObjectInput(ObjectInputStream is) &#123; Assert.notNull(is, \"input == null\"); inputStream = is; &#125; protected ObjectInputStream getObjectInputStream() &#123; return inputStream; &#125; @Override public Object readObject() throws IOException, ClassNotFoundException &#123; return inputStream.readObject(); &#125; @Override @SuppressWarnings(\"unchecked\") public &lt;T&gt; T readObject(Class&lt;T&gt; cls) throws IOException, ClassNotFoundException &#123; return (T) readObject(); &#125; @Override @SuppressWarnings(\"unchecked\") public &lt;T&gt; T readObject(Class&lt;T&gt; cls, Type type) throws IOException, ClassNotFoundException &#123; return (T) readObject(); &#125; @Override public boolean readBool() throws IOException &#123; return inputStream.readBoolean(); &#125; @Override public byte readByte() throws IOException &#123; return inputStream.readByte(); &#125; @Override public short readShort() throws IOException &#123; return inputStream.readShort(); &#125; @Override public int readInt() throws IOException &#123; return inputStream.readInt(); &#125; @Override public long readLong() throws IOException &#123; return inputStream.readLong(); &#125; @Override public float readFloat() throws IOException &#123; return inputStream.readFloat(); &#125; @Override public double readDouble() throws IOException &#123; return inputStream.readDouble(); &#125; @Override public String readUTF() throws IOException &#123; return inputStream.readUTF(); &#125; @Override public byte[] readBytes() throws IOException &#123; int len = inputStream.readInt(); if (len &lt; 0) &#123; return null; &#125; else if (len == 0) &#123; return new byte[]&#123;&#125;; &#125; else &#123; byte[] result = new byte[len]; inputStream.readFully(result); return result; &#125; &#125;&#125; Java 原生的反序列化，无论是基本数据类型还是引用数据类型，进行反序列化时都直接使用 java.io.ObjectInputStream API来完成。 压缩能力的序列化CompactedJava123456789101112131415161718192021222324252627282930public class CompactedJavaSerialization implements Serialization &#123; @Override public byte getContentTypeId() &#123; return 4; &#125; @Override public String getContentType() &#123; return \"x-application/compactedjava\"; &#125; /** * 在创建 JavaObjectOutput 时，根据 compact = true 时，使用 CompactedObjectOutputStream 输出流 * * @param url URL * @param out * @return * @throws IOException */ @Override public ObjectOutput serialize(URL url, OutputStream out) throws IOException &#123; return new JavaObjectOutput(out, true); &#125; @Override public ObjectInput deserialize(URL url, InputStream is) throws IOException &#123; return new JavaObjectInput(is, true); &#125;&#125; 在原生的 Java 序列化的基础上做了压缩，实现了自定义的类描述符的写入和读取，在序列化时只需写入类名而不是完整的类信息，可以有效压缩体积。功能由 CompactedObjectOutputStream 和 CompactedObjectInputStream 实现。 CompactedObjectOutputStream1234567891011121314151617public class CompactedObjectOutputStream extends ObjectOutputStream &#123; public CompactedObjectOutputStream(OutputStream out) throws IOException &#123; super(out); &#125; @Override protected void writeClassDescriptor(ObjectStreamClass desc) throws IOException &#123; Class&lt;?&gt; clazz = desc.forClass(); if (clazz.isPrimitive() || clazz.isArray()) &#123; write(0); super.writeClassDescriptor(desc); &#125; else &#123; write(1); writeUTF(desc.getName()); &#125; &#125;&#125; 继承了 ObjectOutputStream 类，重写了 writeClassDescriptor 方法，实现了对 ClassDescriptor 的写入。 CompactedObjectInputStream1234567891011121314151617181920212223242526272829303132public class CompactedObjectInputStream extends ObjectInputStream &#123; private ClassLoader mClassLoader; public CompactedObjectInputStream(InputStream in) throws IOException &#123; this(in, Thread.currentThread().getContextClassLoader()); &#125; public CompactedObjectInputStream(InputStream in, ClassLoader cl) throws IOException &#123; super(in); mClassLoader = cl == null ? ClassHelper.getClassLoader() : cl; &#125; @Override protected ObjectStreamClass readClassDescriptor() throws IOException, ClassNotFoundException &#123; int type = read(); if (type &lt; 0) throw new EOFException(); switch (type) &#123; case 0: return super.readClassDescriptor(); case 1: Class&lt;?&gt; clazz = loadClass(readUTF()); return ObjectStreamClass.lookup(clazz); default: throw new StreamCorruptedException(\"Unexpected class descriptor type: \" + type); &#125; &#125; private Class&lt;?&gt; loadClass(String className) throws ClassNotFoundException &#123; return mClassLoader.loadClass(className); &#125;&#125; 继承了 ObjectInputStream 类，重写了 readClassDescriptor 方法，实现了对 ClassDescriptor 读取。 组合原生和压缩序列化JavaSerialization12345678910111213141516171819202122public class JavaSerialization implements Serialization &#123; @Override public byte getContentTypeId() &#123; return 3; &#125; @Override public String getContentType() &#123; return \"x-application/java\"; &#125; @Override public ObjectOutput serialize(URL url, OutputStream out) throws IOException &#123; return new JavaObjectOutput(out); &#125; @Override public ObjectInput deserialize(URL url, InputStream is) throws IOException &#123; return new JavaObjectInput(is); &#125;&#125; JavaObjectOutputJavaObjectOutput 继承了 Java 原生序列化的 NativeJavaObjectOutput 类。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class JavaObjectOutput extends NativeJavaObjectOutput &#123; public JavaObjectOutput(OutputStream os) throws IOException &#123; super(new ObjectOutputStream(os)); &#125; /** * 注意 compact 为true的情况 &#123;@link CompactedJavaSerialization#serialize(URL, OutputStream)&#125; * @param os * @param compact * @throws IOException */ public JavaObjectOutput(OutputStream os, boolean compact) throws IOException &#123; super(compact ? new CompactedObjectOutputStream(os) : new ObjectOutputStream(os)); &#125; /** * 对空字符串的处理 * * @param v * @throws IOException */ @Override public void writeUTF(String v) throws IOException &#123; if (v == null) &#123; getObjectOutputStream().writeInt(-1); &#125; else &#123; getObjectOutputStream().writeInt(v.length()); getObjectOutputStream().writeUTF(v); &#125; &#125; /** * 对空对象的处理 * * @param obj * @throws IOException */ @Override public void writeObject(Object obj) throws IOException &#123; if (obj == null) &#123; getObjectOutputStream().writeByte(0); &#125; else &#123; getObjectOutputStream().writeByte(1); getObjectOutputStream().writeObject(obj); &#125; &#125; @Override public void flushBuffer() throws IOException &#123; getObjectOutputStream().flush(); &#125;&#125; JavaObjectOutput 构造方法可以根据 compact 参数创建不同的实现序列化功能对象。 JavaObjectInputJavaObjectInput 继承了 Java 原生序列化的 NativeJavaObjectInput 类。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class JavaObjectInput extends NativeJavaObjectInput &#123; public final static int MAX_BYTE_ARRAY_LENGTH = 8 * 1024 * 1024; public JavaObjectInput(InputStream is) throws IOException &#123; super(new ObjectInputStream(is)); &#125; public JavaObjectInput(InputStream is, boolean compacted) throws IOException &#123; super(compacted ? new CompactedObjectInputStream(is) : new ObjectInputStream(is)); &#125; @Override public byte[] readBytes() throws IOException &#123; int len = getObjectInputStream().readInt(); if (len &lt; 0) return null; if (len == 0) return new byte[0]; if (len &gt; MAX_BYTE_ARRAY_LENGTH) throw new IOException(\"Byte array length too large. \" + len); byte[] b = new byte[len]; getObjectInputStream().readFully(b); return b; &#125; @Override public String readUTF() throws IOException &#123; int len = getObjectInputStream().readInt(); if (len &lt; 0) return null; return getObjectInputStream().readUTF(); &#125; @Override public Object readObject() throws IOException, ClassNotFoundException &#123; byte b = getObjectInputStream().readByte(); if (b == 0) return null; return getObjectInputStream().readObject(); &#125; @Override @SuppressWarnings(\"unchecked\") public &lt;T&gt; T readObject(Class&lt;T&gt; cls) throws IOException, ClassNotFoundException &#123; return (T) readObject(); &#125; @Override @SuppressWarnings(\"unchecked\") public &lt;T&gt; T readObject(Class&lt;T&gt; cls, Type type) throws IOException, ClassNotFoundException &#123; return (T) readObject(); &#125;&#125; JavaObjectOutput 构造方法可以根据 compact 参数创建不同的实现反序列化功能对象。 小结本篇文章加单介绍了 Dubbo 原生的 Java 序列化实现方式，即直接使用 java.io.ObjectOutputSteam 进行序列化，使用 java.io.ObjectInputStream 进行反序列化，并没有进行过多的其它处理，不依赖其它组件。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"Dubbo源码分析 - 序列化总览","slug":"rpc/序列化总览","date":"2020-05-02T16:00:00.000Z","updated":"2020-12-17T08:41:03.156Z","comments":false,"path":"posts/16132b67/","link":"","permalink":"https://gentryhuang.com/posts/16132b67/","excerpt":"","text":"前言Dubbo 的服务暴露、服务引用以及服务调用除了需要之前介绍的配置、代理、注册中心，还需要协议、网络通信、集群容错、序列化等。因此，从本文开始会由底向上分析 Dubbo 架构中的模块。 概述RPC框架需要网络通信实现信息的发送和接收，既然是网络通信就一定会使用到序列化和反序列化技术。Dubbo 对序列化的定义是，将对象（基本数据类型和引用类型）转成字节流用于网络传输；以及将字节流转为对象（基本数据类型和引用类型），用于在收到字节流数据后进行还原。序列化对于远程调用的响应速度、吞吐量、网络带宽消耗等同样也起着至关重要的作用，是提升分布式系统性能的最关键因素之一。 提起序列化就不得不提到协议这个概念，两者是不同的东西，它们之间属于组合关系，协议需要用到序列化技术，而序列化技术可以服务于不同的协议。序列化层在 Dubbo 的架构图中的位置如下，它处于最低层，属于 Remoting 层的一部分。在 Dubbo 中还有一个和序列化相关的扩展接口 Codec2，是基于序列化之上封装的组件，主要用于实现对数据的编码和解码，即解决粘包和拆包等问题，序列化和反序列化功能是使用序列化层来完成的。 Dubbo 为了支持多种序列化算法，单独抽象了 Serialize 层，对应的模块结构如下图所示： Dubbo 序列化抽象 APIdubbo-serialization-api 模块中定义了 Dubbo 序列化层的核心接口以及类，关系如下： Serialization 接口12345678910111213141516171819202122232425262728293031323334353637383940414243@SPI(\"hessian2\")public interface Serialization &#123; /** * 序列化类型编号 * * @return content type id */ byte getContentTypeId(); /** * 获得序列化对应的类型，每一种序列化算法都对应一个类型 * * @return content type */ String getContentType(); /** * create serializer * &lt;p&gt; * 创建ObjectOutput对象，实现序列化功能，序列化输出到 OutputStream * * @param url URL * @param output 输出流 * @return serializer * @throws IOException */ @Adaptive ObjectOutput serialize(URL url, OutputStream output) throws IOException; /** * create deserializer * &lt;p&gt; * 创建 ObjectInput 对象，实现反序列化，从 InputStream 反序列化 * * @param url URL * @param input 输入流 * @return deserializer * @throws IOException */ @Adaptive ObjectInput deserialize(URL url, InputStream input) throws IOException;&#125; Serialization 接口是一个扩展点，默认扩展实现是 Hessian2Serialization 。它是序列化最核心的接口，serialize方法用来创建实现序列化功能的 ObjectOutput 对象，deserialize方法用来创建实现反序列化功能的 ObjectInput。不同的 Serialization 扩展实现对应不同的 ObjectOutput 和 ObjectInput 对象，但是本质上都是对 JDK的 OutputStream 和 InputStream 类的封装或改造，Dubbo 中一般使用对 ChannelBuffer 装饰的流对象。不同的 Serialization 扩展实现会有所差异，除了效率外还体现在API上，对于引用类型的序列化一般最底层都是使用JDK的OutputStream 和 InputStream的API，上层因不同特性的 Serialization 会有不同，对于基本类型数据的序列化有的 Serialization 会使用自身维护的字节数组来实现，有的直接使用传入的 Stream 流实现。 Serialization 的序列化（serialize）和反序列化（deserialize）方法的 Stream 参数，在使用的时候一般都是 Dubbo 自定义的 Stream 对象，该对象是对 Dubbo 中的 ChannelBuffer 的封装，用以提高效率和性能。关于 Dubbo 的 ChannelBuffer 我们会在后面的文章中进行说明，下面是 Dubbo 相关 Stream : Dubbo 提供了多个 Serialization 实现 ，如下图所示： DataOutput 接口12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091public interface DataOutput &#123; /** * Write boolean. * * @param v value. * @throws IOException */ void writeBool(boolean v) throws IOException; /** * Write byte. * * @param v value. * @throws IOException */ void writeByte(byte v) throws IOException; /** * Write short. * * @param v value. * @throws IOException */ void writeShort(short v) throws IOException; /** * Write integer. * * @param v value. * @throws IOException */ void writeInt(int v) throws IOException; /** * Write long. * * @param v value. * @throws IOException */ void writeLong(long v) throws IOException; /** * Write float. * * @param v value. * @throws IOException */ void writeFloat(float v) throws IOException; /** * Write double. * * @param v value. * @throws IOException */ void writeDouble(double v) throws IOException; /** * Write string. * * @param v value. * @throws IOException */ void writeUTF(String v) throws IOException; /** * Write byte array. * * @param v value. * @throws IOException */ void writeBytes(byte[] v) throws IOException; /** * Write byte array. * * @param v value. * @param off offset. * @param len length. * @throws IOException */ void writeBytes(byte[] v, int off, int len) throws IOException; /** * Flush buffer. * * @throws IOException */ void flushBuffer() throws IOException;&#125; DataOutput 接口中定义了用于序列化 Java 中各种基本数据类型的方法。 ObjectOutput 接口12345678public interface ObjectOutput extends DataOutput &#123; /** * write object. * * @param obj object. */ void writeObject(Object obj) throws IOException;&#125; 继承 DataOutput 接口，在DataOutput 的基础上增加序列化对象的能力。 InputStream 接口1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public interface DataInput &#123; /** * Read boolean. * * @return boolean. * @throws IOException */ boolean readBool() throws IOException; /** * Read byte. * * @return byte value. * @throws IOException */ byte readByte() throws IOException; /** * Read short integer. * * @return short. * @throws IOException */ short readShort() throws IOException; /** * Read integer. * * @return integer. * @throws IOException */ int readInt() throws IOException; /** * Read long. * * @return long. * @throws IOException */ long readLong() throws IOException; /** * Read float. * * @return float. * @throws IOException */ float readFloat() throws IOException; /** * Read double. * * @return double. * @throws IOException */ double readDouble() throws IOException; /** * Read UTF-8 string. * * @return string. * @throws IOException */ String readUTF() throws IOException; /** * Read byte array. * * @return byte array. * @throws IOException */ byte[] readBytes() throws IOException;&#125; InputStream 接口中定义了反序列化 Java 中各种化基本类型的数据。 ObjectInput 接口12345678910111213141516171819202122232425public interface ObjectInput extends DataInput &#123; /** * read object. * * @return object. */ Object readObject() throws IOException, ClassNotFoundException; /** * read object. * * @param cls object type. * @return object. */ &lt;T&gt; T readObject(Class&lt;T&gt; cls) throws IOException, ClassNotFoundException; /** * read object. * * @param cls object type. * @return object. */ &lt;T&gt; T readObject(Class&lt;T&gt; cls, Type type) throws IOException, ClassNotFoundException;&#125; 继承 DataInput 接口，在DataInput 的基础上增加了反序列化对象的能力。 Cleanable123public interface Cleanable &#123; void cleanup();&#125; 完成序列化或反序列化需要做清理工作，通过实现该接口释放资源，目前 Kryo 实现。 序列化优化器SerializationOptimizer 接口12345678910111213/** * 使用文件也是一个选择，这个类可以替换为配置文件中的内容，但是类的方式更容易编写 * This class can be replaced with the contents in config file, but for now I think the class is easier to write */public interface SerializationOptimizer &#123; /** * 返回需要使用优化的类的集合 * * @return */ Collection&lt;Class&gt; getSerializableClasses();&#125; 在Kryo、FST 序列化实现中，支持配置需要优化的类。可以实现自定义的SerializationOptimizer实现，配置需要优化的类，让Kryo和FST完全发挥出高性能。序列化优化器如下： 12345678910111213public class SerializationOptimizerImpl implements SerializationOptimizer &#123; public Collection&lt;Class&gt; getSerializableClasses() &#123; List&lt;Class&gt; classes = new LinkedList&lt;Class&gt;(); classes.add(BidRequest.class); classes.add(BidResponse.class); classes.add(Device.class); classes.add(Geo.class); classes.add(Impression.class); classes.add(SeatBid.class); return classes; &#125;&#125; Dubbo 已经自动将 JDK 中常用的类进行了注册，不要重复注册，即使重复注册也没又任何影响。由于注册被序列化的类仅仅是出于性能优化的目的，所以即使忘记注册某些类也没有关系。事实上，即使不注册任何类，Kryo和FST的性能依然普遍优于hessian和dubbo序列化。 序列化类的注册表123456789101112131415161718192021222324public abstract class SerializableClassRegistry &#123; /** * 要序列化优化的类的注册表 */ private static final Set&lt;Class&gt; registrations = new LinkedHashSet&lt;Class&gt;(); /** * only supposed to be called at startup time * 在 &#123;@link SerializationOptimizer#getSerializableClasses()&#125; 方法获得的类集合，会注册到这里。 */ public static void registerClass(Class clazz) &#123; registrations.add(clazz); &#125; /** * 获得序列化优化类集合。在 Kryo,FST中调用该方法会获得需要优化的类的集合 * * @return */ public static Set&lt;Class&gt; getRegisteredClasses() &#123; return registrations; &#125;&#125; 需要序列化优化的类都会注册到该类中进行缓存。 序列化优化器的使用1234567891011121314151617181920212223242526272829303132333435363738394041424344--- DubboProtocolprivate void optimizeSerialization(URL url) throws RpcException &#123; // 获得 optimizer 序列化优化器 配置项 String className = url.getParameter(Constants.OPTIMIZER_KEY, \"\"); // 如果系统中没有序列化优化器就直接返回 if (StringUtils.isEmpty(className) || optimizers.contains(className)) &#123; return; &#125; logger.info(\"Optimizing the serialization process for Kryo, FST, etc...\"); try &#123; // 根据 序列化优化器名 加载 SerializationOptimizer 实现类 Class clazz = Thread.currentThread().getContextClassLoader().loadClass(className); // 是否是SerializationOptimizer的子 if (!SerializationOptimizer.class.isAssignableFrom(clazz)) &#123; throw new RpcException(\"The serialization optimizer \" + className + \" isn't an instance of \" + SerializationOptimizer.class.getName()); &#125; // 反射创建 SerializationOptimizer 对象 SerializationOptimizer optimizer = (SerializationOptimizer) clazz.newInstance(); // 没有要优化的类直接返回 if (optimizer.getSerializableClasses() == null) &#123; return; &#125; // 将要优化的类注册到 SerializableClassRegistry 注册表中 for (Class c : optimizer.getSerializableClasses()) &#123; SerializableClassRegistry.registerClass(c); &#125; // 将 序列化优化器实现类名 加入到缓存中 optimizers.add(className); &#125; catch (ClassNotFoundException e) &#123; throw new RpcException(\"Cannot find the serialization optimizer class: \" + className, e); &#125; catch (InstantiationException e) &#123; throw new RpcException(\"Cannot instantiate the serialization optimizer class: \" + className, e); &#125; catch (IllegalAccessException e) &#123; throw new RpcException(\"Cannot instantiate the serialization optimizer class: \" + className, e); &#125; &#125; 小结本篇文章主要介绍了序列化层的抽象API，序列化实现具体的职能是由其 serialize 方法创建的ObjectOutput和 deserialize 方法创建的ObjectInput来完成的，而这两个对象又是对 OutputStream 和 InputStream 的封装。还介绍了序列化优化器，它是用来支持序列化实现对指定的序列化类进行序列化优化处理。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"Dubbo源码分析 - 动态代理本地存根","slug":"rpc/动态代理本地存根","date":"2020-05-01T16:00:00.000Z","updated":"2020-10-01T15:06:29.662Z","comments":false,"path":"posts/1663a5dc/","link":"","permalink":"https://gentryhuang.com/posts/1663a5dc/","excerpt":"","text":"前言在 动态代理总览 中已经介绍了抽象层及使用方式，本篇文章介绍动态代理Wrapper StubProxyFactoryWrapper 。 Wrapper 类在 Dubbo SPI 中已经详细介绍了什么是 Wrapper 类以及 Wrapper 类的作用和用法。StubProxyFactoryWrapper 会在 ProxyFactory 实现执行前先执行。 属性12345678910111213141516171819202122232425public class StubProxyFactoryWrapper implements ProxyFactory &#123; private static final Logger LOGGER = LoggerFactory.getLogger(StubProxyFactoryWrapper.class); /** * ProxyFactory$Adaptive 对象 */ private final ProxyFactory proxyFactory; /** * Protocol$Adaptive 对象 */ private Protocol protocol; /** * StubProxyFactoryWrapper 基于 Dubbo SPI Wrapper 机制，根据URL配置，使用具体的实现【JavassistProxyFactory/JdkProxyFactory】 * * @param proxyFactory */ public StubProxyFactoryWrapper(ProxyFactory proxyFactory) &#123; this.proxyFactory = proxyFactory; &#125; // $&#123;省略其它代码&#125;&#125; StubProxyFactoryWrapper 是 ProxyFactory 的 Wrapper 类，同时它又是实现 Dubbo 动态代理本地存根的类，我们继续往下看。 动态代理本地存根获取代理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public class StubProxyFactoryWrapper implements ProxyFactory &#123; // $&#123;省略其它代码&#125; @Override @SuppressWarnings(&#123;\"unchecked\", \"rawtypes\"&#125;) public &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker) throws RpcException &#123; // 获取代理对象【使用JavassistProxyFactory/JdkProxyFactory】 T proxy = proxyFactory.getProxy(invoker); // 非泛化 【泛化不支持使用本地存根】 if (GenericService.class != invoker.getInterface()) &#123; // 获得 `stub` 配置项 ，注意，local 配置项，和 stub 配置项是等价的，目前使用 stub 而不使用 local 。 String stub = invoker.getUrl().getParameter(Constants.STUB_KEY, invoker.getUrl().getParameter(Constants.LOCAL_KEY)); // 服务引用有配置本地存根 if (ConfigUtils.isNotEmpty(stub)) &#123; Class&lt;?&gt; serviceType = invoker.getInterface(); // `stub = true` 的时，使用 接口 + `Stub` 作为存根类的类名 if (ConfigUtils.isDefault(stub)) &#123; if (invoker.getUrl().hasParameter(Constants.STUB_KEY)) &#123; stub = serviceType.getName() + \"Stub\"; &#125; else &#123; stub = serviceType.getName() + \"Local\"; &#125; &#125; try &#123; // 反射获取本地存根类 Class&lt;?&gt; stubClass = ReflectUtils.forName(stub); // 本地存根类必须是实现服务接口 if (!serviceType.isAssignableFrom(stubClass)) &#123; throw new IllegalStateException(\"The stub implementation class \" + stubClass.getName() + \" not implement interface \" + serviceType.getName()); &#125; try &#123; // 反射获取 Stub 的有参构造方法，参数类型是服务类型 Constructor&lt;?&gt; constructor = ReflectUtils.findConstructor(stubClass, serviceType); // 反射创建本地对象，构造参数需要是服务接口类型对象 proxy = (T) constructor.newInstance(new Object[]&#123;proxy&#125;); //设置了 Stub 参数回调就需要暴露 Stub 服务 URL url = invoker.getUrl(); if (url.getParameter(Constants.STUB_EVENT_KEY, Constants.DEFAULT_STUB_EVENT)) &#123; url = url.addParameter(Constants.STUB_EVENT_METHODS_KEY, StringUtils.join(Wrapper.getWrapper(proxy.getClass()).getDeclaredMethodNames(), \",\")); url = url.addParameter(Constants.IS_SERVER_KEY, Boolean.FALSE.toString()); try &#123; // 暴露 Stub 服务 export(proxy, (Class) invoker.getInterface(), url); &#125; catch (Exception e) &#123; LOGGER.error(\"export a stub service error.\", e); &#125; &#125; &#125; catch (NoSuchMethodException e) &#123; throw new IllegalStateException(\"No such constructor \\\"public \" + stubClass.getSimpleName() + \"(\" + serviceType.getName() + \")\\\" in stub implementation class \" + stubClass.getName(), e); &#125; &#125; catch (Throwable t) &#123; LOGGER.error(\"Failed to create stub implementation class \" + stub + \" in consumer \" + NetUtils.getLocalHost() + \" use dubbo version \" + Version.getVersion() + \", cause: \" + t.getMessage(), t); // ignore &#125; &#125; &#125; return proxy; &#125; // $&#123;省略其它代码&#125;&#125; 获取 Invoker12345678910111213141516171819202122public class StubProxyFactoryWrapper implements ProxyFactory &#123; // $&#123;省略其它代码&#125; /** * * * @param proxy 服务对象 * @param type 服务接口 * @param url URL * @param &lt;T&gt; * @return * @throws RpcException */ @Override public &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) throws RpcException &#123; return proxyFactory.getInvoker(proxy, type, url); &#125; // $&#123;省略其它代码&#125;&#125; 注意，服务提供方不支持 Stub 本地存根，即使 &lt;dubbo:service /&gt; 有 stub 配置项，实际是不起作用的。 小结StubProxyFactoryWrapper 功能比较简单，基本流程如下：","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"Dubbo源码分析 - JDK动态代理","slug":"rpc/Jdk动态代理","date":"2020-04-30T16:00:00.000Z","updated":"2021-01-04T10:57:09.740Z","comments":false,"path":"posts/faa2b4a3/","link":"","permalink":"https://gentryhuang.com/posts/faa2b4a3/","excerpt":"","text":"前言在 动态代理总览 中已经介绍了抽象层，本篇文章介绍 JdkProxyFactory 。 配置方式12&lt;dubbo:reference proxy=\"jdk\" /&gt;&lt;dubbo:service proxy=\"jdk\" /&gt; JDK 代理工厂12345678910111213141516171819202122232425262728293031323334353637383940414243public class JdkProxyFactory extends AbstractProxyFactory &#123; /** * * @param invoker invoker * @param interfaces 服务实现的接口 * @param &lt;T&gt; * @return */ @Override @SuppressWarnings(\"unchecked\") public &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker, Class&lt;?&gt;[] interfaces) &#123; return (T) Proxy.newProxyInstance( Thread.currentThread().getContextClassLoader(), interfaces, new InvokerInvocationHandler(invoker) ); &#125; /** * * @param proxy 服务对象 * @param type 服务接口 * @param url URL * @param &lt;T&gt; * @return */ @Override public &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) &#123; return new AbstractProxyInvoker&lt;T&gt;(proxy, type, url) &#123; @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable &#123; // 调用 Class#getMethod(String name, Class&lt;?&gt;... parameterTypes) 方法，反射获得方法。 Method method = proxy.getClass().getMethod(methodName, parameterTypes); // 调用 Method#invoke(proxy, arguments) 方法，执行方法 return method.invoke(proxy, arguments); &#125; &#125;; &#125;&#125; 获取代理对象JDK 获取代理的方式很简单，不依赖三方依赖，直接使用 JDK 的动态代理为服务接口创建一个代理对象，其中 InvokerInvocationHandler 同 JavassistProxyFactory 。 获取 InvokerJDK 获取 Invoker 同样是创建 AbstractProxyInvoker 的匿名对象，不过在 doInvoke 方法中是直接通过反射拿到实现类的Method对象，然后执行对应的方法，非常清爽。 小结Dubbo 使用 JDK 实现动态非常简单，并且不需要依赖三个依赖，直接一个反射就解决了所有问题，就是性能上有所不足。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"Dubbo源码分析 - Javassist动态代理","slug":"rpc/Javassist动态代理","date":"2020-04-29T16:00:00.000Z","updated":"2020-10-01T14:05:11.294Z","comments":false,"path":"posts/c2df2fc6/","link":"","permalink":"https://gentryhuang.com/posts/c2df2fc6/","excerpt":"","text":"前言在 动态代理总览 中已经详细介绍了抽象层，本篇文章介绍 JavassistProxyFactory 。 配置方式12&lt;dubbo:reference proxy=\"javassist\" /&gt;&lt;dubbo:service proxy=\"javassist\" /&gt; 注意，默认情况就是 javassist。 JavassistProxyFactory实现 AbstractProxyFactory 抽象类，基于 Javassist 代理工厂实现类。 1234567891011121314151617181920212223242526272829303132333435363738394041public class JavassistProxyFactory extends AbstractProxyFactory &#123; /** * * @param invoker invoker * @param interfaces 服务实现的接口(包括 EchoService) * @param &lt;T&gt; * @return */ @Override @SuppressWarnings(\"unchecked\") public &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker, Class&lt;?&gt;[] interfaces) &#123; return (T) Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker)); &#125; /** * * @param proxy Service对象 * @param type Service接口类型 * @param url Service对应的Dubbo URL * @param &lt;T&gt; * @return */ @Override public &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) &#123; // 获取服务类的包装对象，注意 Wrapper类不能正确处理类名包含$的类 final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf('$') &lt; 0 ? proxy.getClass() : type); return new AbstractProxyInvoker&lt;T&gt;(proxy, type, url) &#123; @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable &#123; // 调用 Wrapper 的 invokeMethod 方法，invokeMethod 最终会调用目标方法 return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments); &#125; &#125;; &#125;&#125; JavassistProxyFactory 代理工厂有两个方法，通过方法名很容易看出一个是获取代理对象的，另一个是获取 Invoker 的，前者一般是在引用服务的过程会调用该方法，后者是在暴露服务时会调用。我们下面分别分析这两个方法。 获取代理 Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker)) 上面这段代码信息量还是很大的，总体上做了三件事： Proxy.getProxy(interfaces) 用于构建服务接口代理类并放入内存，接着获取 Proxy 的子类并创建对象， 调用子类对象的 newInstance 方法创建服务接口的代理类的实例，需要 InvokerInvocationHandler 基于 Invoker 创建 InvocationHandler 对象 其中 1、2 两步操作的原理在动态代理总览已经介绍过了，下面我们主要分析第 3 步实现的原理。 实现 InvocationHandler1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.alibaba.dubbo.rpc.proxy;import com.alibaba.dubbo.rpc.Invoker;import com.alibaba.dubbo.rpc.RpcInvocation;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;/** * InvokerInvocationHandler，实现了JDK的InvocationHandler */public class InvokerInvocationHandler implements InvocationHandler &#123; /** * Invoker对象，用于 #invoke方法调用 */ private final Invoker&lt;?&gt; invoker; public InvokerInvocationHandler(Invoker&lt;?&gt; handler) &#123; this.invoker = handler; &#125; /** * 代理对象【Proxy创建的】发出请求，会执行到这里。 * * @param proxy 代理对象 * @param method 方法 * @param args 参数 * @return * @throws Throwable * @see com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory#getProxy(com.alibaba.dubbo.rpc.Invoker, java.lang.Class[]) */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; String methodName = method.getName(); // 处理wait(),notify()等方法，直接进行反射调用 Class&lt;?&gt;[] parameterTypes = method.getParameterTypes(); if (method.getDeclaringClass() == Object.class) &#123; return method.invoke(invoker, args); &#125; // 基础方法，不使用RPC调用 if (\"toString\".equals(methodName) &amp;&amp; parameterTypes.length == 0) &#123; return invoker.toString(); &#125; if (\"hashCode\".equals(methodName) &amp;&amp; parameterTypes.length == 0) &#123; return invoker.hashCode(); &#125; if (\"equals\".equals(methodName) &amp;&amp; parameterTypes.length == 1) &#123; return invoker.equals(args[0]); &#125; // RPC 调用 return invoker.invoke(new RpcInvocation(method, args)).recreate(); &#125;&#125; 在第 2 步中，服务接口代理对象所需要的是 Jdk 的 InvocationHandler，我们再把生成的代理拿过来便于对比分析。 12345678910111213141516171819202122232425262728293031323334353637// 官方Demo服务接口package com.alibaba.dubbo.common.bytecode;import com.alibaba.dubbo.demo.DemoService;import com.alibaba.dubbo.rpc.service.EchoService;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;public class proxy0 implements EchoService, DemoService &#123; public static Method[] methods; private InvocationHandler handler; // 服务接口方法，由代理类来执行 public String sayHello(String paramString) &#123; Object[] arrayOfObject = new Object[1]; arrayOfObject[0] = paramString; // proxy.method =&gt; InvocationHandler.invoke Object localObject = this.handler.invoke(this, methods[0], arrayOfObject); return (String) localObject; &#125; // 回声探测方法 public Object $echo(Object paramObject) &#123; Object[] arrayOfObject = new Object[1]; arrayOfObject[0] = paramObject; Object localObject = this.handler.invoke(this, methods[1], arrayOfObject); return (Object) localObject; &#125; public proxy0() &#123; &#125; // 有参数构造方法 public proxy0(InvocationHandler paramInvocationHandler) &#123; this.handler = paramInvocationHandler; &#125;&#125; 通过以上代码我们很容易总结出调用关系： client -&gt; proxy.method -&gt; InvocationHandler.invoke -&gt; Invoker.invoke 一般消费者在调用服务的时候，会先获取服务接口代理对象，代理对象（Proxy 生成的）发起服务调用会经过 Jdk 的 InvocationHandler 进行路由，如果属于远程调用，则执行 Invoker#invoke 方法进行远程调用。 获取 Invoker Wrapper.getWrapper(proxy.getClass().getName().indexOf(‘$’) &lt; 0 ? proxy.getClass() : type);return new AbstractProxyInvoker(proxy, type, url) 获取 Invoker 做了 2 个工作： 1 获取服务类的包装类 Wrapper2 创建 AbstractProxyInvoker 匿名对象 其中第 1 步在上一篇文章中已经详细说明，下面我们分析下 AbstractProxyInvoker 。 AbstractProxyInvoker在介绍 AbstractProxyInvoker 前我们先看 Invoker 接口，它是 Dubbo 中很重要的模型。 1234567891011121314151617181920212223242526/** * Invoker. (API/SPI, Prototype, ThreadSafe) * * @see com.alibaba.dubbo.rpc.Protocol#refer(Class, com.alibaba.dubbo.common.URL) * @see com.alibaba.dubbo.rpc.InvokerListener * @see com.alibaba.dubbo.rpc.protocol.AbstractInvoker */public interface Invoker&lt;T&gt; extends Node &#123; /** * 获取服务接口 * * @return service interface. */ Class&lt;T&gt; getInterface(); /** * RPC 调用 * * @param invocation * @return result * @throws RpcException */ Result invoke(Invocation invocation) throws RpcException;&#125; Invoker 接口很简单，它就有两个方法，获取服务接口和进行RPC调用。它的实现类很多，先不展开说明遇到了再分析。这里我们分析 AbstractProxyInvoker 。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192public abstract class AbstractProxyInvoker&lt;T&gt; implements Invoker&lt;T&gt; &#123; /** * 代理的对象，一般是服务接口的实现对象 */ private final T proxy; /** * 服务接口 */ private final Class&lt;T&gt; type; /** * URL对象，一般是暴露服务的URL对象 */ private final URL url; public AbstractProxyInvoker(T proxy, Class&lt;T&gt; type, URL url) &#123; if (proxy == null) &#123; throw new IllegalArgumentException(\"proxy == null\"); &#125; if (type == null) &#123; throw new IllegalArgumentException(\"interface == null\"); &#125; if (!type.isInstance(proxy)) &#123; throw new IllegalArgumentException(proxy.getClass().getName() + \" not implement interface \" + type); &#125; this.proxy = proxy; this.type = type; this.url = url; &#125; @Override public Class&lt;T&gt; getInterface() &#123; return type; &#125; @Override public URL getUrl() &#123; return url; &#125; @Override public boolean isAvailable() &#123; return true; &#125; /** * 销毁 * 说明：在通过JavassistProxyFactory工厂创建Invoker时，就是创建了AbstractProxyInvoker抽象匿名对象 */ @Override public void destroy() &#123; &#125; /** * 主要逻辑在doInvoke模版方法中实现 * * @param invocation * @return * @throws RpcException */ @Override public Result invoke(Invocation invocation) throws RpcException &#123; try &#123; // 调用 doInvoke 执行后续的调用，并将调用结果封装到 RpcResult 中 return new RpcResult(doInvoke(proxy, invocation.getMethodName(), invocation.getParameterTypes(), invocation.getArguments())); &#125; catch (InvocationTargetException e) &#123; // 发生InvocationTargetException 异常，创建RpcResult对象包装 return new RpcResult(e.getTargetException()); &#125; catch (Throwable e) &#123; throw new RpcException(\"Failed to invoke remote proxy method \" + invocation.getMethodName() + \" to \" + getUrl() + \", cause: \" + e.getMessage(), e); &#125; &#125; /** * 由具体子类覆写 【默认情况使用 JavassistProxyFactory 创建的一个匿名类对象】 * * @param proxy 服务实例 * @param methodName 方法名 * @param parameterTypes 方法参数类型数组 * @param arguments 方法参数数组 * @return 调用结果 * @throws Throwable 发生异常 */ protected abstract Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable; @Override public String toString() &#123; return getInterface() + \" -&gt; \" + (getUrl() == null ? \" \" : getUrl().toString()); &#125;&#125; 服务暴露的时候会创建该类的匿名对象作为 Invoker，该 Invoker 封装了服务对象及服务相关信息（如服务接口、服务URL等），经过层层包装最终成为 Exporter 对象，更详细的流程会在服务暴露章节详细说明。 结合 getInvoker 方法整体说明 Invoker 创建与调用的过程，忽略容错、路由等细节： 为服务类构建 Wrapper 的实现类，该实现类拥有服务类的属性、方法等信息，其中 invokeMethod 方法会为服务方法做方法名和方法参数匹配，然后创建实现类的对象 创建 AbstractProxyInvoker 匿名对象，其中实现的 doInvoke 方法会调用 Wrapper 实现类对象的 invokeMethod 方法 一个服务对应一个 Wrapper 消费方在调用Invoker.invoke 时，会先触发 doInvoke 方法， Wrapper的实现的invokeMethod方法做了一次转发，然后才会真正调用Invoker（AbstractProxyInvoker）中的服务对象的方法（Invoker封装了服务对象ref） 小结JavassistProxyFactory 在创建服务代理对象和 Invoker 的过程，都使用了字节码技术，尽可能地规避反射操作。下一篇分析 Jdk 的动态代理实现。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"Javassist","slug":"Javassist","permalink":"https://gentryhuang.com/tags/Javassist/"}]},{"title":"Dubbo源码分析 - 动态代理总览","slug":"rpc/Dubbo动态代理总览","date":"2020-04-27T16:00:00.000Z","updated":"2021-01-04T10:57:24.177Z","comments":false,"path":"posts/1d1e42a8/","link":"","permalink":"https://gentryhuang.com/posts/1d1e42a8/","excerpt":"","text":"前言前面的一系列文章主要探讨了 框架设计 中的业务层（service）、配置层（config）以及注册中心层（registry）。虽然代理层（proxy）位于配置层和注册中心层之间，但是它是业务层连接 Dubbo 内部的桥梁，因为业务层无法直接使用 Dubbo 内部概念。需要注意的是，代理层具体实现位于 dubbo-rpc-api模块中。 服务暴露时，需要通过代理层将业务接口实现对象转为 Invoker 。服务引用时，需要通过代理层将业务接口实现对象的 Invoker 转为 Dubbo 的 Proxy 。具体过程下面会详细说明。 概述Dubbo 支持 Javassist 和 JDK 的方式生成代理，默认使用 Javassist 生成代理，配置方式： 12&lt;dubbo:service proxy=\"xxx\"/&gt;&lt;dubbo:reference proxy=\"xxx\"/&gt; Dubbo 代理相关的 UML 图如下： 现在看这个 UML 图可能会不理解，等分析完后再回来看就很清晰了。需要说明的是，分析的过程中会涉及到 Invoker 模型，可以简单理解成一个真实的服务对象，它是 Dubbo 框架实体域，所有模型都会向它靠拢，可向它发起 invoke 调用。 代理工厂 ProxyFactory1234567891011121314151617181920212223242526272829303132333435363738394041/** * ProxyFactory. (API/SPI, Singleton, ThreadSafe) */@SPI(\"javassist\")public interface ProxyFactory &#123; /** * 创建代理对象（为Invoker对象创建代理对象），在引用服务的过程会调用该方法。 * &lt;p&gt; * create proxy. * * @param invoker 消费者对提供者调用的Invoker * @return proxy 代理对象 */ @Adaptive(&#123;Constants.PROXY_KEY&#125;) &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker) throws RpcException; /** * create proxy. * * @param invoker * @return proxy */ @Adaptive(&#123;Constants.PROXY_KEY&#125;) &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker, boolean generic) throws RpcException; /** * 创建Invoker（将代理对象反向封装成Invoker对象），在暴露服务时会调用。 * &lt;p&gt; * create invoker. * * @param &lt;T&gt; * @param proxy Service对象 * @param type Service接口类型 * @param url Service对应的Dubbo URL * @return invoker */ @Adaptive(&#123;Constants.PROXY_KEY&#125;) &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) throws RpcException;&#125; 代理工厂接口是个扩展点，用于获取代理对象和Invoker，默认扩展实现是 javassist，它的三个方法都标注有 @Adaptive({Constants.PROXY_KEY}) 注解信息，表明会自动生成自适应扩展实现，关于自适应扩展在之前的文章中已经详细介绍过了。代理工厂的扩展点配置如下： 123stub&#x3D;com.alibaba.dubbo.rpc.proxy.wrapper.StubProxyFactoryWrapperjdk&#x3D;com.alibaba.dubbo.rpc.proxy.jdk.JdkProxyFactoryjavassist&#x3D;com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory 代理工厂抽象实现类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public abstract class AbstractProxyFactory implements ProxyFactory &#123; /** * * @param invoker 消费者对提供者调用的Invoker * @param &lt;T&gt; * @return * @throws RpcException */ @Override public &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker) throws RpcException &#123; // 调用重载方法获取代理对象 return getProxy(invoker, false); &#125; /** * * 注意：这里会在原有Invoker关联的接口之上增加EchoService接口，作用是回声测试，每个服务都会自动实现EchoService接口。 * 如果要使用回声测试，只需要将任意服务引用强制转型为EchoService即可使用。 * * @param invoker invoker * @param generic 是否泛化 * @param &lt;T&gt; * @return * @throws RpcException */ @Override public &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker, boolean generic) throws RpcException &#123; // 记录要代理的接口 Class&lt;?&gt;[] interfaces = null; // 从Invoker的URL中获取接口列表 String config = invoker.getUrl().getParameter(\"interfaces\"); if (config != null &amp;&amp; config.length() &gt; 0) &#123; // 切分接口列表 String[] types = Constants.COMMA_SPLIT_PATTERN.split(config); if (types != null &amp;&amp; types.length &gt; 0) &#123; interfaces = new Class&lt;?&gt;[types.length + 2]; // 设置服务接口类和EchoService.class 到 interfaces 中，这里就是增加EchoService接口的入口，让服务实现它。 interfaces[0] = invoker.getInterface(); // 回声测试接口 interfaces[1] = EchoService.class; for (int i = 0; i &lt; types.length; i++) &#123; // 加载接口类 interfaces[i + 1] = ReflectUtils.forName(types[i]); &#125; &#125; &#125; // 如果interfaces为空，增加EchoService接口，用于回声测试 if (interfaces == null) &#123; interfaces = new Class&lt;?&gt;[]&#123;invoker.getInterface(), EchoService.class&#125;; &#125; // 为http和hessian 协议提供泛化调用支持 if (!invoker.getInterface().equals(GenericService.class) &amp;&amp; generic) &#123; int len = interfaces.length; Class&lt;?&gt;[] temp = interfaces; // 创建新的interfaces数组 interfaces = new Class&lt;?&gt;[len + 1]; System.arraycopy(temp, 0, interfaces, 0, len); // 设置GenericService.class 到数组中 interfaces[len] = GenericService.class; &#125; // 调用重载方法 return getProxy(invoker, interfaces); &#125; /** * 子类需要实现真正获取Proxy对象的逻辑 * * @param invoker * @param types * @param &lt;T&gt; * @return */ public abstract &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker, Class&lt;?&gt;[] types);&#125; 该抽象类主要为服务自动增加一个实现接口 EchoService，用于回声测试，获取代理的工作交给了具体子类来完成。我们前面也说了子类有两个，具体获取哪一个可以通过配置决定，没有配置默认使用 JavassistProxyFactory 。 Proxy该类位于 dubbo-common 模块下，是 Dubbo 框架自定义的类，用于构建 Proxy 的实现类及创建其对象，为什说是构建 Proxy 的实现类呢？因为 Proxy 是一个抽象类，它的 getProxy 方法利用 Javassist API 构建 Proxy 的子类并通过反射创建其对象。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361package com.alibaba.dubbo.common.bytecode;/** * Proxy. */public abstract class Proxy &#123; /** * 默认的 InvocationHandler 对象，返回 null */ public static final InvocationHandler RETURN_NULL_INVOKER = new InvocationHandler() &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) &#123; return null; &#125; &#125;; /** * 默认的 InvocationHandler 对象，直接抛出异常 */ public static final InvocationHandler THROW_UNSUPPORTED_INVOKER = new InvocationHandler() &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) &#123; throw new UnsupportedOperationException(\"Method [\" + ReflectUtils.getName(method) + \"] unimplemented.\"); &#125; &#125;; /** * 原子对象 */ private static final AtomicLong PROXY_CLASS_COUNTER = new AtomicLong(0); /** * Proxy类所在的包名 */ private static final String PACKAGE_NAME = Proxy.class.getPackage().getName(); /** * Proxy 实例的缓存 * key1: Classloader * key2: 服务实现的接口串 * value: */ private static final Map&lt;ClassLoader, Map&lt;String, Object&gt;&gt; ProxyCacheMap = new WeakHashMap&lt;ClassLoader, Map&lt;String, Object&gt;&gt;(); private static final Object PendingGenerationMarker = new Object(); protected Proxy() &#123; &#125; /** * Get proxy. * * @param ics interface class array. * @return Proxy instance. */ public static Proxy getProxy(Class&lt;?&gt;... ics) &#123; return getProxy(ClassHelper.getClassLoader(Proxy.class), ics); &#125; /** * @param cl 类加载器 * @param ics 服务实现的接口数组 * @return Proxy 接口代理对象 */ public static Proxy getProxy(ClassLoader cl, Class&lt;?&gt;... ics) &#123; //----------------------------------- 1 校验、访问缓存、并发控制 ------------------------------/ if (ics.length &gt; 65535) &#123; throw new IllegalArgumentException(\"interface limit exceeded\"); &#125; StringBuilder sb = new StringBuilder(); // 遍历接口列表 for (int i = 0; i &lt; ics.length; i++) &#123; String itf = ics[i].getName(); // 检测类型是否为接口 if (!ics[i].isInterface()) &#123; throw new RuntimeException(itf + \" is not a interface.\"); &#125; Class&lt;?&gt; tmp = null; try &#123; // 反射获取接口对应的Class tmp = Class.forName(itf, false, cl); &#125; catch (ClassNotFoundException e) &#123; &#125; // 检测接口是否相同，这里tmp有可能为空 if (tmp != ics[i]) &#123; throw new IllegalArgumentException(ics[i] + \" is not visible from class loader\"); &#125; // 拼接接口全限定性名，分隔符为 `;` sb.append(itf).append(';'); &#125; // 使用拼接后的接口名作为 key String key = sb.toString(); // get cache by class loader. Map&lt;String, Object&gt; cache; synchronized (ProxyCacheMap) &#123; // cl 类加载器是否有对应的值，没有则创建一个新的值 cache = ProxyCacheMap.get(cl); if (cache == null) &#123; cache = new HashMap&lt;String, Object&gt;(); ProxyCacheMap.put(cl, cache); &#125; &#125; Proxy proxy = null; synchronized (cache) &#123; do &#123; // 从缓存中获取 key 对应的值，可能是标志未 Object value = cache.get(key); if (value instanceof Reference&lt;?&gt;) &#123; proxy = (Proxy) ((Reference&lt;?&gt;) value).get(); if (proxy != null) &#123; return proxy; &#125; &#125; // 多线程控制，保证只有一个线程可以进行后续操作，即如果已经是标志位说明已经有线程在获取了，当前线程要等待 if (value == PendingGenerationMarker) &#123; try &#123; // 线程要等待 cache.wait(); &#125; catch (InterruptedException e) &#123; &#125; &#125; else &#123; // 设置标志位到缓存中，并跳出while循环进行后续操作 cache.put(key, PendingGenerationMarker); break; &#125; &#125; while (true); &#125; long id = PROXY_CLASS_COUNTER.getAndIncrement(); String pkg = null; // 用于为服务接口生成代理类 ClassGenerator ccp = null; // 为 org.apache.dubbo.common.bytecode.Proxy 抽象类生成子类，主要是实现 Proxy 类的抽象方法 ClassGenerator ccm = null; try &#123; //----------------------------------------- 2 构建接口代理类 -----------------------------------------/ // 创建 javassist 工具对象 （ClassGenerator对 javassist进行了封装） ccp = ClassGenerator.newInstance(cl); Set&lt;String&gt; worked = new HashSet&lt;String&gt;(); List&lt;Method&gt; methods = new ArrayList&lt;Method&gt;(); // 遍历 服务实现的接口数组 for (int i = 0; i &lt; ics.length; i++) &#123; // 检测接口访问级别是否为protected或private if (!Modifier.isPublic(ics[i].getModifiers())) &#123; // 获取接口包名 String npkg = ics[i].getPackage().getName(); if (pkg == null) &#123; pkg = npkg; &#125; else &#123; if (!pkg.equals(npkg)) &#123; // 非public 级别的接口必须在同一个包下，否则报错 throw new IllegalArgumentException(\"non-public interfaces from different packages\"); &#125; &#125; &#125; // 添加接口到 ClassGenerator 工具类的属性中 ccp.addInterface(ics[i]); // 遍历接口方法 for (Method method : ics[i].getMethods()) &#123; // 获取方法签名 String desc = ReflectUtils.getDesc(method); // 如果已经包含在worked中，则忽略。可能会出现，A接口和B接口中包含一个完全相同的方法 if (worked.contains(desc)) &#123; continue; &#125; worked.add(desc); int ix = methods.size(); // 获取方法返回值类型 Class&lt;?&gt; rt = method.getReturnType(); // 获取参数列表 Class&lt;?&gt;[] pts = method.getParameterTypes(); // 生成 Object[] args = new Object[1...N] StringBuilder code = new StringBuilder(\"Object[] args = new Object[\").append(pts.length).append(\"];\"); for (int j = 0; j &lt; pts.length; j++) &#123; code.append(\" args[\").append(j).append(\"] = ($w)$\").append(j + 1).append(\";\"); &#125; // 生成InvokerHandler接口的invoker 方法调用语句，如： Object ret = handler.invoke(this,methods[1...N],args); code.append(\" Object ret = handler.invoke(this, methods[\" + ix + \"], args);\"); // 返回值不为void if (!Void.TYPE.equals(rt)) &#123; // 生成返回语句，形如 return (java.lang.String) ret; code.append(\" return \").append(asArgument(rt, \"ret\")).append(\";\"); &#125; methods.add(method); // 添加方法名、访问控制符、参数列表、方法代码等信息到 ClassGenerator 中 ccp.addMethod(method.getName(), method.getModifiers(), rt, pts, method.getExceptionTypes(), code.toString()); &#125; &#125; if (pkg == null) &#123; pkg = PACKAGE_NAME; &#125; // 拼接接口代理类名称：pkg + \".proxy\" + id，比如 org.apache.dubbo.proxy0 String pcn = pkg + \".proxy\" + id; ccp.setClassName(pcn); // 声明方法数组 ccp.addField(\"public static java.lang.reflect.Method[] methods;\"); // 声明 private java.lang.reflect.InvocationHandler handler; ccp.addField(\"private \" + InvocationHandler.class.getName() + \" handler;\"); /** * 为接口代理类添加带有 InvocationHandler 参数的构造方法，比如： * porxy0(java.lang.reflect.InvocationHandler arg0) &#123; * handler=$1; * &#125; */ ccp.addConstructor(Modifier.PUBLIC, new Class&lt;?&gt;[]&#123;InvocationHandler.class&#125;, new Class&lt;?&gt;[0], \"handler=$1;\"); // 为接口代理类添加默认构造方法，如： public proxy0() &#123;&#125; ccp.addDefaultConstructor(); // 生成接口代理。需要注意的是，下面构建并创建的 Proxy 的子类对象会调用它的 newInstance 方法，进而创建接口代理对象 Class&lt;?&gt; clazz = ccp.toClass(); clazz.getField(\"methods\").set(null, methods.toArray(new Method[0])); //----------------------------------------- 3 构建 Proxy抽象类的子类并创建对象 -----------------------------------------/ // 构建Proxy子类名称，比如：Proxy1 String fcn = Proxy.class.getName() + id; // 创建 javassist 工具对象 （ClassGenerator对 javassist进行了封装） ccm = ClassGenerator.newInstance(cl); // 类名 ccm.setClassName(fcn); // 默认构造方法 ccm.addDefaultConstructor(); // 设置父类 Proxy ccm.setSuperClass(Proxy.class); /** * 为 Proxy 的抽象方法 newInstance 生成实现代码，这里会调用前面生成的接口代理类的有参构造方法。形如： * public Object newInstance(java.lang.reflect.InvocationHandler h) &#123; * return new com.alibaba.demo.proxy0($1); * &#125; */ ccm.addMethod(\"public Object newInstance(\" + InvocationHandler.class.getName() + \" h)&#123; return new \" + pcn + \"($1); &#125;\"); // 生成Proxy实现类 Class&lt;?&gt; pc = ccm.toClass(); /** * 通过反射创建Proxy子类的对象 */ proxy = (Proxy) pc.newInstance(); &#125; catch (RuntimeException e) &#123; throw e; &#125; catch (Exception e) &#123; throw new RuntimeException(e.getMessage(), e); &#125; finally &#123; // release ClassGenerator if (ccp != null) &#123; // 释放资源 ccp.release(); &#125; if (ccm != null) &#123; ccm.release(); &#125; synchronized (cache) &#123; if (proxy == null) &#123; cache.remove(key); &#125; else &#123; // 缓存，注意弱引用 cache.put(key, new WeakReference&lt;Proxy&gt;(proxy)); &#125; // 唤醒其他等待线程 cache.notifyAll(); &#125; &#125; return proxy; &#125; /** * 生成返回语句 * * @param cl * @param name * @return */ private static String asArgument(Class&lt;?&gt; cl, String name) &#123; if (cl.isPrimitive()) &#123; if (Boolean.TYPE == cl) &#123; return name + \"==null?false:((Boolean)\" + name + \").booleanValue()\"; &#125; if (Byte.TYPE == cl) &#123; return name + \"==null?(byte)0:((Byte)\" + name + \").byteValue()\"; &#125; if (Character.TYPE == cl) &#123; return name + \"==null?(char)0:((Character)\" + name + \").charValue()\"; &#125; if (Double.TYPE == cl) &#123; return name + \"==null?(double)0:((Double)\" + name + \").doubleValue()\"; &#125; if (Float.TYPE == cl) &#123; return name + \"==null?(float)0:((Float)\" + name + \").floatValue()\"; &#125; if (Integer.TYPE == cl) &#123; return name + \"==null?(int)0:((Integer)\" + name + \").intValue()\"; &#125; if (Long.TYPE == cl) &#123; return name + \"==null?(long)0:((Long)\" + name + \").longValue()\"; &#125; if (Short.TYPE == cl) &#123; return name + \"==null?(short)0:((Short)\" + name + \").shortValue()\"; &#125; throw new RuntimeException(name + \" is unknown primitive type.\"); &#125; return \"(\" + ReflectUtils.getName(cl) + \")\" + name; &#125; /** * get instance with default handler. * * @return instance. */ public Object newInstance() &#123; return newInstance(THROW_UNSUPPORTED_INVOKER); &#125; /** * get instance with special handler. * * @return instance. */ abstract public Object newInstance(InvocationHandler handler);&#125; Proxy 类是一个抽象类，其逻辑操作主要是使用 Javassist API ，已参考官方文档进行详细注释。该类主要做了两件事，也即构建了两个类： 1 为服务接口创建代理类，这个代理类构建完成后先放入内存中2 构建 Proxy 的实现类并创建该实现类的对象，创建的服务接口代理类的初始化就是在 Proxy 实现类的 newInstance 方法中进行的 服务接口代理类 12345678910111213141516171819202122232425262728293031323334353637// 官方Demo服务接口生成的代理类package com.alibaba.dubbo.common.bytecode;import com.alibaba.dubbo.demo.DemoService;import com.alibaba.dubbo.rpc.service.EchoService;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;public class proxy0 implements EchoService, DemoService &#123; public static Method[] methods; private InvocationHandler handler; // 服务接口方法，由代理类来执行 public String sayHello(String paramString) &#123; Object[] arrayOfObject = new Object[1]; arrayOfObject[0] = paramString; // proxy.method =&gt; InvocationHandler.invoke 【这里是调用目标方法的入口，即通过 InvocationHandler.invoke() 方法调用目标方法 】 Object localObject = this.handler.invoke(this, methods[0], arrayOfObject); return (String) localObject; &#125; // 回声探测方法 public Object $echo(Object paramObject) &#123; Object[] arrayOfObject = new Object[1]; arrayOfObject[0] = paramObject; Object localObject = this.handler.invoke(this, methods[1], arrayOfObject); return (Object) localObject; &#125; public proxy0() &#123; &#125; // 有参数构造方法 public proxy0(InvocationHandler paramInvocationHandler) &#123; this.handler = paramInvocationHandler; &#125;&#125; Proxy 的子类 1234567891011package com.alibaba.dubbo.common.bytecode;import java.lang.reflect.InvocationHandler;public class Proxy0 extends Proxy &#123; // 实现 Proxy 的抽象方法 public Object newInstance(InvocationHandler paramInvocationHandler) &#123; // 创建服务接口的代理对象，构造参数为 InvocationHandler return new proxy0(paramInvocationHandler); &#125;&#125; 注意：Proxy 实例对象和服务没有直接关系的，Proxy 实例对象是用来创建服务的代理对象的。在下一篇文章 Javassist动态代理 中会使用到Proxy实例对象，这里先分析其生成原理及其作用。 Wrapper该类位于 dubbo-common 模块下，是 Dubbo 框架自定义的类，用于包裹目标类，以避免反射调用提高性能。Wrapper同样是基于 Javassit API 进行代码生成。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572package com.alibaba.dubbo.common.bytecode;public abstract class Wrapper &#123; /** * Wrapper缓存对象 * key: Wrapper 包装的类 * value: Wrapper对象 */ private static final Map&lt;Class&lt;?&gt;, Wrapper&gt; WRAPPER_MAP = new ConcurrentHashMap&lt;Class&lt;?&gt;, Wrapper&gt;(); /** * String[] */ private static final String[] EMPTY_STRING_ARRAY = new String[0]; /** * Object 中的部分方法 */ private static final String[] OBJECT_METHODS = new String[]&#123;\"getClass\", \"hashCode\", \"toString\", \"equals\"&#125;; /** * 创建匿名对象，这个仅仅针对目标类是Object 的情况 */ private static final Wrapper OBJECT_WRAPPER = new Wrapper() &#123; @Override public String[] getMethodNames() &#123; return OBJECT_METHODS; &#125; @Override public String[] getDeclaredMethodNames() &#123; return OBJECT_METHODS; &#125; @Override public String[] getPropertyNames() &#123; return EMPTY_STRING_ARRAY; &#125; @Override public Class&lt;?&gt; getPropertyType(String pn) &#123; return null; &#125; @Override public Object getPropertyValue(Object instance, String pn) throws NoSuchPropertyException &#123; throw new NoSuchPropertyException(\"Property [\" + pn + \"] not found.\"); &#125; @Override public void setPropertyValue(Object instance, String pn, Object pv) throws NoSuchPropertyException &#123; throw new NoSuchPropertyException(\"Property [\" + pn + \"] not found.\"); &#125; @Override public boolean hasProperty(String name) &#123; return false; &#125; @Override public Object invokeMethod(Object instance, String mn, Class&lt;?&gt;[] types, Object[] args) throws NoSuchMethodException &#123; if (\"getClass\".equals(mn)) &#123; return instance.getClass(); &#125; if (\"hashCode\".equals(mn)) &#123; return instance.hashCode(); &#125; if (\"toString\".equals(mn)) &#123; return instance.toString(); &#125; if (\"equals\".equals(mn)) &#123; if (args.length == 1) &#123; return instance.equals(args[0]); &#125; throw new IllegalArgumentException(\"Invoke method [\" + mn + \"] argument number error.\"); &#125; throw new NoSuchMethodException(\"Method [\" + mn + \"] not found.\"); &#125; &#125;; private static AtomicLong WRAPPER_CLASS_COUNTER = new AtomicLong(0); /** * 关键一点： 实现的invokeMethod方法封装了传入的Class的方法 * * @param c Class instance. * @return Wrapper instance(not null). */ public static Wrapper getWrapper(Class&lt;?&gt; c) &#123; // can not wrapper on dynamic class. /** * 1 ClassGenerator是类生成器，基于Javassist实现。 * 2 判断是否继承ClassGenerator.DC.class，如果是就拿到父类，避免重复包装 */ while (ClassGenerator.isDynamicClass(c)) &#123; c = c.getSuperclass(); &#125; // 如果是Object.class就直接返回创建的匿名Wrapper if (c == Object.class) &#123; return OBJECT_WRAPPER; &#125; // 从缓存中获得Wrapper Wrapper ret = WRAPPER_MAP.get(c); if (ret == null) &#123; // 缓存未命中，创建Wrapper ret = makeWrapper(c); // 写入缓存 WRAPPER_MAP.put(c, ret); &#125; return ret; &#125; /** * 创建Wrapper * * @param c * @return */ private static Wrapper makeWrapper(Class&lt;?&gt; c) &#123; // -------------------------------------------------- 1 组装、创建Wrapper实例的准备工作 ----------------------------------------------------/ // 检测 c 是否为基本类型，若是则抛出异常 if (c.isPrimitive()) &#123; throw new IllegalArgumentException(\"Can not create wrapper for primitive type: \" + c); &#125; // 类名 String name = c.getName(); // 类加载器 ClassLoader cl = ClassHelper.getClassLoader(c); /** * c1 用于存储 setPropertyValue 方法代码 */ StringBuilder c1 = new StringBuilder(\"public void setPropertyValue(Object o, String n, Object v)&#123; \"); /** * c2 用于存储getPropertyValue 方法代码 */ StringBuilder c2 = new StringBuilder(\"public Object getPropertyValue(Object o, String n)&#123; \"); /** * c3 用于存储 invokeMethod 方法代码 */ StringBuilder c3 = new StringBuilder(\"public Object invokeMethod(Object o, String n, Class[] p, Object[] v) throws \" + InvocationTargetException.class.getName() + \"&#123; \"); /** * 添加每个方法的被调用对象的类型转换的代码。即生成类型转换代码及异常捕捉代码，如： DemoService w; try &#123; w = ((DemoServcie) $1); &#125;&#125;catch(Throwable e)&#123; throw new IllegalArgumentException(e); &#125; */ c1.append(name).append(\" w; try&#123; w = ((\").append(name).append(\")$1); &#125;catch(Throwable e)&#123; throw new IllegalArgumentException(e); &#125;\"); c2.append(name).append(\" w; try&#123; w = ((\").append(name).append(\")$1); &#125;catch(Throwable e)&#123; throw new IllegalArgumentException(e); &#125;\"); c3.append(name).append(\" w; try&#123; w = ((\").append(name).append(\")$1); &#125;catch(Throwable e)&#123; throw new IllegalArgumentException(e); &#125;\"); /** * pts 用于存储成员变量名和类型 */ Map&lt;String, Class&lt;?&gt;&gt; pts = new HashMap&lt;String, Class&lt;?&gt;&gt;(); // &lt;property name, property types&gt; /** * ms 用于存储方法签名 及 Method 实例 */ Map&lt;String, Method&gt; ms = new LinkedHashMap&lt;String, Method&gt;(); // &lt;method desc, Method instance&gt; /** * mns 为方法名列表 */ List&lt;String&gt; mns = new ArrayList&lt;String&gt;(); // method names. /** * dmns 用于存储定义在当前类中的方法的名称 */ List&lt;String&gt; dmns = new ArrayList&lt;String&gt;(); // declaring method names. // -------------------------------------------------- 2 解析目标类的属性 ----------------------------------------------------/ // 获取public 访问级别的字段，并为所有字段生成条件判断语句 for (Field f : c.getFields()) &#123; String fn = f.getName(); Class&lt;?&gt; ft = f.getType(); // 忽略关键字 static 或 transient 修饰的变量 if (Modifier.isStatic(f.getModifiers()) || Modifier.isTransient(f.getModifiers())) &#123; continue; &#125; // 生成条件判断及赋值语句，如：if($2.equals(\"name\"))&#123;w.name = (java.lang.String)$3;return;&#125; c1.append(\" if( $2.equals(\\\"\").append(fn).append(\"\\\") )&#123; w.\").append(fn).append(\"=\").append(arg(ft, \"$3\")).append(\"; return; &#125;\"); // 生成条件判断及返回语句，如: if($2.equals(\"name\"))&#123;return ($w)w.name;&#125; c2.append(\" if( $2.equals(\\\"\").append(fn).append(\"\\\") )&#123; return ($w)w.\").append(fn).append(\"; &#125;\"); // 存储 &lt;字段名，字段类型&gt; 赋值对到pts中 pts.put(fn, ft); &#125; // -------------------------------------------------- 3 解析目标类的方法 ---------------------------------------------------/ // 获取目标类中的方法列表 Method[] methods = c.getMethods(); // get all public method. // 检测目标类中是否包含在当前类中声明的方法 boolean hasMethod = hasMethods(methods); if (hasMethod) &#123; c3.append(\" try&#123;\"); &#125; for (Method m : methods) &#123; // 忽略Ojbect 中定义的方法 if (m.getDeclaringClass() == Object.class) &#123; continue; &#125; String mn = m.getName(); // 生成方法名判断语句，如：if ( \"sayHello\".equals( $2 ) c3.append(\" if( \\\"\").append(mn).append(\"\\\".equals( $2 ) \"); int len = m.getParameterTypes().length; // 生成运行时传入参数的数量与方法的参数列表长度判读语句，如：&amp;&amp; $3.length == 2 c3.append(\" &amp;&amp; \").append(\" $3.length == \").append(len); // 若相同方法名存在多个，增加参数类型数组的比较判断 boolean override = false; for (Method m2 : methods) &#123; // 检测方法是否存在重载情况，条件为：方法对象不同 &amp;&amp; 方法名相同 if (m != m2 &amp;&amp; m.getName().equals(m2.getName())) &#123; override = true; break; &#125; &#125; /** * 对重载方法进行处理，考虑下面的方法： * 1 void sayHello(Integer,String) * 2 void sayHello(Integer,Integer) * 方法名相同，参数列表长度也相同，因此不能仅通过上面两个条件判断两个方法是否相等，需要进一步判断方法的参数类型 */ if (override) &#123; if (len &gt; 0) &#123; for (int l = 0; l &lt; len; l++) &#123; /** * &amp;&amp; $3[0].getName().equals(\"java.lang.Integer\") &amp;&amp; $3[1].getName().equals(\"java.lang.String\") */ c3.append(\" &amp;&amp; \").append(\" $3[\").append(l).append(\"].getName().equals(\\\"\") .append(m.getParameterTypes()[l].getName()).append(\"\\\")\"); &#125; &#125; &#125; /** * 添加 )&#123;,完成方法判断语句，此时生成的方法可能如下： * if(\"sayHello\".equals($2) &amp;&amp; $3.length == 2 &amp;&amp; $3[0].getName().equals(\"java.lang.Integer\") &amp;&amp; $3[1].getName().equals(\"java.lang.String\") */ c3.append(\" ) &#123; \"); // 根据返回值类型生成目标方法调用语句 if (m.getReturnType() == Void.TYPE) &#123; // w.sayHello((java.lang.Integer)$4[0],(java.lang.String)$4[1]); return null; c3.append(\" w.\").append(mn).append('(').append(args(m.getParameterTypes(), \"$4\")).append(\");\").append(\" return null;\"); &#125; else &#123; // return w.sayHello((java.lang.Integer)$4[0],(java.lang.String)$4[1]) c3.append(\" return ($w)w.\").append(mn).append('(').append(args(m.getParameterTypes(), \"$4\")).append(\");\"); &#125; /** * 添加 &#125; ，目标方法调用语句生成完毕，如下： * * if(\"sayHello\".equals($2) &amp;&amp; $3.length == 2 &amp;&amp; $3[0].getName().equals(\"java.lang.Integer\") &amp;&amp; $3[1].getName().equals(\"java.lang.String\") * w.sayHello((java.lang.Integer)$4[0],(java.lang.String)$4[1]); return null; * return null; * &#125; */ c3.append(\" &#125;\"); // 添加方法名到mns集合中 mns.add(mn); // 检测当前方法是否在c中被声明 if (m.getDeclaringClass() == c) &#123; // 若是，则将当前方法名添加到dmns中 dmns.add(mn); &#125; ms.put(ReflectUtils.getDesc(m), m); &#125; // 如果有方法，就添加 invokeMethod(o,n,p,v) 的 catch 的代码 if (hasMethod) &#123; // 添加异常捕获语句 c3.append(\" &#125; catch(Throwable e) &#123; \"); c3.append(\" throw new java.lang.reflect.InvocationTargetException(e); \"); c3.append(\" &#125;\"); &#125; // 添加 invokeMethod(o,n,p,v) 的未匹配到方法的代码。即添加NoSuchMethodException 异常抛出代码 c3.append(\" throw new \" + NoSuchMethodException.class.getName() + \"(\\\"Not found method \\\\\\\"\\\"+$2+\\\"\\\\\\\" in class \" + c.getName() + \".\\\"); &#125;\"); //----------------------------------------------4 解析目标类属性操作方法，setter/getter ----------------------------------------------------------/ // 循环 setting/getting 方法，添加每个属性的设置和获得分别到 `#setPropertyValue(o, n, v)` 和 `#getPropertyValue(o, n)` 的代码 Matcher matcher; // 处理get/set方法 for (Map.Entry&lt;String, Method&gt; entry : ms.entrySet()) &#123; String md = entry.getKey(); Method method = entry.getValue(); // 匹配以get开头的方法 if ((matcher = ReflectUtils.GETTER_METHOD_DESC_PATTERN.matcher(md)).matches()) &#123; // 获取属性名 String pn = propertyName(matcher.group(1)); // 生成属性判断以及返回语句，示例如： if($2.equals(\"name\")) &#123; return ($w).w.getName()&#125; c2.append(\" if( $2.equals(\\\"\").append(pn).append(\"\\\") )&#123; return ($w)w.\").append(method.getName()).append(\"(); &#125;\"); pts.put(pn, method.getReturnType()); // 匹配以is/has/can 开头的方法 &#125; else if ((matcher = ReflectUtils.IS_HAS_CAN_METHOD_DESC_PATTERN.matcher(md)).matches()) &#123; String pn = propertyName(matcher.group(1)); // 生成属性判断以及 返回语句，如： if($2.equals(\"dream\"))&#123;return ($w)w.hasDream();&#125; c2.append(\" if( $2.equals(\\\"\").append(pn).append(\"\\\") )&#123; return ($w)w.\").append(method.getName()).append(\"(); &#125;\"); pts.put(pn, method.getReturnType()); // 匹配以set 开头的方法 &#125; else if ((matcher = ReflectUtils.SETTER_METHOD_DESC_PATTERN.matcher(md)).matches()) &#123; Class&lt;?&gt; pt = method.getParameterTypes()[0]; String pn = propertyName(matcher.group(1)); // 生成属性判断以及setter 调用语句，如： if($2.equals(\"name\"))&#123;w.setName(java.lang.String)$3);return;&#125; c1.append(\" if( $2.equals(\\\"\").append(pn).append(\"\\\") )&#123; w.\").append(method.getName()).append(\"(\").append(arg(pt, \"$3\")).append(\"); return; &#125;\"); pts.put(pn, pt); &#125; &#125; // 添加 NoSuchPropertyException 异常抛出语句 c1.append(\" throw new \" + NoSuchPropertyException.class.getName() + \"(\\\"Not found property \\\\\\\"\\\"+$2+\\\"\\\\\\\" filed or setter method in class \" + c.getName() + \".\\\"); &#125;\"); c2.append(\" throw new \" + NoSuchPropertyException.class.getName() + \"(\\\"Not found property \\\\\\\"\\\"+$2+\\\"\\\\\\\" filed or setter method in class \" + c.getName() + \".\\\"); &#125;\"); //--------------------------------------------------- 5 为上面生成的代码构建 Class 类并组、射创建 Wrapper 实例 ---------------------------------------------------/ // make class long id = WRAPPER_CLASS_COUNTER.getAndIncrement(); // 创建类生成器 ClassGenerator cc = ClassGenerator.newInstance(cl); // 设置类名 cc.setClassName((Modifier.isPublic(c.getModifiers()) ? Wrapper.class.getName() : c.getName() + \"$sw\") + id); // 设置父类为 Wrapper.class cc.setSuperClass(Wrapper.class); // 添加默认构造方法 cc.addDefaultConstructor(); // 添加静态属性 `pns` 的代码 cc.addField(\"public static String[] pns;\"); // property name array. // 添加静态属性 `pts` 的代码 cc.addField(\"public static \" + Map.class.getName() + \" pts;\"); // property type map. // 添加静态属性 `mns` 的代码 cc.addField(\"public static String[] mns;\"); // all method name array. // 添加静态属性 `dmns` 的代码 cc.addField(\"public static String[] dmns;\"); // declared method name array. // 添加静态属性 `mts` 的代码。每个方法的参数数组。 for (int i = 0, len = ms.size(); i &lt; len; i++) &#123; cc.addField(\"public static Class[] mts\" + i + \";\"); &#125; // ======= 添加抽象方法的实现，到 `cc` 中 // 添加 `#getPropertyNames()` 的代码到 `cc` cc.addMethod(\"public String[] getPropertyNames()&#123; return pns; &#125;\"); // 添加 `#hasProperty(n)` 的代码到 `cc` cc.addMethod(\"public boolean hasProperty(String n)&#123; return pts.containsKey($1); &#125;\"); // 添加 `#getPropertyType(n)` 的代码到 `cc` cc.addMethod(\"public Class getPropertyType(String n)&#123; return (Class)pts.get($1); &#125;\"); // 添加 `#getMethodNames()` 的代码到 `cc` cc.addMethod(\"public String[] getMethodNames()&#123; return mns; &#125;\"); // 添加 `#getDeclaredMethodNames()` 的代码到 `cc` cc.addMethod(\"public String[] getDeclaredMethodNames()&#123; return dmns; &#125;\"); // 添加 `#setPropertyValue(o, n, v)` 的代码到 `cc` cc.addMethod(c1.toString()); // 添加 `#getPropertyValue(o, n)` 的代码到 `cc` cc.addMethod(c2.toString()); // 添加 `#invokeMethod(o, n, p, v)` 的代码到 `cc` cc.addMethod(c3.toString()); try &#123; // 生成类，通过javassist构建 Class&lt;?&gt; wc = cc.toClass(); // 反射，设置静态变量的值 wc.getField(\"pts\").set(null, pts); wc.getField(\"pns\").set(null, pts.keySet().toArray(new String[0])); wc.getField(\"mns\").set(null, mns.toArray(new String[0])); wc.getField(\"dmns\").set(null, dmns.toArray(new String[0])); int ix = 0; for (Method m : ms.values()) &#123; wc.getField(\"mts\" + ix++).set(null, m.getParameterTypes()); &#125; // 通过反射创建对象 创建Wrapper 实例 return (Wrapper) wc.newInstance(); &#125; catch (RuntimeException e) &#123; throw e; &#125; catch (Throwable e) &#123; throw new RuntimeException(e.getMessage(), e); &#125; finally &#123; // 释放资源 cc.release(); ms.clear(); mns.clear(); dmns.clear(); &#125; &#125; // 方法返回语句 private static String arg(Class&lt;?&gt; cl, String name) &#123; if (cl.isPrimitive()) &#123; if (cl == Boolean.TYPE) &#123; return \"((Boolean)\" + name + \").booleanValue()\"; &#125; if (cl == Byte.TYPE) &#123; return \"((Byte)\" + name + \").byteValue()\"; &#125; if (cl == Character.TYPE) &#123; return \"((Character)\" + name + \").charValue()\"; &#125; if (cl == Double.TYPE) &#123; return \"((Number)\" + name + \").doubleValue()\"; &#125; if (cl == Float.TYPE) &#123; return \"((Number)\" + name + \").floatValue()\"; &#125; if (cl == Integer.TYPE) &#123; return \"((Number)\" + name + \").intValue()\"; &#125; if (cl == Long.TYPE) &#123; return \"((Number)\" + name + \").longValue()\"; &#125; if (cl == Short.TYPE) &#123; return \"((Number)\" + name + \").shortValue()\"; &#125; throw new RuntimeException(\"Unknown primitive type: \" + cl.getName()); &#125; return \"(\" + ReflectUtils.getName(cl) + \")\" + name; &#125; private static String args(Class&lt;?&gt;[] cs, String name) &#123; int len = cs.length; if (len == 0) &#123; return \"\"; &#125; StringBuilder sb = new StringBuilder(); for (int i = 0; i &lt; len; i++) &#123; if (i &gt; 0) &#123; sb.append(','); &#125; sb.append(arg(cs[i], name + \"[\" + i + \"]\")); &#125; return sb.toString(); &#125; private static String propertyName(String pn) &#123; return pn.length() == 1 || Character.isLowerCase(pn.charAt(1)) ? Character.toLowerCase(pn.charAt(0)) + pn.substring(1) : pn; &#125; // 是否是有效的方法 private static boolean hasMethods(Method[] methods) &#123; if (methods == null || methods.length == 0) &#123; return false; &#125; for (Method m : methods) &#123; // 有一个不是Object中定义的方法就说明符合条件 if (m.getDeclaringClass() != Object.class) &#123; return true; &#125; &#125; return false; &#125; /** * get property name array. * * @return property name array. */ abstract public String[] getPropertyNames(); /** * get property type. * * @param pn property name. * @return Property type or nul. */ abstract public Class&lt;?&gt; getPropertyType(String pn); /** * has property. * * @param name property name. * @return has or has not. */ abstract public boolean hasProperty(String name); /** * get property value. * * @param instance instance. * @param pn property name. * @return value. */ abstract public Object getPropertyValue(Object instance, String pn) throws NoSuchPropertyException, IllegalArgumentException; /** * set property value. * * @param instance instance. * @param pn property name. * @param pv property value. */ abstract public void setPropertyValue(Object instance, String pn, Object pv) throws NoSuchPropertyException, IllegalArgumentException; /** * get property value. * * @param instance instance. * @param pns property name array. * @return value array. */ public Object[] getPropertyValues(Object instance, String[] pns) throws NoSuchPropertyException, IllegalArgumentException &#123; Object[] ret = new Object[pns.length]; for (int i = 0; i &lt; ret.length; i++) &#123; ret[i] = getPropertyValue(instance, pns[i]); &#125; return ret; &#125; /** * set property value. * * @param instance instance. * @param pns property name array. * @param pvs property value array. */ public void setPropertyValues(Object instance, String[] pns, Object[] pvs) throws NoSuchPropertyException, IllegalArgumentException &#123; if (pns.length != pvs.length) &#123; throw new IllegalArgumentException(\"pns.length != pvs.length\"); &#125; for (int i = 0; i &lt; pns.length; i++) &#123; setPropertyValue(instance, pns[i], pvs[i]); &#125; &#125; /** * get method name array. * * @return method name array. */ abstract public String[] getMethodNames(); /** * get method name array. * * @return method name array. */ abstract public String[] getDeclaredMethodNames(); /** * has method. * * @param name method name. * @return has or has not. */ public boolean hasMethod(String name) &#123; for (String mn : getMethodNames()) &#123; if (mn.equals(name)) &#123; return true; &#125; &#125; return false; &#125; /** * 抽象方法，Dubbo在运行时会通过 Javassist 框架 为 Wrapper生成实现类，并实现该方法，该方法会根据调用信息调用具体的服务 * * @param instance 被调用的对象 * @param mn 方法名 * @param types 参数类型数组 * @param args 参数数组 * @return 返回值 */ abstract public Object invokeMethod(Object instance, String mn, Class&lt;?&gt;[] types, Object[] args) throws NoSuchMethodException, InvocationTargetException;&#125; Wrapper 类的代码很多，但是就做一件事，对方法调用的包装，为什么能包装？ 为什么要包装？怎么执行目标对象方法？ 1 Wrapper 是一个抽象类，仅可通过 getWrapper(Class) 方法创建子类然后反射创建对象。在创建 Wrapper 子类的过程中，子类代码生成逻辑会对 getWrapper 方法传入的 Class 进行解析，拿到其方法，类成员变量等信息，以及生成 invokeMethod 方法代码等。2 包装的目的是避免反射调用，提高性能。需要注意的是，创建 Wrapper 实例还是要通过反射的。3 包装后，只需把包装类的对象、方法及参数传入invokeMethod方法中，无需通过反射就能匹配到方法并执行 可以发现 Wrapper 逻辑的套路和 Proxy 差不多，都是通过 Javassist API 生成类并反射创建对象。以 Dubbo 的官方Demo服务接口为例，生成的 Wrapper 实现类整理后如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778package com.alibaba.dubbo.common.bytecode;public class Wrapper0 extends Wrapper &#123; public static String[] pns; public static java.util.Map pts; public static String[] mns;, public static String[] dmns; public static Class[] mts0; public Wrapper0() &#123; &#125; public String[] getPropertyNames() &#123; return pns; &#125; public boolean hasProperty(String n) &#123; return pts.containsKey($1); &#125; public Class getPropertyType(String n) &#123; return (Class) pts.get($1); &#125; public String[] getMethodNames() &#123; return mns; &#125; public String[] getDeclaredMethodNames() &#123; return dmns; &#125; public void setPropertyValue(Object o, String n, Object v) &#123; com.alibaba.dubbo.demo.DemoService w; try &#123; w = ((com.alibaba.dubbo.demo.DemoService) $1); &#125; catch (Throwable e) &#123; throw new IllegalArgumentException(e); &#125; throw new com.alibaba.dubbo.common.bytecode.NoSuchPropertyException(\"Not found property \\\"\" + $2 + \"\\\" filed or setter method in class com.alibaba.dubbo.demo.DemoService.\"); &#125; public Object getPropertyValue(Object o, String n) &#123; com.alibaba.dubbo.demo.DemoService w; try &#123; w = ((com.alibaba.dubbo.demo.DemoService) $1); &#125; catch (Throwable e) &#123; throw new IllegalArgumentException(e); &#125; throw new com.alibaba.dubbo.common.bytecode.NoSuchPropertyException(\"Not found property \\\"\" + $2 + \"\\\" filed or setter method in class com.alibaba.dubbo.demo.DemoService.\"); &#125; /** * * @param o 目标类对象 * @param n 方名 * @param p 参数类型 * @param v 参数值 * @return * @throws java.lang.reflect.InvocationTargetException */ public Object invokeMethod(Object o, String n, Class[] p, Object[] v) throws java.lang.reflect.InvocationTargetException &#123; com.alibaba.dubbo.demo.DemoService w; try &#123; w = ((com.alibaba.dubbo.demo.DemoService) $1); &#125; catch (Throwable e) &#123; throw new IllegalArgumentException(e); &#125; try &#123; if (\"sayHello\".equals($2) &amp;&amp; $3.length == 1) &#123; return ($w) w.sayHello((java.lang.String) $4[0]); &#125; &#125; catch (Throwable e) &#123; throw new java.lang.reflect.InvocationTargetException(e); &#125; throw new com.alibaba.dubbo.common.bytecode.NoSuchMethodException(\"Not found method \\\"\" + $2 + \"\\\" in class com.alibaba.dubbo.demo.DemoService.\"); &#125;&#125; 小结本篇文章主要分析了 Dubbo 动态代理的抽象层，具体的实现是通过 Dubbo SPI 来决策的。此外，重点介绍了 Proxy 和 Wrapper 这两个类，Proxy 类用来创建服务接口代理类的实例，Wrapper 类是对服务类进行拆解、包装，对服务方法进行映射处理，避免反射调用。 服务消费者使用Proxy创建的服务代理对象屏蔽了网络通信等细节，服务提供者使用Wrapper将个性化的服务接口实现统一转成Invoker， Proxy 和 Wrapper 实现了 Dubbo 内部和业务接口之间的无缝转换。在之后的服务暴露、服务引用以及服务调用环节中可以看到它们的必要性。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"Javassist","slug":"Javassist","permalink":"https://gentryhuang.com/tags/Javassist/"}]},{"title":"Dubbo源码分析 - Redis注册中心","slug":"rpc/注册中心之Redis","date":"2020-04-25T16:00:00.000Z","updated":"2020-10-13T11:46:23.954Z","comments":false,"path":"posts/b2453481/","link":"","permalink":"https://gentryhuang.com/posts/b2453481/","excerpt":"","text":"前言在 注册中心总览 中介绍了 Dubbo 的注册中心抽象层，包括注册中心及其工厂。本篇文章将介绍 Dubbo 的 Redis 注册中心及其工厂。 UML 图中的 RedisRegistry 类中实现了 Redis 作为注册中心的逻辑，其中 Redis 的客户端使用的是 Jedis 。 Dubbo 中的 Redis 注册中心 Redis 注册中心也沿用了 Dubbo 抽象的 Root、Service、Type、URL 四层结构。在 Redis 中数据都是以键值对的形式保存的，并不能像 Zookeeper 一样直接实现树形目录结构。因此，Redis 使用了 key/Map 结构存储数据： 主key：Root、Service、Type 组合成的值，即服务名和类型，对应图中 /dubbo/com.foo.BarService/providers主key的值Map中的key：URL串，对应图中 dubbo://10.20.153.10:123/barService=13658…主key的值Map中的value: 过期时间 Zookeeper 是基于监听器来感知数据的变化，而 Redis 使用基于 Publish/Subscribe 事件通知数据变更： 通过事件的值区分事件消息类型：register,unregister普通消费者订阅指定的服务提供者的Key，只会收到指定服务的 register,unregister 事件监控中心订阅 /dubbo/*，会收到所有服务的所有变更事件 注意事项： 当前 Dubbo 版本的 Redis注册中心只会发送两种事件，分别对应服务提供者、服务消费者、动态配置、路由配置的注册与反注册，发送这两个事件的通道Channel是由服务接口决定的。 服务实例的启动或关闭，会写入或删除对应的数据，并通过通道发布对应的 register，unregister 事件消息，从而保证实时性。 如果使用监控中心（会订阅/dubbo/*）,Redis 注册中心会定时调度触发清理逻辑，保证未正常关闭的服务实例的 URL 的删除，并发起对应的 unregister 事件消息，从而保证数据的最终一致性。 不使用 Redis 的自动过期机制，而是通过监控中心实现过期机制，因为 Redis 的key自动过期不存在相应的事件消息通知。 选项 可通过 &lt;dubbo:registry group=”dubbo” /&gt; 设置 redis 中 key 的前缀，缺省为 dubbo。 可通过 &lt;dubbo:registry cluster=”replicate” /&gt; 设置 redis 集群策略，缺省为 failover。failover: 只写入和读取任意一台，失败时重试另一台，需要服务器端自行配置数据同步，replicate: 在客户端同时写入所有服务器，只读取单台，服务器端不需要同步，注册中心集群增大，性能压力也会更大。 流程说明订阅与通知是注册中心非常重要的功能，使用 Redis 作为注册中心，其订阅与通知实现方式与 Zookeeper 不同。Redis 订阅通知机制使用的是 过期机制 和 Publish/Subscribe 机制。 服务提供者启动服务提供者启动时，首先会在 Redis 中创建约定的k-v键值对，然后在通道（Root + Service + Type）中发布一条 register 事件消息。接着服务提供者会订阅动态配置信息，也就是在订阅URL中设置 category=configurators 。但是需要说明的是，Redis 的订阅实现方式不同 Zookeeper ，Zookeeper 可以直接注册子节点监听器直接监听 .../configurators 下的子节点变化，并且首次订阅就可以返回全量数据。而 Redis 每次订阅并没有订阅详细的Channel，如 /dubbo/com.foo.BarService/configurators，而是统一订阅 Root + Service + *，如 Channel:/dubbo/com.alibaba.dubbo.demo.DemoService/* ,这样一来任何只要是 Root + Service 匹配到的通道有消息都可以被订阅通知对象感知到。除此以外，使用 Redis 作为注册中心进行首次订阅的时候，当前订阅URL的 Root + Service 没有对应的通知器时会为其创建通知器，这个通知器就是用来订阅通道的， 由于 Redis 没有像 Zookeeper 那样绑定监听器，因此首次订阅需要主动使用 Redis 客户端获取 Root + Service 下的所有分类即 Type，然后再根据每个具体的分类获取其对应的 URL 列表，最后就是 Dubbo 的通知逻辑了。 服务消费者启动服务消费者启动的流程和服务提供者几乎一致，不同的是，在 Redis 中创建的k-v队是消费者的，消费者订阅的信息除了动态配置信息，还包括服务提供者信息和路由信息。 监控中心启动监控中心(dubbo-admin)启动的时候只会进行订阅，而且订阅的是所有服务信息，即订阅的通道为 /dubbo/*，也就是说它会订阅所有服务的 providers、consumers、configurators和routers。通过监控中心进行服务治理时，如 设置配置参数、设置路由规则、调整权重、设置黑白名单等才会涉及注册与反注册操作。当订阅的通道有数据变动时，就会触发回调操作。 源码分析RedisRegistryFactory12345678910111213public class RedisRegistryFactory extends AbstractRegistryFactory &#123; /** * * @param url 注册中心地址 * @return */ @Override protected Registry createRegistry(URL url) &#123; // 创建 RedisRegistry 对象 return new RedisRegistry(url); &#125;&#125; RedisRegistry 工厂比较简单，没有其它逻辑，仅仅创建了一个 RedisRegistry 对象。 RedisRegistry属性1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class RedisRegistry extends FailbackRegistry &#123; private static final Logger logger = LoggerFactory.getLogger(RedisRegistry.class); /** * 默认端口 */ private static final int DEFAULT_REDIS_PORT = 6379; /** * 默认redis的key的根据节点 */ private final static String DEFAULT_ROOT = \"dubbo\"; /** * Redis Key 延时过期执行器 */ private final ScheduledExecutorService expireExecutor = Executors.newScheduledThreadPool(1, new NamedThreadFactory(\"DubboRegistryExpireTimer\", true)); /** * Redis Key 延时过期任务的Future */ private final ScheduledFuture&lt;?&gt; expireFuture; /** * Redis 根节点 */ private final String root; /** * JedisPool 集合 * key: ip:port * value: JedisPool */ private final Map&lt;String, JedisPool&gt; jedisPools = new ConcurrentHashMap&lt;String, JedisPool&gt;(); /** * 通知器集合，用于Redis Publish/Subscribe机制中的订阅，本质是调用 Jedis的psubscribe方法进行订阅通道 * key: Root + Service,例如： /dubbo/com.alibaba.dubbo.demo.DemoService * value: 通知器 */ private final ConcurrentMap&lt;String, Notifier&gt; notifiers = new ConcurrentHashMap&lt;String, Notifier&gt;(); /** * 重连周期，单位：毫秒 * 订阅发生Redis连接异常时，Notifier sleep，等待重连 */ private final int reconnectPeriod; /** * 过期周期，单位：毫秒 */ private final int expirePeriod; /** * 是否使用了监控中心，使用了监控中心该属性会被设置 true * 用于判断脏数据，脏数据由监控中心删除&#123;@link #clean(Jedis)&#125; */ private volatile boolean admin = false; /** * 是否复制模式，缺省是failover */ private boolean replicate; // $&#123;省略其它代码&#125;&#125; 构造方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117public class RedisRegistry extends FailbackRegistry &#123; // $&#123;省略其它代码&#125; public RedisRegistry(URL url) &#123; super(url); if (url.isAnyHost()) &#123; throw new IllegalStateException(\"registry address == null\"); &#125; // 创建 GenericObjectPoolConfig 对象 GenericObjectPoolConfig config = new GenericObjectPoolConfig(); // 连接从pool中获取，使用前会被验证，通过ping命令检测 config.setTestOnBorrow(url.getParameter(\"test.on.borrow\", true)); // 连接在被归还给pool前，会验证连接的有效性，通过ping命令来检测 config.setTestOnReturn(url.getParameter(\"test.on.return\", false)); // 打开空闲连接存活和回收，周期性检测 config.setTestWhileIdle(url.getParameter(\"test.while.idle\", false)); // pool中最大的空闲连接数；达到后pool会开始回收空闲连接，直到空闲连接数达到Mindle个数。 主要避免空连接占用，资源浪费 if (url.getParameter(\"max.idle\", 0) &gt; 0) &#123; config.setMaxIdle(url.getParameter(\"max.idle\", 0)); &#125; // pool中保持最小的空闲可用连接数，这部分不被回收。可防止流量增量时，连接创建不及时 if (url.getParameter(\"min.idle\", 0) &gt; 0) &#123; config.setMinIdle(url.getParameter(\"min.idle\", 0)); &#125; // pool可分配的连接数 if (url.getParameter(\"max.active\", 0) &gt; 0) &#123; config.setMaxTotal(url.getParameter(\"max.active\", 0)); &#125; // 当前pool可并发的最大连接数 if (url.getParameter(\"max.total\", 0) &gt; 0) &#123; config.setMaxTotal(url.getParameter(\"max.total\", 0)); &#125; // 获取连接的最大等待时间 if (url.getParameter(\"max.wait\", url.getParameter(\"timeout\", 0)) &gt; 0) &#123; config.setMaxWaitMillis(url.getParameter(\"max.wait\", url.getParameter(\"timeout\", 0))); &#125; if (url.getParameter(\"num.tests.per.eviction.run\", 0) &gt; 0) &#123; config.setNumTestsPerEvictionRun(url.getParameter(\"num.tests.per.eviction.run\", 0)); &#125; if (url.getParameter(\"time.between.eviction.runs.millis\", 0) &gt; 0) &#123; config.setTimeBetweenEvictionRunsMillis(url.getParameter(\"time.between.eviction.runs.millis\", 0)); &#125; if (url.getParameter(\"min.evictable.idle.time.millis\", 0) &gt; 0) &#123; config.setMinEvictableIdleTimeMillis(url.getParameter(\"min.evictable.idle.time.millis\", 0)); &#125; // 是否复制模式 String cluster = url.getParameter(\"cluster\", \"failover\"); if (!\"failover\".equals(cluster) &amp;&amp; !\"replicate\".equals(cluster)) &#123; throw new IllegalArgumentException(\"Unsupported redis cluster: \" + cluster + \". The redis cluster only supported failover or replicate.\"); &#125; replicate = \"replicate\".equals(cluster); // 解析 List&lt;String&gt; addresses = new ArrayList&lt;String&gt;(); addresses.add(url.getAddress()); // ULR中设置了从库地址 String[] backups = url.getParameter(Constants.BACKUP_KEY, new String[0]); if (backups != null &amp;&amp; backups.length &gt; 0) &#123; addresses.addAll(Arrays.asList(backups)); &#125; // 创建JedisPool对象 for (String address : addresses) &#123; int i = address.indexOf(':'); String host; int port; if (i &gt; 0) &#123; host = address.substring(0, i); port = Integer.parseInt(address.substring(i + 1)); &#125; else &#123; host = address; port = DEFAULT_REDIS_PORT; &#125; this.jedisPools.put(address, new JedisPool(config, host, port, url.getParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT), StringUtils.isEmpty(url.getPassword()) ? null : url.getPassword(), url.getParameter(\"db.index\", 0))); &#125; // 解析重连周期 this.reconnectPeriod = url.getParameter(Constants.REGISTRY_RECONNECT_PERIOD_KEY, Constants.DEFAULT_REGISTRY_RECONNECT_PERIOD); // 获得Redis 根节点 String group = url.getParameter(Constants.GROUP_KEY, DEFAULT_ROOT); if (!group.startsWith(Constants.PATH_SEPARATOR)) &#123; group = Constants.PATH_SEPARATOR + group; &#125; if (!group.endsWith(Constants.PATH_SEPARATOR)) &#123; group = group + Constants.PATH_SEPARATOR; &#125; this.root = group; // 解析会话过期时间 this.expirePeriod = url.getParameter(Constants.SESSION_TIMEOUT_KEY, Constants.DEFAULT_SESSION_TIMEOUT); // 创建实现Redis Key 过期机制的任务 this.expireFuture = expireExecutor.scheduleWithFixedDelay(new Runnable() &#123; @Override public void run() &#123; try &#123; // 延时过期时间 deferExpired(); &#125; catch (Throwable t) &#123; // Defensive fault tolerance logger.error(\"Unexpected exception occur at defer expire time, cause: \" + t.getMessage(), t); &#125; &#125; &#125;, expirePeriod / 2, expirePeriod / 2, TimeUnit.MILLISECONDS); &#125;// $&#123;省略其它代码&#125;&#125; RedisRegistry 构造方法做了两件事，初始化 JedisPool 和 创建 Redis key的延迟过期的任务。初始化 JedisPool 没有什么好说的，主要是设置一些参数，下面我们来看 deferExpired 方法是怎么做到延时key过期的。 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * 被Key过期机制执行器expireExecutor定时调用，用来延时过期时间. */ private void deferExpired() &#123; for (Map.Entry&lt;String, JedisPool&gt; entry : jedisPools.entrySet()) &#123; JedisPool jedisPool = entry.getValue(); try &#123; Jedis jedis = jedisPool.getResource(); try &#123; // 循环已注册的URL集合 for (URL url : new HashSet&lt;URL&gt;(getRegistered())) &#123; // 是否是动态节点，只有动态节点需要延长过期时间 if (url.getParameter(Constants.DYNAMIC_KEY, true)) &#123; // 获得分类路径，如：/dubbo/com.foo.BarService/providers String key = toCategoryPath(url); /** * 1 写入Redis Map中，更新过期时间 * 2 注意，如果过期时间更新的时候返回值为1，说明key已经被删除了，这次算重新发布，因此需要在通道key 中发布 register 事件消息 */ if (jedis.hset(key, url.toFullString(), String.valueOf(System.currentTimeMillis() + expirePeriod)) == 1) &#123; // 发布 register 事件 jedis.publish(key, Constants.REGISTER); &#125; &#125; &#125; // 如果是监控中心（admin = true），就负责删除过期脏数据。admin默认为false,可能修改的地方在 doSubscribe 方法中 if (admin) &#123; clean(jedis); &#125; // 如果Redis集群策略为 failover，则操作一台Redis即可。 if (!replicate) &#123; break;// If the server side has synchronized data, just write a single machine &#125; &#125; finally &#123; jedis.close(); &#125; &#125; catch (Throwable t) &#123; logger.warn(\"Failed to write provider heartbeat to redis registry. registry: \" + entry.getKey() + \", cause: \" + t.getMessage(), t); &#125; &#125; &#125; 服务的 key 写入Redis 后，需要周期性地刷新key过期时间，RedisRegistry 构造方法中启动了一个定时调度线程池，不断调用该方法延续key的过期时间。前面也说明了，Redis 的key自动过期不存在相应的事件通知（订阅者无法感知到key已经不存在），如果提供者宕机而非主动下线，则会造成没有发布 unregister 事件，这时订阅方是不知道服务已经下线的，此外，Redis 的 publish/subscribe 并不是绝对可靠的，如果 Redis 的集群策略设置为 failover 模式，消费者订阅了从节点，某一时刻主节点还没有完成数据同步给从节点就宕机了，那么消费者也是不知道服务已经下线的。因此，如果使用 Redis 作为注册中心，会依赖服务治理中心，使用了服务治理中心，Redis 注册中心就会定时触发清理逻辑，下面我们来看下 Redis 注册中心清理脏数据的逻辑。 123456789101112131415161718192021222324252627282930313233343536373839404142/** * 监控中心负责清理过期脏数据 * * @param jedis */ private void clean(Jedis jedis) &#123; // 获得所有的 Root + Service + Type Set&lt;String&gt; keys = jedis.keys(root + Constants.ANY_VALUE); if (keys != null &amp;&amp; !keys.isEmpty()) &#123; for (String key : keys) &#123; // 获得分类下的Map,key-&gt;URL,value-&gt;过期时间 Map&lt;String, String&gt; values = jedis.hgetAll(key); if (values != null &amp;&amp; values.size() &gt; 0) &#123; boolean delete = false; long now = System.currentTimeMillis(); for (Map.Entry&lt;String, String&gt; entry : values.entrySet()) &#123; // 获取URL URL url = URL.valueOf(entry.getKey()); // 动态节点 if (url.getParameter(Constants.DYNAMIC_KEY, true)) &#123; // 获取URL对应的过期时间 long expire = Long.parseLong(entry.getValue()); // 已经过期 if (expire &lt; now) &#123; jedis.hdel(key, entry.getKey()); delete = true; if (logger.isWarnEnabled()) &#123; logger.warn(\"Delete expired key: \" + key + \" -&gt; value: \" + entry.getKey() + \", expire: \" + new Date(expire) + \", now: \" + new Date(now)); &#125; &#125; &#125; &#125; // 若发生删除行为，说明存在URL过期了，需要向key通道发布 `unregister`事件 if (delete) &#123; jedis.publish(key, Constants.UNREGISTER); &#125; &#125; &#125; &#125; &#125; clean 方法主要做了两件事，把过期的key删除并在通道key中发布 unregister 事件，保证了未正常下线的服务信息的删除，从而保证数据的最终一致性。但这里还有一个问题没有解决，如果 Redis 的集群策略设置为 failover 模式，消费者订阅了从节点，某一时刻提供者下线了，主节点还没有完成数据同步给从节点就宕机了，那么消费者也是不知道服务已经下线的，那这样情况怎么解决呢？问题先抛出来。 注册1234567891011121314151617181920212223242526272829303132333435363738394041@Override public void doRegister(URL url) &#123; // 获取分类路径 Root + Service + Type String key = toCategoryPath(url); // 获得URL字符串作为Value String value = url.toFullString(); // 计算过期时间，这会作为Redis Map的值 String expire = String.valueOf(System.currentTimeMillis() + expirePeriod); boolean success = false; RpcException exception = null; // 向Redis注册 for (Map.Entry&lt;String, JedisPool&gt; entry : jedisPools.entrySet()) &#123; JedisPool jedisPool = entry.getValue(); try &#123; Jedis jedis = jedisPool.getResource(); try &#123; // 写入Redis hash 中，注意，过期时间是作为Map的值。 jedis.hset(key, value, expire); // 发布Redis 注册事件。 key为通道， Constants.REGISTER-&gt;register为事件消息，订阅该通道的就会实时从Redis读取最新消息 jedis.publish(key, Constants.REGISTER); success = true; // 如果非replicate模式，只需要写入单台机器，结束循环。否则，就继续循环，向所有的Redis写入 if (!replicate) &#123; break; &#125; &#125; finally &#123; jedis.close(); &#125; &#125; catch (Throwable t) &#123; exception = new RpcException(\"Failed to register service to redis registry. registry: \" + entry.getKey() + \", service: \" + url + \", cause: \" + t.getMessage(), t); &#125; &#125; // 处理异常 if (exception != null) &#123; if (success) &#123; logger.warn(exception.getMessage(), exception); &#125; else &#123; throw exception; &#125; &#125; &#125; 注册方法主要做了两件事，把信息写到 Redis 中，然后发布注册事件。这里注册不仅是服务提供者和消费者，还可能是动态配置，路由规则等。 反注册1234567891011121314151617181920212223242526272829303132333435363738@Overridepublic void doUnregister(URL url) &#123; // 获取分类路径 Root + Service + Type String key = toCategoryPath(url); // 获得URL字符串作为Value String value = url.toFullString(); RpcException exception = null; boolean success = false; for (Map.Entry&lt;String, JedisPool&gt; entry : jedisPools.entrySet()) &#123; JedisPool jedisPool = entry.getValue(); try &#123; Jedis jedis = jedisPool.getResource(); try &#123; // 删除 Redis Map 建 jedis.hdel(key, value); // 发布Redis 取消注册事件 key为通道 ， Constants.UNREGISTER-&gt;unregister 为事件消息 jedis.publish(key, Constants.UNREGISTER); success = true; // 如果非replicate模式，只需操作单台机器，因此结束循环。否则，就继续循环，向所有的Redis写入 if (!replicate) &#123; break; // If the server side has synchronized data, just write a single machine &#125; &#125; finally &#123; jedis.close(); &#125; &#125; catch (Throwable t) &#123; exception = new RpcException(\"Failed to unregister service to redis registry. registry: \" + entry.getKey() + \", service: \" + url + \", cause: \" + t.getMessage(), t); &#125; &#125; if (exception != null) &#123; if (success) &#123; logger.warn(exception.getMessage(), exception); &#125; else &#123; throw exception; &#125; &#125;&#125; 反注册主要也做了两件事，从Redis 中删除数据，然后发布 unregister 为事件。当服务消费者或服务提供者关闭时，会调用该方法，取消注册，因为正常情况下，无需使用监控中心做脏数据删除的工作。同样，这里反注册不仅是服务提供者和消费者，还可能是动态配置，路由规则等。 订阅1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889@Overridepublic void doSubscribe(final URL url, final NotifyListener listener) &#123; // 获得服务路径 Root + Service 如： /dubbo/com.alibaba.dubbo.demo.DemoService String service = toServicePath(url); // 获得服务路径对应的通知器 Notifier 对象,不存在对应的通知器，则创建Notifier对象 Notifier notifier = notifiers.get(service); if (notifier == null) &#123; /** * 创建服务路径对应的通知器Notifier对象，即基于 Root + Service 开启订阅线程，如果服务很多，就意味着有很多此类线程，创建线程是消耗资源的，而且还是那种阻塞不释放的。 * 说明： * zk是直接调用客户端API绑定监听器实现订阅，redis是使用多个独立的订阅线程，使用pub/sub机制进行处理，因为redis的pub/sub是基于channel进行的长连接通信，因此每个服务只能使用单独的线程。 */ Notifier newNotifier = new Notifier(service); notifiers.putIfAbsent(service, newNotifier); notifier = notifiers.get(service); // 保证并发的情况下，有且仅有一个启动 if (notifier == newNotifier) &#123; // 启动线程（订阅了通道，有消息发布就会被通知订阅对象收到，然后进行后续的通知处理），需要注意：Jedis的订阅是阻塞的，因此需要开启线程，不然主线程会阻塞。 notifier.start(); &#125; &#125; boolean success = false; RpcException exception = null; // 循环 jedisPools,仅从一个Redis获取数据，然后进行通知，直到成功 for (Map.Entry&lt;String, JedisPool&gt; entry : jedisPools.entrySet()) &#123; JedisPool jedisPool = entry.getValue(); try &#123; Jedis jedis = jedisPool.getResource(); try &#123; // 处理 Root + * 的订阅，一般是监听中心的订阅 if (service.endsWith(Constants.ANY_VALUE)) &#123; // 标记admin = true,监控中心才会清理脏数据 admin = true; // 调用Jedis#keys(pattern)方法根据`/dubbo/*` 通配符获得分类层集合。始终记住 Redis 作为注册中心时，key是分类，如： /dubbo/com.alibaba.dubbo.demo.DemoService/providers Set&lt;String&gt; keys = jedis.keys(service); if (keys != null &amp;&amp; !keys.isEmpty()) &#123; // key: Root + Service value: Root + Service + Type Map&lt;String, Set&lt;String&gt;&gt; serviceKeys = new HashMap&lt;String, Set&lt;String&gt;&gt;(); for (String key : keys) &#123; // 获取Root + Service，如：/dubbo/com.alibaba.dubbo.demo.DemoService String serviceKey = toServicePath(key); Set&lt;String&gt; sk = serviceKeys.get(serviceKey); if (sk == null) &#123; sk = new HashSet&lt;String&gt;(); serviceKeys.put(serviceKey, sk); &#125; sk.add(key); &#125; // 循环serviceKeys for (Set&lt;String&gt; sk : serviceKeys.values()) &#123; // 通知监听器 doNotify(jedis, sk, url, Arrays.asList(listener)); &#125; &#125; // 处理指定 Root + Service 的订阅 &#125; else &#123; /** * 1 调用Jedis#keys(pattern)方法，获得所有分类，例如：/dubbo/com.alibaba.dubbo.demo.DemoService/providers * 2 通知监听器 */ doNotify(jedis, jedis.keys(service + Constants.PATH_SEPARATOR + Constants.ANY_VALUE), url, Arrays.asList(listener)); &#125; // 标记成功 success = true; // Just read one server's data break; &#125; finally &#123; jedis.close(); &#125; &#125; catch (Throwable t) &#123; // Try the next server exception = new RpcException(\"Failed to subscribe service from redis registry. registry: \" + entry.getKey() + \", service: \" + url + \", cause: \" + t.getMessage(), t); &#125; &#125; // 处理异常 if (exception != null) &#123; if (success) &#123; logger.warn(exception.getMessage(), exception); &#125; else &#123; throw exception; &#125; &#125;&#125; 服务提供者、服务消费者、和服务治理中心都会使用注册中心的订阅功能。在订阅时，如果是首次订阅，则会先创建一个 Notifier 通知器，它是一个线程类，以异步方式进行通道的订阅。在启动通知器的同时，主线程会继续往下执行，全量拉取注册中心上和本次订阅相关的数据信息。后续注册中心上的信息变更则通过通知器订阅的通道来实现，发生变更订阅器会收到。此外，这里有两个分支，第一个是处理监控中心的订阅即 Root + *，第二个是处理指定Root + Service + * 的订阅，如果是监控中心的订阅会开启脏数据的清理任务。有了订阅，下面我们来看通知器的实现。 Notifier 通知器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175public class RedisRegistry extends FailbackRegistry &#123; // $&#123;省略其它代码&#125; /** * 通知器类，是一个线程对象 */ private class Notifier extends Thread &#123; /** * 服务名 Root + Service */ private final String service; /** * 需要忽略连接的次数 */ private final AtomicInteger connectSkip = new AtomicInteger(); /** * 已经忽略连接的次数 */ private final AtomicInteger connectSkiped = new AtomicInteger(); /** * 随机对象 */ private final Random random = new Random(); /** * Jedis */ private volatile Jedis jedis; /** * 是否首次 */ private volatile boolean first = true; /** * 是否运行中 */ private volatile boolean running = true; /** * 连接次数随机数 */ private volatile int connectRandom; public Notifier(String service) &#123; super.setDaemon(true); super.setName(\"DubboRedisSubscribe\"); this.service = service; &#125; /** * 重置忽略连接的信息 */ private void resetSkip() &#123; // 重置需要忽略连接的次数 connectSkip.set(0); // 重置已忽略次数和随机数 connectSkiped.set(0); connectRandom = 0; &#125; /** * 判断是否忽略本次对Redis的连接 * 原则是：连接失败的次数越多，每一轮加大需要忽略的总次数 * * @return */ private boolean isSkip() &#123; // 获得需要忽略的连接数，如果超过10，则加上一个10以内的随机数 int skip = connectSkip.get(); // Growth of skipping times if (skip &gt;= 10) &#123; // If the number of skipping times increases by more than 10, take the random number if (connectRandom == 0) &#123; connectRandom = random.nextInt(10); &#125; skip = 10 + connectRandom; &#125; // 自增忽略次数，若忽略次数不够，则继续忽略 if (connectSkiped.getAndIncrement() &lt; skip) &#123; // Check the number of skipping times return true; &#125; // 增加需要忽略的次数 connectSkip.incrementAndGet(); // 重置已忽略次数和随机数 connectSkiped.set(0); connectRandom = 0; return false; &#125; @Override public void run() &#123; // 这里的循环处理是为了避免网络等异常的发生，便于重新尝试连接redis 订阅channel while (running) &#123; try &#123; // 是否跳过本次Redis连接 todo if (!isSkip()) &#123; try &#123; // 循环连接池 for (Map.Entry&lt;String, JedisPool&gt; entry : jedisPools.entrySet()) &#123; JedisPool jedisPool = entry.getValue(); try &#123; jedis = jedisPool.getResource(); try &#123; // 如果是监控中心的订阅 if (service.endsWith(Constants.ANY_VALUE)) &#123; if (!first) &#123; first = false; // 获取分类集合 Set&lt;String&gt; keys = jedis.keys(service); if (keys != null &amp;&amp; !keys.isEmpty()) &#123; for (String s : keys) &#123; doNotify(jedis, s); &#125; &#125; // 由于连接过程允许一定量的失败，调用该方法重置计数器 resetSkip(); &#125; // 订阅给定模式的通道，当订阅的通道有发布消息时，NotifySub对象的回调方法就能接收到。需要注意的是，订阅方法是阻塞的。 jedis.psubscribe(new NotifySub(jedisPool), service); // blocking // 服务提供者或者消费者 &#125; else &#123; if (!first) &#123; first = false; doNotify(jedis, service); // 由于连接过程允许一定量的失败，调用该方法重置计数器 resetSkip(); &#125; jedis.psubscribe(new NotifySub(jedisPool), service + Constants.PATH_SEPARATOR + Constants.ANY_VALUE); // blocking &#125; break; &#125; finally &#123; jedis.close(); &#125; &#125; catch (Throwable t) &#123; // Retry another server logger.warn(\"Failed to subscribe service from redis registry. registry: \" + entry.getKey() + \", cause: \" + t.getMessage(), t); // If you only have a single redis, you need to take a rest to avoid overtaking a lot of CPU resources sleep(reconnectPeriod); &#125; &#125; &#125; catch (Throwable t) &#123; logger.error(t.getMessage(), t); sleep(reconnectPeriod); &#125; &#125; &#125; catch (Throwable t) &#123; logger.error(t.getMessage(), t); &#125; &#125; &#125; /** * 停止 Notifier，关闭redis订阅相关工作的关键。它是通过设置停止循环标识，以及关闭redis连接实现的。 */ public void shutdown() &#123; try &#123; // 设置停止标识 running = false; // 断开redis连接，它还会停止psubscribe的调用，从而间接中止订阅 jedis.disconnect(); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; &#125; &#125; // $&#123;省略其它代码&#125;&#125; 通知器是一个线程，它是 RedisRegistry的内部类，每一个服务（Root + Service）对应一个通知器，如果存在大量订阅请求并且订阅URL都不是同一个服务，那么就要创建大量的线程。不仅如此，由通知器类还可以发现其任务方法中调用了订阅方法 jedis.psubscribe ，这个方法是阻塞的。因此，使用 Redis 注册中心要考虑线程资源。目前为止，Redis 的发布我们已经知道了，主要在注册和反注册的方法中，如果使用了监控中心，还会在脏数据清理方法中。订阅接收对象依然没有出现，请注意，通知器并非是订阅器，但是通知器创建了订阅器 NotifySub，我们继续跟进该类。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class RedisRegistry extends FailbackRegistry &#123; // $&#123;省略其它代码&#125; /** * RedisRegistry 的内部类，继承 redis.clients.jedis.JedisPubSub 抽象类，它是个通知订阅实现类 */ private class NotifySub extends JedisPubSub &#123; private final JedisPool jedisPool; public NotifySub(JedisPool jedisPool) &#123; this.jedisPool = jedisPool; &#125; /** * 订阅后的通知回调方法 * * @param key 订阅的key，一般为类目，如：/dubbo/com.alibaba.dubbo.demo.DemoService/providers * @param msg 事件消息 */ @Override public void onMessage(String key, String msg) &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"redis event: \" + key + \" = \" + msg); &#125; // 收到register/unregister事件，调用#doNotify方法，组装目标URL然后通知监听器，从而实现实时更新 if (msg.equals(Constants.REGISTER) || msg.equals(Constants.UNREGISTER)) &#123; try &#123; Jedis jedis = jedisPool.getResource(); try &#123; // 进行通知，这里不是真正意义上的通知 doNotify(jedis, key); &#125; finally &#123; jedis.close(); &#125; &#125; catch (Throwable t) &#123; // TODO Notification failure does not restore mechanism guarantee logger.error(t.getMessage(), t); &#125; &#125; &#125; @Override public void onPMessage(String pattern, String key, String msg) &#123; onMessage(key, msg); &#125; @Override public void onSubscribe(String key, int num) &#123; &#125; @Override public void onPSubscribe(String pattern, int num) &#123; &#125; @Override public void onUnsubscribe(String key, int num) &#123; &#125; @Override public void onPUnsubscribe(String pattern, int num) &#123; &#125; &#125; // $&#123;省略其它代码&#125;&#125; NotifySub 继承 redis.clients.jedis.JedisPubSub 抽象类，这样它就具有了订阅的功能，它也是 RedisRegistry 的内部类。当 jedis.psubscribe(JedisPubSub,channel) 订阅了通道（支持通配符）后，一旦该通道有事件消息发布 NotifySub 的通知回调方法就会调用，就能拿到具体的通道和在通道中发布的事件消息。至此， Redis 注册中心的两大核心角色就有了，下面我们简单梳理下整个过程。 服务提供者、消费者在启动过程会进行服务的注册和订阅 1 注册的过程会先把服务信息写入到Redis中，并且通过分类路径 ‘Root + Service + Type’ 这个通道发布注册事件消息 register2 订阅的过程会先创建一个通知器线程并启动，这个通知器线程会订阅服务路径 ‘Root + Service + *’ 这个通道，订阅后就坐等该通道的事件消息，NotifySub 对象就是用来接收通道消息的。然后会主动从Redis注册中心拉取 服务路径 ‘Root + Service + *’ 下的所有分类。 有服务下线会进行反注册 1 反注册会先把服务信息从Redis中删除，并且通过分类路径 ‘Root + Service + Type’ 这个通道发布反注册事件消息 unregister2 如果通知已经被订阅，那么NotifySub就会接收通道发来的 反注册事件消息 unregister 监控中心启动会订阅所有服务 订阅的过程会先创建一个通知器线程并启动，这个通知器线程会订阅服务路径 ‘Root + *’ 这个通道，订阅后就坐等该通道的事件消息。然后会从Redis注册中心拉取所有数据并分类存储在缓存中 监控中心进行服务治理 服务治理涉及到注册和反注册，如：创建提供者、设置动态配置、设置路由规则等，都会向对应的通道发送消息。这些都会触发 NotifySub 通知回调 以上分析主要是针对 注册（反注册）和订阅的分析，我们还少了一步通知，前文订阅的过程会调用通知方法，下面我们就来分析 Redis 注册中心的通知是怎么做的。 通知需要说明的是，Zookeeper 由于可以注册监听器进而直接拿到订阅关注的全量数据，但是 Redis 订阅后得到的通知结果并不是订阅关注的数据而是大Key，需要多做一步查询大Key对应的目标URL集合，即 使用 doNotify 方法将 Redis 中的数据接入到应用中，然后回调监听器的方法完成通知。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101 /** * @param jedis * @param key 分类，NotifySub获取到的，例如： /dubbo/com.alibaba.dubbo.demo.DemoService/providers */ private void doNotify(Jedis jedis, String key) &#123; // 调用getSubscribed()方法，获得所有 订阅 URL 的监听器集合 for (Map.Entry&lt;URL, Set&lt;NotifyListener&gt;&gt; entry : new HashMap&lt;URL, Set&lt;NotifyListener&gt;&gt;(getSubscribed()).entrySet()) &#123; doNotify(jedis, Arrays.asList(key), entry.getKey(), new HashSet&lt;NotifyListener&gt;(entry.getValue())); &#125; &#125;/** * @param jedis Jedis * @param keys 分类数组 ，如 /dubbo/com.alibaba.dubbo.demo.DemoService/providers （首次会拉取某个Service层下的所有分类） * @param url 订阅URL * @param listeners 订阅URL对应的监听器集合 */ private void doNotify(Jedis jedis, Collection&lt;String&gt; keys, URL url, Collection&lt;NotifyListener&gt; listeners) &#123; if (keys == null || keys.isEmpty() || listeners == null || listeners.isEmpty()) &#123; return; &#125; // 当前时间 long now = System.currentTimeMillis(); // 目标URL集合 List&lt;URL&gt; result = new ArrayList&lt;URL&gt;(); /** * 获得订阅URL的分类，不同的角色关注不同的分类数据【zookeeper也是如此】 * 1 服务提供者，关注configurators * 2 服务消费者，关注providers,configurators.routers * 3 监控中心关注所有 */ List&lt;String&gt; categories = Arrays.asList(url.getParameter(Constants.CATEGORY_KEY, new String[0])); // 订阅URL映射的服务接口名 ，Root + Service String consumerService = url.getServiceInterface(); // 循环分类数组，如： /dubbo/com.alibaba.dubbo.demo.DemoService/providers for (String key : keys) &#123; if (!Constants.ANY_VALUE.equals(consumerService)) &#123; // 获取分类对应的服务接口名 ，Root + Service String prvoiderService = toServiceName(key); // 分离对应的服务接口名是否匹配订阅URL映射的服务接口名,不匹配直接返回，说明不是订阅URl关注的分类 if (!prvoiderService.equals(consumerService)) &#123; continue; &#125; &#125; // 如果订阅URL不关注该分类，则直接返回 String category = toCategoryName(key); if (!categories.contains(Constants.ANY_VALUE) &amp;&amp; !categories.contains(category)) &#123; continue; &#125; List&lt;URL&gt; urls = new ArrayList&lt;URL&gt;(); // 获得分类下所有URL数组，如： /dubbo/com.alibaba.dubbo.demo.DemoService/providers 下的所有提供者URL及其过期时间 Map&lt;String, String&gt; values = jedis.hgetAll(key); if (values != null &amp;&amp; values.size() &gt; 0) &#123; for (Map.Entry&lt;String, String&gt; entry : values.entrySet()) &#123; URL u = URL.valueOf(entry.getKey()); // 过滤掉已过期的动态节点 [动态节点才可能会变化，把动态节点收集起来，去和原来的节点对比，看是否有变化，有变化就需要做些操作，如 服务重新暴露] if (!u.getParameter(Constants.DYNAMIC_KEY, true) || Long.parseLong(entry.getValue()) &gt;= now) &#123; if (UrlUtils.isMatch(url, u)) &#123; urls.add(u); &#125; &#125; &#125; &#125; // 若不存在匹配，则创建 `empty://` 的 URL if (urls.isEmpty()) &#123; urls.add(url.setProtocol(Constants.EMPTY_PROTOCOL) .setAddress(Constants.ANYHOST_VALUE) .setPath(toServiceName(key)) .addParameter(Constants.CATEGORY_KEY, category)); &#125; result.addAll(urls); if (logger.isInfoEnabled()) &#123; logger.info(\"redis notify: \" + key + \" = \" + urls); &#125; &#125; if (result == null || result.isEmpty()) &#123; return; &#125; // 回调父类的notify方法，进行通知，这里才是真正通知监听器的入口。接下来的流程和 Zookeeper 一致 for (NotifyListener listener : listeners) &#123; notify(url, listener, result); &#125; &#125; 该方法需要注意一个点，分类不一定能够匹配上订阅URL，因此需要过滤。造成原因就一个，Redis 是使用Root + Service 获取分类的，主动获取和订阅都是这样。该方法看着逻辑不少，不过主要做了三个工作： 根据订阅URL选出匹配的分类，因为 Redis 是根据订阅URL的Root + Service 获取其下的所有分类，但是订阅URL中也许没有指定那么多，就是订阅URL的category参数的值。 选出匹配的分类后，获取分类下的URL集合，然后筛选出没有过期的URL。如果没有预期的URL，就创建一个 empty://… 回调NotifyListener，进行通知。如 服务重新暴露，服务目录更新等 至此，Redis 注册中心的 注册（反注册）、订阅、通知分析完毕，值得一说的是 Redis 的取消订阅什么都没有做是个空方法，在ZookeeperRegistry的该方法中，是移除了对应的监听器，这里理论上 Redis 应该解除订阅，不过 Redis 把这个收尾操作放到了 destroy 方法中了，我们一起来看看这个收尾方法。 destroy123456789101112131415161718192021222324252627282930@Overridepublic void destroy() &#123; // 父类关闭 super.destroy(); try &#123; // 取消定时任务，过期时间不会更新 expireFuture.cancel(true); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; try &#123; // 关闭通知器，依次调用 shutdown方法，停止订阅工作。 for (Notifier notifier : notifiers.values()) &#123; notifier.shutdown(); &#125; &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; // 关闭连接池 for (Map.Entry&lt;String, JedisPool&gt; entry : jedisPools.entrySet()) &#123; JedisPool jedisPool = entry.getValue(); try &#123; jedisPool.destroy(); &#125; catch (Throwable t) &#123; logger.warn(\"Failed to destroy the redis registry client. registry: \" + entry.getKey() + \", cause: \" + t.getMessage(), t); &#125; &#125; // 最后优雅关闭过期扫描定时任务线程池，即 shutdown()..awaitTermination()的应用。 ExecutorUtil.gracefulShutdown(expireExecutor, expirePeriod);&#125; 销毁方法主要做了以下工作： 调用父类FailbackRegistry的 destroy 方法 取消延时key过期的任务 关闭通知器线程，停止订阅工作 关闭JedisPool，释放资源 小结Redis 作为注册中心与 Zookeeper 作为注册的前置操作都是一样的，其核心是基于 Redis 的 Publish/Subscribe 。和 Zookeeper 相比较，Redis 功能实现会相对繁琐一些，并且其可靠性依赖于 Redis 本身的可靠性，相比较 Redis 一般更常用 Zookeeper 。Redis 作为注册中心的原理还是非常值得学习的，毕竟 Redis 那么流行。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"Redis","slug":"Redis","permalink":"https://gentryhuang.com/tags/Redis/"}]},{"title":"Dubbo源码分析 - Zookeeper客户端","slug":"rpc/注册中心之Zookeeper客户端","date":"2020-04-19T16:00:00.000Z","updated":"2020-10-25T04:00:29.344Z","comments":false,"path":"posts/817d6a19/","link":"","permalink":"https://gentryhuang.com/posts/817d6a19/","excerpt":"","text":"前言在 Dubbo源码分析 - Zookeeper注册中心 中介绍的是 Dubbo 的 Zookeeper 注册中心实现，但是并没有涉及到 Zookeeper 客户端的操作，下面我们介绍 Zookeeper 在 Dubbo 框架中具体实现。 概述 上图的 UML 描述了 Dubbo 封装的 Zookeeper 注册中心和 Zookeeper 相关实现的关系。 Dubbo 对 Zookeeper 客户端的封装是在 dubbo-remoting-zookeeper 模块中，该模块对 Zookeeper 客户端接口进行了抽象。在 Zookeeper注册中心 中也提到 dubbo-remoting-zookeeper 模块是 dubbo-remoting 模块的子模块，但它并不依赖 dubbo-remoting 中的其他模块，是相对独立的。 目前支持 ZkClient 和 Curator 两种 Zookeeper 客户端实现： Curator 实现 1&lt;dubbo:registry ... client=\"curator\" /&gt; ZkClient 实现 1&lt;dubbo:registry ... client=\"zkclient\" /&gt; 注意: 在2.7.x的版本中已经移除了zkclient的实现,如果要使用zkclient客户端,需要显示配置。下面分析上图的 UML 中涉及的接口和实现类。 无论服务提供者还是消费者，或者服务治理中心，任何一个节点连接到 Zookeeper 注册中心都需要使用一个客户端。从 Zookeeper 架构的角度来看，使用 Dubbo 的业务节点也只是一个 Zookeeper 客户端。 ZookeeperTransporter12345678910111213@SPI(\"curator\")public interface ZookeeperTransporter &#123; /** * 创建 ZookeeperClient 对象。该方法被 @Adaptive 注解修饰，可通过 URL 参数中的 client 或 transporter 参数覆盖 @SPI 注解指定的默认扩展名 * * @param url 注册中心地址 * @return ZookeeperClient 对象 */ @Adaptive(&#123;Constants.CLIENT_KEY, Constants.TRANSPORTER_KEY&#125;) ZookeeperClient connect(URL url);&#125; 该接口是 Dubbo 的扩展点，是 Zookeeper 客户端工厂，就是用来创建 ZookeeperClient 对象的。 默认是使用 CuratorZookeeperTransporter 创建 ZookeeperClient ，后面会详细分析 ZookeeperClient 继承体系。下图是两者 UML 关系图： StateListener123456789101112131415161718192021public interface StateListener &#123; /** * 已断开 */ int DISCONNECTED = 0; /** * 已连接 */ int CONNECTED = 1; /** * 已重连 */ int RECONNECTED = 2; /** * 状态变更回调方法 * * @param connected 状态 */ void stateChanged(int connected);&#125; 该接口不是真正意义上的监听器，它的实现是一个匿名内部类，在 ZookeeperRegistry 的构造方法中，作为 ZookeeperClient 的状态变化（会话）的回调，具体调用入口是 AbstractZookeeperClient#stateChanged(int) ，主要负责监听 Dubbo 与 Zookeeper 集群的连接状态。 12345678910111213141516171819202122public ZookeeperRegistry(URL url, ZookeeperTransporter zookeeperTransporter) &#123; // 创建 Zookeeper 客户端，默认为 CuratorZookeeperTransporter，由SPI确定具体的实例。创建好Zookeeper客户端，意味着注册中心的创建完成【Zookeeper服务端必需先启动，Dubbo应用作为Zookeeper的客户端进行连接，然后操作Zookeeper】 zkClient = zookeeperTransporter.connect(url); /** * 添加 StateListener 状态监听器，该监听器在重连时，调用恢复方法 recover()，重新发起注册和订阅【将之前已经注册和订阅的数据进行重试】 * 注意： * StateListener 不是真正意义上的监听器，这里就是创建了一个匿名对象，其中的 #stateChanged 方法触发需要主动调用该匿名对象的该方法 &#123;@link AbstractZookeeperClient#stateChanged(int)&#125; */ zkClient.addStateListener(new StateListener() &#123; @Override public void stateChanged(int state) &#123; if (state == RECONNECTED) &#123; try &#123; recover(); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; &#125; &#125; &#125;); &#125; ChildListener1234567891011public interface ChildListener &#123; /** * 子节点发生变化的回调 * * @param path 节点 * @param children 最新的子节点列表 */ void childChanged(String path, List&lt;String&gt; children);&#125; 该接口只是一个普通的接口，具体实现是一个匿名内部类，主要监听某个 ZNode 节点下的子节点变化。入口在 ZookeeperRegistry 实现类的 doSubscribe 方法中，该接口的对象最终会用于 Zookeeper 客户端的某个节点下子节点变化的回调方法中，下面我们再分析两种客户端的不同实现。 ZookeeperClient123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public interface ZookeeperClient &#123; /** * 创建节点 * * @param path 节点路径 * @param ephemeral 是否临时节点 */ void create(String path, boolean ephemeral); /** * 删除节点 * * @param path 节点路径 */ void delete(String path); /** * 获取指定节点的子节点集合 * @param path * @return */ List&lt;String&gt; getChildren(String path); /** * 添加 ChildListener * * @param path 节点路径 * @param listener 监听器 * @return 子节点列表 */ List&lt;String&gt; addChildListener(String path, ChildListener listener); /** * 移除 ChildListener * * @param path 节点路径 * @param listener 监听器 */ void removeChildListener(String path, ChildListener listener); /** * 添加 StateListener * * @param listener 监听器 */ void addStateListener(StateListener listener); /** * 移除 StateListener * * @param listener 监听器 */ void removeStateListener(StateListener listener); /** * @return 是否连接 */ boolean isConnected(); /** * 关闭 */ void close(); /** * @return 获得注册中心 URL */ URL getUrl();&#125; ZookeeperClient 接口是 Dubbo 对 Zookeeper 客户端接口的抽象，定义了一系列的操作方法，都是用来和 Zookeeper 进行交互的，它的具体子类中封装了 Zookeeper 的客户端对象。 AbstractZookeeperClientZookeeperClient 接口的抽象类，主要实现了通用的逻辑，如，创建节点，管理 ZookeeperClient 对象添加的监听器，管理 ZookeeperClient 的运行状态。 12345678910111213141516171819202122232425262728293031323334353637383940/** * 实现 ZookeeperClient 接口，Zookeeper 客户端抽象类，实现通用的逻辑。 * * @param &lt;TargetChildListener&gt; 泛型 */public abstract class AbstractZookeeperClient&lt;TargetChildListener&gt; implements ZookeeperClient &#123; protected static final Logger logger = LoggerFactory.getLogger(AbstractZookeeperClient.class); /** * 注册中心 URL */ private final URL url; /** * StateListener 状态监听器集合 */ private final Set&lt;StateListener&gt; stateListeners = new CopyOnWriteArraySet&lt;StateListener&gt;(); /** * ChildListener 集合 * &lt;p&gt; * key1：节点路径 * key2：ChildListener 对象 * value ：监听器具体对象，不同 Zookeeper 客户端，实现会不同。CuratorZookeeperClient的是CuratorWatcher;ZkclientZookeeperClient 的是 IZkChildListener */ private final ConcurrentMap&lt;String, ConcurrentMap&lt;ChildListener, TargetChildListener&gt;&gt; childListeners = new ConcurrentHashMap&lt;String, ConcurrentMap&lt;ChildListener, TargetChildListener&gt;&gt;(); /** * 是否关闭 */ private volatile boolean closed = false; public AbstractZookeeperClient(URL url) &#123; this.url = url; &#125; // $&#123;省略其他代码&#125;&#125; 该抽象类中的属性主要四个，stateListeners 和 childListeners 属性用于分别管理 StateListener 和 ChildListener 监听器。其中 stateListeners 属性是当 Zookeeper的状态变化时要通知的对象，childListeners 属性比较关键，是节点路径到其子节点监听器的映射。 create 创建节点1234567891011121314151617181920212223242526272829public abstract class AbstractZookeeperClient&lt;TargetChildListener&gt; implements ZookeeperClient &#123; // $&#123;省略其他代码&#125; @Override public void create(String path, boolean ephemeral) &#123; if (!ephemeral) &#123; // 如果要创建的节点类型非临时节点，那么这里要检测节点是否存在。临时节点有序号，不需要考虑覆盖问题 if (checkExists(path)) &#123; return; &#125; &#125; int i = path.lastIndexOf('/'); if (i &gt; 0) &#123; // 递归创建上一级路径 create(path.substring(0, i), false); &#125; // 根据 ephemeral 的值创建临时或持久节点 if (ephemeral) &#123; createEphemeral(path); &#125; else &#123; createPersistent(path); &#125; &#125; // $&#123;省略其他代码&#125;&#125; StateListener 操作方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546public abstract class AbstractZookeeperClient&lt;TargetChildListener&gt; implements ZookeeperClient &#123; // $&#123;省略其他代码&#125; /** * 加入 StateListener 到缓存 * * @param listener StateListener */ @Override public void addStateListener(StateListener listener) &#123; stateListeners.add(listener); &#125; /** * 移除缓存中的 StateListener * * @param listener 监听器 */ @Override public void removeStateListener(StateListener listener) &#123; stateListeners.remove(listener); &#125; /** * 获取缓存中的 StateListener * @return */ public Set&lt;StateListener&gt; getSessionListeners() &#123; return stateListeners; &#125; /** * 遍历StateListener 数组，回调 * * @param state 状态 */ protected void stateChanged(int state) &#123; for (StateListener sessionListener : getSessionListeners()) &#123; sessionListener.stateChanged(state); &#125; &#125; // $&#123;省略其他代码&#125;&#125; StateListener 操作方法很简单，需要注意的是 addStateListener 和 stateChanged 方法，前者是在 ZookeeperRegistry 构造方法中被调用，前文已经说明。后者是当 Zookeeper 客户端的会话变化时会主动调用，下文会说明。 addChildListener123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public abstract class AbstractZookeeperClient&lt;TargetChildListener&gt; implements ZookeeperClient &#123; // $&#123;省略其他代码&#125; /** * * @param path 订阅url 映射的目录，如 .../providers * @param listener 订阅url 映射的目录下子节点变化时执行回调的对象 */ @Override public List&lt;String&gt; addChildListener(String path, final ChildListener listener) &#123; // 1 获取/创建：ConcurrentMap&lt;categorypath, ConcurrentMap&lt;ZookeeperRegistry的内部类ChildListener实例, TargetChildListener&gt;&gt; childListeners，这里主要是创建TargetChildListener ConcurrentMap&lt;ChildListener, TargetChildListener&gt; listeners = childListeners.get(path); if (listeners == null) &#123; childListeners.putIfAbsent(path, new ConcurrentHashMap&lt;ChildListener, TargetChildListener&gt;()); listeners = childListeners.get(path); &#125; // 获得是否已经有该监听器 TargetChildListener targetListener = listeners.get(listener); // zk监听器对象不存在，进行创建 if (targetListener == null) &#123; /** * 1 创建一个监听path下子节点的watcher【CuratorZookeeperClient实现】或 IZkChildListener 【ZkclientZookeeperClient实现】 * 2 当path下有子节点变化时，调用listener（即传入的ZookeeperRegistry的内部类ChildListener实例的childChanged(String parentPath, List&lt;String&gt; currentChilds)方法） */ listeners.putIfAbsent(listener, createTargetChildListener(path, listener)); targetListener = listeners.get(listener); &#125; // 向 Zookeeper ，真正发起订阅，即为 path添加TargetChildListener监听器实例 return addTargetChildListener(path, targetListener); &#125; /** * 抽象方法，创建真正的 ChildListener 对象。因为，每个 Zookeeper 的库，实现不同。 * * @param path * @param listener * @return */ protected abstract TargetChildListener createTargetChildListener(String path, ChildListener listener); /** * 向 Zookeeper ，真正发起订阅 * * @param path * @param listener * @return */ protected abstract List&lt;String&gt; addTargetChildListener(String path, TargetChildListener listener); /** * 向 Zookeeper ，真正发起取消订阅 * * @param path * @param listener */ protected abstract void removeTargetChildListener(String path, TargetChildListener listener); // $&#123;省略其他代码&#125;&#125; 这里的 createTargetChildListener(path, listener) 方法和 addTargetChildListener(path, targetListener) 方法都是抽象方法，由 AbstractZookeeperClient 的子类实现，TargetChildListener 是 AbstractZookeeperClient 中标记的一个泛型。因为 ZookeeperClient 实现可能依赖不同的 Zookeeper 客户端组件，不同的 Zookeeper 客户端组件的监听器实现是不同的，而整个 dubbo-remoting-zookeeper 模块进行了抽象，对外暴露的监听器是统一的，使用泛型进行了转换，原则上抽象一个接口也是可以的。该方法的核心就是为订阅 URL 映射的节点绑定一个子节点监听器，子节点发生变化时会被子节点监听器捕捉到，然后将变化的数据信息通过 ChildListener 匿名对象的方法传递出去，下面会结合具体的 Zookeeper 客户端说明。 removeChildListener12345678910111213141516171819public abstract class AbstractZookeeperClient&lt;TargetChildListener&gt; implements ZookeeperClient &#123; // $&#123;省略其他代码&#125; @Override public void removeChildListener(String path, ChildListener listener) &#123; ConcurrentMap&lt;ChildListener, TargetChildListener&gt; listeners = childListeners.get(path); if (listeners != null) &#123; TargetChildListener targetListener = listeners.remove(listener); if (targetListener != null) &#123; // 向 Zookeeper ，真正发起取消订阅 removeTargetChildListener(path, targetListener); &#125; &#125; &#125; // $&#123;省略其他代码&#125;&#125; 该方法用于解除 path 目录的子节点变化监听器。 目录的子节点变化监听器操作123456789101112131415161718192021222324252627282930313233public abstract class AbstractZookeeperClient&lt;TargetChildListener&gt; implements ZookeeperClient &#123; // $&#123;省略其他代码&#125; /** * 抽象方法，创建真正的 ChildListener 对象。因为，每个 Zookeeper 的库，实现不同。 * * @param path * @param listener * @return */ protected abstract TargetChildListener createTargetChildListener(String path, ChildListener listener); /** * 向 Zookeeper ，真正发起订阅 * * @param path * @param listener * @return */ protected abstract List&lt;String&gt; addTargetChildListener(String path, TargetChildListener listener); /** * 向 Zookeeper ，真正发起取消订阅 * * @param path * @param listener */ protected abstract void removeTargetChildListener(String path, TargetChildListener listener); // $&#123;省略其他代码&#125;&#125; 上面三个方法是用来对 path 目录下的子节点的监听器进行操作的，具体逻辑交给子类实现。下面我们详细分析 AbstractZookeeperClient 的两个具体实现类。 CuratorZookeeperClient属性123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class CuratorZookeeperClient extends AbstractZookeeperClient&lt;CuratorWatcher&gt; &#123; /** * Zookeeper 的 Curator 客户端对象 */ private final CuratorFramework client; /** * CuratorZookeeperClient 构造方法主要用于创建和启动 CuratorFramework 实例 * * @param url */ public CuratorZookeeperClient(URL url) &#123; super(url); try &#123; // 创建 CuratorFramework 构造器 CuratorFrameworkFactory.Builder builder = CuratorFrameworkFactory.builder() // 连接地址 .connectString(url.getBackupAddress()) // 重试策略: 重试次数：1，每次重试间隔： 1000 ms .retryPolicy(new RetryNTimes(1, 1000)) // 连接超时时间 .connectionTimeoutMs(5000); String authority = url.getAuthority(); if (authority != null &amp;&amp; authority.length() &gt; 0) &#123; builder = builder.authorization(\"digest\", authority.getBytes()); &#125; // 构建 CuratorFramework 实例 client = builder.build(); // 添加连接监听器。在连接状态发生变化时，调用#stateChange(state)方法，进行StateListener的回调 client.getConnectionStateListenable().addListener(new ConnectionStateListener() &#123; /** * 在连接状态发生变化时，调用 #stateChange(state) 方法，进行 StateListener 的回调。 * @param client * @param state */ @Override public void stateChanged(CuratorFramework client, ConnectionState state) &#123; if (state == ConnectionState.LOST) &#123; CuratorZookeeperClient.this.stateChanged(StateListener.DISCONNECTED); &#125; else if (state == ConnectionState.CONNECTED) &#123; CuratorZookeeperClient.this.stateChanged(StateListener.CONNECTED); &#125; else if (state == ConnectionState.RECONNECTED) &#123; CuratorZookeeperClient.this.stateChanged(StateListener.RECONNECTED); &#125; &#125; &#125;); // 启动客户端 (当连接不上zk服务时，默认将一直重试) client.start(); &#125; catch (Exception e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; &#125; // $&#123;省略其他代码&#125;&#125; 从 CuratorZookeeperClient 的属性中，可以得到上文中的一个答案，stateChanged 方法调用的入口，CuratorZookeeperClient 构造方法执行完毕，Zookeeper 的 Curator 客户端连接创建完毕。 操作节点方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104public class CuratorZookeeperClient extends AbstractZookeeperClient&lt;CuratorWatcher&gt; &#123; // $&#123;省略其他代码&#125; /** * 创建 path 持久节点 * * @param path */ @Override public void createPersistent(String path) &#123; try &#123; client.create().forPath(path); &#125; catch (NodeExistsException e) &#123; &#125; catch (Exception e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; &#125; /** * 创建 path 临时节点 * * @param path */ @Override public void createEphemeral(String path) &#123; try &#123; client.create().withMode(CreateMode.EPHEMERAL).forPath(path); &#125; catch (NodeExistsException e) &#123; &#125; catch (Exception e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; &#125; /** * 删除 path 节点 * * @param path 节点路径 */ @Override public void delete(String path) &#123; try &#123; client.delete().forPath(path); &#125; catch (NoNodeException e) &#123; &#125; catch (Exception e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; &#125; /** * 获取 path 节点下的子节点列表 * * @param path * @return */ @Override public List&lt;String&gt; getChildren(String path) &#123; try &#123; return client.getChildren().forPath(path); &#125; catch (NoNodeException e) &#123; return null; &#125; catch (Exception e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; &#125; /** * 检查 path 节点是否存在 * * @param path * @return */ @Override public boolean checkExists(String path) &#123; try &#123; if (client.checkExists().forPath(path) != null) &#123; return true; &#125; &#125; catch (Exception e) &#123; &#125; return false; &#125; /** * 连接是否已经关闭 * * @return */ @Override public boolean isConnected() &#123; return client.getZookeeperClient().isConnected(); &#125; /** * 关闭连接 */ @Override public void doClose() &#123; client.close(); &#125; // $&#123;省略其他代码&#125;&#125; CuratorZookeeperClient 中的操作节点的方法很简单，直接调用 Curator 的 API 即可。 子节点监听器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990public class CuratorZookeeperClient extends AbstractZookeeperClient&lt;CuratorWatcher&gt; &#123; // $&#123;省略其他代码&#125; /** * 创建一个监听path子节点的watcher 注意：这里只是创建一个CuratorWatcher监听器，并没有对节点进行绑定 * * @param path * @param listener * @return */ @Override public CuratorWatcher createTargetChildListener(String path, ChildListener listener) &#123; return new CuratorWatcherImpl(listener); &#125; /** * 为path节点绑定CuratorWatcher监听器，并返回path的子路径列表 * * @param path * @param listener * @return */ @Override public List&lt;String&gt; addTargetChildListener(String path, CuratorWatcher listener) &#123; try &#123; return client.getChildren().usingWatcher(listener).forPath(path); &#125; catch (NoNodeException e) &#123; return null; &#125; catch (Exception e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; &#125; /** * 移除监听器 * * @param path * @param listener */ @Override public void removeTargetChildListener(String path, CuratorWatcher listener) &#123; ((CuratorWatcherImpl) listener).unwatch(); &#125; /** * 实现CuratorWatcher接口，实现监听器功能。CuratorWatcherImpl 就是 CuratorZookeeperClient 实现 AbstractZookeeperClient 时指定的泛型类 */ private class CuratorWatcherImpl implements CuratorWatcher &#123; /** * ChildListener 匿名对象 */ private volatile ChildListener listener; public CuratorWatcherImpl(ChildListener listener) &#123; this.listener = listener; &#125; public void unwatch() &#123; this.listener = null; &#125; /** * 1 当path节点下的子节点发生变化的时候，会首先调用TargetChildListener的process(WatchedEvent event)方法， * 2 在该方法中又会调用ChildListener实例的childChanged(String parentPath, List&lt;String&gt; currentChilds)方法 * 3 配置信息还是通过客户端拉取 * @param event * @throws Exception */ @Override public void process(WatchedEvent event) throws Exception &#123; if (listener != null) &#123; String path = event.getPath() == null ? \"\" : event.getPath(); // 主动调用ChildListener 匿名对象的方法 listener.childChanged(path, // if path is null, curator using watcher will throw NullPointerException. // if client connect or disconnect to server, zookeeper will queue // watched event(Watcher.Event.EventType.None, .., path = null). StringUtils.isNotEmpty(path) ? client.getChildren().usingWatcher(this).forPath(path) // 重新发起连接，并传入最新的子节点列表 : Collections.&lt;String&gt;emptyList()); &#125; &#125; &#125; // $&#123;省略其他代码&#125;&#125; 子节点监听器，核心是实现 CuratorWatcher 接口，实现监听器功能，CuratorWatcherImpl 就是 CuratorZookeeperClient 实现 AbstractZookeeperClient 时指定的泛型类。当监听的节点下的子节点发生变化时，会在监听器的回调方法中主动调用 ChildListener 匿名对象的 childChanged 方法，这是 Dubbo 中订阅的核心点。 ZkclientZookeeperClientZkclientZookeeperClient 并没有直接封装 ZkClient 对象，而是通过 ZkClientWrapper 封装了 ZkClient 对象，我们先来分析 ZkClientWrapper。 ZkClientWrapper123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177public class ZkClientWrapper &#123; Logger logger = LoggerFactory.getLogger(ZkClientWrapper.class); /** * 超时时间 */ private long timeout; /** * Zookeeper 的 ZkClient 客户端 */ private ZkClient client; /** * 状态 */ private volatile KeeperState state; /** * FutureTask */ private ListenableFutureTask&lt;ZkClient&gt; listenableFutureTask; /** * 是否开始 */ private volatile boolean started = false; /** * @param serverAddr Zookeeper 服务端地址 * @param timeout 超时时间 */ public ZkClientWrapper(final String serverAddr, long timeout) &#123; this.timeout = timeout; listenableFutureTask = ListenableFutureTask.create(new Callable&lt;ZkClient&gt;() &#123; /** * 通过回调创建 Zookeeper 的 ZkClient 客户端 * @return * @throws Exception */ @Override public ZkClient call() throws Exception &#123; return new ZkClient(serverAddr, Integer.MAX_VALUE); &#125; &#125;); &#125; /** * 创建Z ookeeper 的 ZkClient 客户端 */ public void start() &#123; if (!started) &#123; Thread connectThread = new Thread(listenableFutureTask); connectThread.setName(\"DubboZkclientConnector\"); connectThread.setDaemon(true); connectThread.start(); try &#123; client = listenableFutureTask.get(timeout, TimeUnit.MILLISECONDS); &#125; catch (Throwable t) &#123; logger.error(\"Timeout! zookeeper server can not be connected in : \" + timeout + \"ms!\", t); &#125; started = true; &#125; else &#123; logger.warn(\"Zkclient has already been started!\"); &#125; &#125; /** * 设置客户端监听器 * * @param listener */ public void addListener(final IZkStateListener listener) &#123; listenableFutureTask.addListener(new Runnable() &#123; @Override public void run() &#123; try &#123; client = listenableFutureTask.get(); client.subscribeStateChanges(listener); &#125; catch (InterruptedException e) &#123; logger.warn(Thread.currentThread().getName() + \" was interrupted unexpectedly, which may cause unpredictable exception!\"); &#125; catch (ExecutionException e) &#123; logger.error(\"Got an exception when trying to create zkclient instance, can not connect to zookeeper server, please check!\", e); &#125; &#125; &#125;); &#125; /** * ZkClient 是否处理连接状态 * * @return */ public boolean isConnected() &#123; return client != null &amp;&amp; state == KeeperState.SyncConnected; &#125; /** * 使用 ZkClient AIP 创建持久节点 * * @param path */ public void createPersistent(String path) &#123; Assert.notNull(client, new IllegalStateException(\"Zookeeper is not connected yet!\")); client.createPersistent(path, true); &#125; /** * 使用 ZkClient AIP 创建临时节点 * * @param path */ public void createEphemeral(String path) &#123; Assert.notNull(client, new IllegalStateException(\"Zookeeper is not connected yet!\")); client.createEphemeral(path); &#125; /** * 使用 ZkClient AIP 删除节点 * * @param path */ public void delete(String path) &#123; Assert.notNull(client, new IllegalStateException(\"Zookeeper is not connected yet!\")); client.delete(path); &#125; /** * 使用 ZkClient AIP 获取 path 节点下的子节点列表 * * @param path * @return */ public List&lt;String&gt; getChildren(String path) &#123; Assert.notNull(client, new IllegalStateException(\"Zookeeper is not connected yet!\")); return client.getChildren(path); &#125; /** * 使用 ZkClient AIP 判断是否存在 path 节点 * * @param path * @return */ public boolean exists(String path) &#123; Assert.notNull(client, new IllegalStateException(\"Zookeeper is not connected yet!\")); return client.exists(path); &#125; /** * 断开 Zookeeper 连接 */ public void close() &#123; Assert.notNull(client, new IllegalStateException(\"Zookeeper is not connected yet!\")); client.close(); &#125; /** * 为 path 节点绑定其子节点的监听器，用于监听 path 节点下子节点的变化 * * @param path * @param listener * @return */ public List&lt;String&gt; subscribeChildChanges(String path, final IZkChildListener listener) &#123; Assert.notNull(client, new IllegalStateException(\"Zookeeper is not connected yet!\")); return client.subscribeChildChanges(path, listener); &#125; /** * 删除 path 节点的子节点监听器 * * @param path * @param listener */ public void unsubscribeChildChanges(String path, IZkChildListener listener) &#123; Assert.notNull(client, new IllegalStateException(\"Zookeeper is not connected yet!\")); client.unsubscribeChildChanges(path, listener); &#125;&#125; ZkClientWrapper 用来创建 Zookeeper 的 ZkClient 客户端，并调用 ZkClient API 操作节点以及绑定监听器，代码已经详细注释。下面我们继续看 ZkclientZookeeperClient 实现类。 属性123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class ZkclientZookeeperClient extends AbstractZookeeperClient&lt;IZkChildListener&gt; &#123; /** * 封装了 Zookeeper 的 ZkClient 对象 */ private final ZkClientWrapper client; /** * 状态对象 */ private volatile KeeperState state = KeeperState.SyncConnected; /** * ZkclientZookeeperClient 构造方法主要用于创建和启动 ZkClient 实例 * * @param url */ public ZkclientZookeeperClient(URL url) &#123; super(url); // 创建 ZkClientWrapper 【包装了ZkClient,实现监听】 client = new ZkClientWrapper(url.getBackupAddress(), 30000); // 添加监听器到 ZkClient 对象 client.addListener(new IZkStateListener() &#123; /** * 处理状态变化 * @param state * @throws Exception */ @Override public void handleStateChanged(KeeperState state) throws Exception &#123; ZkclientZookeeperClient.this.state = state; /** * 状态变更进行回调 &#123;@link StateListener#stateChanged(int)&#125; */ if (state == KeeperState.Disconnected) &#123; stateChanged(StateListener.DISCONNECTED); &#125; else if (state == KeeperState.SyncConnected) &#123; stateChanged(StateListener.CONNECTED); &#125; &#125; /** * 处理新会话 （处理失败重连），最终会回调&#123;@link StateListener#stateChanged(int)&#125; * @throws Exception */ @Override public void handleNewSession() throws Exception &#123; stateChanged(StateListener.RECONNECTED); &#125; &#125;); // 创建客户端 client.start(); &#125; // $&#123;省略其他代码&#125;&#125; client 属性对应的 ZkClientWrapper 中封装了 ZkClient 客户端对象，构造方法主要做了两件事，创建 ZkClient 并为其绑定状态监听器。 操作节点方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class ZkclientZookeeperClient extends AbstractZookeeperClient&lt;IZkChildListener&gt; &#123; // $&#123;省略其他代码&#125; /** * 调用 ZkClientWrapper 的 createPersistent 方法，以下同理 * * @param path */ @Override public void createPersistent(String path) &#123; try &#123; client.createPersistent(path); &#125; catch (ZkNodeExistsException e) &#123; &#125; &#125; @Override public void createEphemeral(String path) &#123; try &#123; client.createEphemeral(path); &#125; catch (ZkNodeExistsException e) &#123; &#125; &#125; @Override public void delete(String path) &#123; try &#123; client.delete(path); &#125; catch (ZkNoNodeException e) &#123; &#125; &#125; @Override public List&lt;String&gt; getChildren(String path) &#123; try &#123; return client.getChildren(path); &#125; catch (ZkNoNodeException e) &#123; return null; &#125; &#125; @Override public boolean checkExists(String path) &#123; try &#123; return client.exists(path); &#125; catch (Throwable t) &#123; &#125; return false; &#125; @Override public boolean isConnected() &#123; return state == KeeperState.SyncConnected; &#125; @Override public void doClose() &#123; client.close(); &#125; // $&#123;省略其他代码&#125;&#125; 子节点监听器12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class ZkclientZookeeperClient extends AbstractZookeeperClient&lt;IZkChildListener&gt; &#123; // $&#123;省略其他代码&#125; /** * 创建节点监听器 * * @param path * @param listener * @return */ @Override public IZkChildListener createTargetChildListener(String path, final ChildListener listener) &#123; return new IZkChildListener() &#123; /** * 监听的子节点发生变化会回调该方法，方法主动调用 ChildListener的匿名对象的方法 * @param parentPath 父节点 * @param currentChilds 子节点列表 * @throws Exception */ @Override public void handleChildChange(String parentPath, List&lt;String&gt; currentChilds) throws Exception &#123; listener.childChanged(parentPath, currentChilds); &#125; &#125;; &#125; /** * 为 path 节点绑定子节点监听器 * * @param path * @param listener path的子节点监听器 * @return */ @Override public List&lt;String&gt; addTargetChildListener(String path, final IZkChildListener listener) &#123; return client.subscribeChildChanges(path, listener); &#125; /** * 移除 path 节点绑定的子节点监听器 * * @param path * @param listener path的子节点监听器 */ @Override public void removeTargetChildListener(String path, IZkChildListener listener) &#123; client.unsubscribeChildChanges(path, listener); &#125; // $&#123;省略其他代码&#125;&#125; 实现上和 Curator 客户端有所差别，但本质上是相同的。 小结至此，dubbo-remoting-zookeeper 模块的核心实现就介绍完了，该模块作为 Dubbo 与 Zookeeper 交互的基础，不仅支撑了基于 Zookeeper 的注册中心的实现，还支撑了基于 Zookeeper 的服务发现的实现。Dubbo 中的 Zookeeper 客户端主要两部分操作，节点的操作和节点监听器的操作，节点的操作主要是注册服务的元数据信息，节点监听器的操作主要是用于订阅通知，订阅通知依赖服务节点的元数据变化信息，这正是监听器来完成的。","categories":[],"tags":[]},{"title":"Dubbo源码分析 - Zookeeper注册中心","slug":"rpc/注册中心之Zookeeper","date":"2020-04-16T16:00:00.000Z","updated":"2020-11-14T03:14:54.716Z","comments":false,"path":"posts/f70c2f2e/","link":"","permalink":"https://gentryhuang.com/posts/f70c2f2e/","excerpt":"","text":"前言注册中心总览 中介绍了 Dubbo 的注册中心抽象层，包括注册中心及其工厂。本篇文章将介绍 Dubbo 的 Zookeeper 注册中心及其工厂。 UML 图中 ZookeeperRegistryFactory 中有个 ZookeeperTransporter 属性，该属性就是创建 Zookeeper 客户端的关键对象，下一篇文章会详细介绍 Dubbo 对 Zookeeper 客户端的封装。 Dubbo 中的 Zookeeper 注册中心Zookeeper 是 Apache Hadoop 的子项目，是一个树型的目录服务，支持变更推送，适合作为 Dubbo 服务的注册中心，工业强度较高，可用于生产环境，并推荐使用。下图是 Dubbo 使用 Zookeeper 作为注册中心的元数据信息： Dubbo 中的 Zookeeper 注册中心说明 Zookeeper 是树形结构的注册中心，每个节点的类型分为持久节点、持久顺序节点、临时节点和临时顺序节点。 1234持久节点：服务注册后保证节点不会丢失，注册中心重启也会存在。持久顺序节点：在持久节点特性的基础上增加了节点先后顺序的特点。临时节点：节点注册后，如果客户端与服务端的连接断开或会话超时，节点会自动被删除。临时顺序节点：在临时节点特性的基础上增加了节点先后属性的特点。 Dubbo 使用 Zookeeper 作为注册中心时，只会创建持久节点和临时节点，不关心节点的顺序。 节点路径说明 Root 层：Zookeeper的根目录，默认是 dubbo ，也可以进行设置。对应图中的dubbo。 Service 层：服务接口的全路径名，对应图中的 com.foo.BarService 。 Type 层：目录，对于 Dubbo 而言就是分类，目前 Dubbo 有四个分类，服务提供者列表（providers）、服务消费者列表（consumers）、路由规则列表（routers）和 配置规则列表(configurators) URL 层：Dubbo 的 URL，可以是服务提供者 URL、服务消费者 URL、路由规则 URL、以及配置规则 URL，具体哪类，看在哪个 Type 层下。 注意，URL 层的元数据信息是临时节点，其上层的节点是持久节点。 树形结构的关系 123456&#x2F;dubbo +-- service +-- providers +-- consumers +-- routers +-- configurators 树的根节点默认是dubbo，下面有多个服务接口，根节点可以手动设置。 服务接口下包含四种子目录，分别是 providers、consumers、routers、configurators，这些路径是持久节点。 服务提供者目录[/dubbo/service/providers]下面包含的接口有多个服务提供者URL元数据信息 服务消费者目录[/dubbo/service/consumers]下面包含的接口有多个消费者URL元数据信息 路由规则目录[/dubbo/service/routers]下面包含多个用于消费者路由策略URL元数据信息 动态配置目录[/dubbo/service/configurators]下面包含多个用于服务提供者动态配置URL元数据信息 在 Dubbo 框架启动启动时，会根据用户配置的服务，在 Zookeeper 注册中心中创建4个目录，这里说的 Dubbo 框架启动包括提供者和消费者启动。 流程简单说明： 服务提供者启动时: 向 /dubbo/com.foo.BarService/providers 目录下写入自己的 URL 地址 服务消费者启动时: 订阅 /dubbo/com.foo.BarService/providers 目录下的提供者 URL 地址。并向 /dubbo/com.foo.BarService/consumers 目录下写入自己的 URL 地址 监控中心启动时: 订阅 /dubbo/com.foo.BarService 目录下的所有提供者和消费者 URL 地址 注意: 上面描述的并不是完整的流程，只是根据图进行简单说明，比如，服务提供者不仅写入了自己的 URL 地址，还订阅了 configurators 目录下的 URL 地址，消费者除了订阅 providers 目录下的 URL 地址，还订阅了 routers 和 configurators 目录下的 URL 地址。 在 Dubbo 框架进行服务调用时，用户可以通过服务治理平台在运行时改变服务参数，服务端会通过订阅机制决定是否需要重新暴露服务，消费端通过订阅机制决定是否更新服务目录等。 支持但不限于以下功能： 当提供者出现断电等异常停机时，注册中心能自动删除提供者信息 当注册中心重启时，能自动恢复注册数据，以及订阅请求 当会话过期时，能自动恢复注册数据，以及订阅请求 当设置 &lt;dubbo:registry check=”false” /&gt; 时，记录失败注册和订阅请求，后台定时重试 可通过 &lt;dubbo:registry username=”admin” password=”1234” /&gt; 设置 zookeeper 登录信息 可通过 &lt;dubbo:registry group=”dubbo” /&gt; 设置 zookeeper 的根节点，不配置将使用默认的根节点。 支持 * 号通配符 &lt;dubbo:reference group=”*” version=”*” /&gt;，可订阅服务的所有分组和所有版本的提供者 ZookeeperRegistryFactory实现 AbstractRegistryFactory 抽象类，该抽象类仅仅是提供了缓存 Registry 对象的功能，具体创建逻辑交给子类完成，这里是 ZookeeperRegistry 的工厂。 12345678910111213141516171819202122public class ZookeeperRegistryFactory extends AbstractRegistryFactory &#123; /** * zookeeperTransporter 由 SPI 在运行时注入，类型为 ZookeeperTransporter$Adaptive。 是Zookeeper的客户端工厂 */ private ZookeeperTransporter zookeeperTransporter; /** * 设置Zookeeper客户端 工厂，该方法通过Dubbo IOC 注入 * * @param zookeeperTransporter */ public void setZookeeperTransporter(ZookeeperTransporter zookeeperTransporter) &#123; this.zookeeperTransporter = zookeeperTransporter; &#125; @Override public Registry createRegistry(URL url) &#123; // 创建 ZookeeperRegistry return new ZookeeperRegistry(url, zookeeperTransporter); &#125;&#125; ZookeeperRegistryFactory 就是用来创建 ZookeeperRegistry 对象的，而 ZookeeperRegistry 对象需要依赖创建 Zookeeper 客户端的 ZookeeperTransporter 对象，该对象是通过 Dubbo IOC 注入的，详细可参考 Dubbo SPI 。ZookeeperTransporter 所在的模块是 dubbo-remoting-zookeeper ，它虽然是 dubbo-remoting 模块的子模块，但它并不依赖 dubbo-remoting 中的其它模块，是相对独立的，我们在下一篇文章中介绍它。 下面我们来看看 ZookeeperRegistry 的实现。 ZookeeperRegistry该类继承抽象类 FailbackRegistry ，具有重试功能。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879/** * ZookeeperRegistry */public class ZookeeperRegistry extends FailbackRegistry &#123; private final static Logger logger = LoggerFactory.getLogger(ZookeeperRegistry.class); /** * Zookeeper 默认端口 */ private final static int DEFAULT_ZOOKEEPER_PORT = 2181; /** * Dubbo 元数据写入Zookeeper上的根节点，默认值是 dubbo */ private final static String DEFAULT_ROOT = \"dubbo\"; /** * Zookeeper 根节点 */ private final String root; /** * Service 接口全名集合。该属性适合用于监控中心，订阅整个Service层，因为Service层是动态的 */ private final Set&lt;String&gt; anyServices = new ConcurrentHashSet&lt;String&gt;(); /** * 监听器集合，建立NotifyListener和ChildListener的映射关系，k1为订阅URL,k2为监听器,value为ChildListener【真正起作用的对象】 */ private final ConcurrentMap&lt;URL, ConcurrentMap&lt;NotifyListener, ChildListener&gt;&gt; zkListeners = new ConcurrentHashMap&lt;URL, ConcurrentMap&lt;NotifyListener, ChildListener&gt;&gt;(); /** * Zookeeper 客户端 */ private final ZookeeperClient zkClient; public ZookeeperRegistry(URL url, ZookeeperTransporter zookeeperTransporter) &#123; super(url); if (url.isAnyHost()) &#123; throw new IllegalStateException(\"registry address == null\"); &#125; // 获取组名，默认为 'dubbo'，url.parameters.group 参数值，即Zookeeper的根节点 String group = url.getParameter(Constants.GROUP_KEY, DEFAULT_ROOT); if (!group.startsWith(Constants.PATH_SEPARATOR)) &#123; // 订正路径： group = \"/\" + group; group = Constants.PATH_SEPARATOR + group; &#125; // 确定根路径，以组名作为根路径 this.root = group; // 创建 Zookeeper 客户端，默认为 CuratorZookeeperTransporter，由SPI确定具体的实例。创建好Zookeeper客户端，意味着注册中心的创建完成【Zookeeper服务端必需先启动，Dubbo应用作为Zookeeper的客户端进行连接，然后操作Zookeeper】 zkClient = zookeeperTransporter.connect(url); /** * 添加 StateListener 状态监听器，该监听器在重连时，调用恢复方法 recover()，重新发起注册和订阅【将之前已经注册和订阅的数据进行重试】 * 注意： * StateListener 不是真正意义上的监听器，这里就是创建了一个匿名对象，其中的 #stateChanged 方法触发需要主动调用该匿名对象的该方法 &#123;@link AbstractZookeeperClient#stateChanged(int)&#125; */ zkClient.addStateListener(new StateListener() &#123; @Override public void stateChanged(int state) &#123; if (state == RECONNECTED) &#123; try &#123; recover(); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; &#125; &#125; &#125;); &#125; // $&#123;省略其他代码&#125;&#125; 在 ZookeeperRegistry 的构造方法中，会通过 ZookeeperTransporter 创建 ZookeeperClient 实例并连接到 Zookeeper 集群，同时还会添加一个连接状态的监听器。在该监听器中主要关注RECONNECTED 状态，在当前 Dubbo 节点于 Zookeeper 的连接恢复时，会重新进行注册，订阅操作，防止数据丢失。 doRegister 注册12345678910111213141516171819202122232425262728/** * ZookeeperRegistry */public class ZookeeperRegistry extends FailbackRegistry &#123; // $&#123;省略其他代码&#125; /** * 调用Zookeeper客户端创建服务节点 * * @param url */ @Override protected void doRegister(URL url) &#123; try &#123; /** * 1 通过 Zookeeper 客户端创建节点，节点路径由 toUrlPath 方法生成，路径格式如下: /$&#123;group&#125;/$&#123;serviceInterface&#125;/$&#123;Type&#125;/$&#123;url&#125; * 比如： /dubbo/com.alibaba.dubbo.demo.DemoService/providers/dubbo%3A%2F%2F127.0.0.1...... * 2 url.parameters.dynamic ,是否动态数据。若为false，该数据为持久数据，当注册方退出时，数据仍然保存在注册中心 */ zkClient.create(toUrlPath(url), url.getParameter(Constants.DYNAMIC_KEY, true)); &#125; catch (Throwable e) &#123; throw new RpcException(\"Failed to register \" + url + \" to zookeeper \" + getUrl() + \", cause: \" + e.getMessage(), e); &#125; &#125; // $&#123;省略其他代码&#125; 该方法是实现了其父类 FailbackRegistry 的模版方法，使用 Zookeeper 客户端进行节点的创建。服务提供者和消费者都需要把自己注册到注册中心，服务提供者的注册是为了让消费者发现自己从而发起远程调用。也让治理中心感知有新的服务提供者上线。消费者的发布是为了让服务治理中心发现自己。 doUnregister 取消注册12345678910111213141516171819202122/** * ZookeeperRegistry */public class ZookeeperRegistry extends FailbackRegistry &#123; // $&#123;省略其他代码&#125; /** * 取消注册，删除节点 * * @param url */ @Override protected void doUnregister(URL url) &#123; try &#123; zkClient.delete(toUrlPath(url)); &#125; catch (Throwable e) &#123; throw new RpcException(\"Failed to unregister \" + url + \" to zookeeper \" + getUrl() + \", cause: \" + e.getMessage(), e); &#125; &#125; // $&#123;省略其他代码&#125; 该方法是实现了其父类 FailbackRegistry 的模版方法，使用 Zookeeper 客户端进行节点的删除。 doSubscribe 订阅订阅通常有 pull 和 push 两种方式，一种是客户端定时轮询注册中心拉取配置，另一种是注册中心主动推送数据给客户端。目前 Dubbo 采用的是 第一次启动拉取方式，后续接收事件重新拉取数据。在服务暴露时，服务提供者会订阅 configurators 用于监听动态配置。在消费端启动时，消费者会订阅 providers,routers 和 configurators 这三个目录，用于分别监听服务提供者、路由规则和动态配置。Zookeeper 注册中心采用的是 事件通知 + 客户端拉取 的方式，第一次订阅时会把对应目录下的全量数据都拉取过来（客户端拉取），并在订阅的节点上注册监听器监听其子节点的变化。客户端与注册中心之间保持 TCP 长连接，后续每个订阅节点有任何数据变化（子节点变化也属于该节点变化，具体可参数ZK客户端API）时，注册中心会根据监听器的回调主动通知客户端（事件通知），客户端接到通知后，会把对应节点下的全量数据都拉取过来（客户端拉取），即子节点变化时监听器捕捉到事件后会回调它的方法，该回调方法会调用childChanged方法，而childChanged方法会把对应节点下的全量数据都拉取过来（客户端拉取）。需要说明的，Zookeeper 监听器被触发时，由 Zookeeper 集群主动将更新推送给 Zookeeper 客户端，而不需要客户端轮询。 Dubbo 应用作为一个 Zookeeper 客户端，当监听的节点发生变化时 Zookeeper 集群会主动把对应节点下的更新推送给 Zookeeper 客户端也就是 Dubbo 应用，这个过程是注册中心主动推的，但 Dubbo 是将这个更新通过自己内部的方法 childChanged 传递出去的，这个过程属于客户端拉取。这样我们就明白了，在 Dubbo 使用 Zookeeper 作为注册中心时，获取配置信息总体来说采用的都是客户端拉取的方式，在注册监听器后的情况是更新的数据会被 Zookeeper 集群主动推送过来，然后在 Zookeeper 监听的回调方法中 Dubbo 调用内部方法把数据传递出去，这一定意义上是拉取的方式。 订阅有两种情况，一种是服务治理中心会处理所有Service层订阅，Service被设置成统配符，另一种是某一个Service层的订阅。订阅的核心是通过 ZookeeperClient 在指定的路径上（category节点）添加 ChildListener 监听器，当订阅的节点发生变化时，会通过 ChildListener 监听器触发 notify 方法，进而触发 NotifyListener 监听器。 服务治理中心订阅服务治理中心订阅最终的处理还是会走某个Service层的订阅逻辑。这个分支的处理逻辑是在根节点上添加一个 ChildListener 监听器，当 Service 层的节点变化时，会触发这个 ChildListener。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public class ZookeeperRegistry extends FailbackRegistry &#123; // $&#123;省略其他代码&#125; @Override protected void doSubscribe(final URL url, final NotifyListener listener) &#123; try &#123; // ----------------- 订阅所有Service层的节点，例如监控中心的订阅 ---------------------/ if (Constants.ANY_VALUE.equals(url.getServiceInterface())) &#123; // service 层是 * // 根据节点 String root = toRootPath(); // 获的订阅的url 对应的监听器集合 ConcurrentMap&lt;NotifyListener, ChildListener&gt; listeners = zkListeners.get(url); // 不存在，进行创建 if (listeners == null) &#123; zkListeners.putIfAbsent(url, new ConcurrentHashMap&lt;NotifyListener, ChildListener&gt;()); listeners = zkListeners.get(url); &#125; ChildListener zkListener = listeners.get(listener); // 不存在ChildListener 对象，进行创建ChildListener对象 if (zkListener == null) &#123; listeners.putIfAbsent(listener, new ChildListener() &#123; /** * 节点变化回调，根节点下的子节点有变化就回调。 * @param parentPath 根节点 * @param currentChilds 根节点下的 service 层节点列表 */ @Override public void childChanged(String parentPath, List&lt;String&gt; currentChilds) &#123; // 遍历子节点列表 for (String child : currentChilds) &#123; // 解码 child = URL.decode(child); // 如果存在子节点还未被订阅，则说明是新的节点，则发起该Service层的订阅，走另一个分支 if (!anyServices.contains(child)) &#123; // 记录该节点已经订阅过 anyServices.add(child); // 处理具体 service 层订阅 subscribe(url.setPath(child).addParameters(Constants.INTERFACE_KEY, child, Constants.CHECK_KEY, String.valueOf(false)), listener); &#125; &#125; &#125; &#125;); zkListener = listeners.get(listener); &#125; // 创建Service 节点，该节点为持久化节点 zkClient.create(root, false); // 向Zookeeper service节点发起订阅 List&lt;String&gt; services = zkClient.addChildListener(root, zkListener); // 首次订阅时，要处理当前已有的 Service 层的订阅，调用subscribe(url,listener)，即走另一个分支 if (services != null &amp;&amp; !services.isEmpty()) &#123; for (String service : services) &#123; service = URL.decode(service); anyServices.add(service); subscribe(url.setPath(service).addParameters(Constants.INTERFACE_KEY, service, Constants.CHECK_KEY, String.valueOf(false)), listener); &#125; &#125; &#125; else &#123; // $&#123;某个Service 层订阅&#125; &#125; // $&#123;省略其他代码&#125; &#125; 该分支是订阅根节点下的所有Service层数据，当Service层发生变更时，若变更的有新增Service接口，即新增服务，则调用subscribe(url,listener)方法发起订阅，走处理指定Service层节点的逻辑。 订阅指定Service层节点该方法会根据订阅 URL 中的 category 属性获取关注的 category 节点集合，然后在每个 category 节点上添加 ChildListener 监听器。首次订阅或监听的 category 节点数据发生变化，会拉取该类别下的子节点的数据进行通知。 如果是providers类别的数据，则订阅方（一般是消费者）会更新本地的服务目录。 如果是routers类别的数据，则订阅方会更新本地路由规则列表。 如果是configurators类别的数据，则订阅方会更新或覆盖本地动态参数列表。 如果是consumers类别的数据，则服务治理中心会更新缓存中的数据。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public class ZookeeperRegistry extends FailbackRegistry &#123; // $&#123;省略其他代码&#125; @Override protected void doSubscribe(final URL url, final NotifyListener listener) &#123; try &#123; //----------------- 订阅所有Service层的节点，例如监控中心的订阅 ------------------------/ if (Constants.ANY_VALUE.equals(url.getServiceInterface())) &#123; // service 层是 * // $&#123;所有Service 层订阅&#125; &#125; else &#123; /** * ConcurrentMap&lt;URL, ConcurrentMap&lt;NotifyListener, ChildListener&gt;&gt; zkListeners * 1 根据url获取ConcurrentMap&lt;NotifyListener, ChildListener&gt;，没有就创建 * 2 根据listener从ConcurrentMap&lt;NotifyListener, ChildListener&gt;获取ChildListener，没有就创建 * 3 创建path持久化节点 * 4 创建path子节点监听器 */ // 子节点数据数组 List&lt;URL&gt; urls = new ArrayList&lt;URL&gt;(); // 循环分类数组，其中，调用toCategoriesPath(url)方法，解析订阅url获得分类数组，即要订阅的path，如：/dubbo/com.alibaba.dubbo.demo.DemoService/configurators for (String path : toCategoriesPath(url)) &#123; // 获得分类路径（由订阅的url得到的） 对应的监听器映射 ConcurrentMap&lt;NotifyListener, ChildListener&gt; listeners = zkListeners.get(url); // 不存在，进行创建 if (listeners == null) &#123; zkListeners.putIfAbsent(url, new ConcurrentHashMap&lt;NotifyListener, ChildListener&gt;()); listeners = zkListeners.get(url); &#125; /** * 1 获得listener(NotifyListener)对应的ChildListener对象，没有就会创建，一个NotifyListener关联一个ChildListener。 * 注意： * ChildListener的childChanged方法实际上就是当parentPath[即toCategoriesPath方法处理后的path]下的currentChilds发生变化时回调的方法，该方法内部又会回调NotifyListener#notify方法 */ ChildListener zkListener = listeners.get(listener); if (zkListener == null) &#123; listeners.putIfAbsent(listener, new ChildListener() &#123; @Override public void childChanged(String parentPath, List&lt;String&gt; currentChilds) &#123; // 变更时，调用 notity方法，回调 NotifyListener ZookeeperRegistry.this.notify(url, listener, toUrlsWithEmpty(url, parentPath, currentChilds)); &#125; &#125;); zkListener = listeners.get(listener); &#125; // 创建 Type 节点，该节点为持久节点，如： /dubbo/com.alibaba.dubbo.demo.DemoService/configurators。为了确保该path在Zookeeper 上存在 zkClient.create(path, false); /** * 向Zookeeper path节点发起订阅，并返回该节点下的子路径 */ List&lt;String&gt; children = zkClient.addChildListener(path, zkListener); // 添加到urls 中 if (children != null) &#123; urls.addAll(toUrlsWithEmpty(url, path, children)); &#125; &#125; /** * 首次订阅会主动调用NofityListener#notify(url,listener,currentChilds)方法，执行NotifyListener的逻辑 */ notify(url, listener, urls); &#125; // $&#123;省略其他代码&#125; &#125; 订阅时涉及到的绑定监听器以及 ChildListener 匿名对象方法回调，会在下一章节 Zookeeper 客户端详细说明。订阅的核心是为指定的类目绑定监听器，该监听器用于监听类目下的子节点变化，发生变化则会调用 ChildListener 匿名对象方法，传递类目下变更后的子节点列表，有了这个新的子节点列表，就可以根据需要进行服务的重新暴露、服务目录重新生成等。 doUnsubscribe 取消订阅1234567891011121314151617181920212223242526272829303132/** * ZookeeperRegistry */public class ZookeeperRegistry extends FailbackRegistry &#123; // $&#123;省略其他代码&#125; /** * 真正取消订阅的逻辑，删除对应的监听器 * * @param url * @param listener */ @Override protected void doUnsubscribe(URL url, NotifyListener listener) &#123; ConcurrentMap&lt;NotifyListener, ChildListener&gt; listeners = zkListeners.get(url); if (listeners != null) &#123; ChildListener zkListener = listeners.get(listener); if (zkListener != null) &#123; if (Constants.ANY_VALUE.equals(url.getServiceInterface())) &#123; String root = toRootPath(); zkClient.removeChildListener(root, zkListener); &#125; else &#123; for (String path : toCategoriesPath(url)) &#123; zkClient.removeChildListener(path, zkListener); &#125; &#125; &#125; &#125; &#125; // $&#123;省略其他代码&#125; 该方法是实现了其父类 FailbackRegistry 的模版方法，使用 Zookeeper 客户端删除订阅 URL 对应的监听器，达到不再监听该path的目的。 订阅时辅助方法 获取Root层路径123456789101112131415161718192021/** * 获得根目录 * root * * @return */ private String toRootDir() &#123; if (root.equals(Constants.PATH_SEPARATOR)) &#123; return root; &#125; return root + Constants.PATH_SEPARATOR; &#125; /** * Root * * @return 根路径 */ private String toRootPath() &#123; return root; &#125; 获取Service层路径12345678910111213/** * 获得服务路径 ， Root + service * * @param url * @return */ private String toServicePath(URL url) &#123; String name = url.getServiceInterface(); if (Constants.ANY_VALUE.equals(name)) &#123; return toRootPath(); &#125; return toRootDir() + URL.encode(name); &#125; 获得分类路径123456789/** * 获得分类路径 如： 到 providers/consumers/routes/configurations 的路径 * * @param url URL * @return 分类路径 */private String toCategoryPath(URL url) &#123; return toServicePath(url) + Constants.PATH_SEPARATOR + url.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY);&#125; 获得URL路径12345678910111213/** * 获得URL 路径，即 要注册到注册中心上的完整路径 * &lt;p&gt; * Root + Service + Type + URL * &lt;p&gt; * 被 &#123;@link #doRegister(URL)&#125; 和 &#123;@link #doUnregister(URL)&#125; 调用 * * @param url URL * @return 路径 */ private String toUrlPath(URL url) &#123; return toCategoryPath(url) + Constants.PATH_SEPARATOR + URL.encode(url.toFullString()); &#125; URL匹配1234567891011121314151617181920212223242526272829303132/** * 获得providers 中，和consumer 匹配的URL数组 * * @param consumer 订阅URL 如：provider://10.1.22.101:20880/com.alibaba.dubbo.demo.DemoService?key=value&amp;... * @param providers 订阅URL映射的路径的子路径集合 * @return 匹配的URL数组 */ private List&lt;URL&gt; toUrlsWithoutEmpty(URL consumer, List&lt;String&gt; providers) &#123; List&lt;URL&gt; urls = new ArrayList&lt;URL&gt;(); // 遍历所有的服务列表 if (providers != null &amp;&amp; !providers.isEmpty()) &#123; // 遍历子路径 for (String provider : providers) &#123; // 解码 provider = URL.decode(provider); // 是URL的路径才会处理 if (provider.contains(\"://\")) &#123; // 将字符串转为URL URL url = URL.valueOf(provider); // 子路径URL是否匹配订阅URL，以关键属性进行匹配，如服务接口名、类目、服务group、服务version等 if (UrlUtils.isMatch(consumer, url)) &#123; urls.add(url); &#125; &#125; &#125; &#125; return urls; &#125; Dubbo 客户端根据本地 URL 配置（引用配置信息）的接口、分类、分组和版本做过滤，通过上述方法对服务列表进行过滤，得到符合条件的服务。 筛选URL12345678910111213141516171819202122232425/** * 1 从providers中筛选和consumer匹配的URL集合 * 2 如果URL集合不为空，直接返回这个集合 * 3 如果URL集合为空，首先从path中获取category的值，然后将consumer的协议换成empty并添加参数category=path中的category的值。 * 形式：'empty://' 的URL返回，通过这样的方式，可以处理类似服务提供者为空的情况 * * @param consumer 订阅URL 如：provider://10.1.22.101:20880/com.alibaba.dubbo.demo.DemoService?key=value&amp;... * @param path 订阅URL映射的路径 如：/dubbo/com.alibaba.dubbo.demo.DemoService/configurators * @param providers 订阅URL映射的路径的子路径集合 * @return */ private List&lt;URL&gt; toUrlsWithEmpty(URL consumer, String path, List&lt;String&gt; providers) &#123; // 从providers中筛选和consumer 匹配的URL数组 List&lt;URL&gt; urls = toUrlsWithoutEmpty(consumer, providers); // 如果不存在匹配的，则创建 'empty://' 的URL返回 if (urls == null || urls.isEmpty()) &#123; int i = path.lastIndexOf('/'); String category = i &lt; 0 ? path : path.substring(i + 1); URL empty = consumer.setProtocol(Constants.EMPTY_PROTOCOL).addParameter(Constants.CATEGORY_KEY, category); urls.add(empty); &#125; return urls; &#125; 获得Type层路径1234567891011121314151617181920212223242526272829303132333435/** * 获得分类路径数组 * Root + Service + Type * * @param url 订阅URL * @return 分类路径数组 */ private String[] toCategoriesPath(URL url) &#123; String[] categories; // 如果category的值为 * ，表示分别订阅：providers,consumers,routers,configurators if (Constants.ANY_VALUE.equals(url.getParameter(Constants.CATEGORY_KEY))) &#123; categories = new String[]&#123; Constants.PROVIDERS_CATEGORY, Constants.CONSUMERS_CATEGORY, Constants.ROUTERS_CATEGORY, Constants.CONFIGURATORS_CATEGORY &#125;; &#125; else &#123; // 如果category的值不为 * ，就取出 category的值，如果没有值，就把providers作为默认值。注意，当category的值不为空时会使用 ',' 分割category的值，为数组 categories = url.getParameter(Constants.CATEGORY_KEY, new String[]&#123;Constants.DEFAULT_CATEGORY&#125;); &#125; // 获得分类路径数组 String[] paths = new String[categories.length]; for (int i = 0; i &lt; categories.length; i++) &#123; // 构建分类路径 paths[i] = toServicePath(url) + Constants.PATH_SEPARATOR + categories[i]; &#125; return paths; &#125; 销毁方法12345678910111213141516171819/** * ZookeeperRegistry */public class ZookeeperRegistry extends FailbackRegistry &#123; // $&#123;省略其他代码&#125; @Override public void destroy() &#123; super.destroy(); try &#123; // 关闭 Zookeeper 客户端连接 zkClient.close(); &#125; catch (Exception e) &#123; logger.warn(\"Failed to close zookeeper client \" + getUrl() + \", cause: \" + e.getMessage(), e); &#125; &#125; // $&#123;省略其他代码&#125; 重写了父类 FailbackRegistry 的销毁方法，使用 Zookeeper 客户端关闭会话，该方法会先调用父类的销毁方法。 小结本篇文章主要介绍了 Dubbo 封装的 ZookeeperRegistry，该注册中心类将具体操作任务交给内部封装的 Zookeeper 客户端去完成，自己本身只是处理 Zookeeper 客户端操作前的逻辑，如调用父类方法、解析URL的所属类目等，其中创建 Zookeeper 客户端的直接入口就在该类的构造方法中。此外，该类中的一些方法没有分析到，它们和订阅与通知相关，会和订阅通知一起分析。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://gentryhuang.com/tags/Zookeeper/"}]},{"title":"Dubbo源码分析 - 注册中心总览","slug":"rpc/注册中心总览","date":"2020-04-12T16:00:00.000Z","updated":"2020-10-25T02:22:09.273Z","comments":false,"path":"posts/dafcd048/","link":"","permalink":"https://gentryhuang.com/posts/dafcd048/","excerpt":"","text":"前言在 Dubbo 体系中，注册中心是核心组件之一。Dubbo 本身是一个分布式的 RPC 框架，依赖于 Dubbo 的应用都是单独部署的，为了让各个应用能够实时获取彼此的信息，就需要依赖一个一致性的服务注册和发现组件。Dubbo 通过注册中心实现了分布式环境中各服务之间的注册与发现，是各个分布式节点之间的纽带。主要作用如下： 动态加入。服务提供方通过注册中心记录自己的信息并动态地把自己暴露给其他消费者。 动态发现。一个消费者可以动态地感知新的配置、路由规则、新的服务，无需重新启动服务。一个服务提供者可以动态地感知配置的变化无需启动服务。 动态调整。注册中心支持参数的动态调整，新参数自动更新到相关服务节点。 Registry 只是 Consumer 和 Provider 感知彼此状态变化和配置改变（强调服务治理）的一种途径，实际通讯交互过程是直接进行的，对于 Registry 来说是透明无感知的。需要说明的是，我们所说的注册中心其实是指应用中的注册中心客户端，真正的注册中心服务是独立部署的进程或进程组成的集群，如 Zookeeper 集群、Redis 集群。对于注册中心而言，Provider 和 Consumer 仅是一个 URL。 工作流程 服务提供者启动时，会向注册中心写入自己的元数据信息，并订阅配置元数据信息。 消费者启动时，也会向注册中心写入自己的元数据信息，并订阅服务提供者、路由会配置元数据信息。 服务治理中心(dubbo-admin)启动时，会同时订阅所有服务提供者、服务消费者、路由和配置元数据信息。 服务提供者下线或新的服务提供者加入时，注册中心服务提供者目录会发生变化，变化信息会动态通知给消费者、服务治理中心。 消费方发起服务调用时，会异步将调用、统计信息等上报给监控中心。 需要注意的是，Dubbo 中的注册中心总体流程相同，框架对流程进行了抽象，采用抽象工厂和模版方法模式，主要区别是不同的注册中心有不同的具体实现，其数据结构也不相同。 注册中心在 Dubbo 架构中的位置为下图的 Registry，其中红框中的是我们接下来几篇文章着重分析的内容。 注册中心抽象APIDubbo服务暴露、服务引用以及服务调用等几乎都会使用到注册中心，这篇文章对Dubbo 的注册中心抽象API进行说明。 上图是Dubbo的注册中心抽象API代码结构图，红框中的代码都是抽象API的基础代码，黄框是具体的注册中心抽象API。 注册中心核心抽象API的UML UML图非常清楚，注册中心核心抽象API中主要有三个角色，注册中心、注册中心工厂、注册中心的监听器。它们之间采用继承、组合、以及工厂的方式联系在一起，需要注意的是该图中的 ZookeeperRegistry 注册中心实现没有涉及到具体的客户端，关于 Dubbo 的 Zookeeper 客户端会单独写一篇文章进行详细说明。从UML图可以看出当前 Dubbo 版本支持四种注册中心的实现。Zookeeper 是官方推荐的注册中心，在生产环境中有过实际使用。Redis 注册中心并没有经过长时间运行的可靠性验证，其稳定性依赖 Redis 本身。Simple 注册中心是一个简单的基于内存的注册中心实现，它本身就是一个标准的PRC服务，不支持集群。Multicast 模块则不需要启动任何注册中心，只要通过广播地址，就可以互相发现，不推荐生产环境使用。下面分别介绍该UML图中涉及到的组件。 Node12345678910111213141516171819202122public interface Node &#123; /** * 获取当前节点的 URL * * @return url. */ URL getUrl(); /** * 检测当前节点是否可用 * * @return available. */ boolean isAvailable(); /** * 销毁当前节点，释放资源 */ void destroy();&#125; 需要说明的是，在 Dubbo 中，一般使用 Node 这个接口来抽象节点的概念。Node 不仅可以表示 Provider 和 Consumer节点，还可以表示注册中心节点。Node 接口是一个顶级接口，Dubbo 中的核心组件几乎都继承该接口，只封装了三个和节点相关的方法。 RegistryService12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public interface RegistryService &#123; /** * 注册数据，如：提供者地址，消费者地址，路由规则，覆盖规则等数据 * * @param url Registration information , is not allowed to be empty, e.g: dubbo://10.20.153.10/com.alibaba.foo.BarService?version=1.0.0&amp;application=kylin */ void register(URL url); /** * 取消注册数据 * * @param url Registration information , is not allowed to be empty, e.g: dubbo://10.20.153.10/com.alibaba.foo.BarService?version=1.0.0&amp;application=kylin */ void unregister(URL url); /** * - 订阅符合条件的已注册数据，当订阅的数据发生改变时，注册中心会主动通知 listener 对象，NotifyListener 接口中定义的 notify 方法就是用来接收通知的。 * - 在 URL的category 属性上，表示订阅的数据分类。目前有四种类型： * 1 consumers 服务消费者列表 * 2 providers 服务提供者列表 * 3 routers 路由规则列表 * 4 configurations 配置规则列表 * * @param url Subscription condition, not allowed to be empty, e.g. consumer://10.20.153.10/com.alibaba.foo.BarService?version=1.0.0&amp;application=kylin * @param listener A listener of the change event, not allowed to be empty * */ void subscribe(URL url, NotifyListener listener); /** * 取消订阅 * * @param url Subscription condition, not allowed to be empty, e.g. consumer://10.20.153.10/com.alibaba.foo.BarService?version=1.0.0&amp;application=kylin * @param listener A listener of the change event, not allowed to be empty * */ void unsubscribe(URL url, NotifyListener listener); /** * 查询符合条件的已注册数据，它与 subscribe() 方法是有区别的，subscribe() 方法采用的是 push 模式，lookup() 方法采用的是 pull 模式。 * * @param url Query condition, is not allowed to be empty, e.g. consumer://10.20.153.10/com.alibaba.foo.BarService?version=1.0.0&amp;application=kylin * @return The registered information list, which may be empty, the meaning is the same as the parameters of &#123;@link com.alibaba.dubbo.registry.NotifyListener#notify(List&lt;URL&gt;)&#125;. * @see com.alibaba.dubbo.registry.NotifyListener#notify(List) */ List&lt;URL&gt; lookup(URL url);&#125; RegistryService 接口也是一个顶级接口，是注册中心服务接口，抽象了注册服务的基本行为。定义了节点的注册/反注册、订阅/反订阅以及查询三种操作方法。Dubbo 在上层进行了抽象，具体的实现细节交给不同的注册中心。 Registry12345678/** * Registry. (SPI, Prototype, ThreadSafe) * * @see com.alibaba.dubbo.registry.RegistryFactory#getRegistry(com.alibaba.dubbo.common.URL) * @see com.alibaba.dubbo.registry.support.AbstractRegistry */public interface Registry extends Node, RegistryService &#123;&#125; 注册中心接口，该接口中没有定义方法只是继承了 Node 和 RegistryService 接口，因此具备了注册、订阅、查询等操作，注册中心具体实现都要继承该接口。 AbstractRegistryRegistry 的抽象类，实现了通用的注册、订阅、查询以及通知等方法。其中，实现了当前节点订阅的数据（URL）缓存到本地及持久化到文件，一方面为了减轻注册中心组件的压力，另一方面该文件可用于当消费者无法从注册中心拉取服务提供者列表信息时就从该文件中获取，支持了即使注册中心宕机消费者仍然可以和提供者通信。 属性123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105public abstract class AbstractRegistry implements Registry &#123; // Log output protected final Logger logger = LoggerFactory.getLogger(getClass()); // URL地址分割符，用于文件缓存中，分割URL private static final char URL_SEPARATOR = ' '; // URL地址分隔正则表达式，用于解析文件缓存中URL列表 private static final String URL_SPLIT = \"\\\\s+\"; /** * 本地磁盘缓存 * 1 其中特殊的 key值为 registries， 对应的值记录注册中心列表， 其他的均为&#123;@link #notified&#125; 服务提供者列表 * 2 数据流向： 创建注册中心实例时从file读取数据到 properties中；监听到注册中心数据发生变更时，修改properties对应的值，并写入file * 3 数据的键-值对 * （1）大多数情况下，键为订阅者的服务键 &#123;@link URL#getServiceKey()&#125;,值为 服务提供者列表/路由规则列表/配置规则列表 * （2）特殊情况下是 键为 registries，值为注册中心列表 */ // Local disk cache, where the special key value.registies records the list of registry centers, and the others are the list of notified service providers private final Properties properties = new Properties(); /** * 注册中心数据缓存线程池 */ private final ExecutorService registryCacheExecutor = Executors.newFixedThreadPool(1, new NamedThreadFactory(\"DubboSaveRegistryCache\", true)); /** * properties发生变更时，是否同步写入文件 */ private final boolean syncSaveFile; /** * 数据版本号 &#123;@link #properties&#125;，每次写入 file 文件时都是全覆盖写入，而不是修改文件，因此需要并发处理，防止旧数据覆盖新数据 */ private final AtomicLong lastCacheChanged = new AtomicLong(); /** * 已注册 URL 集合 */ private final Set&lt;URL&gt; registered = new ConcurrentHashSet&lt;URL&gt;(); /** * 订阅 URL 的监听器集合 * key： 订阅URL，也即被监听的URL * value: 订阅URL相应的监听器集合 */ private final ConcurrentMap&lt;URL, Set&lt;NotifyListener&gt;&gt; subscribed = new ConcurrentHashMap&lt;URL, Set&lt;NotifyListener&gt;&gt;(); /** * 通知的URL到监听器监听到数据变化后的 结果URL集合 * key1: 订阅URL，当前节点作为消费者或提供者的一个订阅URL，如服务引用时进行订阅的 consumer协议的的URL，服务暴暴露时订阅的 provider协议的URL，和 &#123;@link #subscribed&#125; 的键一致 * key2: 分类，如： providers,consumers,routes,configurators。【对于消费着来说一般是无consumers,因为消费者不会去订阅另外的消费者的列表】 * value: 新的URL集合 */ private final ConcurrentMap&lt;URL, Map&lt;String, List&lt;URL&gt;&gt;&gt; notified = new ConcurrentHashMap&lt;URL, Map&lt;String, List&lt;URL&gt;&gt;&gt;(); /** * 注册中心 URL，包含了创建当前Registry对象的全部配置信息，注意，AbstractRegistryFactory 对其进行了规范化处理 */ private URL registryUrl; /** * 缓存数据的磁盘文件 */ private File file; /** * 构造方法，每次创建注册中心都会同步磁盘文件数据到缓存中 * @param url */ public AbstractRegistry(URL url) &#123; setUrl(url); /** * 可以指定注册中心磁盘缓存文件，配置方式： * 1 使用file属性指定 &lt;dubbo:registry address=\"xxx\" file=\"/opt/xxx\"/&gt; * 2 使用save.file属性指定 &lt;dubbo:registry address=\"xxx\" save.file=\"/opt/xxx\"/&gt; * 3 不显示指定的话，使用默认值：System.getProperty(\"user.home\") + \"/.dubbo/dubbo-registry-\" + 应用名 + \"-\" + url.getAddress() + \".cache\" */ // Start file save timer syncSaveFile = url.getParameter(Constants.REGISTRY_FILESAVE_SYNC_KEY, false); // 获得 file String filename = url.getParameter(Constants.FILE_KEY, System.getProperty(\"user.home\") + \"/.dubbo/dubbo-registry-\" + url.getParameter(Constants.APPLICATION_KEY) + \"-\" + url.getAddress() + \".cache\"); File file = null; if (ConfigUtils.isNotEmpty(filename)) &#123; file = new File(filename); if (!file.exists() &amp;&amp; file.getParentFile() != null &amp;&amp; !file.getParentFile().exists()) &#123; if (!file.getParentFile().mkdirs()) &#123; throw new IllegalArgumentException(\"Invalid registry store file \" + file + \", cause: Failed to create directory \" + file.getParentFile() + \"!\"); &#125; &#125; &#125; this.file = file; // 加载本地磁盘缓存文件到内存缓存，即 properties.load(in)，到properties属性中 loadProperties(); // 通知监听器，URL 变化结果 。 为什么构造方法要通知，zk连接都没有建立，监听器更没有注册，即 subscribed 里面还没有值 notify(url.getBackupUrls()); &#125; // $&#123;省略其他代码&#125;&#125; AbstractRegistry 抽象类中的属性大致有四类，注册的URL、缓存数据相关的、订阅URL的监听器、通知URL对应的变更URL。在 AbstractRegistry 初始化时，会将对应的 file 文件中的订阅数据加载到 properties 字段中。当 properties 中的注册数据发生变化时，会写入本地的 file 文件进行同步。本地缓存文件的路径如下： user.home/.dubbo/dubbo-registry-${当前应用名}-${当前注册中心所在的IP地址}.cache 注册/反注册123456789101112131415161718192021222324252627282930313233343536373839public abstract class AbstractRegistry implements Registry &#123; // $&#123;省略其他代码&#125; /** * 先添加到 registered 缓存中，进行状态的维护。再由子类 FailbackRegistry类 真正注册 * * @param url Registration information , is not allowed to be empty, e.g: dubbo://10.20.153.10/com.alibaba.foo.BarService?version=1.0.0&amp;application=kylin */ @Override public void register(URL url) &#123; if (url == null) &#123; throw new IllegalArgumentException(\"register url == null\"); &#125; if (logger.isInfoEnabled()) &#123; logger.info(\"Register: \" + url); &#125; registered.add(url); &#125; /** * 先从 registered 缓存中移除，再由子类 FailbackRegistry 真正取消注册 * * @param url Registration information , is not allowed to be empty, e.g: dubbo://10.20.153.10/com.alibaba.foo.BarService?version=1.0.0&amp;application=kylin */ @Override public void unregister(URL url) &#123; if (url == null) &#123; throw new IllegalArgumentException(\"unregister url == null\"); &#125; if (logger.isInfoEnabled()) &#123; logger.info(\"Unregister: \" + url); &#125; registered.remove(url); &#125; // $&#123;省略其他代码&#125;&#125; AbstractRegistry 抽象类中的注册和反注册方法只是操作缓存，真正的实现交给子类 FailbackRegistry 完成。 订阅/反订阅1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public abstract class AbstractRegistry implements Registry &#123; // $&#123;省略其他代码&#125; /** * 先缓存到 subscribed 中，再通过子类 FailbackRegistry 具体执行订阅逻辑 * * @param url 订阅条件，不允许为空，如：consumer://10.10.10.10/com.alibaba.foo.BarService?version=1.0.0&amp;application=kylin * @param listener 变更事件监听器，不允许为空 */ @Override public void subscribe(URL url, NotifyListener listener) &#123; if (url == null) &#123; throw new IllegalArgumentException(\"subscribe url == null\"); &#125; if (listener == null) &#123; throw new IllegalArgumentException(\"subscribe listener == null\"); &#125; if (logger.isInfoEnabled()) &#123; logger.info(\"Subscribe: \" + url); &#125; /** * 1 从ConcurrentMap&lt;URL, Set&lt;NotifyListener&gt;&gt; subscribed中获取key为url的集合Set&lt;NotifyListener&gt; * 2 如果该集合存在，直接将当前的NotifyListener实例存入该集合,如果集合不存在，先创建，之后放入subscribed中，并将当前的NotifyListener实例存入刚刚创建的集合 */ Set&lt;NotifyListener&gt; listeners = subscribed.get(url); if (listeners == null) &#123; subscribed.putIfAbsent(url, new ConcurrentHashSet&lt;NotifyListener&gt;()); listeners = subscribed.get(url); &#125; listeners.add(listener); &#125; /** * 先从缓存中移除，再通过子类 FailbackRegistry 具体执行取消订阅的逻辑 * * @param url Subscription condition, not allowed to be empty, e.g. consumer://10.20.153.10/com.alibaba.foo.BarService?version=1.0.0&amp;application=kylin * @param listener A listener of the change event, not allowed to be empty */ @Override public void unsubscribe(URL url, NotifyListener listener) &#123; if (url == null) &#123; throw new IllegalArgumentException(\"unsubscribe url == null\"); &#125; if (listener == null) &#123; throw new IllegalArgumentException(\"unsubscribe listener == null\"); &#125; if (logger.isInfoEnabled()) &#123; logger.info(\"Unsubscribe: \" + url); &#125; Set&lt;NotifyListener&gt; listeners = subscribed.get(url); if (listeners != null) &#123; listeners.remove(listener); &#125; &#125; // $&#123;省略其他代码&#125;&#125; AbstractRegistry 抽象类中的订阅和反订阅方法只是操作缓存，真正的实现交给子类 FailbackRegistry 完成。 断线重连12345678910111213141516171819202122232425262728293031323334353637public abstract class AbstractRegistry implements Registry &#123; // $&#123;省略其他代码&#125; /** * 和注册中心断开，重连成功会调用该方法，恢复注册和订阅 * * @throws Exception */ protected void recover() throws Exception &#123; // register Set&lt;URL&gt; recoverRegistered = new HashSet&lt;URL&gt;(getRegistered()); if (!recoverRegistered.isEmpty()) &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Recover register url \" + recoverRegistered); &#125; for (URL url : recoverRegistered) &#123; // 放入缓存 register(url); &#125; &#125; // subscribe Map&lt;URL, Set&lt;NotifyListener&gt;&gt; recoverSubscribed = new HashMap&lt;URL, Set&lt;NotifyListener&gt;&gt;(getSubscribed()); if (!recoverSubscribed.isEmpty()) &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Recover subscribe url \" + recoverSubscribed.keySet()); &#125; for (Map.Entry&lt;URL, Set&lt;NotifyListener&gt;&gt; entry : recoverSubscribed.entrySet()) &#123; URL url = entry.getKey(); for (NotifyListener listener : entry.getValue()) &#123; subscribe(url, listener); &#125; &#125; &#125; &#125; // $&#123;省略其他代码&#125; AbstractRegistry 抽象类中的断线重连逻辑是，与注册中心断开后重新连接时会从缓存中取出已经注册的URL集合，然后放入缓存，订阅同理。 通知于本地缓存1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public abstract class AbstractRegistry implements Registry &#123; // $&#123;省略其他代码&#125; /* * 订阅URL映射的节点对应的子节点发生变化时，通知监听器 * @param url 订阅URL * @param listener 订阅ULR对应的监听器 * @param urls 订阅URL映射的路径下的子路径集合（全量数据） */ protected void notify(URL url, NotifyListener listener, List&lt;URL&gt; urls) &#123; if (url == null) &#123; throw new IllegalArgumentException(\"notify url == null\"); &#125; if (listener == null) &#123; throw new IllegalArgumentException(\"notify listener == null\"); &#125; if ((urls == null || urls.isEmpty()) &amp;&amp; !Constants.ANY_VALUE.equals(url.getServiceInterface())) &#123; logger.warn(\"Ignore empty notify urls for subscribe url \" + url); return; &#125; if (logger.isInfoEnabled()) &#123; logger.info(\"Notify urls for subscribe url \" + url + \", urls: \" + urls); &#125; // 1 将 `urls` 按照 URL中的 'category` 参数进行分类，添加到Map集合result中 Map&lt;String, List&lt;URL&gt;&gt; result = new HashMap&lt;String, List&lt;URL&gt;&gt;(); // 遍历 for (URL u : urls) &#123; // 子路径URL是否匹配订阅URL if (UrlUtils.isMatch(url, u)) &#123; // 获取分类，默认为 providers String category = u.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY); // 加入到结果集 List&lt;URL&gt; categoryList = result.get(category); if (categoryList == null) &#123; categoryList = new ArrayList&lt;URL&gt;(); result.put(category, categoryList); &#125; categoryList.add(u); &#125; &#125; if (result.size() == 0) &#123; return; &#125; // 获得订阅URL对应的缓存`notified`,即通知的 URL 变化结果（全量数据），会把result中的值放入到 categoryNotified中 Map&lt;String, List&lt;URL&gt;&gt; categoryNotified = notified.get(url); if (categoryNotified == null) &#123; notified.putIfAbsent(url, new ConcurrentHashMap&lt;String, List&lt;URL&gt;&gt;()); categoryNotified = notified.get(url); &#125; // 处理通知的 URL 变化结果（全量数据），即按照分类，循环处理通知的URL变化结果（全量数据） for (Map.Entry&lt;String, List&lt;URL&gt;&gt; entry : result.entrySet()) &#123; // 获得分类名 String category = entry.getKey(); // 获得分类名对应的通知ULR列表 List&lt;URL&gt; categoryList = entry.getValue(); // 1 将result 覆盖到 `notified`缓存【更新notified集合中的通知ULR列表】，需要注意：当某个分类的数据为空时，会依然有URL，如 empty://...` ，通过这种方式统一处理所有订阅URL对应的数据为空的情况。 categoryNotified.put(category, categoryList); // 2 保存订阅url对应的被通知的URL到 properties和文件 中 // 在循环中的保存的原因是，订阅url对应的通知url可能是变动的，上一步的操作会更新notified集合，为了让 properties和文件中的 订阅-通知关系正确就需要不断更新。 saveProperties(url); // 3 调用传入的listener的notify()方法 listener.notify(categoryList); &#125; &#125; // $&#123;省略其他代码&#125; 需要说明的是，向注册中心发起订阅后，会获取到订阅URL所对应的全量数据，接着调用该上述方法；当注册中心监控的数据发生变更时，会调用上述方法，虽然变化的是增量的，但是从注册中心拉取的是全量的数据，即最新的数据。该方法的使用主要在服务暴露过程中服务提供者订阅配置信息，便于配置发生改变时通过监听器进行捕捉然后回调该方法，最终完成服务重新暴露。在服务引用过程中消费者订阅服务信息、配置信息等最终完成服务引用。该方法在 Dubbo 整个生命周期内发挥重要的作用，在分析完服务暴露和服务引用后会单独写一篇文章详细说明。 销毁12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public abstract class AbstractRegistry implements Registry &#123; // $&#123;省略其他代码&#125; @Override public void destroy() &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Destroy registry:\" + getUrl()); &#125; // 取消注册逻辑 Set&lt;URL&gt; destroyRegistered = new HashSet&lt;URL&gt;(getRegistered()); if (!destroyRegistered.isEmpty()) &#123; for (URL url : new HashSet&lt;URL&gt;(getRegistered())) &#123; if (url.getParameter(Constants.DYNAMIC_KEY, true)) &#123; try &#123; // 取消注册，操作缓存，具体实现交给子类 unregister(url); if (logger.isInfoEnabled()) &#123; logger.info(\"Destroy unregister url \" + url); &#125; &#125; catch (Throwable t) &#123; logger.warn(\"Failed to unregister url \" + url + \" to registry \" + getUrl() + \" on destroy, cause: \" + t.getMessage(), t); &#125; &#125; &#125; &#125; // 取消订阅，操作缓存，具体实现交给子类 Map&lt;URL, Set&lt;NotifyListener&gt;&gt; destroySubscribed = new HashMap&lt;URL, Set&lt;NotifyListener&gt;&gt;(getSubscribed()); if (!destroySubscribed.isEmpty()) &#123; for (Map.Entry&lt;URL, Set&lt;NotifyListener&gt;&gt; entry : destroySubscribed.entrySet()) &#123; // 订阅URL URL url = entry.getKey(); // 订阅URL对应的监听器列表 for (NotifyListener listener : entry.getValue()) &#123; try &#123; // 取消订阅 unsubscribe(url, listener); if (logger.isInfoEnabled()) &#123; logger.info(\"Destroy unsubscribe url \" + url); &#125; &#125; catch (Throwable t) &#123; logger.warn(\"Failed to unsubscribe url \" + url + \" to registry \" + getUrl() + \" on destroy, cause: \" + t.getMessage(), t); &#125; &#125; &#125; &#125; &#125; // $&#123;省略其他代码&#125; 主要是取消注册和订阅。需要注意的是，无论是服务提供者还是消费者，都会向Registry发起注册和订阅，所以在JVM关闭示，都要进行取消。 本地缓存123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public abstract class AbstractRegistry implements Registry &#123; // $&#123;省略其他代码&#125; /** * * @param url 订阅URL */ private void saveProperties(URL url) &#123; if (file == null) &#123; return; &#125; try &#123; StringBuilder buf = new StringBuilder(); // notified 缓存的值： 订阅URL 对应的映射集合，只要订阅URL关联的路径下有节点变化，就会不断刷新，最新最全数据。 Map&lt;String, List&lt;URL&gt;&gt; categoryNotified = notified.get(url); if (categoryNotified != null) &#123; for (List&lt;URL&gt; us : categoryNotified.values()) &#123; for (URL u : us) &#123; if (buf.length() &gt; 0) &#123; buf.append(URL_SEPARATOR); &#125; buf.append(u.toFullString()); &#125; &#125; &#125; properties.setProperty(url.getServiceKey(), buf.toString()); // 版本号，使用CAS long version = lastCacheChanged.incrementAndGet(); // 保存变更数据到磁盘文件 if (syncSaveFile) &#123; doSaveProperties(version); &#125; else &#123; registryCacheExecutor.execute(new SaveProperties(version)); &#125; &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; &#125; // $&#123;省略其他代码&#125; 该方法中会取出订阅的各个分类下的URL连接起来（中间以空格分隔），然后以订阅URL的服务键为key先保存到内存中的 Properties 中，然后在同步或异步保存到磁盘文件中，同步或异步根据 syncSaveFile 参数值。接着分析保存变更数据到磁盘文件。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public abstract class AbstractRegistry implements Registry &#123; // $&#123;省略其他代码&#125; /** * @param version 版本号 */ public void doSaveProperties(long version) &#123; /** * 安全措施： * 1 CAS判断： * 在saveProperties(URL url)方法中执行了long version = lastCacheChanged.incrementAndGet(); * 这里进行if (version &lt; lastCacheChanged.get())判断，如果满足这个条件，说明当前线程在进行doSaveProperties(long version)时， * 已经有其他线程执行了saveProperties(URL url)，马上就要执行doSaveProperties(long version)，所以当前线程放弃操作，让后边的这个线程来做保存操作。 * 2 文件锁 FileLock： * FileLock 是进程文件锁，用于进程间并发，控制不同程序（JVM）对同一文件的并发访问，文件锁可以解决多个进程并发访问、可以通过对一个可写文件加锁，保证同时只有一个进程可以拿到文件锁，这个进程从而可以对文件进行操作， * 而其它拿不到锁的进程要么被挂起等待，要么可以去做一些其它事情，这种机制保证了进程间文件的并发安全操作。修改同一个文件的问题，但不能解决多线程并发访问、修改同一文件的问题。FileLock 文件锁的效果是与操作系统相关的，是由操作系统底层来实现。 */ if (version &lt; lastCacheChanged.get()) &#123; return; &#125; if (file == null) &#123; return; &#125; // Save try &#123; File lockfile = new File(file.getAbsolutePath() + \".lock\"); if (!lockfile.exists()) &#123; lockfile.createNewFile(); &#125; RandomAccessFile raf = new RandomAccessFile(lockfile, \"rw\"); try &#123; FileChannel channel = raf.getChannel(); try &#123; // 对文件加锁，默认为排它锁，没有获取到锁的进程阻塞等待 FileLock lock = channel.tryLock(); if (lock == null) &#123; throw new IOException(\"Can not lock the registry cache file \" + file.getAbsolutePath() + \", ignore and retry later, maybe multi java process use the file, please config: dubbo.registry.file=xxx.properties\"); &#125; // Save try &#123; if (!file.exists()) &#123; file.createNewFile(); &#125; FileOutputStream outputFile = new FileOutputStream(file); try &#123; properties.store(outputFile, \"Dubbo Registry Cache\"); &#125; finally &#123; outputFile.close(); &#125; // 释放文件锁 &#125; finally &#123; lock.release(); &#125; &#125; finally &#123; channel.close(); &#125; &#125; finally &#123; raf.close(); &#125; &#125; catch (Throwable e) &#123; if (version &lt; lastCacheChanged.get()) &#123; return; &#125; else &#123; registryCacheExecutor.execute(new SaveProperties(lastCacheChanged.incrementAndGet())); &#125; logger.warn(\"Failed to save registry store file, cause: \" + e.getMessage(), e); &#125; &#125; // $&#123;省略其他代码&#125; 该方法用于将 Properties 文件中的变更数据保存到磁盘文件中，在保存的时候做了并发处理操作，详细见代码注释。 加载变更数据到内存12345678910111213141516171819202122232425262728public abstract class AbstractRegistry implements Registry &#123; // $&#123;省略其他代码&#125; private void loadProperties() &#123; if (file != null &amp;&amp; file.exists()) &#123; InputStream in = null; try &#123; in = new FileInputStream(file); properties.load(in); if (logger.isInfoEnabled()) &#123; logger.info(\"Load registry store file \" + file + \", data: \" + properties); &#125; &#125; catch (Throwable e) &#123; logger.warn(\"Failed to load registry store file \" + file, e); &#125; finally &#123; if (in != null) &#123; try &#123; in.close(); &#125; catch (IOException e) &#123; logger.warn(e.getMessage(), e); &#125; &#125; &#125; &#125; &#125; // $&#123;省略其他代码&#125; 该方法用于将磁盘文件中的变更数据加载到内存中的 Properties 中。 获取订阅URL对应的变更URL列表1234567891011121314151617181920212223242526272829303132public abstract class AbstractRegistry implements Registry &#123; // $&#123;省略其他代码&#125; /** * @param url 订阅URL * @return */ public List&lt;URL&gt; getCacheUrls(URL url) &#123; for (Map.Entry&lt;Object, Object&gt; entry : properties.entrySet()) &#123; // 映射URL String key = (String) entry.getKey(); // 映射URL 对应的 通知URL串 String value = (String) entry.getValue(); if (key != null &amp;&amp; key.length() &gt; 0 &amp;&amp; key.equals(url.getServiceKey()) &amp;&amp; (Character.isLetter(key.charAt(0)) || key.charAt(0) == '_') &amp;&amp; value != null &amp;&amp; value.length() &gt; 0) &#123; // 对通知的URL串 以 '空格' 进行分割成字符串 String[] arr = value.trim().split(URL_SPLIT); List&lt;URL&gt; urls = new ArrayList&lt;URL&gt;(); for (String u : arr) &#123; // 解析URL串 urls.add(URL.valueOf(u)); &#125; return urls; &#125; &#125; return null; &#125; // $&#123;省略其他代码&#125; AbstractRegistry 小结AbstractRegistry 核心功能是本地文件缓存，在 AbstractRegistry 初始化时，会调用 loadProperties() 方法将本地文件加载到 properties 对象中。当网络抖动等情况导致订阅失败时，消费者端的 Registry 就可以调用 getCacheUrls() 方法获取本地缓存，从而得到最近注册的服务提供者URL列表（还有其它列表），AbstractRegistry 通过本地缓存提供了一种容错机制，保证了服务的可靠性。 重试机制在微服务系统中，注册中心一般都会独立部署成一个集群，其它应用通过客户端连接集群，以完成注册、订阅等操作。但网络通信是不可靠的，为了保证服务的可靠性，重试机制就变得必不可少了。 FailbackRegistry继承了 AbstractRegistry 抽闲类，支持失败重试的 Registry 抽象类。AbstractRegistry 中的注册、订阅操作更多的是操作缓存，并没有和注册中心交互。FailbackRegistry 在 AbstractRegistry 的基础上提供了注册和订阅的模版方法交由具体子类实现逻辑，并支持失败重试操作。也就是说 FailbackRegistry 及其上层将整个流程模型构建好了，具体实现如 ZookeeperRegistry、RedisRegistry 等只需关注功能点即可，无需关注整个注册中心流程。 属性1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public abstract class FailbackRegistry extends AbstractRegistry &#123; /** * 定时任务执行器 */ private final ScheduledExecutorService retryExecutor = Executors.newScheduledThreadPool(1, new NamedThreadFactory(\"DubboRegistryFailedRetryTimer\", true)); /** * 失败重试ScheduledFuture，定时检查是否有请求失败，如有，无限次重试 */ private final ScheduledFuture&lt;?&gt; retryFuture; /** * 注册失败的URL集合 */ private final Set&lt;URL&gt; failedRegistered = new ConcurrentHashSet&lt;URL&gt;(); /** * 取消注册失败的URL集合 */ private final Set&lt;URL&gt; failedUnregistered = new ConcurrentHashSet&lt;URL&gt;(); /** * 订阅失败的监听器集合 key: 订阅失败的URL value: 对应的监听器 */ private final ConcurrentMap&lt;URL, Set&lt;NotifyListener&gt;&gt; failedSubscribed = new ConcurrentHashMap&lt;URL, Set&lt;NotifyListener&gt;&gt;(); /** * 取消订阅失败的监听器集合 key: 订阅URL value: 对应的监听器 */ private final ConcurrentMap&lt;URL, Set&lt;NotifyListener&gt;&gt; failedUnsubscribed = new ConcurrentHashMap&lt;URL, Set&lt;NotifyListener&gt;&gt;(); /** * 通知失败的URL集合 key1: 订阅URL key2: 订阅URL对应的监听器 value: 订阅URL对应的变更数据 */ private final ConcurrentMap&lt;URL, Map&lt;NotifyListener, List&lt;URL&gt;&gt;&gt; failedNotified = new ConcurrentHashMap&lt;URL, Map&lt;NotifyListener, List&lt;URL&gt;&gt;&gt;(); /** * The time in milliseconds the retryExecutor will wait // 重试操作的时间间隔 */ private final int retryPeriod; public FailbackRegistry(URL url) &#123; /** * 执行父类构造方法， 加载本地磁盘缓存文件到内存缓存，即 properties.load(in)，到properties属性中。 * 说明： * 这个很重要，注册中心宕机的情况下，依赖缓存文件中的信息可以构建Invoker，不影响服务的调用，只是不能调用新的服务了。 */ super(url); // 重试频率，单位 毫秒 this.retryPeriod = url.getParameter(Constants.REGISTRY_RETRY_PERIOD_KEY, Constants.DEFAULT_REGISTRY_RETRY_PERIOD); // 创建失败重试定时器【就是将一堆失败记录进行对应的重试操作】 this.retryFuture = retryExecutor.scheduleWithFixedDelay(new Runnable() &#123; @Override public void run() &#123; // Check and connect to the registry try &#123; // 执行重试操作 retry(); &#125; catch (Throwable t) &#123; // Defensive fault tolerance logger.error(\"Unexpected error occur at failed retry, cause: \" + t.getMessage(), t); &#125; &#125; &#125;, retryPeriod, retryPeriod, TimeUnit.MILLISECONDS); &#125; // $&#123;省略其它代码&#125; // ==== Template method ==== protected abstract void doRegister(URL url); protected abstract void doUnregister(URL url); protected abstract void doSubscribe(URL url, NotifyListener listener); protected abstract void doUnsubscribe(URL url, NotifyListener listener);&#125; 该抽象类主要维护了注册/取消注册失败、订阅/取消订阅失败、通知失败的缓存，以及提供者了注册/取消注册、订阅/取消订阅的模版方法。进行注册或订阅操作时，会先调用其父类 AbstractRegistry 中的方法进行缓存操作，然后再调用其具体子类的方法。 register1234567891011121314151617181920212223242526272829303132333435363738public abstract class FailbackRegistry extends AbstractRegistry &#123; // $&#123;省略其它代码&#125; @Override public void register(URL url) &#123; // 调用父类操作缓存的方法 super.register(url); failedRegistered.remove(url); failedUnregistered.remove(url); try &#123; // 发起注册请求到注册中心服务器，具体由子类实现，通过注册中心客户端连接到服务端 doRegister(url); &#125; catch (Exception e) &#123; Throwable t = e; // 如果开启了启动时检测，则直接抛出异常 boolean check = getUrl().getParameter(Constants.CHECK_KEY, true) &amp;&amp; url.getParameter(Constants.CHECK_KEY, true) &amp;&amp; !Constants.CONSUMER_PROTOCOL.equals(url.getProtocol()); boolean skipFailback = t instanceof SkipFailbackWrapperException; if (check || skipFailback) &#123; if (skipFailback) &#123; t = t.getCause(); &#125; throw new IllegalStateException(\"Failed to register \" + url + \" to registry \" + getUrl().getAddress() + \", cause: \" + t.getMessage(), t); &#125; else &#123; logger.error(\"Failed to register \" + url + \", waiting for retry, cause: \" + t.getMessage(), t); &#125; // 记录注册失败的URL到注册失败的列表中，为了以后定时重试 failedRegistered.add(url); &#125; &#125; // $&#123;省略其它代码&#125;&#125; unregister1234567891011121314151617181920212223242526272829303132333435363738public abstract class FailbackRegistry extends AbstractRegistry &#123; // $&#123;省略其它代码&#125; @Override public void unregister(URL url) &#123; // 调用父类操作缓存的方法 super.unregister(url); failedRegistered.remove(url); failedUnregistered.remove(url); try &#123; // 发起取消注册请求到注册中心服务器，具体由子类实现，通过注册中心客户端连接到服务端 doUnregister(url); &#125; catch (Exception e) &#123; Throwable t = e; // If the startup detection is opened, the Exception is thrown directly. boolean check = getUrl().getParameter(Constants.CHECK_KEY, true) &amp;&amp; url.getParameter(Constants.CHECK_KEY, true) &amp;&amp; !Constants.CONSUMER_PROTOCOL.equals(url.getProtocol()); boolean skipFailback = t instanceof SkipFailbackWrapperException; if (check || skipFailback) &#123; if (skipFailback) &#123; t = t.getCause(); &#125; throw new IllegalStateException(\"Failed to unregister \" + url + \" to registry \" + getUrl().getAddress() + \", cause: \" + t.getMessage(), t); &#125; else &#123; logger.error(\"Failed to uregister \" + url + \", waiting for retry, cause: \" + t.getMessage(), t); &#125; // Record a failed registration request to a failed list, retry regularly failedUnregistered.add(url); &#125; &#125; // $&#123;省略其它代码&#125;&#125; subscribe12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public abstract class FailbackRegistry extends AbstractRegistry &#123; // $&#123;省略其它代码&#125; @Override public void subscribe(URL url, NotifyListener listener) &#123; /** 调用父类 将listener实例加入到url所对应的监听器集合中 &#123;@link #subscribed &#125; 中 */ super.subscribe(url, listener); // 将listener从failedSubscribed/failedUnsubscribed中删除 ，接着从failedNotified获取当前url的通知失败Map&lt;NotifyListener, List&lt;URL&gt;&gt;，然后从中 删除掉listener 到 需要通知的所有url 的映射 removeFailedSubscribed(url, listener); try &#123; // 向服务端发送订阅请求,具体请求处理由子类实现 doSubscribe(url, listener); /** 如果在订阅的过程抛出异常，那么尝试获取缓存url，如果有缓存url，则进行失败通知。之后“将失败的订阅请求记录到失败列表，定时重试”，如果没有缓存url， * 若开启了启动时检测或者直接抛出的异常是SkipFailbackWrapperException，则直接抛出异常，不会“将失败的订阅请求记录到失败列表，定时重试” */ &#125; catch (Exception e) &#123; Throwable t = e; /** * * 从Properties缓存文件中取出通知URL集合 * 【注意：这些URL是由注册中心维护的，每次订阅方请求订阅时，注册中心都会把对应的要通知的URL列表记录到properties文件中，然后写入磁盘，注意 empty://的情况】 */ List&lt;URL&gt; urls = getCacheUrls(url); if (urls != null &amp;&amp; !urls.isEmpty()) &#123; notify(url, listener, urls); logger.error(\"Failed to subscribe \" + url + \", Using cached list: \" + urls + \" from cache file: \" + getUrl().getParameter(Constants.FILE_KEY, System.getProperty(\"user.home\") + \"/dubbo-registry-\" + url.getHost() + \".cache\") + \", cause: \" + t.getMessage(), t); &#125; else &#123; // 如果开启了启动时检测check=true,则直接抛出异常 boolean check = getUrl().getParameter(Constants.CHECK_KEY, true) &amp;&amp; url.getParameter(Constants.CHECK_KEY, true); boolean skipFailback = t instanceof SkipFailbackWrapperException; if (check || skipFailback) &#123; if (skipFailback) &#123; t = t.getCause(); &#125; throw new IllegalStateException(\"Failed to subscribe \" + url + \", cause: \" + t.getMessage(), t); &#125; else &#123; logger.error(\"Failed to subscribe \" + url + \", waiting for retry, cause: \" + t.getMessage(), t); &#125; &#125; // 将失败的订阅请求记录到失败列表，定时重试 addFailedSubscribed(url, listener); &#125; &#125; // $&#123;省略其它代码&#125;&#125; 该方法中向服务端发送订阅请求会交给子类处理，失败时会进入到 catch 块中的逻辑，注册中心维护的通知URL列表用在了这里，即当订阅发生异常时，会取出缓存中的通知ULR列表，调用 notify 方法进行通知。该逻辑也解释了即使注册中心宕机了，无论是消费方在注册中心宕机前启动完成还是宕机后启动，只要消费方缓存中的服务提供者可用，就可以实现服务调用。 unsubscribe123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public abstract class FailbackRegistry extends AbstractRegistry &#123; // $&#123;省略其它代码&#125; /** * 取消订阅，移除相关的缓存。真正的取消订阅由子类执行 * * @param url Subscription condition, not allowed to be empty, e.g. consumer://10.20.153.10/com.alibaba.foo.BarService?version=1.0.0&amp;application=kylin * @param listener A listener of the change event, not allowed to be empty */ @Override public void unsubscribe(URL url, NotifyListener listener) &#123; // 调用父类方法，移除url对应的listener实例 super.unsubscribe(url, listener); // 移除相关的 订阅/取消订阅失败缓存，以及失败通知缓存 removeFailedSubscribed(url, listener); try &#123; // 向服务端发送取消订阅请求,具体请求处理由子类实现 doUnsubscribe(url, listener); &#125; catch (Exception e) &#123; Throwable t = e; // If the startup detection is opened, the Exception is thrown directly. boolean check = getUrl().getParameter(Constants.CHECK_KEY, true) &amp;&amp; url.getParameter(Constants.CHECK_KEY, true); boolean skipFailback = t instanceof SkipFailbackWrapperException; if (check || skipFailback) &#123; if (skipFailback) &#123; t = t.getCause(); &#125; throw new IllegalStateException(\"Failed to unsubscribe \" + url + \" to registry \" + getUrl().getAddress() + \", cause: \" + t.getMessage(), t); &#125; else &#123; logger.error(\"Failed to unsubscribe \" + url + \", waiting for retry, cause: \" + t.getMessage(), t); &#125; // 记录取消订阅，便于重试 Set&lt;NotifyListener&gt; listeners = failedUnsubscribed.get(url); if (listeners == null) &#123; failedUnsubscribed.putIfAbsent(url, new ConcurrentHashSet&lt;NotifyListener&gt;()); listeners = failedUnsubscribed.get(url); &#125; listeners.add(listener); &#125; &#125; // $&#123;省略其它代码&#125;&#125; notify1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public abstract class FailbackRegistry extends AbstractRegistry &#123; // $&#123;省略其它代码&#125; /** * @param url 订阅URL * @param listener 监听器 * @param urls 通知的URL变化结果（全量数据）【注意：全量指的是至少要是一个分类的全量[动态类型的]，而不一定是全部数据】 */ @Override protected void notify(URL url, NotifyListener listener, List&lt;URL&gt; urls) &#123; if (url == null) &#123; throw new IllegalArgumentException(\"notify url == null\"); &#125; if (listener == null) &#123; throw new IllegalArgumentException(\"notify listener == null\"); &#125; try &#123; // 进行通知 doNotify(url, listener, urls); &#125; catch (Exception t) &#123; // 将失败的通知请求记录到失败列表中，定时重试 Map&lt;NotifyListener, List&lt;URL&gt;&gt; listeners = failedNotified.get(url); if (listeners == null) &#123; failedNotified.putIfAbsent(url, new ConcurrentHashMap&lt;NotifyListener, List&lt;URL&gt;&gt;()); listeners = failedNotified.get(url); &#125; listeners.put(listener, urls); logger.error(\"Failed to notify for subscribe \" + url + \", waiting for retry, cause: \" + t.getMessage(), t); &#125; &#125; /** * 会调用父类的通知方法 * * @param url 订阅URL * @param listener 监听器 * @param urls 订阅URL映射路径 下的子路径集合 */ protected void doNotify(URL url, NotifyListener listener, List&lt;URL&gt; urls) &#123; super.notify(url, listener, urls); &#125; // $&#123;省略其它代码&#125;&#125; FailbackRegistry 中的 notify方法 本质上还是调用 AbstractRegistry 中的 notify 方法，区别在于 FailbackRegistry 会收集失败通知请求并记录到缓存中，便于重试。 断线重连1234567891011121314151617181920212223242526272829303132333435363738public abstract class FailbackRegistry extends AbstractRegistry &#123; // $&#123;省略其它代码&#125; /** * * @throws Exception */ @Override protected void recover() throws Exception &#123; // register Set&lt;URL&gt; recoverRegistered = new HashSet&lt;URL&gt;(getRegistered()); if (!recoverRegistered.isEmpty()) &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Recover register url \" + recoverRegistered); &#125; for (URL url : recoverRegistered) &#123; failedRegistered.add(url); &#125; &#125; // subscribe Map&lt;URL, Set&lt;NotifyListener&gt;&gt; recoverSubscribed = new HashMap&lt;URL, Set&lt;NotifyListener&gt;&gt;(getSubscribed()); if (!recoverSubscribed.isEmpty()) &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Recover subscribe url \" + recoverSubscribed.keySet()); &#125; for (Map.Entry&lt;URL, Set&lt;NotifyListener&gt;&gt; entry : recoverSubscribed.entrySet()) &#123; URL url = entry.getKey(); for (NotifyListener listener : entry.getValue()) &#123; addFailedSubscribed(url, listener); &#125; &#125; &#125; &#125; // $&#123;省略其它代码&#125;&#125; FailbackRegistry 完全覆写父类方法(即不像前几个方法，会调用父类的方法)，将已注册和订阅的URL添加到 {@link #failedRegistered} ,{@link #failedSubscribed} 属性中，这样在{@link #retry()}方法中会进行重试。 重试123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156public abstract class FailbackRegistry extends AbstractRegistry &#123; // $&#123;省略其它代码&#125; protected void retry() &#123; //重新注册没有注册成功的URL集合 if (!failedRegistered.isEmpty()) &#123; Set&lt;URL&gt; failed = new HashSet&lt;URL&gt;(failedRegistered); if (failed.size() &gt; 0) &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Retry register \" + failed); &#125; try &#123; for (URL url : failed) &#123; try &#123; doRegister(url); failedRegistered.remove(url); &#125; catch (Throwable t) &#123; // Ignore all the exceptions and wait for the next retry logger.warn(\"Failed to retry register \" + failed + \", waiting for again, cause: \" + t.getMessage(), t); &#125; &#125; &#125; catch (Throwable t) &#123; // Ignore all the exceptions and wait for the next retry logger.warn(\"Failed to retry register \" + failed + \", waiting for again, cause: \" + t.getMessage(), t); &#125; &#125; &#125; // 重新取消注册没有取消注册成功的URL集合 if (!failedUnregistered.isEmpty()) &#123; Set&lt;URL&gt; failed = new HashSet&lt;URL&gt;(failedUnregistered); if (!failed.isEmpty()) &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Retry unregister \" + failed); &#125; try &#123; for (URL url : failed) &#123; try &#123; doUnregister(url); failedUnregistered.remove(url); &#125; catch (Throwable t) &#123; // Ignore all the exceptions and wait for the next retry logger.warn(\"Failed to retry unregister \" + failed + \", waiting for again, cause: \" + t.getMessage(), t); &#125; &#125; &#125; catch (Throwable t) &#123; // Ignore all the exceptions and wait for the next retry logger.warn(\"Failed to retry unregister \" + failed + \", waiting for again, cause: \" + t.getMessage(), t); &#125; &#125; &#125; /** * * 重新订阅 之前订阅失败的URL *1 把要订阅的URL映射的路径与监听器绑定 *2 创建该监听器关联的ChildListener，底层又会使用TargetChildListener去包裹ChildListener，注意，TargetChildListener的实现会有不同 *3 TargetChildListener直接监听订阅的URL映射路径的子路径，当子路径有变化，先触发TargetChildListener的方法，然后该方法会调用ChildListener的childChanged方法，接着调用监听的notify方法 * * TargetChildListener */ if (!failedSubscribed.isEmpty()) &#123; Map&lt;URL, Set&lt;NotifyListener&gt;&gt; failed = new HashMap&lt;URL, Set&lt;NotifyListener&gt;&gt;(failedSubscribed); for (Map.Entry&lt;URL, Set&lt;NotifyListener&gt;&gt; entry : new HashMap&lt;URL, Set&lt;NotifyListener&gt;&gt;(failed).entrySet()) &#123; if (entry.getValue() == null || entry.getValue().size() == 0) &#123; failed.remove(entry.getKey()); &#125; &#125; if (failed.size() &gt; 0) &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Retry subscribe \" + failed); &#125; try &#123; for (Map.Entry&lt;URL, Set&lt;NotifyListener&gt;&gt; entry : failed.entrySet()) &#123; URL url = entry.getKey(); Set&lt;NotifyListener&gt; listeners = entry.getValue(); for (NotifyListener listener : listeners) &#123; try &#123; doSubscribe(url, listener); listeners.remove(listener); &#125; catch (Throwable t) &#123; // Ignore all the exceptions and wait for the next retry logger.warn(\"Failed to retry subscribe \" + failed + \", waiting for again, cause: \" + t.getMessage(), t); &#125; &#125; &#125; &#125; catch (Throwable t) &#123; // Ignore all the exceptions and wait for the next retry logger.warn(\"Failed to retry subscribe \" + failed + \", waiting for again, cause: \" + t.getMessage(), t); &#125; &#125; &#125; // 重新移除URL映射路径下的子路径关联的监听器 if (!failedUnsubscribed.isEmpty()) &#123; Map&lt;URL, Set&lt;NotifyListener&gt;&gt; failed = new HashMap&lt;URL, Set&lt;NotifyListener&gt;&gt;(failedUnsubscribed); for (Map.Entry&lt;URL, Set&lt;NotifyListener&gt;&gt; entry : new HashMap&lt;URL, Set&lt;NotifyListener&gt;&gt;(failed).entrySet()) &#123; if (entry.getValue() == null || entry.getValue().isEmpty()) &#123; failed.remove(entry.getKey()); &#125; &#125; if (failed.size() &gt; 0) &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Retry unsubscribe \" + failed); &#125; try &#123; for (Map.Entry&lt;URL, Set&lt;NotifyListener&gt;&gt; entry : failed.entrySet()) &#123; URL url = entry.getKey(); Set&lt;NotifyListener&gt; listeners = entry.getValue(); for (NotifyListener listener : listeners) &#123; try &#123; doUnsubscribe(url, listener); listeners.remove(listener); &#125; catch (Throwable t) &#123; // Ignore all the exceptions and wait for the next retry logger.warn(\"Failed to retry unsubscribe \" + failed + \", waiting for again, cause: \" + t.getMessage(), t); &#125; &#125; &#125; &#125; catch (Throwable t) &#123; // Ignore all the exceptions and wait for the next retry logger.warn(\"Failed to retry unsubscribe \" + failed + \", waiting for again, cause: \" + t.getMessage(), t); &#125; &#125; &#125; // 重新通知【看通知的URL列表（发生改变的URL列表）和原始的URL列表对比，看是否改变，改变了就需要重新暴露服务】 if (!failedNotified.isEmpty()) &#123; Map&lt;URL, Map&lt;NotifyListener, List&lt;URL&gt;&gt;&gt; failed = new HashMap&lt;URL, Map&lt;NotifyListener, List&lt;URL&gt;&gt;&gt;(failedNotified); for (Map.Entry&lt;URL, Map&lt;NotifyListener, List&lt;URL&gt;&gt;&gt; entry : new HashMap&lt;URL, Map&lt;NotifyListener, List&lt;URL&gt;&gt;&gt;(failed).entrySet()) &#123; if (entry.getValue() == null || entry.getValue().size() == 0) &#123; failed.remove(entry.getKey()); &#125; &#125; if (failed.size() &gt; 0) &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Retry notify \" + failed); &#125; try &#123; for (Map&lt;NotifyListener, List&lt;URL&gt;&gt; values : failed.values()) &#123; for (Map.Entry&lt;NotifyListener, List&lt;URL&gt;&gt; entry : values.entrySet()) &#123; try &#123; NotifyListener listener = entry.getKey(); List&lt;URL&gt; urls = entry.getValue(); listener.notify(urls); values.remove(listener); &#125; catch (Throwable t) &#123; // Ignore all the exceptions and wait for the next retry logger.warn(\"Failed to retry notify \" + failed + \", waiting for again, cause: \" + t.getMessage(), t); &#125; &#125; &#125; &#125; catch (Throwable t) &#123; // Ignore all the exceptions and wait for the next retry logger.warn(\"Failed to retry notify \" + failed + \", waiting for again, cause: \" + t.getMessage(), t); &#125; &#125; &#125; &#125; // $&#123;省略其它代码&#125;&#125; 重试方法就是遍历缓存中五个 failedXxx属性，重试对应的操作，很清晰。 销毁12345678910111213141516171819202122public abstract class FailbackRegistry extends AbstractRegistry &#123; // $&#123;省略其它代码&#125; @Override public void destroy() &#123; // 调用父方法，取消注册和订阅 super.destroy(); try &#123; // 取消重试任务 retryFuture.cancel(true); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; // 优雅关闭线程池 ExecutorUtil.gracefulShutdown(retryExecutor, retryPeriod); &#125; // $&#123;省略其它代码&#125;&#125; 取消注册和订阅，并关闭重试任务。取消注册和订阅还是调用其父类 AbstractRegistry 的 destroy 的方法，在父类基础上增加了对任务取消操作以及关闭重试线程池。 RegistryFactory1234567891011121314151617/** * RegistryFactory. (SPI, Singleton, ThreadSafe) 注册中心工厂接口，创建的注册中心，包含注册中心客户端。注意和注册中心客户端工厂的区别。 * * @see com.alibaba.dubbo.registry.support.AbstractRegistryFactory */@SPI(\"dubbo\")public interface RegistryFactory &#123; /** * 获取注册中心 * * @param url 注册中心地址，不允许为空 * @return 注册中心引用，总不返回空 */ @Adaptive(&#123;\"protocol\"&#125;) Registry getRegistry(URL url);&#125; 注册中心工厂，它是一个 Dubbo 的扩展点，默认扩展名是 dubbo ，即默认的扩展实现是 DubboRegistryFactory ，@Adaptive 注解表示会生成适配器类并根据 URL 参数中的 protocol 参数值选择相应的实现。用于负责创建 Registry 对象，每个 Registry 实现类都有对应的 RegistryFactory 工厂实现。 AbstractRegistryFactory1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495/** * AbstractRegistryFactory. (SPI, Singleton, ThreadSafe) * * @see com.alibaba.dubbo.registry.RegistryFactory */public abstract class AbstractRegistryFactory implements RegistryFactory &#123; // Log output private static final Logger LOGGER = LoggerFactory.getLogger(AbstractRegistryFactory.class); /** * LOCK 锁，用于 #destroyAll() 和 #getRegistry(url) 方法，处理对 REGISTRIES 属性访问的竞争。 */ private static final ReentrantLock LOCK = new ReentrantLock(); /** * Registry 集合 */ private static final Map&lt;String, Registry&gt; REGISTRIES = new ConcurrentHashMap&lt;String, Registry&gt;(); /** * Get all registries * * @return all registries */ public static Collection&lt;Registry&gt; getRegistries() &#123; return Collections.unmodifiableCollection(REGISTRIES.values()); &#125; /** * 销毁所有的Registry对象 */ public static void destroyAll() &#123; if (LOGGER.isInfoEnabled()) &#123; LOGGER.info(\"Close all registries \" + getRegistries()); &#125; // 获得锁 // Lock up the registry shutdown process LOCK.lock(); try &#123; // 循环调用 destroy() 方法 for (Registry registry : getRegistries()) &#123; try &#123; // AbstractRegistry 实现了公用的销毁逻辑，取消注册和订阅 registry.destroy(); &#125; catch (Throwable e) &#123; LOGGER.error(e.getMessage(), e); &#125; &#125; // 清空缓存 REGISTRIES.clear(); &#125; finally &#123; // Release the lock LOCK.unlock(); &#125; &#125; @Override public Registry getRegistry(URL url) &#123; url = url.setPath(RegistryService.class.getName()) // 将 RegistryService 的类名设置为 URL 的 path 值 .addParameter(Constants.INTERFACE_KEY, RegistryService.class.getName()) // 将 RegistryService 的类名设置为 URL 的interface 值，该属性在后来的订阅通知很有用 .removeParameters(Constants.EXPORT_KEY, Constants.REFER_KEY); // 规范 URL 操作，及删除 export 和 refer 参数 String key = url.toServiceString(); // Lock the registry access process to ensure a single instance of the registry LOCK.lock(); try &#123; // 访问缓存 Registry registry = REGISTRIES.get(key); if (registry != null) &#123; return registry; &#125; // 缓存未命中，创建Registry 实例，交给具体子类实现 registry = createRegistry(url); if (registry == null) &#123; throw new IllegalStateException(\"Can not create registry \" + url); &#125; // 写入缓存 REGISTRIES.put(key, registry); return registry; &#125; finally &#123; // Release the lock LOCK.unlock(); &#125; &#125; /** * 创建注册中心的模版方法，由具体子类实现，过程包括： * 1 创建注册中心客户端 * 2 启动客户端 * * @param url 注册中心地址 * @return Registry 对象 */ protected abstract Registry createRegistry(URL url);&#125; 实现 RegistryFactory 接口，是RegistryFactory 抽象类，主要两个工作，将获取的注册中心放入到缓存和实现了公用的销毁逻辑，取消注册和订阅。 NotifyListener1234567891011121314/** * NotifyListener. (API, Prototype, ThreadSafe) 通知监听器 * * @see com.alibaba.dubbo.registry.RegistryService#subscribe(URL, NotifyListener) */public interface NotifyListener &#123; /** * 当收到订阅URL对应的数据发生变化，通知触发 * * @param urls 已注册信息列表，总不为空 */ void notify(List&lt;URL&gt; urls);&#125; 该接口的实现类主要分为两大类，RegistryDirectory 和 匿名类内部类，具体的作用在订阅通知章节说明。 小结本章主要介绍了注册的抽象层，接下来的文章会分析 Zookeeper 和 Redis 的实现，其他两种不做分析。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"Dubbo源码分析 - 服务容器","slug":"rpc/服务容器","date":"2020-04-09T16:00:00.000Z","updated":"2020-09-04T07:39:03.454Z","comments":false,"path":"posts/714ea63d/","link":"","permalink":"https://gentryhuang.com/posts/714ea63d/","excerpt":"","text":"前言前面的 Dubbo SPI、Dubbo配置等文章描述的几乎都只是服务暴露、服务引用、服务调用之前的准备工作，有了这些准备工作后，下面介绍Dubbo的服务容器，通过Dubbo服务容器可以非常方便启动一个Dubbo服务。 Dubbo服务容器Dubbo的服务容器只是一个简单的Main，类似SpringBoot,负责初始化和启动不同功能的 Container ，如果说dubbo的服务容器是一个简单的Main方法，那么承载不同功能的Container就是服务容器的具体实现，可以有不同的类型。uml关系图如下： 容器扩展点123456789101112131415161718/** * Container. (SPI, Singleton, ThreadSafe) * * 服务容器接口，Dubbo的扩展点，默认为 spring */@SPI(\"spring\")public interface Container &#123; /** * start. 启动容器 */ void start(); /** * stop. 体制容器 */ void stop();&#125; 启动器Main123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106public class Main &#123; private static final Logger logger = LoggerFactory.getLogger(Main.class); /** * Container的配置项，如 dubbo.container=spring,log4j */ public static final String CONTAINER_KEY = \"dubbo.container\"; /** * Dubbo 优雅停机配置项，如 dubbo.shutdown.hook=true */ public static final String SHUTDOWN_HOOK_KEY = \"dubbo.shutdown.hook\"; /** * Container扩展点的加载器 */ private static final ExtensionLoader&lt;Container&gt; loader = ExtensionLoader.getExtensionLoader(Container.class); /** * 锁 */ private static final ReentrantLock LOCK = new ReentrantLock(); /** * 锁的条件 */ private static final Condition STOP = LOCK.newCondition(); /** * @param args 启动参数，可以在启动时指定要加载的容器，如 java com.alibaba.dubbo.container.Main spring log4j */ public static void main(String[] args) &#123; try &#123; // 如果 main 方法的参数没有传入值，则从配置中加载。如果获取不到就使用Container 默认扩展 spring if (args == null || args.length == 0) &#123; String config = ConfigUtils.getProperty(CONTAINER_KEY, loader.getDefaultExtensionName()); args = Constants.COMMA_SPLIT_PATTERN.split(config); &#125; final List&lt;Container&gt; containers = new ArrayList&lt;Container&gt;(); for (int i = 0; i &lt; args.length; i++) &#123; // 使用Dubbo SPI 加载 Container ,并把加载的Container 放入到List中 containers.add(loader.getExtension(args[i])); &#125; logger.info(\"Use container type(\" + Arrays.toString(args) + \") to run dubbo serivce.\"); // 当配置JVM启动参数带有 -Ddubbo.shutdown.hook=true时，添加关闭的ShutdownHook if (\"true\".equals(System.getProperty(SHUTDOWN_HOOK_KEY))) &#123; // 优雅停机 Runtime.getRuntime().addShutdownHook(new Thread(\"dubbo-container-shutdown-hook\") &#123; @Override public void run() &#123; for (Container container : containers) &#123; try &#123; // 关闭容器 container.stop(); logger.info(\"Dubbo \" + container.getClass().getSimpleName() + \" stopped!\"); &#125; catch (Throwable t) &#123; logger.error(t.getMessage(), t); &#125; try &#123; // 获得 ReentrantLock LOCK.lock(); // 唤醒 Main 主线程的等待 STOP.signal(); &#125; finally &#123; // 释放 LOCK LOCK.unlock(); &#125; &#125; &#125; &#125;); &#125; // 启动容器 for (Container container : containers) &#123; container.start(); logger.info(\"Dubbo \" + container.getClass().getSimpleName() + \" started!\"); &#125; System.out.println(new SimpleDateFormat(\"[yyyy-MM-dd HH:mm:ss]\").format(new Date()) + \" Dubbo service server started!\"); // 发生异常，打印错误日志，并JVM退出 &#125; catch (RuntimeException e) &#123; e.printStackTrace(); logger.error(e.getMessage(), e); System.exit(1); &#125; try &#123; // 获得 LOCK 锁 LOCK.lock(); /** * 释放锁，进入等待，直到被唤醒 * 作用：线程不结束，不触发JVM退出，这样Dubbo就不会退出。如果不等待，main方法执行完成，就会触发JVM退出，导致Dubbo服务退出 */ STOP.await(); &#125; catch (InterruptedException e) &#123; logger.warn(\"Dubbo service server stopped, interrupted by other thread!\", e); &#125; finally &#123; // 释放 LOCK LOCK.unlock(); &#125; &#125;&#125; 说明 dubbo服务容器只是一个简单Main 方法，默认情况下只会加载一个简单的Spring容器，用于暴露服务。Dubbo服务容器的加载内容可以扩展，即可通过容器扩展点进行扩展，如：spring、logback等。 dubbo服务容器是dubbo服务的启动器，它的本质是启动时加载dubbo的相关内容【通过spring配置，log4j配置等体现】然后启动Container。但是 实际生产中，一般不会直接使用dubbo的服务容器，更多主流的是使用Spring或者SpringBoot SpringContainer123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/** * SpringContainer. (SPI, Singleton, ThreadSafe) * 实现Container接口，Spring容器实现类 */public class SpringContainer implements Container &#123; private static final Logger logger = LoggerFactory.getLogger(SpringContainer.class); /** * Spring 配置属性 */ public static final String SPRING_CONFIG = \"dubbo.spring.config\"; /** * 默认配置文件地址 */ public static final String DEFAULT_SPRING_CONFIG = \"classpath*:META-INF/spring/*.xml\"; /** * Spring 上下文 ，静态属性，全局唯一 */ static ClassPathXmlApplicationContext context; public static ClassPathXmlApplicationContext getContext() &#123; return context; &#125; @Override public void start() &#123; // 获得Spring 配置文件的地址【先优先从JVM参数中取，没有再从dubbo.properties文件中取】 String configPath = ConfigUtils.getProperty(SPRING_CONFIG); // 如果没有配置就使用默认路径下的配置文件 if (configPath == null || configPath.length() == 0) &#123; configPath = DEFAULT_SPRING_CONFIG; &#125; // 创建Spring 上下文 context = new ClassPathXmlApplicationContext(configPath.split(\"[,\\\\s]+\"), false); // 添加监听器 [dubbo服务暴露、服务销毁以及优雅停机的关键] context.addApplicationListener(new DubboApplicationListener()); // 监听容器关闭 [注册优雅停机钩子] context.registerShutdownHook(); // 刷新Spring容器 context.refresh(); // 启动Spring容器，加载Dubbo的配置，从而启动Dubbo 服务 context.start(); &#125; @Override public void stop() &#123; try &#123; if (context != null) &#123; // 停止上下文，会触发 ContextStoppedEvent 事件 context.stop(); // 关闭上下文，会触发 ContextClosedEvent 事件 context.close(); // 置空，便于被回收 context = null; &#125; &#125; catch (Throwable e) &#123; logger.error(e.getMessage(), e); &#125; &#125;&#125; 说明 DubboApplicationListener实现了ApplicationListener接口，用于监听Spring容器的起停，在启动和销毁的时候分别执行服务暴露和取消服务暴露以及执行优雅停机 创建DubboApplicationListener对象的时候，都会创建DubboBootstrap对象，该对象主要完成服务暴露、取消服务暴露、注册与移除jdk shutdownhook 在创建DubboBootstrap对象时，会为该类注入DubboShutdownHook对象，该对象继承了Thread，将释放资源的方法作为任务体，该对象是真正要注册到系统中的钩子，当JVM退出时该钩子会回调它的任务体 关系图如下 DubboApplicationListener1234567891011121314151617181920212223242526272829303132333435/** * An application listener that listens the ContextClosedEvent. * Upon the event, this listener will do the necessary clean up to avoid memory leak. */public class DubboApplicationListener implements ApplicationListener&lt;ApplicationEvent&gt; &#123; /** * Dubbo引导程序 */ private DubboBootstrap dubboBootstrap; public DubboApplicationListener() &#123; // 创建DubboBootstrap dubboBootstrap = new DubboBootstrap(false); &#125; public DubboApplicationListener(DubboBootstrap dubboBootstrap) &#123; this.dubboBootstrap = dubboBootstrap; &#125; /** * 监听spring事件 * @param applicationEvent */ @Override public void onApplicationEvent(ApplicationEvent applicationEvent) &#123; // spring容器刷新完成 if (applicationEvent instanceof ContextRefreshedEvent) &#123; dubboBootstrap.start(); // spring容器销毁 &#125; else if (applicationEvent instanceof ContextClosedEvent) &#123; dubboBootstrap.stop(); &#125; &#125;&#125; DubboBootstrap123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103/** * A bootstrap class to easily start and stop Dubbo via programmatic API. * The bootstrap class will be responsible to cleanup the resources during stop. */public class DubboBootstrap &#123; /** * 服务配置对象列表 */ private List&lt;ServiceConfig&gt; serviceConfigList; /** * 启动期间是否注册 钩子 */ private final boolean registerShutdownHookOnStart; /** * 在嵌入式环境下[Main方法]运行Dubbo时使用的 钩子 */ private DubboShutdownHook shutdownHook; public DubboBootstrap() &#123; // 获取DubboShutdownHook，并注入到该类中 this(true, DubboShutdownHook.getDubboShutdownHook()); &#125; public DubboBootstrap(boolean registerShutdownHookOnStart) &#123; // 获取DubboShutdownHook，并注入到该类中 this(registerShutdownHookOnStart, DubboShutdownHook.getDubboShutdownHook()); &#125; public DubboBootstrap(boolean registerShutdownHookOnStart, DubboShutdownHook shutdownHook) &#123; this.serviceConfigList = new ArrayList&lt;ServiceConfig&gt;(); this.shutdownHook = shutdownHook; this.registerShutdownHookOnStart = registerShutdownHookOnStart; &#125; /** * Register service config to bootstrap, which will be called during &#123;@link DubboBootstrap#stop()&#125; * @param serviceConfig the service * @return the bootstrap instance */ public DubboBootstrap registerServiceConfig(ServiceConfig serviceConfig) &#123; serviceConfigList.add(serviceConfig); return this; &#125; /** * dubbo引导程序 - start * 1 是否注册shutdown hook * 2 服务暴露 */ public void start() &#123; // 启动期间是否注册过shutdown hook if (registerShutdownHookOnStart) &#123; registerShutdownHook(); &#125; else &#123; // 如果DubboShutdown hook 已经注册到系统中，需要移除掉 removeShutdownHook(); &#125; // 循环服务配置对象，依次进行服务暴露 for (ServiceConfig serviceConfig: serviceConfigList) &#123; serviceConfig.export(); &#125; &#125; /** * dubbo引导程序 - stop * 1 取消服务暴露 * 2 */ public void stop() &#123; for (ServiceConfig serviceConfig: serviceConfigList) &#123; serviceConfig.unexport(); &#125; // 执行 shutdown hook 释放资源 shutdownHook.destroyAll(); // 如果启动期已经注册过，则从系统中移除 todo ??? 为什么还要注册到系统，直接根据spring销毁事件然后执行释放任务不就可以了吗？ if (registerShutdownHookOnStart) &#123; removeShutdownHook(); &#125; &#125; /** * 注册 shutdown hook */ public void registerShutdownHook() &#123; Runtime.getRuntime().addShutdownHook(shutdownHook); &#125; /** * 移除 shutdown hook */ public void removeShutdownHook() &#123; try &#123; Runtime.getRuntime().removeShutdownHook(shutdownHook); &#125; catch (IllegalStateException ex) &#123; // ignore - VM is already shutting down &#125; &#125;&#125; DubboShutdownHook123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778/** * The shutdown hook thread to do the clean up stuff. * This is a singleton in order to ensure there is only one shutdown hook registered. * Because &#123;@link ApplicationShutdownHooks&#125; use &#123;@link java.util.IdentityHashMap&#125; * to store the shutdown hooks. */public class DubboShutdownHook extends Thread &#123; private static final Logger logger = LoggerFactory.getLogger(DubboShutdownHook.class); /** * ShutdownHook,类属性 */ private static final DubboShutdownHook dubboShutdownHook = new DubboShutdownHook(\"DubboShutdownHook\"); public static DubboShutdownHook getDubboShutdownHook() &#123; return dubboShutdownHook; &#125; /** * Has it already been destroyed or not? * &lt;p&gt; * 是否已经被销毁标识 */ private final AtomicBoolean destroyed; private DubboShutdownHook(String name) &#123; super(name); this.destroyed = new AtomicBoolean(false); &#125; /** * ShutdownHook的任务体 */ @Override public void run() &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Run shutdown hook now.\"); &#125; destroyAll(); &#125; /** * Destroy all the resources, including registries and protocols. * &lt;p&gt; * 销毁所有的资源，包括 Registry相关 和 Protocol相关 */ public void destroyAll() &#123; //如果已经销毁则忽略 if (!destroyed.compareAndSet(false, true)) &#123; return; &#125; // 销毁所有的 Registry,取消应用程序中的服务提供者和消费者的订阅与注册 AbstractRegistryFactory.destroyAll(); /** * 销毁所有的 Protocol * * 说明： * 这里的Protocol比较多，大体上可以分两类： * 1 和Registry相关的Protocol，RegistryProtocol关注服务的注册 * 2 具体协议，如 DubboProtocol、httpProtocol等,关注服务的暴露和引用 */ ExtensionLoader&lt;Protocol&gt; loader = ExtensionLoader.getExtensionLoader(Protocol.class); for (String protocolName : loader.getLoadedExtensions()) &#123; try &#123; Protocol protocol = loader.getLoadedExtension(protocolName); if (protocol != null) &#123; protocol.destroy(); &#125; &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; &#125; &#125;&#125; LogbackContainer123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596/** * LogbackContainer. (SPI, Singleton, ThreadSafe) * 实现 Container 接口，Logback 容器实现类 */public class LogbackContainer implements Container &#123; /** * 日志文件路径 */ public static final String LOGBACK_FILE = \"dubbo.logback.file\"; /** * 日志文件级别 */ public static final String LOGBACK_LEVEL = \"dubbo.logback.level\"; /** * 日志保留天数 */ public static final String LOGBACK_MAX_HISTORY = \"dubbo.logback.maxhistory\"; /** * 默认日志级别 */ public static final String DEFAULT_LOGBACK_LEVEL = \"ERROR\"; @Override public void start() &#123; // 获得 logback 配置的日志文件路径 String file = ConfigUtils.getProperty(LOGBACK_FILE); if (file != null &amp;&amp; file.length() &gt; 0) &#123; // 获得日志级别 String level = ConfigUtils.getProperty(LOGBACK_LEVEL); if (level == null || level.length() == 0) &#123; level = DEFAULT_LOGBACK_LEVEL; &#125; // 获得日志保留天数，如果是0则永久保留 int maxHistory = StringUtils.parseInteger(ConfigUtils.getProperty(LOGBACK_MAX_HISTORY)); // 初始化 logback doInitializer(file, level, maxHistory); &#125; &#125; /** * 停止为空，因为不需要关闭 */ @Override public void stop() &#123; &#125; /** * 初始化 logback * * @param file 日志文件路径 * @param level 日志级别 * @param maxHistory 日志保留天数 */ private void doInitializer(String file, String level, int maxHistory) &#123; // 获取日志工厂 LoggerContext loggerContext = (LoggerContext) LoggerFactory.getILoggerFactory(); // 通过工厂获取Logger Logger rootLogger = loggerContext.getLogger(Logger.ROOT_LOGGER_NAME); rootLogger.detachAndStopAllAppenders(); // 创建日志追加器 RollingFileAppender&lt;ILoggingEvent&gt; fileAppender = new RollingFileAppender&lt;ILoggingEvent&gt;(); fileAppender.setContext(loggerContext); fileAppender.setName(\"application\"); fileAppender.setFile(file); fileAppender.setAppend(true); // 创建滚动策略 TimeBasedRollingPolicy&lt;ILoggingEvent&gt; policy = new TimeBasedRollingPolicy&lt;ILoggingEvent&gt;(); policy.setContext(loggerContext); policy.setMaxHistory(maxHistory); policy.setFileNamePattern(file + \".%d&#123;yyyy-MM-dd&#125;\"); policy.setParent(fileAppender); policy.start(); fileAppender.setRollingPolicy(policy); // 格式 PatternLayoutEncoder encoder = new PatternLayoutEncoder(); encoder.setContext(loggerContext); encoder.setPattern(\"%date [%thread] %-5level %logger (%file:%line\\\\) - %msg%n\"); encoder.start(); fileAppender.setEncoder(encoder); fileAppender.start(); rootLogger.addAppender(fileAppender); rootLogger.setLevel(Level.toLevel(level)); rootLogger.setAdditive(false); &#125;&#125; Log4jContainer123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899/** * Log4jContainer. (SPI, Singleton, ThreadSafe) * 实现Container接口，Log4j容器实现类 */public class Log4jContainer implements Container &#123; /** * 日志文件路径配置，如 dubbo.log4j.file=/opt/log/access.log */ public static final String LOG4J_FILE = \"dubbo.log4j.file\"; /** * 日志级别 如： dubbo.log4j.level=WARN */ public static final String LOG4J_LEVEL = \"dubbo.log4j.level\"; /** * 日志子路径配置 */ public static final String LOG4J_SUBDIRECTORY = \"dubbo.log4j.subdirectory\"; /** * 默认日志级别 */ public static final String DEFAULT_LOG4J_LEVEL = \"ERROR\"; /** * 自动配置log4j */ @Override @SuppressWarnings(\"unchecked\") public void start() &#123; // 获得 log4j 配置的日志文件路径 String file = ConfigUtils.getProperty(LOG4J_FILE); // 获取日志级别 if (file != null &amp;&amp; file.length() &gt; 0) &#123; String level = ConfigUtils.getProperty(LOG4J_LEVEL); if (level == null || level.length() == 0) &#123; level = DEFAULT_LOG4J_LEVEL; &#125; // 创建PropertyConfigurator所需的 Properties 对象， Properties properties = new Properties(); properties.setProperty(\"log4j.rootLogger\", level + \",application\"); properties.setProperty(\"log4j.appender.application\", \"org.apache.log4j.DailyRollingFileAppender\"); properties.setProperty(\"log4j.appender.application.File\", file); properties.setProperty(\"log4j.appender.application.Append\", \"true\"); properties.setProperty(\"log4j.appender.application.DatePattern\", \"'.'yyyy-MM-dd\"); properties.setProperty(\"log4j.appender.application.layout\", \"org.apache.log4j.PatternLayout\"); properties.setProperty(\"log4j.appender.application.layout.ConversionPattern\", \"%d [%t] %-5p %C&#123;6&#125; (%F:%L) - %m%n\"); PropertyConfigurator.configure(properties); &#125; // 获得日志子目录，用于多进程启动时，避免冲突 String subdirectory = ConfigUtils.getProperty(LOG4J_SUBDIRECTORY); if (subdirectory != null &amp;&amp; subdirectory.length() &gt; 0) &#123; // 获取 Logger 列表 Enumeration&lt;org.apache.log4j.Logger&gt; ls = LogManager.getCurrentLoggers(); while (ls.hasMoreElements()) &#123; org.apache.log4j.Logger l = ls.nextElement(); if (l != null) &#123; // 拿到当前Logger 的追加器 Enumeration&lt;Appender&gt; as = l.getAllAppenders(); while (as.hasMoreElements()) &#123; Appender a = as.nextElement(); if (a instanceof FileAppender) &#123; FileAppender fa = (FileAppender) a; String f = fa.getFile(); if (f != null &amp;&amp; f.length() &gt; 0) &#123; int i = f.replace('\\\\', '/').lastIndexOf('/'); String path; if (i == -1) &#123; path = subdirectory; &#125; else &#123; path = f.substring(0, i); if (!path.endsWith(subdirectory)) &#123; path = path + \"/\" + subdirectory; &#125; f = f.substring(i + 1); &#125; // 设置新的文件名 fa.setFile(path + \"/\" + f); // 生效配置 fa.activateOptions(); &#125; &#125; &#125; &#125; &#125; &#125; &#125; /** * 空方法，无需关闭 */ @Override public void stop() &#123; &#125;&#125; 容器启动 通过加载properties配置文件加载目标容器 1dubbo.container&#x3D;spring,logback,log4j 缺省只加载spring容器 1java org.apache.dubbo.container.Main 通过main方法参数传入要加载的容器 1java org.apache.dubbo.container.Main spring logback log4j 通过 JVM 启动参数传入要加载的容器 1java org.apache.dubbo.container.Main -Ddubbo.container&#x3D;spring,jetty,log4j 小结虽然实际生产中一般不会直接使用dubbo的服务容器，但是它的实现机制我们可以学习下。了解了Dubbo服务容器后，我们从源码层面上重新认识了Dubbo的启停流程，从下一篇文章开始正式进入到Dubbo的核心模块源码分析阶段。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"Spring","slug":"Spring","permalink":"https://gentryhuang.com/tags/Spring/"}]},{"title":"Dubbo源码分析 - 注解配置","slug":"rpc/注解配置","date":"2020-04-01T16:00:00.000Z","updated":"2020-09-04T07:15:55.737Z","comments":false,"path":"posts/1a889dcd/","link":"","permalink":"https://gentryhuang.com/posts/1a889dcd/","excerpt":"","text":"前言在 Dubbo源码分析 - XML配置 中，详细介绍了Dubbo的XML配置方式，本篇文章介绍Dubbo注解配置方式，使用示例见 Dubbo示例 - 注解配置。 示例说明1234567891011121314151617181920212223242526272829/** * AnnotationProvider * * Java Config + 注解的方式 */public class AnnotationProvider &#123; public static void main(String[] args) throws Exception &#123; AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(ProviderConfiguration.class); context.start(); System.in.read(); &#125; @Configuration @EnableDubbo(scanBasePackages = \"com.alibaba.dubbo.examples.annotation.impl\") @PropertySource(\"classpath:/com/alibaba/dubbo/examples/annotation/dubbo-provider.properties\") static public class ProviderConfiguration &#123; /** * 这里通过Java Config显示组装Bean，会注入给Dubbo服务，即标注有@Service的类。如果不显示装配，Dubbo会默认创建内置的配置类定义，创建内置的配置类定义的前提是配置了相关的属性，否则不会创建。其他配置类似。 */ @Bean public ProviderConfig providerConfig() &#123; ProviderConfig providerConfig = new ProviderConfig(); providerConfig.setTimeout(5000); return providerConfig; &#125; &#125;&#125; 这里使用 Dubbo示例 - 注解配置 中的提供者配置进行说明。当Spring启动后，会先获取配置类上的 @PropertySource 注解，把外部配置进行解析然后放入Spring环境中，为之后流程中的Dubbo配置类的对象进行属性赋值。Spring会递归获取配置类的 @Import 注解，即搜集配置相关的所有@Import注解，以获取使用该注解引入的Selector或Registrar类，这些类是用来给Spring容器导入组件的。Dubbo的注解实现包括两大部分，一个是外部化配置，另一个是注解驱动，它们的能力是由Selector或Registrar类导入所需组件实现的，笔者调试这块花了很多时间，细节点还是挺多的，由于这些都是Spring源码的知识点就不进行分析了。 注解配置代码结构 在 Dubbo 2.5.7之前的版本 ，Dubbo 提供了两个核心注解 @Service 以及 @Reference，分别用于Dubbo 服务提供和 Dubbo 服务引用。@Service 作为 XML配置&lt;dubbo:service&gt;的替代，与 Spring Framework @Service 类似，用于服务暴露。@Reference 则是替代&lt;dubbo:reference &gt; ，类似于 Spring 中的 @Autowired，引用服务。但2.5.7之前Dubbo注解是基于AnnotationBean实现的，主要存在以下几个问题： 注解支持不充分，需要XML配置&lt;dubbo:annotation&gt; @Service 不支持Spring AOP @Reference 不支持字段继承性 基于原来实现思路的基础上无法解决历史遗留问题，从2.5.7开始Dubbo的注解实现已经完全重写，AnnotationBean已经被废弃。 设计原则Spring Framework 3.1 引入了 @ComponentScan 完全替代了 XML 元素 &lt;context:component-scan&gt; 。同样地， @DubboComponentScan 作为 Dubbo 2.5.7 新增的 Annotation，也是XML 元素 &lt;dubbo:annotation&gt; 的替代方案，与注解驱动相关。 @DubboComponentScan 相对比较繁重，原因在于处理Dubbo @Service 标注的类暴露Dubbo服务外，还要支持Spring Bean的 @Reference 字段或方法注入Dubbo服务代理，即 @DubboComponentScan 除了扫描 Dubbo @Service 组件以外，还需要处理 @Reference注入。需要注意的是，如果 @Reference 字段或方法所在的类不是 Spring Bean 的话， @DubboComponentScan 不会处理 @Reference 注入，其原理与 Spring @Autowired 一致。@EnableDubboConfig 用于支持Dubbo的外部化配置，常用于显示指定Dubbo的配置。需要注意的是Dubbo框架中的dubbo.properties从某种意义上来说是特殊的Dubbo的外部化配置，框架默认情况下会加载类路径下的该配置文件，详细参见 属性配置。 注解介绍@Service 注解@Service 用来配置Dubbo的服务提供方，通过 @Service 上提供的属性，可以进一步的定制化 Dubbo 的服务提供者。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@Documented@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.TYPE&#125;)@Inheritedpublic @interface Service &#123; Class&lt;?&gt; interfaceClass() default void.class; String interfaceName() default \"\"; String version() default \"\"; String group() default \"\"; String path() default \"\"; boolean export() default false; String token() default \"\"; boolean deprecated() default false; boolean dynamic() default false; String accesslog() default \"\"; int executes() default 0; boolean register() default true; int weight() default 0; String document() default \"\"; int delay() default 0; String local() default \"\"; String stub() default \"\"; String cluster() default \"\"; String proxy() default \"\"; int connections() default 0; int callbacks() default 0; String onconnect() default \"\"; String ondisconnect() default \"\"; String owner() default \"\"; String layer() default \"\"; int retries() default 0; String loadbalance() default \"\"; boolean async() default false; int actives() default 0; boolean sent() default false; String mock() default \"\"; String validation() default \"\"; int timeout() default 0; String cache() default \"\"; String[] filter() default &#123;&#125;; String[] listener() default &#123;&#125;; String[] parameters() default &#123;&#125;; String application() default \"\"; String module() default \"\"; String provider() default \"\"; String[] protocol() default &#123;&#125;; String monitor() default \"\"; String[] registry() default &#123;&#125;;&#125; @Service定义在一个类上，表示一个服务的具体实现，比较重要的属性： interfaceClass：指定服务提供方实现的 interface 的类 interfaceName：指定服务提供方实现的 interface 的类名 version：指定服务的版本号 group：指定服务的分组 export：是否暴露服务 registry：是否向注册中心注册服务 application：应用配置 module：模块配置 provider：服务提供方配置 protocol：协议配置 monitor：监控中心配置 registry：注册中心配置 其中，application、module、provider、protocol、monitor、registry属性需要提供的是对应的Spring Bean的名字，Bean组装方式可以通过XML配置，也可以通过Java Config配置。 @Reference 注解@Reference 用来配置Dubbo的服务消费方，通过 @Reference 上提供的属性，可以进一步的定制化 Dubbo 的服务消费方。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * Reference * * @export */@Documented@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.FIELD, ElementType.METHOD, ElementType.ANNOTATION_TYPE&#125;)public @interface Reference &#123; Class&lt;?&gt; interfaceClass() default void.class; String interfaceName() default \"\"; String version() default \"\"; String group() default \"\"; String url() default \"\"; String client() default \"\"; boolean generic() default false; boolean injvm() default false; boolean check() default true; boolean init() default false; boolean lazy() default false; boolean stubevent() default false; String reconnect() default \"\"; boolean sticky() default false; String proxy() default \"\"; String stub() default \"\"; String cluster() default \"\"; int connections() default 0; int callbacks() default 0; String onconnect() default \"\"; String ondisconnect() default \"\"; String owner() default \"\"; String layer() default \"\"; int retries() default 2; String loadbalance() default \"\"; boolean async() default false; int actives() default 0; boolean sent() default false; String mock() default \"\"; String validation() default \"\"; int timeout() default 0; String cache() default \"\"; String[] filter() default &#123;&#125;; String[] listener() default &#123;&#125;; String[] parameters() default &#123;&#125;; String application() default \"\"; String module() default \"\"; String consumer() default \"\"; String monitor() default \"\"; String[] registry() default &#123;&#125;;&#125; @Reference 可以定义在类中的一个字段上，也可以定义在一个方法上，甚至可以用来修饰另一个 annotation，表示一个服务引用。一般多把@Reference 定义在一个字段上，该注解有以下重要属性： interfaceClass：指定服务的 interface 的类 interfaceName：指定服务的 interface 的类名 version：指定服务的版本号 group：指定服务的分组 url：通过指定服务提供方的 URL 地址直接绕过注册中心发起调用 application：应用配置 module：模块配置 consumer：服务消费方配置 protocol：协议配置 monitor：监控中心配置 registry：注册中心配置 其中，application、module、consumer、protocol、monitor、registry属性需要提供的是对应的Spring Bean的名字，Bean组装方式可以通过XML配置，也可以通过Java Config配置。 @EnableDubbo 注解@EnableDubbo 注解是 @EnableDubboConfig 和 @DubboComponentScan 两者组合的便捷表达方式。与注解驱动相关的是 @DubboComponentScan，与外部化配置相关的是 @EnableDubboConfig 。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Inherited@Documented@EnableDubboConfig // 开启Dubbo Config 【DubboConfig对象的创建和DubboConfig中的属性设置】@DubboComponentScan // 扫描Dubbo 的@Service 和 @Reference 注解的包或者类，从而创建Bean对象public @interface EnableDubbo &#123; /** * * 配置@DubboComponentScan 注解 扫描的包 * * Base packages to scan for annotated @Service classes. * &lt;p&gt; * Use &#123;@link #scanBasePackageClasses()&#125; for a type-safe alternative to String-based * package names. * * @return the base packages to scan * @see DubboComponentScan#basePackages() */ @AliasFor(annotation = DubboComponentScan.class, attribute = \"basePackages\") String[] scanBasePackages() default &#123;&#125;; /** * * 配置 @DubboComponentScan 注解 扫描的类 * * Type-safe alternative to &#123;@link #scanBasePackages()&#125; for specifying the packages to * scan for annotated @Service classes. The package of each class specified will be * scanned. * * @return classes from the base packages to scan * @see DubboComponentScan#basePackageClasses */ @AliasFor(annotation = DubboComponentScan.class, attribute = \"basePackageClasses\") Class&lt;?&gt;[] scanBasePackageClasses() default &#123;&#125;; /** * 配置 @EnableDubboConfig 注解，是否将配置属性绑定到多个Spring Bean 上 * * It indicates whether &#123;@link AbstractConfig&#125; binding to multiple Spring Beans. * * @return the default value is &lt;code&gt;false&lt;/code&gt; * @see EnableDubboConfig#multiple() */ @AliasFor(annotation = EnableDubboConfig.class, attribute = \"multiple\") boolean multipleConfig() default false;&#125; @EnableDubbo 可以通过 scanBasePackages属性 指定要扫描的包，通过 scanBasePackageClasses属性 指定要扫描的类[最后还是会转为扫描包的方式]，进而扫描Dubbo 的服务提供者（以 @Service 标注）以及 Dubbo 的服务消费者（以 Reference 标注）。扫描到 Dubbo 的服务提供方和消费者之后，对其做相应的组装并初始化，并最终完成服务暴露或者引用的工作。如果不使用外部化配置的话，也可以直接使用 @DubboComponentScan。 @EnableDubboConfig 注解该注解用于开启Dubbo配置，支持外部化配置。 1234567891011121314151617181920212223242526272829/** * As a convenient and multiple &#123;@link EnableDubboConfigBinding&#125; * * @see EnableDubboConfigBinding * @see DubboConfigConfiguration * @see DubboConfigConfigurationSelector * @since 2.5.8 * * 开启Dubbo配置 * */@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Inherited@Documented@Import(DubboConfigConfigurationSelector.class) public @interface EnableDubboConfig &#123; /** * 配置是否绑定到多个Spring Bean上，即表示是否支持多Dubbo配置Bean的绑定，默认值为false，即单Dubbo 配置Bean的绑定。 * * It indicates whether binding to multiple Spring Beans. * * @return the default value is &lt;code&gt;false&lt;/code&gt; * @revised 2.5.9 */ boolean multiple() default false;&#125; 该注解有一个核心的属性，multiple 属性用于支持多Dubbo配置Bean的数据绑定。@Import 的value属性值 DubboConfigConfigurationSelector 用于给Spring容器导入组件，导入的组件是 DubboConfigConfiguration.Single 或 DubboConfigConfiguration.Multiple，具体导入哪个组件取决于 multiple 的值。 DubboConfigConfigurationSelector1234567891011121314151617181920212223242526272829303132public class DubboConfigConfigurationSelector implements ImportSelector, Ordered &#123; /** * @param importingClassMetadata @Import(DubboConfigConfigurationSelector.class) 所标注的注解信息 * @return */ @Override public String[] selectImports(AnnotationMetadata importingClassMetadata) &#123; // 获得 @EnableDubboConfig注解的属性 AnnotationAttributes attributes = AnnotationAttributes.fromMap( importingClassMetadata.getAnnotationAttributes(EnableDubboConfig.class.getName())); //获得multiple属性 boolean multiple = attributes.getBoolean(\"multiple\"); // 如果为true，则注册 DubboConfigConfiguration.Multiple Bean对象 if (multiple) &#123; return of(DubboConfigConfiguration.Multiple.class.getName()); &#125; else &#123; // 如果为false，则注册 DubboConfigConfiguration.Single Bean对象 return of(DubboConfigConfiguration.Single.class.getName()); &#125; &#125; private static &lt;T&gt; T[] of(T... values) &#123; return values; &#125; @Override public int getOrder() &#123; return HIGHEST_PRECEDENCE; &#125;&#125; 该类实现了Spring的ImportSelector接口，功能如下： 利用ImportSelector要导入哪些组件，只需要返回要导入组件的全限定类名，即 selectImports方法返回值。 如果selectImports方法返回值对应的类，它里面有使用@Bean注解的方法，那么此时给容器中导入的不只有当前返回值对应类的实例，还有该类型中加了@Bean对应的实例。 给容器导入的不是 DubboConfigConfigurationSelector，因为它实现了ImportSelector接口，导入的是该类的selectImports方法中返回的值对应的类。 通过以上规则可以知道，该类就是给Spring容器导入 DubboConfigConfiguration.Single 或 DubboConfigConfiguration.Multiple 组件。可以看出它们都是 DubboConfigConfiguration 类的内部类，下面我们看下该类的具体信息。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * Dubbo &#123;@link AbstractConfig Config&#125; &#123;@link Configuration&#125; * * @see Configuration * @see EnableDubboConfigBindings * @see EnableDubboConfigBinding * @see ApplicationConfig * @see ModuleConfig * @see RegistryConfig * @see ProtocolConfig * @see MonitorConfig * @see ProviderConfig * @see ConsumerConfig * @since 2.5.8 */public class DubboConfigConfiguration &#123; /** * Single Dubbo &#123;@link AbstractConfig Config&#125; Bean Binding * @EnableDubboConfigBinding 注解 prefix 都是单数 */ @EnableDubboConfigBindings(&#123; @EnableDubboConfigBinding(prefix = \"dubbo.application\", type = ApplicationConfig.class), @EnableDubboConfigBinding(prefix = \"dubbo.module\", type = ModuleConfig.class), @EnableDubboConfigBinding(prefix = \"dubbo.registry\", type = RegistryConfig.class), @EnableDubboConfigBinding(prefix = \"dubbo.protocol\", type = ProtocolConfig.class), @EnableDubboConfigBinding(prefix = \"dubbo.monitor\", type = MonitorConfig.class), @EnableDubboConfigBinding(prefix = \"dubbo.provider\", type = ProviderConfig.class), @EnableDubboConfigBinding(prefix = \"dubbo.consumer\", type = ConsumerConfig.class) &#125;) public static class Single &#123; &#125; /** * Multiple Dubbo &#123;@link AbstractConfig Config&#125; Bean Binding * @EnableDubboConfigBinding 注解 prefix 都是复数 */ @EnableDubboConfigBindings(&#123; @EnableDubboConfigBinding(prefix = \"dubbo.applications\", type = ApplicationConfig.class, multiple = true), @EnableDubboConfigBinding(prefix = \"dubbo.modules\", type = ModuleConfig.class, multiple = true), @EnableDubboConfigBinding(prefix = \"dubbo.registries\", type = RegistryConfig.class, multiple = true), @EnableDubboConfigBinding(prefix = \"dubbo.protocols\", type = ProtocolConfig.class, multiple = true), @EnableDubboConfigBinding(prefix = \"dubbo.monitors\", type = MonitorConfig.class, multiple = true), @EnableDubboConfigBinding(prefix = \"dubbo.providers\", type = ProviderConfig.class, multiple = true), @EnableDubboConfigBinding(prefix = \"dubbo.consumers\", type = ConsumerConfig.class, multiple = true) &#125;) public static class Multiple &#123; &#125;&#125; DubboConfigConfiguration 类中没有属性和方法，只有两个静态内部类，具体导入哪个类上面已经介绍过了，下面我们来详介绍下 @EnableDubboConfigBindings 和 @EnableDubboConfigBinding 注解。 @EnableDubboConfigBindings 注解12345678910111213141516171819/** * Multiple &#123;@link EnableDubboConfigBinding&#125; &#123;@link Annotation&#125; * * @since 2.5.8 * @see EnableDubboConfigBinding */@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(DubboConfigBindingsRegistrar.class) public @interface EnableDubboConfigBindings &#123; /** * The value of &#123;@link EnableDubboConfigBindings&#125; * * @return non-null */ EnableDubboConfigBinding[] value();&#125; 该注解有一个value属性，类型是 EnableDubboConfigBinding[] ，即 @EnableDubboConfigBinding 数组。该注解上使用 @Import 注解，使用DubboConfigBindingsRegistrar 类给Spring容器导入组件，下面我们继续跟进，看下具体导入哪些组件。 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * &#123;@link AbstractConfig Dubbo Config&#125; binding Bean registrar for &#123;@link EnableDubboConfigBindings&#125; * * @see EnableDubboConfigBindings * @see DubboConfigBindingRegistrar * @since 2.5.8 */public class DubboConfigBindingsRegistrar implements ImportBeanDefinitionRegistrar, EnvironmentAware &#123; private ConfigurableEnvironment environment; /** * * @param importingClassMetadata 标注类注解信息 * @param registry Bean定义注册表 */ @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; /** * 获得 EnableDubboConfigBindings 注解 */ AnnotationAttributes attributes = AnnotationAttributes.fromMap(importingClassMetadata.getAnnotationAttributes(EnableDubboConfigBindings.class.getName())); // 获得EnableDubboConfigBindings 注解的value 属性值（这里是 EnableDubboConfigBinding 注解数组） AnnotationAttributes[] annotationAttributes = attributes.getAnnotationArray(\"value\"); // 创建DubboConfigBindignRegistrar 对象，并设置环境变量 DubboConfigBindingRegistrar registrar = new DubboConfigBindingRegistrar(); registrar.setEnvironment(environment); // 依次遍历 EnableDubboConfigBinding 注解集合，调用 DubboConfigBindingRegistrar的注册Bean方法进行组件注册 for (AnnotationAttributes element : annotationAttributes) &#123; // 根据 EnableDubboConfigBinding 注解信息，进行对应组件的注册 registrar.registerBeanDefinitions(element, registry); &#125; &#125; @Override public void setEnvironment(Environment environment) &#123; Assert.isInstanceOf(ConfigurableEnvironment.class, environment); this.environment = (ConfigurableEnvironment) environment; &#125;&#125; 上面的类主要做了三件事情： 获取 @EnableDubboConfigBindings 注解信息，并获取该注解的value属性值，即获取的是 @EnableDubboConfigBinding 注解数组。 创建 DubboConfigBindingRegistrar对象。 遍历@EnableDubboConfigBinding 注解数组，调用DubboConfigBindingRegistrar对象的 registerBeanDefinitions方法。 我们可以发现，@EnableDubboConfigBindings利用DubboConfigBindingsRegistrar导入组件逻辑很简单，因为整个导入逻辑都封装在了DubboConfigBindingRegistrar对象的 registerBeanDefinitions方法中。我们接着分析DubboConfigBindingsRegistrar类，需要说明的是@EnableDubboConfigBinding注解就是通过@Import注解使用该类。 1234567891011121314151617181920212223public class DubboConfigBindingRegistrar implements ImportBeanDefinitionRegistrar, EnvironmentAware &#123; // $&#123;其他代码&#125; /** * @param attributes @EnableDubboConfigBinding注解信息 * @param registry Bean定义注册表 */ protected void registerBeanDefinitions(AnnotationAttributes attributes, BeanDefinitionRegistry registry) &#123; // 获得prefix 属性（因为有可能有占位符，需要要解析） String prefix = environment.resolvePlaceholders(attributes.getString(\"prefix\")); // 获得type属性，即AbstractConfig的实现类，这就是要导入的组件。需要特别说明的是，使用注解方式创建Dubbo的配置Bean，Dubbo Config 都是固定写在@EnableDubboConfigBinding注解属性中。 Class&lt;? extends AbstractConfig&gt; configClass = attributes.getClass(\"type\"); // 获的multiple属性，决定配置是否用于多BeanDefinition boolean multiple = attributes.getBoolean(\"multiple\"); // 注册Dubbo Config Bean registerDubboConfigBeans(prefix, configClass, multiple, registry); &#125; // $&#123;其他代码&#125;&#125; 由代码可以看出DubboConfigBindingsRegistrar就是使用 DubboConfigBindingRegistrar 对象解析@EnableDubboConfigBinding 注解信息，即配置属性的前缀和配置属性对应的Dubbo Config类，接着调用registerDubboConfigBeans 方法执行注册Bean定义逻辑。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105public class DubboConfigBindingRegistrar implements ImportBeanDefinitionRegistrar, EnvironmentAware &#123; // $&#123;省略其他代码&#125; /** * 注册dubbo Config Bean对象 * * @param prefix 配置属性前缀 * @param configClass 配置类 * @param multiple 是否支持多Bean配置 * @param registry Spring注册表 */ private void registerDubboConfigBeans(String prefix, Class&lt;? extends AbstractConfig&gt; configClass, boolean multiple, BeanDefinitionRegistry registry) &#123; // 获得prefix 开头的配置属性，以map形式返回 【environment.getPropertySources() 获得是系统属性、系统变量和@ResourceProperty注解导入的propertis配置属性】 Map&lt;String, Object&gt; properties = getSubProperties(environment.getPropertySources(), prefix); // 配置类没有配置相关属性，则不创建对应的BeanDefinition if (CollectionUtils.isEmpty(properties)) &#123; if (log.isDebugEnabled()) &#123; log.debug(\"There is no property for binding to dubbo config class [\" + configClass.getName() + \"] within prefix [\" + prefix + \"]\"); &#125; return; &#125; // 获得配置类的Bean名称，Bean名称生成规则取决与 multiple 的值 Set&lt;String&gt; beanNames = multiple ? resolveMultipleBeanNames(properties) : Collections.singleton(resolveSingleBeanName(properties, configClass, registry)); // 遍历Bean名字集合 for (String beanName : beanNames) &#123; // 1. 注册Dubbo Config的Bean 对象【没有设置属性值】 registerDubboConfigBean(beanName, configClass, registry); // 2. 注册Dubbo Config的Bean对象对应的DubboConfigBindingBeanPostProcessor对象，即Dubbo配置属性绑定的后置处理器【注意，每一个Dubbo Config的Bean对象都对应一个绑定配置的后置处理器】 registerDubboConfigBindingBeanPostProcessor(prefix, beanName, multiple, registry); &#125; &#125; /** * 注册Dubbo ConfigBean对象 * * @param beanName Bean的名称 * @param configClass 配置类 * @param registry 注册表 */ private void registerDubboConfigBean(String beanName, Class&lt;? extends AbstractConfig&gt; configClass, BeanDefinitionRegistry registry) &#123; // 创建 configClass对应的Bean定义Builder [该过程Bean定义已经创建] BeanDefinitionBuilder builder = rootBeanDefinition(configClass); // 由 Bean定义Builder 获取Bean定义 AbstractBeanDefinition beanDefinition = builder.getBeanDefinition(); // 注册到 Spring 的注册表中 registry.registerBeanDefinition(beanName, beanDefinition); if (log.isInfoEnabled()) &#123; log.info(\"The dubbo config bean definition [name : \" + beanName + \", class : \" + configClass.getName() + \"] has been registered.\"); &#125; &#125; /** * 创建的Dubbo Config的Bean对象的DubboConfigBindingBeanPostProcessor对象 【目的：实现对Dubbo Config的Bean对象的配置属性设置】 * * @param prefix 配置属性前缀 * @param beanName Bean的名称 * @param multiple 是否支持多Bean * @param registry Spring注册表 */ private void registerDubboConfigBindingBeanPostProcessor(String prefix, String beanName, boolean multiple, BeanDefinitionRegistry registry) &#123; // 创建Dubbo配置绑定 Bean后置处理器对应的BeanDefinitionBuilder对象 Class&lt;?&gt; processorClass = DubboConfigBindingBeanPostProcessor.class; BeanDefinitionBuilder builder = rootBeanDefinition(processorClass); /** * 构造方法的参数为 actualPrefix 和 beanName，即创建DubboConfigBindingBeanPostProcessor对象需要这两个参数，后面属性绑定会用到这两个属性。 * @see DubboConfigBindingBeanPostProcessor#DubboConfigBindingBeanPostProcessor(java.lang.String, java.lang.String) */ String actualPrefix = multiple ? normalizePrefix(prefix) + beanName : prefix; builder.addConstructorArgValue(actualPrefix).addConstructorArgValue(beanName); // 获得 DubboConfigBindingBeanPostProcessor 的 BeanDefinition 对象 AbstractBeanDefinition beanDefinition = builder.getBeanDefinition(); // 设置rol属性 beanDefinition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); // 注册到注册表 registerWithGeneratedName(beanDefinition, registry); if (log.isInfoEnabled()) &#123; log.info(\"The BeanPostProcessor bean definition [\" + processorClass.getName() + \"] for dubbo config bean [name : \" + beanName + \"] has been registered.\"); &#125; &#125; // $&#123;省略代码&#125; &#125; registerDubboConfigBeans 方法主要完成了两个核心的工作，创建Dubbo Config的Bean定义和Dubbo Config的属性绑定后置处理器。Dubbo Config是约定好的配置类，具体约定的配置类可以参见 DubboConfigConfiguration，并且指定了这些配置类的外部配置属性的前缀。这个过程还涉及到Dubbo Config的Bean定义的名称生成，我们来看下。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class DubboConfigBindingRegistrar implements ImportBeanDefinitionRegistrar, EnvironmentAware &#123; // $&#123;省略其他代码&#125; /** * 获得配置类对应的Bean 名称的集合。配置用于多个Bean的情况 * &lt;p&gt; * 例如： dubbo.application.$&#123;beanName&#125;.name=dubbo-demo-annotation-provider，$&#123;beanName&#125;就是配置类对应的Bean的名称 * * @param properties 配置属性集合 * @return */ private Set&lt;String&gt; resolveMultipleBeanNames(Map&lt;String, Object&gt; properties) &#123; Set&lt;String&gt; beanNames = new LinkedHashSet&lt;String&gt;(); for (String propertyName : properties.keySet()) &#123; // 获取$&#123;beanName&#125; 字符串 int index = propertyName.indexOf(\".\"); if (index &gt; 0) &#123; String beanName = propertyName.substring(0, index); beanNames.add(beanName); &#125; &#125; return beanNames; &#125; /** * 获得配置类对应的Bean 名称 * 例如： dubbo.application.name=dubbo-demo-annotation-provider * * @param properties * @param configClass * @param registry * @return */ private String resolveSingleBeanName(Map&lt;String, Object&gt; properties, Class&lt;? extends AbstractConfig&gt; configClass, BeanDefinitionRegistry registry) &#123; // 获得Bean的名称 String beanName = (String) properties.get(\"id\"); // 没有没有定义，就基于Spring提供的机制生成对应的Bean的名字。 如： org.apache.dubbo.config.ApplicationConfig#0 if (!StringUtils.hasText(beanName)) &#123; BeanDefinitionBuilder builder = rootBeanDefinition(configClass); beanName = BeanDefinitionReaderUtils.generateBeanName(builder.getRawBeanDefinition(), registry); &#125; return beanName; &#125; // $&#123;省略其他代码&#125;&#125; 由上面的代码可以看出，配置用于多个Bean的时候Bean的名称直接从配置属性值中获取，即获取${beanName} 的值作为Bean名称，Bean的名称可能会有多个。配置用于单个Bean的时候Bean的名称先尝试使用id属性值，没有配置id属性就自动生成。这两种情况可能一下子不好理解，下文还会详细说明。上面的过程中Bean定义是注册到了注册表中，但是Bean的属性还没有设置，下面我们来分析 DubboConfigBindingBeanPostProcessor 是如何进行属性绑定的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159/** * Dubbo Config Binding &#123;@link BeanPostProcessor&#125; * * @see EnableDubboConfigBinding * @see DubboConfigBindingRegistrar * @since 2.5.8 * &lt;p&gt; * 处理Dubbo AbstractConfig Bean的配置属性注入 */public class DubboConfigBindingBeanPostProcessor implements BeanPostProcessor, ApplicationContextAware, InitializingBean &#123; private final Log log = LogFactory.getLog(getClass()); /** * 属性配置前缀 */ private final String prefix; /** * Binding Bean Name // Bean的名字，每个配置类的Bean都有自己的名称 */ private final String beanName; /** * Dubbo 配置属性绑定器 ，用来绑定配置属性到Dubbo Config中 （内部使用Spring DataBinder完成属性绑定） */ private DubboConfigBinder dubboConfigBinder; /** * 应用上下文 */ private ApplicationContext applicationContext; /** * 是否忽略未知的属性 */ private boolean ignoreUnknownFields = true; /** * 是否忽略类型不对的属性 */ private boolean ignoreInvalidFields = true; /** * 构造方法，属性前缀和配置类的Bean是通过构造方法传入进来的。 * * @param prefix the prefix of Configuration Properties * @param beanName the binding Bean Name */ public DubboConfigBindingBeanPostProcessor(String prefix, String beanName) &#123; Assert.notNull(prefix, \"The prefix of Configuration Properties must not be null\"); Assert.notNull(beanName, \"The name of bean must not be null\"); this.prefix = prefix; this.beanName = beanName; &#125; /** * Bean后处理器的 前置处理方法。将配置属性绑定到Dubbo Config中 * * @param bean * @param beanName * @return * @throws BeansException */ @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; // 选择bean的名称是 this.beanName【针对注解机制创建Bean定义，其他方式创建的Bean定义不符合条件】，并且是AbstractConfig类型的 Bean定义 if (beanName.equals(this.beanName) &amp;&amp; bean instanceof AbstractConfig) &#123; AbstractConfig dubboConfig = (AbstractConfig) bean; // 设置prefix开头的配置属性到 DubboConfig中 dubboConfigBinder.bind(prefix, dubboConfig); if (log.isInfoEnabled()) &#123; log.info(\"The properties of bean [name : \" + beanName + \"] have been binding by prefix of \" + \"configuration properties : \" + prefix); &#125; &#125; return bean; &#125; /** * Bean后处理器的后置处理方法，这里直接返回Dubbo Config的Bean对象，不做其他的处理 * * @param bean * @param beanName * @return * @throws BeansException */ @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; return bean; &#125; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.applicationContext = applicationContext; &#125; /** * 设置 Dubbo 配置属性绑定器，注意它的触发时机。 * * @throws Exception */ @Override public void afterPropertiesSet() throws Exception &#123; // 获得DubboConfigBinder对象 if (dubboConfigBinder == null) &#123; try &#123; dubboConfigBinder = applicationContext.getBean(DubboConfigBinder.class); &#125; catch (BeansException ignored) &#123; if (log.isDebugEnabled()) &#123; log.debug(\"DubboConfigBinder Bean can't be found in ApplicationContext.\"); &#125; // Use Default implementation // 创建默认的配置绑定器 dubboConfigBinder = createDubboConfigBinder(applicationContext.getEnvironment()); &#125; &#125; // 设置 是否忽略未知/无效的属性 dubboConfigBinder.setIgnoreUnknownFields(ignoreUnknownFields); dubboConfigBinder.setIgnoreInvalidFields(ignoreInvalidFields); &#125; /** * Create &#123;@link DubboConfigBinder&#125; instance. * * @param environment * @return &#123;@link DefaultDubboConfigBinder&#125; */ protected DubboConfigBinder createDubboConfigBinder(Environment environment) &#123; // 创建DefaultDubboConfigBinder对象 DefaultDubboConfigBinder defaultDubboConfigBinder = new DefaultDubboConfigBinder(); // 设置environment属性 defaultDubboConfigBinder.setEnvironment(environment); return defaultDubboConfigBinder; &#125; public boolean isIgnoreUnknownFields() &#123; return ignoreUnknownFields; &#125; public void setIgnoreUnknownFields(boolean ignoreUnknownFields) &#123; this.ignoreUnknownFields = ignoreUnknownFields; &#125; public boolean isIgnoreInvalidFields() &#123; return ignoreInvalidFields; &#125; public void setIgnoreInvalidFields(boolean ignoreInvalidFields) &#123; this.ignoreInvalidFields = ignoreInvalidFields; &#125; public DubboConfigBinder getDubboConfigBinder() &#123; return dubboConfigBinder; &#125; public void setDubboConfigBinder(DubboConfigBinder dubboConfigBinder) &#123; this.dubboConfigBinder = dubboConfigBinder; &#125;&#125; Dubbo Config的属性绑定后置处理器逻辑不算复杂，就是从Spring环境中获取配置属性，然后利用Spring的数据绑定器DataBinder完成Dubbo Config的Bean属性的绑定，逻辑如下： 12345678910111213141516171819202122/** * Default &#123;@link DubboConfigBinder&#125; implementation based on Spring &#123;@link DataBinder&#125; * &lt;p&gt; * 使用Spring DataBinder，将配置属性设置到Dubbo Config对象中 */public class DefaultDubboConfigBinder extends AbstractDubboConfigBinder &#123; @Override public &lt;C extends AbstractConfig&gt; void bind(String prefix, C dubboConfig) &#123; // 将Dubbo Config包装成 DataBinder对象 DataBinder dataBinder = new DataBinder(dubboConfig); // 是否忽略无效和未知属性 dataBinder.setIgnoreInvalidFields(isIgnoreInvalidFields()); dataBinder.setIgnoreUnknownFields(isIgnoreUnknownFields()); // 从PropertySources中获取prefix开头的配置属性 [getPropertySources() : 系统属性，系统环境和@ProperSources的属性k-v] Map&lt;String, Object&gt; properties = getSubProperties(getPropertySources(), prefix); // 根据配置属性集合 创建 MutablePropertyValues对象 MutablePropertyValues propertyValues = new MutablePropertyValues(properties); // 绑定配置属性到 Dubbo的配置对象中 dataBinder.bind(propertyValues); &#125;&#125; 在Spring的后置处理器的方法中会调用 DefaultDubboConfigBinder#bind方法进行Dubbo Config的Bean的属性设置，本质是使用Spring的DataBinder完成属性设置。至此，@EnableDubboConfigBindings涉及的处理逻辑分析完毕，这个过程创建了Dubbo Config的Bean，并且创建了该Bean对应的属性绑定Bean后置处理器，在Spring的生命周期中该Bean后置处理器会回调对应的方法以完成属性的绑定。接下来我们再来分析 @EnableDubboConfigBinding 注解，该注解是 @EnableDubboConfigBindings 注解的属性数组的类型， @EnableDubboConfigBindings 注解的逻辑处理基本就是 @EnableDubboConfigBinding 注解的逻辑处理。 @EnableDubboConfigBinding 注解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * Enables Spring's annotation-driven &#123;@link AbstractConfig Dubbo Config&#125; from &#123;@link PropertySources properties&#125;. * &lt;p&gt; * Default , &#123;@link #prefix()&#125; associates with a prefix of &#123;@link PropertySources properties&#125;, e,g. \"dubbo.application.\" * or \"dubbo.application\" * &lt;pre class=\"code\"&gt; * &lt;/pre&gt; * * @see DubboConfigBindingRegistrar * @see DubboConfigBindingBeanPostProcessor * @see EnableDubboConfigBindings * @since 2.5.8 */@Target(&#123;ElementType.TYPE, ElementType.ANNOTATION_TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(DubboConfigBindingRegistrar.class)public @interface EnableDubboConfigBinding &#123; /** * 配置属性的前缀，用于映射到 AbstractConfig 中的属性 * &lt;p&gt; * The name prefix of the properties that are valid to bind to &#123;@link AbstractConfig Dubbo Config&#125;. * * @return the name prefix of the properties to bind */ String prefix(); /** * Dubbo Config 配置类，这是一个约定，Dubbo Config配置类有哪些是固定的，这个配置必须是AbstractConfig的实现子类。 * * @return The binding type of &#123;@link AbstractConfig Dubbo Config&#125;. * @see AbstractConfig * @see ApplicationConfig * @see ModuleConfig * @see RegistryConfig */ Class&lt;? extends AbstractConfig&gt; type(); /** * 是否支持配置用于多个Bean * * It indicates whether &#123;@link #prefix()&#125; binding to multiple Spring Beans. * * @return the default value is &lt;code&gt;false&lt;/code&gt; */ boolean multiple() default false;&#125; 该注解有三个属性，每个属性的作用已经注释过了，我们直接来看 @Import(DubboConfigBindingRegistrar.class)，DubboConfigBindingRegistrar的主要逻辑已经在上面分析过了，我们在简单看下没有分析到的代码。 12345678910111213141516171819202122232425262728/** * &#123;@link AbstractConfig Dubbo Config&#125; binding Bean registrar * * @see EnableDubboConfigBinding * @see DubboConfigBindingBeanPostProcessor * @since 2.5.8 * &lt;p&gt; * 处理 @EnableDubboConfigBinding 注解，注册相应的 Dubbo AbstractConfig 到Spring 容器 */public class DubboConfigBindingRegistrar implements ImportBeanDefinitionRegistrar, EnvironmentAware &#123; private final Log log = LogFactory.getLog(getClass()); private ConfigurableEnvironment environment; @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; // 获得 @EnableDubboConfigBinding注解信息 AnnotationAttributes attributes = AnnotationAttributes.fromMap(importingClassMetadata.getAnnotationAttributes(EnableDubboConfigBinding.class.getName())); // 根据 @EnableDubboConfigBinding注解信息 注册配置对应的 BeanDefinition 对象 registerBeanDefinitions(attributes, registry); &#125; // $&#123;省略其他代码&#125;&#125; 至此，@EnableDubboConfig 注解已经分析完了，该注解就是用于开启Dubbo的配置，创建Dubbo框架内置的配置类的Bean，并且创建配置类的Bean对应的属性绑定Bean后置处理器，Spring应用上下文启动后，就可以实现配置对象的创建与初始化。但是需要注意的是，并不是指定了配置类就会创建对应的Bean，只有当规约的外部配置存在时，配置类才会提升为Spring Bean。 Dubbo配置Bean绑定及自定义配置Bean绑定这块内容还是不少的，这里就不详细说明了。我们直接看 Dubbo PMC 的文章 Dubbo 新编程模型之外部化配置，里面详细介绍了多配置Bean的属性绑定以及自定义Bean的属性绑定。 @DubboComponentScan 注解该注解用于配置要扫描 @Service 和 @Reference 注解的包或类，进而创建对应的Bean对象。注解扫描是委托给Spring的，本质上使用ASM库进行字节码扫描注解元数据。当用户使用注解 @DubboComponentScan 时，会激活 DubboComponentScanRegistrar，这个类就是实现服务提供者通过注解 @Service 进行服务暴露的，对消费者通过注解 @Reference 进行服务引用的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * Dubbo Component Scan &#123;@link Annotation&#125;,scans the classpath for annotated components that will be auto-registered as * Spring beans. Dubbo-provided &#123;@link Service&#125; and &#123;@link Reference&#125;. * * @see Service * @see Reference * @since 2.5.7 */@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(DubboComponentScanRegistrar.class)public @interface DubboComponentScan &#123; /** * Alias for the &#123;@link #basePackages()&#125; attribute. Allows for more concise annotation * declarations e.g.: &#123;@code @DubboComponentScan(\"org.my.pkg\")&#125; instead of * &#123;@code @DubboComponentScan(basePackages=\"org.my.pkg\")&#125;. * * @return the base packages to scan * * 和 basePackages 等价 * */ String[] value() default &#123;&#125;; /** * Base packages to scan for annotated @Service classes. &#123;@link #value()&#125; is an * alias for (and mutually exclusive with) this attribute. * &lt;p&gt; * Use &#123;@link #basePackageClasses()&#125; for a type-safe alternative to String-based * package names. * * @return the base packages to scan * * 要扫描包的数组 * */ String[] basePackages() default &#123;&#125;; /** * Type-safe alternative to &#123;@link #basePackages()&#125; for specifying the packages to * scan for annotated @Service classes. The package of each class specified will be * scanned. * * @return classes from the base packages to scan * * 要扫描的类的数组 * */ Class&lt;?&gt;[] basePackageClasses() default &#123;&#125;;&#125; 该注解的属性作用已经注释，我们重点关注下@Import的value属性值 DubboComponentScanRegistrar ，它用于处理DubboComponentScan注解，为Spring容器注册ServiceAnnotation和ReferenceAnnotation的Bean后置处理器，进而创建ServiceBean和ReferenceBean对象。下面我们就来详细分析Dubbo注解实现的这个核心类。 DubboComponentScanRegistrar1234567891011121314151617181920212223242526272829303132333435/** * Dubbo &#123;@link DubboComponentScan&#125; Bean Registrar * * @see Service * @see DubboComponentScan * @see ImportBeanDefinitionRegistrar * @see ServiceAnnotationBeanPostProcessor * @see ReferenceAnnotationBeanPostProcessor * @since 2.5.7 * */public class DubboComponentScanRegistrar implements ImportBeanDefinitionRegistrar &#123; /** * @param importingClassMetadata @DubboComponentScan 注解的信息 * @param registry Bean定义注册表 */ @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; /** * 1. 获得要扫描的包 */ Set&lt;String&gt; packagesToScan = getPackagesToScan(importingClassMetadata); /** * 2. 创建 ServiceAnnotationBeanPostProcessor Bean 对象，后续扫描 `@Service` 注解的类，创建对应的 Service Bean 对象 */ registerServiceAnnotationBeanPostProcessor(packagesToScan, registry); /** * 3. 创建 ReferenceAnnotationBeanPostProcessor Bean 对象，后续扫描 `@Reference` 注解的类，创建对应的 Reference Bean 对象 */ registerReferenceAnnotationBeanPostProcessor(registry); &#125; // $&#123;省略其他的代码&#125;&#125; DubboComponentScanRegistrar 实现 ImportBeanDefinitionRegistrar接口，用来处理 @DubboComponentScan注解，注册 ServiceAnnotationBeanPostProcessor 和 ReferenceAnnotationBeanPostProcessor 到Spring容器，Spring应用上下文启动后，就可以实现Service Bean对象和Reference Bean对象的创建。下面我们依次分析以上三个步骤的具体逻辑。 获取要扫描的包123456789101112131415161718192021222324252627282930313233343536373839public class DubboComponentScanRegistrar implements ImportBeanDefinitionRegistrar &#123; // $&#123;省略其他代码&#125; /** * 获得 DubboComponentScan注解扫描的包 * * @param metadata * @return */ private Set&lt;String&gt; getPackagesToScan(AnnotationMetadata metadata) &#123; // 获得 @DubboComponentScan 注解 AnnotationAttributes attributes = AnnotationAttributes.fromMap(metadata.getAnnotationAttributes(DubboComponentScan.class.getName())); // 获得basePackages 属性值 String[] basePackages = attributes.getStringArray(\"basePackages\"); // 获得basePackageClasses属性值 Class&lt;?&gt;[] basePackageClasses = attributes.getClassArray(\"basePackageClasses\"); // 获得默认属性（basePackages的默认属性） String[] value = attributes.getStringArray(\"value\"); // 将属性添加到 packagesToScan 集合中 Set&lt;String&gt; packagesToScan = new LinkedHashSet&lt;String&gt;(Arrays.asList(value)); packagesToScan.addAll(Arrays.asList(basePackages)); // 处理 扫描的类的数组 ，得到每个类的包名，然后添加到 包路径数组中 for (Class&lt;?&gt; basePackageClass : basePackageClasses) &#123; packagesToScan.add(ClassUtils.getPackageName(basePackageClass)); &#125; // packagesToScan 为空的话，则默认使用DubboComponentScan注解类所在的包做为扫描包 if (packagesToScan.isEmpty()) &#123; return Collections.singleton(ClassUtils.getPackageName(metadata.getClassName())); &#125; return packagesToScan; &#125; // $&#123;省略其他代码&#125;&#125; 获取要扫描的包逻辑还是很直观的，将配置的扫描包路径和配置的扫描类对应的包路径聚合在一起作为目标包路径，需要注意的是当配置扫描类时需要获取扫描类的包名，即还是会转为包扫描。如果没有配置扫描包及扫描类，那么就是使用DubboComponentScan注解类所在的包做为扫描包。 创建扫描 @Service 注解的后置处理器1234567891011121314151617181920212223242526272829public class DubboComponentScanRegistrar implements ImportBeanDefinitionRegistrar &#123; // $&#123;省略其他代码&#125; /** * Registers &#123;@link ServiceAnnotationBeanPostProcessor&#125; * * @param packagesToScan packages to scan without resolving placeholders * @param registry &#123;@link BeanDefinitionRegistry&#125; * @since 2.5.8 * &lt;p&gt; * 创建 ServiceAnnotationBeanPostProcessor Bean 对象，后续扫描 @Service 注解的类，创建对应的 Service Bean 对象 */ private void registerServiceAnnotationBeanPostProcessor(Set&lt;String&gt; packagesToScan, BeanDefinitionRegistry registry) &#123; // 创建ServiceAnnotationBeanPostProcessor的BeanDefinitionBuilder 对象 BeanDefinitionBuilder builder = rootBeanDefinition(ServiceAnnotationBeanPostProcessor.class); // 设置构造方法参数为 packagesToScan builder.addConstructorArgValue(packagesToScan); // 设置 role 属性 builder.setRole(BeanDefinition.ROLE_INFRASTRUCTURE); // 获得 AbstractBeanDefinition 对象 AbstractBeanDefinition beanDefinition = builder.getBeanDefinition(); // 注册到注册表中 BeanDefinitionReaderUtils.registerWithGeneratedName(beanDefinition, registry); &#125; // $&#123;省略其他代码&#125;&#125; 创建扫描 @Service 注解的类的后置处理器逻辑很简单，就是创建一个Bean定义然后注册到注册表中。下面我们重点分析这个后置处理的逻辑，看它是如何将 @Service 标注的类提升为Spring Bean的。 ServiceAnnotationBeanPostProcessor12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/** * &#123;@link Service&#125; Annotation * &#123;@link BeanDefinitionRegistryPostProcessor Bean Definition Registry Post Processor&#125; * * @since 2.5.8 */public class ServiceAnnotationBeanPostProcessor implements BeanDefinitionRegistryPostProcessor, EnvironmentAware, ResourceLoaderAware, BeanClassLoaderAware &#123; private final Logger logger = LoggerFactory.getLogger(getClass()); /** * 要扫描的包的集合，通过构造方法进行设置 */ private final Set&lt;String&gt; packagesToScan; /** * 环境 */ private Environment environment; /** * 资源加载器 */ private ResourceLoader resourceLoader; /** * 类加载器 */ private ClassLoader classLoader; public ServiceAnnotationBeanPostProcessor(String... packagesToScan) &#123; this(Arrays.asList(packagesToScan)); &#125; public ServiceAnnotationBeanPostProcessor(Collection&lt;String&gt; packagesToScan) &#123; this(new LinkedHashSet&lt;String&gt;(packagesToScan)); &#125; public ServiceAnnotationBeanPostProcessor(Set&lt;String&gt; packagesToScan) &#123; this.packagesToScan = packagesToScan; &#125; // $&#123;省略其他逻辑代码&#125; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; &#125; @Override public void setEnvironment(Environment environment) &#123; this.environment = environment; &#125; @Override public void setResourceLoader(ResourceLoader resourceLoader) &#123; this.resourceLoader = resourceLoader; &#125; @Override public void setBeanClassLoader(ClassLoader classLoader) &#123; this.classLoader = classLoader; &#125; ServiceAnnotationBeanPostProcessor 实现 BeanDefinitionRegistryPostProcessor、EnvironmentAware、ResourceLoaderAware、BeanClassLoaderAware 接口，具备了Spring的特定功能，如Spring容器中所有Bean注册之后回调 postProcessBeanDefinitionRegistry 方法。该类主要是将 @Service 标注的类提升为Spring Bean，主要的逻辑如下： 解析扫描包集合，处理存在占位符的包名。 创建DubboClassPathBeanDefinitionScanner对象，用于扫描指定包下的 @Service 标注的类并注册该类的Bean定义到注册表。 为每个@Service标注的类创建对应的 ServiceBean，并注册到注册表。 解析扫描包集合 123456789101112131415161718192021222324252627public class ServiceAnnotationBeanPostProcessor implements BeanDefinitionRegistryPostProcessor, EnvironmentAware, ResourceLoaderAware, BeanClassLoaderAware &#123; // $&#123;省略其他代码&#125; /** * * @param registry 注册表 * @throws BeansException */ @Override public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException &#123; // 解析 packagesToScan集合，包名可能存在占位符的情况 Set&lt;String&gt; resolvedPackagesToScan = resolvePackagesToScan(packagesToScan); if (!CollectionUtils.isEmpty(resolvedPackagesToScan)) &#123; // 扫描 packagesToScan 包，创建对应的 Spring BeanDefinition 对象，从而触发 Dubbo ServiceBean 定义和注册 registerServiceBeans(resolvedPackagesToScan, registry); &#125; else &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"packagesToScan is empty , ServiceBean registry will be ignored!\"); &#125; &#125; &#125; // $&#123;省略其他代码&#125;&#125; 上面的代码主要处理包名存在占位符的情况，同时上面的方法也是Spring的Bean后处理器的回调方法，在Spring的生命周期内进行回调。接下我们看扫描Dubbo的 @Service 注解的逻辑。 扫描Dubbo的 @Service 注解 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class ServiceAnnotationBeanPostProcessor implements BeanDefinitionRegistryPostProcessor, EnvironmentAware, ResourceLoaderAware, BeanClassLoaderAware &#123; // $&#123;省略其他代码&#125; /** * 扫描 packagesToScan 包，创建对应的 Spring BeanDefinition 对象，从而创建 Dubbo Service Bean 对象 * &lt;p&gt; * Registers Beans whose classes was annotated &#123;@link Service&#125; * * @param packagesToScan 要扫描的包集合 * @param registry 注册表 */ private void registerServiceBeans(Set&lt;String&gt; packagesToScan, BeanDefinitionRegistry registry) &#123; // 创建 Dubbo的类路径Bean定义扫描对象，该类继承了Spring的 ClassPathBeanDefinitionScanner，即用于扫描指定包下符合条件的类，将符合条件的类创建对应的BeanDefinition对象 DubboClassPathBeanDefinitionScanner scanner = new DubboClassPathBeanDefinitionScanner(registry, environment, resourceLoader); // 获得 BeanNameGenerator 对象，并设置 beanNameGenerator 到 scanner 中 BeanNameGenerator beanNameGenerator = resolveBeanNameGenerator(registry); scanner.setBeanNameGenerator(beanNameGenerator); // 指定扫描器扫描带有Dubbo的@Service注解的类，不会扫描Spring的@Service注解 scanner.addIncludeFilter(new AnnotationTypeFilter(Service.class)); // 遍历扫描的包集合 for (String packageToScan : packagesToScan) &#123; // 执行扫描，并注册目标类的Bean定义到注册表，使用beanNameGenerator生成Bean的名称 scanner.scan(packageToScan); // 创建每个被扫描的类的BeanDefinitionHolder对象，返回BeanDefinitionHolder集合，用于生成ServiceBean定义【注意，这里也会创建扫描的类的Bean定义，也是使用 beanNameGenerator 生成名称，但没有注册到注册表】 Set&lt;BeanDefinitionHolder&gt; beanDefinitionHolders = findServiceBeanDefinitionHolders(scanner, packageToScan, registry, beanNameGenerator); // 为每个@Service标注的类创建对应的 ServiceBean，并注册到注册表。 if (!CollectionUtils.isEmpty(beanDefinitionHolders)) &#123; for (BeanDefinitionHolder beanDefinitionHolder : beanDefinitionHolders) &#123; registerServiceBean(beanDefinitionHolder, registry, scanner); &#125; if (logger.isInfoEnabled()) &#123; logger.info(beanDefinitionHolders.size() + \" annotated Dubbo's @Service Components &#123; \" + beanDefinitionHolders + \" &#125; were scanned under package[\" + packageToScan + \"]\"); &#125; &#125; else &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"No Spring Bean annotating Dubbo's @Service was found under package[\" + packageToScan + \"]\"); &#125; &#125; &#125; &#125; // $&#123;省略其他代码&#125;&#125; 上面代码主要做了四件事情，如下： 创建类路径扫描器 DubboClassPathBeanDefinitionScanner，指定扫描的注解包含Dubbo的@Service注解。 获取BeanNameGenerator对象，用于 @Service 标注类的Bean定义名称。 使用扫描器扫描包，提升@Service标注的类为Spring Bean，并注册到注册表中。 获取第3步的Spring Bean的BeanDefinitionHolder集合，将用于创建Dubbo的ServiceBean对象。 代码中的主要逻辑已经详细标注，胖友自己瞅瞅，下面我们简单分析下扫描器的原理。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105ClassPathBeanDefinitionScanner#scan(String... basePackages) &#123; int beanCountAtScanStart = this.registry.getBeanDefinitionCount(); // 扫描逻辑 doScan(basePackages); // Register annotation config processors, if necessary. if (this.includeAnnotationConfig) &#123; AnnotationConfigUtils.registerAnnotationConfigProcessors(this.registry); &#125; return (this.registry.getBeanDefinitionCount() - beanCountAtScanStart); &#125; // 扫描包逻辑 protected Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) &#123; Assert.notEmpty(basePackages, \"At least one base package must be specified\"); Set&lt;BeanDefinitionHolder&gt; beanDefinitions = new LinkedHashSet&lt;BeanDefinitionHolder&gt;(); for (String basePackage : basePackages) &#123; // 从包中获取候选BeanDefinition Set&lt;BeanDefinition&gt; candidates = findCandidateComponents(basePackage); for (BeanDefinition candidate : candidates) &#123; ScopeMetadata scopeMetadata = this.scopeMetadataResolver.resolveScopeMetadata(candidate); candidate.setScope(scopeMetadata.getScopeName()); // 使用beanNameGenerator 生成BeanDefinition的名称 String beanName = this.beanNameGenerator.generateBeanName(candidate, this.registry); if (candidate instanceof AbstractBeanDefinition) &#123; postProcessBeanDefinition((AbstractBeanDefinition) candidate, beanName); &#125; if (candidate instanceof AnnotatedBeanDefinition) &#123; AnnotationConfigUtils.processCommonDefinitionAnnotations((AnnotatedBeanDefinition) candidate); &#125; // 是否是候选BeanDefinition if (checkCandidate(beanName, candidate)) &#123; BeanDefinitionHolder definitionHolder = new BeanDefinitionHolder(candidate, beanName); definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder, this.registry); beanDefinitions.add(definitionHolder); // 注册到注册表 registerBeanDefinition(definitionHolder, this.registry); &#125; &#125; &#125; return beanDefinitions; &#125; /** * 从包中获取BeanDefinition集合 * * Scan the class path for candidate components. * @param basePackage the package to check for annotated classes * @return a corresponding Set of autodetected bean definitions */ public Set&lt;BeanDefinition&gt; findCandidateComponents(String basePackage) &#123; Set&lt;BeanDefinition&gt; candidates = new LinkedHashSet&lt;BeanDefinition&gt;(); try &#123; // 类路径下的指定包下的所有.class文件 （如：classpath*:com/code/resource/reading/consumer/annotation/consumer/**/*.class） String packageSearchPath = ResourcePatternResolver.CLASSPATH_ALL_URL_PREFIX + resolveBasePackage(basePackage) + '/' + this.resourcePattern; Resource[] resources = this.resourcePatternResolver.getResources(packageSearchPath); boolean traceEnabled = logger.isTraceEnabled(); boolean debugEnabled = logger.isDebugEnabled(); for (Resource resource : resources) &#123; if (traceEnabled) &#123; logger.trace(\"Scanning \" + resource); &#125; if (resource.isReadable()) &#123; try &#123; MetadataReader metadataReader = this.metadataReaderFactory.getMetadataReader(resource); // 是否是候选 BeanDefinition if (isCandidateComponent(metadataReader)) &#123; // 创建 BeanDefinition ScannedGenericBeanDefinition sbd = new ScannedGenericBeanDefinition(metadataReader); sbd.setResource(resource); sbd.setSource(resource); if (isCandidateComponent(sbd)) &#123; if (debugEnabled) &#123; logger.debug(\"Identified candidate component class: \" + resource); &#125; candidates.add(sbd); &#125; else &#123; if (debugEnabled) &#123; logger.debug(\"Ignored because not a concrete top-level class: \" + resource); &#125; &#125; &#125; else &#123; if (traceEnabled) &#123; logger.trace(\"Ignored because not matching any filter: \" + resource); &#125; &#125; &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException( \"Failed to read candidate component class: \" + resource, ex); &#125; &#125; else &#123; if (traceEnabled) &#123; logger.trace(\"Ignored because not readable: \" + resource); &#125; &#125; &#125; &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException(\"I/O failure during classpath scanning\", ex); &#125; return candidates; &#125; 我们只要大致了解下扫描器是怎么把指定包下的注解标注的类提升为Spring Bean就可以了。有了目标类的Bean定义，接下来我们分析Dubbo是如何创建该目标类对应的ServiceBean对象的。 创建ServiceBean并注册到注册表 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class ServiceAnnotationBeanPostProcessor implements BeanDefinitionRegistryPostProcessor, EnvironmentAware, ResourceLoaderAware, BeanClassLoaderAware &#123; // $&#123;省略其他代码&#125;/** * Registers &#123;@link ServiceBean&#125; from new annotated &#123;@link Service&#125; &#123;@link BeanDefinition&#125; * * @param beanDefinitionHolder @Service标注的类的BeanDefinitionHolder * @param registry 注册表 * @param scanner 扫描器 * @see ServiceBean * @see BeanDefinition */ private void registerServiceBean(BeanDefinitionHolder beanDefinitionHolder, BeanDefinitionRegistry registry, DubboClassPathBeanDefinitionScanner scanner) &#123; // 从holder中取出BeanDefinition，并解析出对应的类 Class&lt;?&gt; beanClass = resolveClass(beanDefinitionHolder); // 获得@Service 注解 Service service = findAnnotation(beanClass, Service.class); // 获得注解标注类的接口 Class&lt;?&gt; interfaceClass = resolveServiceInterfaceClass(beanClass, service); // 获得Bean的名字 String annotatedServiceBeanName = beanDefinitionHolder.getBeanName(); // 创建AbstractBeanDefinition 对象 ，这里真正创建ServiceBean AbstractBeanDefinition serviceBeanDefinition = buildServiceBeanDefinition(service, interfaceClass, annotatedServiceBeanName); // 重新生成Bean 的名字 【格式：ServiceBean:$&#123;interfaceClassName&#125;:$&#123;version&#125;:$&#123;group&#125;】，重新创建的ServiceBean名称是把上面的BeanDefinition注册到注册表中，需要一个名称 String beanName = generateServiceBeanName(service, interfaceClass, annotatedServiceBeanName); // 校验在 注册表 中是否已经存在beanName，若不存在则进行注册 if (scanner.checkCandidate(beanName, serviceBeanDefinition)) &#123; // 注册 registry.registerBeanDefinition(beanName, serviceBeanDefinition); if (logger.isInfoEnabled()) &#123; logger.warn(\"The BeanDefinition[\" + serviceBeanDefinition + \"] of ServiceBean has been registered with name : \" + beanName); &#125; &#125; else &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"The Duplicated BeanDefinition[\" + serviceBeanDefinition + \"] of ServiceBean[ bean name : \" + beanName + \"] was be found , Did @DubboComponentScan scan to same package in many times?\"); &#125; &#125; &#125; // $&#123;省略其他代码&#125;&#125; 上面的方法主要是为创建ServiceBean提供条件，如：获取Dubbo的@Service标注类的Class及接口、获取@Service信息、获取Dubbo的@Service标注类的Bean定义的名称。有了这些信息，就可以创建目标服务类（Dubbo的@Service标注的类）的ServiceBean。在分析创建ServiceBean之前，我们先来看下目标服务类的接口获取逻辑。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class ServiceAnnotationBeanPostProcessor implements BeanDefinitionRegistryPostProcessor, EnvironmentAware, ResourceLoaderAware, BeanClassLoaderAware &#123; // $&#123;省略其他代码&#125; /** * 获得@Service 注解的类的接口 * * @param annotatedServiceBeanClass * @param service * @return */ private Class&lt;?&gt; resolveServiceInterfaceClass(Class&lt;?&gt; annotatedServiceBeanClass, Service service) &#123; // 从注解属性中获取 Class&lt;?&gt; interfaceClass = service.interfaceClass(); if (void.class.equals(interfaceClass)) &#123; interfaceClass = null; // 获得@Service 注解的interfaceName 属性 String interfaceClassName = service.interfaceName(); // 如果存在，获得其对应的类 if (StringUtils.hasText(interfaceClassName)) &#123; if (ClassUtils.isPresent(interfaceClassName, classLoader)) &#123; interfaceClass = resolveClassName(interfaceClassName, classLoader); &#125; &#125; &#125; //从注解属性中获得不到，则从被注解的类上获得其实现的第一个接口 if (interfaceClass == null) &#123; // 获取接口列表 Class&lt;?&gt;[] allInterfaces = annotatedServiceBeanClass.getInterfaces(); // 存在的话取第一个接口 if (allInterfaces.length &gt; 0) &#123; interfaceClass = allInterfaces[0]; &#125; &#125; Assert.notNull(interfaceClass,\"@Service interfaceClass() or interfaceName() or interface class must be present!\"); Assert.isTrue(interfaceClass.isInterface(),\"The type that was annotated @Service is not an interface!\"); return interfaceClass; &#125; // $&#123;省略其他代码&#125;&#125; 获取目标服务类的接口规则是先从@Service注解属性中取，没有设置再获取目标服务类的第一个实现接口。下面我们来分析下ServiceBean的定义如何生成，可以对比下XML配置的生成规则。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182public class ServiceAnnotationBeanPostProcessor implements BeanDefinitionRegistryPostProcessor, EnvironmentAware, ResourceLoaderAware, BeanClassLoaderAware &#123; // $&#123;省略其他代码&#125;/** * 创建AbstraceBeanDefinition对象 * * @param service @Service 注解 * @param interfaceClass 目标服务类的接口 * @param annotatedServiceBeanName 目标服务类的Bean定义的名称 * @return */ private AbstractBeanDefinition buildServiceBeanDefinition(Service service, Class&lt;?&gt; interfaceClass, String annotatedServiceBeanName) &#123; // 创建ServiceBean的BeanDefinitionBuilder对象 BeanDefinitionBuilder builder = rootBeanDefinition(ServiceBean.class); // 获得ServiceBean的AbstractBeanDefinition 对象 AbstractBeanDefinition beanDefinition = builder.getBeanDefinition(); // 获得 MutablePropertyValues对象，后续可以通过它为ServiceBean添加属性 MutablePropertyValues propertyValues = beanDefinition.getPropertyValues(); // 创建AnnotationPropertyValuesAdapter 对象，添加到propertyValues中。注意是将注解上的属性设置到PropertyValues中，并且指定哪些属性要忽略。被忽略的属性会单独设置。 String[] ignoreAttributeNames = of(\"provider\", \"monitor\", \"application\", \"module\", \"registry\", \"protocol\", \"interface\"); propertyValues.addPropertyValues(new AnnotationPropertyValuesAdapter(service, environment, ignoreAttributeNames)); // 设置ServiceBean ref 属性，即@Service标注的类的Bean定义名称 addPropertyReference(builder, \"ref\", annotatedServiceBeanName); // 设置ServiceBean的 interface 属性 builder.addPropertyValue(\"interface\", interfaceClass.getName()); // 添加ServiceBean的 provider 属性 String providerConfigBeanName = service.provider(); if (StringUtils.hasText(providerConfigBeanName)) &#123; addPropertyReference(builder, \"provider\", providerConfigBeanName); &#125; // 添加ServiceBean的monitor属性 String monitorConfigBeanName = service.monitor(); if (StringUtils.hasText(monitorConfigBeanName)) &#123; addPropertyReference(builder, \"monitor\", monitorConfigBeanName); &#125; // 添加ServiceBean 的 application 属性 String applicationConfigBeanName = service.application(); if (StringUtils.hasText(applicationConfigBeanName)) &#123; addPropertyReference(builder, \"application\", applicationConfigBeanName); &#125; // 添加ServiceBean的 module 属性对应的 ModuleConfig Bean 对象 String moduleConfigBeanName = service.module(); if (StringUtils.hasText(moduleConfigBeanName)) &#123; addPropertyReference(builder, \"module\", moduleConfigBeanName); &#125; //-------------- 下面两个属性和上面的不一样，因为可能会有多个 ，即多注册中心，多协议的情况-------------------/ // 添加ServiceBean的 registries 属性 String[] registryConfigBeanNames = service.registry(); List&lt;RuntimeBeanReference&gt; registryRuntimeBeanReferences = toRuntimeBeanReferences(registryConfigBeanNames); if (!registryRuntimeBeanReferences.isEmpty()) &#123; builder.addPropertyValue(\"registries\", registryRuntimeBeanReferences); &#125; // 添加ServiceBean的 protocols 属性 String[] protocolConfigBeanNames = service.protocol(); List&lt;RuntimeBeanReference&gt; protocolRuntimeBeanReferences = toRuntimeBeanReferences(protocolConfigBeanNames); if (!protocolRuntimeBeanReferences.isEmpty()) &#123; builder.addPropertyValue(\"protocols\", protocolRuntimeBeanReferences); &#125; return builder.getBeanDefinition(); &#125; // $&#123;省略其他代码&#125;&#125; 上面的代码就是为ServiceBean设置简单属性值和引用类型的值，当ServiceBean的属性是引用类型时，解析器会依据依赖bean的name创建一个RuntimeBeanReference对像，将这个对像放入ServiceBean的BeanDefinition的MutablePropertyValues中。ServiceBean的Bean定义创建完成后，接着就把该Bean定义注册到注册表中。至此，扫描 @Service 注解的Bean后置处理器逻辑已经分析完毕。下面我们开始分析扫描 @Reference 注解的后置处理器。 创建扫描 @Reference 注解的后置处理器123456789101112131415161718public class DubboComponentScanRegistrar implements ImportBeanDefinitionRegistrar &#123; // $&#123;省略其他代码&#125; /** * Registers &#123;@link ReferenceAnnotationBeanPostProcessor&#125; into &#123;@link BeanFactory&#125; * * @param registry &#123;@link BeanDefinitionRegistry&#125; */ private void registerReferenceAnnotationBeanPostProcessor(BeanDefinitionRegistry registry) &#123; // Register @Reference Annotation Bean Processor BeanRegistrar.registerInfrastructureBean(registry, ReferenceAnnotationBeanPostProcessor.BEAN_NAME, ReferenceAnnotationBeanPostProcessor.class); &#125; // $&#123;省略其他代码&#125;&#125; 创建扫描 @Reference 注解的后置处理器需要注意该Bean定义的名称是 referenceAnnotationBeanPostProcessor，是常量维护的。下面我们开始分析ReferenceAnnotationBeanPostProcessor的逻辑，看它又是如何为 @Reference 注解的属性或方法引入代理对象。 ReferenceAnnotationBeanPostProcessor12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576/** * &#123;@link org.springframework.beans.factory.config.BeanPostProcessor&#125; implementation * that Consumer service &#123;@link Reference&#125; annotated fields * @since 2.5.7 */public class ReferenceAnnotationBeanPostProcessor extends AnnotationInjectedBeanPostProcessor&lt;Reference&gt; implements ApplicationContextAware, ApplicationListener &#123; /** * The bean name of &#123;@link ReferenceAnnotationBeanPostProcessor&#125; */ public static final String BEAN_NAME = \"referenceAnnotationBeanPostProcessor\"; /** * Cache size */ private static final int CACHE_SIZE = Integer.getInteger(BEAN_NAME + \".cache.size\", 32); /** * ReferenceBean 缓存 Map,key:Reference Bean 的名字 */ private final ConcurrentMap&lt;String, ReferenceBean&lt;?&gt;&gt; referenceBeanCache = new ConcurrentHashMap&lt;String, ReferenceBean&lt;?&gt;&gt;(CACHE_SIZE); /** * ReferenceBeanInvocationHandler 缓存 Map，key：Reference Bean的名字 */ private final ConcurrentHashMap&lt;String, ReferenceBeanInvocationHandler&gt; localReferenceBeanInvocationHandlerCache = new ConcurrentHashMap&lt;String, ReferenceBeanInvocationHandler&gt;(CACHE_SIZE); /** * 使用属性进行注入的 @Reference Bean 的缓存 Map。（这种方式使用的较多） */ private final ConcurrentMap&lt;InjectionMetadata.InjectedElement, ReferenceBean&lt;?&gt;&gt; injectedFieldReferenceBeanCache = new ConcurrentHashMap&lt;InjectionMetadata.InjectedElement, ReferenceBean&lt;?&gt;&gt;(CACHE_SIZE); /** * 使用方法进行注入的 @Reference Bean 的缓存 Map */ private final ConcurrentMap&lt;InjectionMetadata.InjectedElement, ReferenceBean&lt;?&gt;&gt; injectedMethodReferenceBeanCache = new ConcurrentHashMap&lt;InjectionMetadata.InjectedElement, ReferenceBean&lt;?&gt;&gt;(CACHE_SIZE); /** * 应用上下文 */ private ApplicationContext applicationContext; /** * Gets all beans of &#123;@link ReferenceBean&#125; * * @return non-null read-only &#123;@link Collection&#125; * @since 2.5.9 */ public Collection&lt;ReferenceBean&lt;?&gt;&gt; getReferenceBeans() &#123; return referenceBeanCache.values(); &#125; /** * Get &#123;@link ReferenceBean&#125; &#123;@link Map&#125; in injected field. * * @return non-null &#123;@link Map&#125; * @since 2.5.11 */ public Map&lt;InjectionMetadata.InjectedElement, ReferenceBean&lt;?&gt;&gt; getInjectedFieldReferenceBeanMap() &#123; return Collections.unmodifiableMap(injectedFieldReferenceBeanCache); &#125; /** * Get &#123;@link ReferenceBean&#125; &#123;@link Map&#125; in injected method. * * @return non-null &#123;@link Map&#125; * @since 2.5.11 */ public Map&lt;InjectionMetadata.InjectedElement, ReferenceBean&lt;?&gt;&gt; getInjectedMethodReferenceBeanMap() &#123; return Collections.unmodifiableMap(injectedMethodReferenceBeanCache); &#125; // $&#123;省略其他代码&#125;&#125; 上面代码是扫描 @Reference 注解的后置处理器的属性信息，该类继承了AnnotationInjectedBeanPostProcessor抽象类，该类中有几个很重要的方法和类，它们属于Spring源码的知识点，为了使整个逻辑完整我们还是一起来看看。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147public abstract class AnnotationInjectedBeanPostProcessor&lt;A extends Annotation&gt; extends InstantiationAwareBeanPostProcessorAdapter implements MergedBeanDefinitionPostProcessor, PriorityOrdered, BeanFactoryAware, BeanClassLoaderAware, EnvironmentAware, DisposableBean &#123; // $&#123;省略其他的代码&#125; // 1. Bean后置处理器的回调方法 @Override public void postProcessMergedBeanDefinition(RootBeanDefinition beanDefinition, Class&lt;?&gt; beanType, String beanName) &#123; if (beanType != null) &#123; // 获取BeanType中的字段和方法上的注解，即对于Dubbo框架来说就是查找Bean所有标注了@Reference的字段和方法。 InjectionMetadata metadata = findInjectionMetadata(beanName, beanType, null); metadata.checkConfigMembers(beanDefinition); &#125; &#125; // 5. 创建Bean对象的过程中需要填充Bean对象的属性值，会调用该方法。即在Spring的Bean初始化前会触发该方法。 @Override public PropertyValues postProcessPropertyValues( PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName) throws BeanCreationException &#123; // 获取Bean对象的类中的字段和方法的注解对象 - AnnotatedInjectionMetadata，即对于Dubbo框架来说就是查找Bean所有标注了@Reference的字段和方法。 InjectionMetadata metadata = findInjectionMetadata(beanName, bean.getClass(), pvs); try &#123; // 调用AnnotatedInjectionMetadata的inject方法，对字段或方法进行反射绑定 metadata.inject(bean, beanName, pvs); &#125; catch (BeanCreationException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanCreationException(beanName, \"Injection of @\" + getAnnotationType().getName() + \" dependencies is failed\", ex); &#125; return pvs; &#125; /** * 4. 属性和方法注解包装对象 * &#123;@link A&#125; &#123;@link InjectionMetadata&#125; implementation */ private class AnnotatedInjectionMetadata extends InjectionMetadata &#123; // 字段注解对象集合 private final Collection&lt;AnnotatedFieldElement&gt; fieldElements; // 方法注解对象集合 private final Collection&lt;AnnotatedMethodElement&gt; methodElements; public AnnotatedInjectionMetadata(Class&lt;?&gt; targetClass, Collection&lt;AnnotatedFieldElement&gt; fieldElements, Collection&lt;AnnotatedMethodElement&gt; methodElements) &#123; super(targetClass, combine(fieldElements, methodElements)); this.fieldElements = fieldElements; this.methodElements = methodElements; &#125; public Collection&lt;AnnotatedFieldElement&gt; getFieldElements() &#123; return fieldElements; &#125; public Collection&lt;AnnotatedMethodElement&gt; getMethodElements() &#123; return methodElements; &#125; &#125; /** * 3. 方法注解 * &#123;@link A&#125; &#123;@link Method&#125; &#123;@link InjectionMetadata.InjectedElement&#125; */ private class AnnotatedMethodElement extends InjectionMetadata.InjectedElement &#123; // 方法对象 private final Method method; // 注解 private final A annotation; private volatile Object object; protected AnnotatedMethodElement(Method method, PropertyDescriptor pd, A annotation) &#123; super(method, pd); this.method = method; this.annotation = annotation; &#125; @Override protected void inject(Object bean, String beanName, PropertyValues pvs) throws Throwable &#123; // 获取属性类型 Class&lt;?&gt; injectedType = pd.getPropertyType(); // H偶去依赖 Object injectedObject = getInjectedObject(annotation, bean, beanName, injectedType, this); // 设置可访问 ReflectionUtils.makeAccessible(method); // 反射注入依赖 method.invoke(bean, injectedObject); &#125; &#125; /** * 2. 属性注解 * &#123;@link A&#125; &#123;@link Field&#125; &#123;@link InjectionMetadata.InjectedElement&#125; */ public class AnnotatedFieldElement extends InjectionMetadata.InjectedElement &#123; // 属性对象 private final Field field; // 注解 private final A annotation; private volatile Object bean; protected AnnotatedFieldElement(Field field, A annotation) &#123; super(field, null); this.field = field; this.annotation = annotation; &#125; @Override protected void inject(Object bean, String beanName, PropertyValues pvs) throws Throwable &#123; // 获取属性类型 Class&lt;?&gt; injectedType = field.getType(); // 获取依赖 Object injectedObject = getInjectedObject(annotation, bean, beanName, injectedType, this); // 设置可访问 ReflectionUtils.makeAccessible(field); // 反射设置值 field.set(bean, injectedObject); &#125; &#125;&#125;public class InjectionMetadata &#123; // $&#123;省略其他代码&#125; // 3. 遍历注入元素对象（可能是字段，也可能是方法），完成注入 public void inject(Object target, String beanName, PropertyValues pvs) throws Throwable &#123; // Collection&lt;InjectedElement&gt; elementsToIterate = (this.checkedElements != null ? this.checkedElements : this.injectedElements); if (!elementsToIterate.isEmpty()) &#123; boolean debug = logger.isDebugEnabled(); for (InjectedElement element : elementsToIterate) &#123; if (debug) &#123; logger.debug(\"Processing injected element of bean '\" + beanName + \"': \" + element); &#125; element.inject(target, beanName, pvs); &#125; &#125; &#125;&#125; 上面的代码执行的顺序已经标注，执行顺序比较粗略，先查找服务引用的字段或方法，然后触发字段或方法值的反射注入。但是目的已经达到了，从代码中我们可以看出注解信息已经收集完毕，接下来就是获取依赖对象了，找到依赖对象就可以通过反射注入，对于@Reference注解而言，获取依赖的方法就是 ReferenceAnnotationBeanPostProcessor#doGetInjectedBean。下面我们开始分析 ReferenceAnnotationBeanPostProcessor 中的逻辑。 获取要注入的依赖Bean 123456789101112131415161718192021222324252627282930313233343536373839public class ReferenceAnnotationBeanPostProcessor extends AnnotationInjectedBeanPostProcessor&lt;Reference&gt; implements ApplicationContextAware, ApplicationListener &#123; // $&#123;省略代码&#125; /** * 获得要注入的 依赖 * * @param reference @Reference注解 * @param bean @Reference注解标注属性或方法所在的类的对象 * @param beanName @Reference注解标注属性或方法所在的类的对象名称 * @param injectedType 要注入依赖的类型 * @param injectedElement 注入元信息 * @return * @throws Exception */ @Override protected Object doGetInjectedBean(Reference reference, Object bean, String beanName, Class&lt;?&gt; injectedType, InjectionMetadata.InjectedElement injectedElement) throws Exception &#123; // 1 获得要注入依赖的名字 String referencedBeanName = buildReferencedBeanName(reference, injectedType); // 2 创建ReferenceBean 对象 [比较复杂] ReferenceBean referenceBean = buildReferenceBeanIfAbsent(referencedBeanName, reference, injectedType, getClassLoader()); // 3 缓存到 injectedFieldReferenceBeanCache 或 injectedMethodReferenceBeanCache cacheInjectedReferenceBean(referenceBean, injectedElement); // 4 创建 Proxy 代理 Object proxy = buildProxy(referencedBeanName, referenceBean, injectedType); return proxy; &#125;// $&#123;省略代码&#125;&#125; doGetInjectedBean 方法主要完成以上4个流程，我们重点分析创建ReferenceBean和Proxy代理流程。 创建ReferenceBean对象 123456789101112131415161718192021222324252627282930313233343536public class ReferenceAnnotationBeanPostProcessor extends AnnotationInjectedBeanPostProcessor&lt;Reference&gt; implements ApplicationContextAware, ApplicationListener &#123; // $&#123;省略代码&#125;/** * 获得 ReferenceBean 对象 * * @param referencedBeanName * @param reference * @param referencedType * @param classLoader * @return * @throws Exception */ private ReferenceBean buildReferenceBeanIfAbsent(String referencedBeanName, Reference reference, Class&lt;?&gt; referencedType, ClassLoader classLoader) throws Exception &#123; // 先从缓存中获得referencedBeanName 对应的 ReferenceBean 对象 ReferenceBean&lt;?&gt; referenceBean = referenceBeanCache.get(referencedBeanName); // 如果不存在，则进行创建，然后添加到缓存中 if (referenceBean == null) &#123; ReferenceBeanBuilder beanBuilder = ReferenceBeanBuilder .create(reference, classLoader, applicationContext) // 引用类型作为接口类型 .interfaceClass(referencedType); // 创建ReferenceBean【1. 创建ReferenceBean对象 2.ReferenceBean 配置】 referenceBean = beanBuilder.build(); referenceBeanCache.put(referencedBeanName, referenceBean); &#125; return referenceBean; &#125;// $&#123;省略代码&#125;&#125; buildReferenceBeanIfAbsent 方法基本没有核心逻辑，所有的逻辑都封装在了 ReferenceBeanBuilder 中，它是ReferenceBean的构建器，我们继续跟进该类。 ReferenceBean对象的构建器 12345678910111213141516171819202122232425262728class ReferenceBeanBuilder extends AbstractAnnotationConfigBeanBuilder&lt;Reference, ReferenceBean&gt; &#123; /** * 将注解的属性设置到ReferenceBean，忽略以下属性，这些属性会单独处理 */ static final String[] IGNORE_FIELD_NAMES = of(\"application\", \"module\", \"consumer\", \"monitor\", \"registry\"); private ReferenceBeanBuilder(Reference annotation, ClassLoader classLoader, ApplicationContext applicationContext) &#123; super(annotation, classLoader, applicationContext); &#125; // $&#123;省略其他代码&#125; /** * 创建ReferenceBeanBuilder * * @param annotation * @param classLoader * @param applicationContext * @return */ public static ReferenceBeanBuilder create(Reference annotation, ClassLoader classLoader, ApplicationContext applicationContext) &#123; // 创建 ReferenceBean 的构建器 return new ReferenceBeanBuilder(annotation, classLoader, applicationContext); &#125;&#125;` 由于很多属性都在其父类 AbstractAnnotationConfigBeanBuilder 中，如上面的interfaceClass，以及很重要的build方法。我们再分析下该类。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950abstract class AbstractAnnotationConfigBeanBuilder&lt;A extends Annotation, B extends AbstractInterfaceConfig&gt; &#123; protected final Log logger = LogFactory.getLog(getClass()); /** * 注解 */ protected final A annotation; /** * 应用上下文 */ protected final ApplicationContext applicationContext; /** * 类加载器 */ protected final ClassLoader classLoader; /** * Bean 对象 */ protected Object bean; /** * 接口 */ protected Class&lt;?&gt; interfaceClass; // 构造方法 protected AbstractAnnotationConfigBeanBuilder(A annotation, ClassLoader classLoader, ApplicationContext applicationContext) &#123; Assert.notNull(annotation, \"The Annotation must not be null!\"); Assert.notNull(classLoader, \"The ClassLoader must not be null!\"); Assert.notNull(applicationContext, \"The ApplicationContext must not be null!\"); this.annotation = annotation; this.applicationContext = applicationContext; this.classLoader = classLoader; &#125; public &lt;T extends AbstractAnnotationConfigBeanBuilder&lt;A, B&gt;&gt; T bean(Object bean) &#123; this.bean = bean; return (T) this; &#125; // 设置接口 public &lt;T extends AbstractAnnotationConfigBeanBuilder&lt;A, B&gt;&gt; T interfaceClass(Class&lt;?&gt; interfaceClass) &#123; this.interfaceClass = interfaceClass; return (T) this; &#125; // $&#123;省略其他代码&#125; &#125; 以上代码比较简单，只需注意设置的接口即可，下面我们分析创建ReferenceBean的build方法。 123456789101112131415161718192021222324252627282930313233abstract class AbstractAnnotationConfigBeanBuilder&lt;A extends Annotation, B extends AbstractInterfaceConfig&gt; &#123; // $&#123;省略其他代码&#125; /** * Build &#123;@link B&#125; 构造泛型B对象，此处就是构造ReferenceBean对象 * * @return non-null * @throws Exception */ public final B build() throws Exception &#123; /** * 1. 校验依赖，目前是个空方法 */ checkDependencies(); // 2. 创建 Bean 对象，具体实现交给子类 B bean = doBuild(); // 3. 配置Bean 对象 configureBean(bean); if (logger.isInfoEnabled()) &#123; logger.info(\"The bean[type:\" + bean.getClass().getSimpleName() + \"] has been built.\"); &#125; return bean; &#125; // $&#123;省略其他代码&#125;&#125; 以上代码使用了模版方法模式，我们先看doBuild()方法的具体实现，然后再分析配置Bean对象的逻辑。 123456789101112131415161718class ReferenceBeanBuilder extends AbstractAnnotationConfigBeanBuilder&lt;Reference, ReferenceBean&gt; &#123; // $&#123;省略其他代码&#125; /** * ReferenceBeanBuilder#build的方法调用，用来创建Reference对象。【对父类方法的重写】 * * @return */ @Override protected ReferenceBean doBuild() &#123; // 创建 ReferenceBean对象 return new ReferenceBean&lt;Object&gt;(); &#125; // $&#123;省略其他代码&#125;&#125; 一行代码就搞定了，直接创建ReferenceBean对象，我们接着分析配置Bean逻辑。 12345678910111213141516171819202122232425262728293031323334353637383940414243abstract class AbstractAnnotationConfigBeanBuilder&lt;A extends Annotation, B extends AbstractInterfaceConfig&gt; &#123; // $&#123;省略其他代码&#125; /** * 配置ReferenceBean对象 * @param bean * @throws Exception */ protected void configureBean(B bean) throws Exception &#123; /** * 前置配置Bean逻辑，具体实现交给子类 */ preConfigureBean(annotation, bean); /** * 尝试从Spring中获取@Reference注解中配置的registry属性值对应的RegistryConfig对象集合，然后设置到的ReferenceBean对象的registries属性中 */ configureRegistryConfigs(bean); /** * 设置ReferenceBean的monitor属性，原理同上 */ configureMonitorConfig(bean); /** * 设置ReferenceBean的application属性，原理同上 */ configureApplicationConfig(bean); /** * 设置 ReferenceBean的module属性，原理同上 */ configureModuleConfig(bean); /** * 后置配置Bean逻辑，具体实现交给子类 */ postConfigureBean(annotation, bean); &#125; // $&#123;省略其他代码&#125;&#125; 上面代码也是使用模版方法模式，其中ReferenceBean的registries、monitor、application、module属性的值是通过该方法进行设置的，前置配置Bean和后置配置Bean的逻辑是由子类实现的，我们继续跟进去。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566class ReferenceBeanBuilder extends AbstractAnnotationConfigBeanBuilder&lt;Reference, ReferenceBean&gt; &#123; // $&#123;省略其他代码&#125; /** * ReferenceBean 的前置配置 * @param reference * @param referenceBean */ @Override protected void preConfigureBean(Reference reference, ReferenceBean referenceBean) &#123; Assert.notNull(interfaceClass, \"The interface class must set first!\"); // 创建DataBinder对象,将ReferenceBean包装成DataBinder,进行属性绑定，绑定到的对象就是ReferenceBean DataBinder dataBinder = new DataBinder(referenceBean); // Register CustomEditors for special fields // 注册指定属性的自定义Editor dataBinder.registerCustomEditor(String.class, \"filter\", new StringTrimmerEditor(true)); dataBinder.registerCustomEditor(String.class, \"listener\", new StringTrimmerEditor(true)); dataBinder.registerCustomEditor(Map.class, \"parameters\", new PropertyEditorSupport() &#123; public void setAsText(String text) throws java.lang.IllegalArgumentException &#123; // Trim all whitespace String content = StringUtils.trimAllWhitespace(text); if (!StringUtils.hasText(content)) &#123; // No content , ignore directly return; &#125; // replace \"=\" to \",\" content = StringUtils.replace(content, \"=\", \",\"); // replace \":\" to \",\" content = StringUtils.replace(content, \":\", \",\"); // String[] to Map Map&lt;String, String&gt; parameters = CollectionUtils.toStringMap(commaDelimitedListToStringArray(content)); setValue(parameters); &#125; &#125;); /** Bind annotation attributes 将注解的属性设置到ReferenceBean中，排除 &#123;@link IGNORE_FIELD_NAMES&#125; 属性，这些属性后续单独处理 &#123;@link AbstractAnnotationConfigBeanBuilder#configureBean(com.alibaba.dubbo.config.AbstractInterfaceConfig) */ dataBinder.bind(new AnnotationPropertyValuesAdapter(reference, applicationContext.getEnvironment(), IGNORE_FIELD_NAMES)); &#125; /** * ReferenceBean 的后置配置 * * @param annotation * @param bean * @throws Exception */ @Override protected void postConfigureBean(Reference annotation, ReferenceBean bean) throws Exception &#123; // 设置 Spring 上下文到 ReferenceBean 中，并且 将 Dubbo 和 Spring容器打通，即 设置SpringExtensionFactory中的上下文 bean.setApplicationContext(applicationContext); // 配置服务接口 configureInterface(annotation, bean); // 尝试从Spring中获取@Reference注解中配置的consumer属性值对应的ConsumerConfig对象，然后设置到的ReferenceBean对象的consumer属性中 configureConsumerConfig(annotation, bean); // 主动触发 ReferenceBean 的 afterPropertiesSet 方法 bean.afterPropertiesSet(); &#125; // $&#123;省略其他代码&#125;&#125; 至此，创建ReferenceBean对象分析完毕，我们再回过头分析 ReferenceAnnotationBeanPostProcessor#doGetInjectedBean 方法中的创建 Proxy 对象的逻辑。 创建Proxy对象 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class ReferenceAnnotationBeanPostProcessor extends AnnotationInjectedBeanPostProcessor&lt;Reference&gt; implements ApplicationContextAware, ApplicationListener &#123; // $&#123;省略代码&#125; /** * 创建Proxy代理对象 * * @param referencedBeanName * @param referenceBean * @param injectedType * @return */ private Object buildProxy(String referencedBeanName, ReferenceBean referenceBean, Class&lt;?&gt; injectedType) &#123; // 1. 创建ReferenceBeanInvocationHandler对象 InvocationHandler handler = buildInvocationHandler(referencedBeanName, referenceBean); // 2. 使用JDK的动态代理创建服务接口的代理对象 Object proxy = Proxy.newProxyInstance(getClassLoader(), new Class[]&#123;injectedType&#125;, handler); return proxy; &#125; /** * 创建ReferenceBeanInvocationHandler对象 * * @param referencedBeanName 注入依赖的名字，即服务的名称 * @param referenceBean ReferenceBean对象 * @return */ private InvocationHandler buildInvocationHandler(String referencedBeanName, ReferenceBean referenceBean) &#123; // 从缓存中获取对应的 handler对象 ReferenceBeanInvocationHandler handler = localReferenceBeanInvocationHandlerCache.get(referencedBeanName); // 不存在则创建ReferenceBean的 InvocationHandler 对象 if (handler == null) &#123; handler = new ReferenceBeanInvocationHandler(referenceBean); &#125; // 如果应用上下文中已经初始化了，说明引入的服务是本地的@Service Bean ，则将引入的Dubbo服务的InvocationHandler添加到本地缓存中，不进行初始化（要想初始化，引入的服务必须是已经暴露的状态） if (applicationContext.containsBean(referencedBeanName)) &#123; // ReferenceBeanInvocationHandler's initialization has to wait for current local @Service Bean has been exported. localReferenceBeanInvocationHandlerCache.put(referencedBeanName, handler); &#125; else &#123; // 如果应用上下文中没有，则说明是引入的是远程的服务对象，则立即初始化 handler.init(); &#125; return handler; &#125;// $&#123;省略代码&#125;&#125; 以上代码只做了一件事情，为服务接口创建一个代理对象，创建代理对象是使用JDK的动态代理。其中代理对象的执行逻辑封装在ReferenceBeanInvocationHandler对象中，下面我们就来详细分析该Handler。 ReferenceBeanInvocationHandler 1234567891011121314151617181920212223242526272829303132/** * 实现了 Dubbo 的 InvocationHandler接口 */ private static class ReferenceBeanInvocationHandler implements InvocationHandler &#123; /** * ReferenceBean对象 */ private final ReferenceBean referenceBean; /** * Bean 对象(引用的服务) */ private Object bean; private ReferenceBeanInvocationHandler(ReferenceBean referenceBean) &#123; this.referenceBean = referenceBean; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; // 调用 Bean 的对应的方法 return method.invoke(bean, args); &#125; /** * 1 通过初始化方法，获得 ReferenceBean.ref (引用的服务)，即代理对象 * 2 调用ReferenceBean#get()方法，进行引用的Bean的初始化，最后返回服务接口代理对象 */ private void init() &#123; this.bean = referenceBean.get(); &#125; &#125; ReferenceBeanInvocationHandler是ReferenceAnnotationBeanPostProcessor的静态内部类，实现了InvocationHander接口。其中referenceBean属性值是通过构造方法设置的，bean属性的值就是引用的服务，即服务接口代理对象。invoke方法是回调方法，当消费方通过创建的proxy调用服务方法就会回调。至此，@Reference 所需要的依赖已经创建完毕，通过反射设置到所需组件中即可。 Dubbo注解配置流程总结 前面已经详细分析Dubbo注解配置的流程，这里进行小结。Dubbo的注解解析机制主要依赖上图中的核心组件。如果用户使用了配置文件，则Dubbo框架按需生成对应的Bean。Dubbo框架会将所有使用Dubbo的注解@Service标注的类提升为Bean，为使用@Reference注解的字段或方法注入代理对象。 总结代码量远比预计得多，写的还是有点混乱的。从代码整个流程可以看出，虽然注解使用更加简洁、方便，但是背后的工作一点都没有少，甚至更多更复杂。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"Dubbo源码分析 - XML配置","slug":"rpc/xml配置","date":"2020-03-28T16:00:00.000Z","updated":"2020-09-03T03:12:53.638Z","comments":false,"path":"posts/a8d76a91/","link":"","permalink":"https://gentryhuang.com/posts/a8d76a91/","excerpt":"","text":"前言在 Dubbo源码分析 - API和属性配置 中介绍了Dubbo的配置承载对象，分析了核心的配置类及方法。了解了API配置后XML配置就容易多了，XML配置相比较API配置的区别在配置对象创建及其属性的设置是由Spring管理的，Dubbo和Spring XML融合是关键。 Dubbo和Spring融合Dubbo框架直接集成了Spring的能力，利用Spring配置文件扩展出自定义的解析方式，即使用Spring的自定标签。关于Spring自定标签的示例，在Spring自定义标签 中有详细介绍，Dubbo基于schema的设计也是如此，下面我们就来分析下Dubbo是怎么和Spring融合的。 Dubbo的配置对象模型Dubbo的配置对象模型已经在 [Dubbo源码分析 - API和属性配置] 中详细介绍过了，在Dubbo的命名空间处理器中也可以具体看到哪些配置类和Spring进行交互，这里就不再介绍。 Dubbo的xsd文件dubbo.xsd文件是用来约束使用XML配置时的标签和对应的属性，如Dubbo中的&lt;dubbo:service&gt;标签等。由于当前分析的dubbo版本是2.6.5，Dubbo已经捐给了Apache组织，为了遵循Apache标准和兼容Dubbo原来的版本，会出现两个xsd文件，这篇文章还是按照Dubbo原来的版本进行相关描述。 dubbo.xsd总览 Dubbo设计的粒度很多都是针对方法级别的，如方法级别的timeout、retries等特性。具体的每个复杂类型的详细使用可以参考:官方文档 dubbo.xsd中的类型关系 上图的类型继承关系和Dubbo的配置类之间的关系几乎保持一致，因为这里定义的复杂类型就是要映射到配置类的属性上，即schema中的字段对应Config类中的属性和get/set方法。 Dubbo的spring.schemas文件12http\\:&#x2F;&#x2F;dubbo.apache.org&#x2F;schema&#x2F;dubbo&#x2F;dubbo.xsd&#x3D;META-INF&#x2F;dubbo.xsdhttp\\:&#x2F;&#x2F;code.alibabatech.com&#x2F;schema&#x2F;dubbo&#x2F;dubbo.xsd&#x3D;META-INF&#x2F;compat&#x2F;dubbo.xsd spring.schemas文件用来指明约束文件的具体路径。 Dubbo的spring.handlers12http\\:&#x2F;&#x2F;dubbo.apache.org&#x2F;schema&#x2F;dubbo&#x3D;com.alibaba.dubbo.config.spring.schema.DubboNamespaceHandlerhttp\\:&#x2F;&#x2F;code.alibabatech.com&#x2F;schema&#x2F;dubbo&#x3D;com.alibaba.dubbo.config.spring.schema.DubboNamespaceHandler spring.handlers文件用来指明Dubbo的XML命名空间处理器，即使用DubboNamespaceHandler来解析Dubbo自定义的标签。 Dubbo的DubboNamespaceHandler123456789101112131415161718192021222324public class DubboNamespaceHandler extends NamespaceHandlerSupport &#123; static &#123; Version.checkDuplicate(DubboNamespaceHandler.class); &#125; /** * 方法中定义了每个&lt;xsd:element/&gt;对应的BeanDefinitionParser 【Dubbo Bean定义解析器】 */ @Override public void init() &#123; registerBeanDefinitionParser(\"application\", new DubboBeanDefinitionParser(ApplicationConfig.class, true)); registerBeanDefinitionParser(\"module\", new DubboBeanDefinitionParser(ModuleConfig.class, true)); registerBeanDefinitionParser(\"registry\", new DubboBeanDefinitionParser(RegistryConfig.class, true)); registerBeanDefinitionParser(\"monitor\", new DubboBeanDefinitionParser(MonitorConfig.class, true)); registerBeanDefinitionParser(\"provider\", new DubboBeanDefinitionParser(ProviderConfig.class, true)); registerBeanDefinitionParser(\"consumer\", new DubboBeanDefinitionParser(ConsumerConfig.class, true)); registerBeanDefinitionParser(\"protocol\", new DubboBeanDefinitionParser(ProtocolConfig.class, true)); registerBeanDefinitionParser(\"service\", new DubboBeanDefinitionParser(ServiceBean.class, true)); registerBeanDefinitionParser(\"reference\", new DubboBeanDefinitionParser(ReferenceBean.class, false)); // 注解已经重写，AnnotationBeanDefinitionParser 已经废弃，即@DubboComponentScan 作为 Dubbo 2.5.7 新增的 Annotation，是XML 元素 &lt;dubbo:annotation&gt; 的替代方案。 registerBeanDefinitionParser(\"annotation\", new AnnotationBeanDefinitionParser()); &#125;&#125; Dubbo解析配置的入口是在 DubboNamespaceHandler类中完成的，该类主要把不同的标签关联到解析实现类中，registerBeanDefinitionParser方法约定在遇到Dubbo自定的标签如application、registry、protocol等都会委托给Dubbo的命名空间处理器DubboNamespaceHandler处理，该处理器又会把解析任务交给DubboBeanDefinitionParser来处理。 Dubbo的DubboBeanDefinitionParser实现了Spring的BeanDefinitionParser接口，是真正用来解析自定的Dubbo标签，将标签解析成对应的Bean定义并注册到Spring上下文中。 使用Dubbo标签123456789101112131415161718192021222324&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://dubbo.apache.org/schema/dubbo\" xmlns=\"http://www.springframework.org/schema/beans\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.3.xsd http://dubbo.apache.org/schema/dubbo http://dubbo.apache.org/schema/dubbo/dubbo.xsd\"&gt; &lt;!-- provider's application name, used for tracing dependency relationship --&gt; &lt;dubbo:application name=\"demo-provider\" owner=\"gentryhuang\"/&gt; &lt;!-- use multicast registry center to export service --&gt; &lt;!--&lt;dubbo:registry address=\"multicast://224.5.6.7:1234\" protocol=\"test\"/&gt; --&gt; &lt;dubbo:registry address=\"zookeeper://127.0.0.1:2181\"/&gt; &lt;!-- use dubbo protocol to export service on port 20880 --&gt; &lt;dubbo:protocol name=\"dubbo\" port=\"20880\"/&gt; &lt;!-- service implementation, as same as regular local bean --&gt; &lt;bean id=\"demoService\" class=\"com.alibaba.dubbo.demo.provider.DemoServiceImpl\"/&gt; &lt;!-- declare the service interface to be exported --&gt; &lt;dubbo:service interface=\"com.alibaba.dubbo.demo.DemoService\" ref=\"demoService\"/&gt;&lt;/beans&gt; 小结以上就是Dubbo和Spring的XML配置进行融合的过程，与 Spring自定义标签 文章中的流程是一样的。总的来说，Dubbo框架先以流的形式装载Spring的XML配置文件，在将流解析成DOM的过程中会加载spring.schemas文件，然后读取该文件中指定的的xsd约束文件，接着使用xsd中的约束规则对每个标签及其属性进行校验，不合法则抛出异常，整个配置文件符合约束规则则生成DOM对象。和spring.handlers文件。spring.schema文件指定了配置约束文件的位置，加载spring.schemas文件的目的就是用来校验Spring的XML配置文件内容是否合法。加载spring.handlers文件的目的是，当解析Spring的XML配置文件中的标签时,会查找该文件中指定的DubboNamespaceHandler类来进行自定义标签的初始化和解析。 解析准备加载 spring.schemas 文件12345678910111213141516AbstractXmlApplicationContext#loadBeanDefinitions(org.springframework.beans.factory.support.DefaultListableBeanFactory)&#123; // Create a new XmlBeanDefinitionReader for the given BeanFactory. XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); // Configure the bean definition reader with this context's // resource loading environment. beanDefinitionReader.setEnvironment(this.getEnvironment()); beanDefinitionReader.setResourceLoader(this); // 设置 'META-INF/spring.schemas' 到 ResourceEntityResolver beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this)); // Allow a subclass to provide custom initialization of the reader, // then proceed with actually loading the bean definitions. initBeanDefinitionReader(beanDefinitionReader); loadBeanDefinitions(beanDefinitionReader);&#125; 上面代码就设置 spring.schemas 文件路径，为接下来加载 spring.schemas 文件做准备。 123456789XmlBeanDefinitionReader#doLoadBeanDefinitions(InputSource inputSource, Resource resource)&#123; try &#123; // 加载 META-INF/spring.schemas 中xsd文件，在构建Dom时进行校验XML配置内容是否正确 Document doc = doLoadDocument(inputSource, resource); // 加载 META-INF/spring.handlers 中的命名空间处理器，初始化并放入缓存 return registerBeanDefinitions(doc, resource); &#125; // 省略无关代码&#125; 上面的代码是注册XML中的Bean的大流程入口，分别是加载 META-INF/spring.schemas 中xsd文件，用于构建DOM时校验XML配置内容是否正确，加载 META-INF/spring.handlers 中的命名空间处理器，用于处理标签和BeanDefinitionParser的映射关系以及解析标签。下面我们来看Spring是如何加载spring.schemas文件内容的。 12345678910111213141516171819202122232425PluggableSchemaResolver#getSchemaMappings()&#123; if (this.schemaMappings == null) &#123; synchronized (this) &#123; if (this.schemaMappings == null) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Loading schema mappings from [\" + this.schemaMappingsLocation + \"]\"); &#125; try &#123; // 从 META-INF/spring.schemas 中读取xsd文件路径 Properties mappings = PropertiesLoaderUtils.loadAllProperties(this.schemaMappingsLocation, this.classLoader); if (logger.isDebugEnabled()) &#123; logger.debug(\"Loaded schema mappings: \" + mappings); &#125; Map&lt;String, String&gt; schemaMappings = new ConcurrentHashMap&lt;String, String&gt;(mappings.size()); // 放入缓存中 CollectionUtils.mergePropertiesIntoMap(mappings, schemaMappings); this.schemaMappings = schemaMappings; &#125;catch (IOException ex) &#123; throw new IllegalStateException(\"Unable to load schema mappings from location [\" + this.schemaMappingsLocation + \"]\", ex); &#125; &#125; &#125; &#125; return this.schemaMappings;&#125; 12345678910111213141516171819202122232425262728/** * @param publicId * @param systemId */PluggableSchemaResolver#resolveEntity(String publicId, String systemId)&#123; if (systemId != null) &#123; // 根据 spring.schemas中配置的xxx.xsd找到对应的xsd文件 String resourceLocation = getSchemaMappings().get(systemId); if (resourceLocation != null) &#123; // 加载xsd文件 Resource resource = new ClassPathResource(resourceLocation, this.classLoader); try &#123; InputSource source = new InputSource(resource.getInputStream()); source.setPublicId(publicId); source.setSystemId(systemId); if (logger.isDebugEnabled()) &#123; logger.debug(\"Found XML schema [\" + systemId + \"] in classpath: \" + resourceLocation); &#125; return source; &#125;catch (FileNotFoundException ex) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Couldn't find XML schema [\" + systemId + \"]: \" + resource, ex); &#125; &#125; &#125; &#125; return null;&#125; 以上就是Spring在启动时加载spring.schemas中配置的xsd文件的几个代码片段，将XML配置文件解析成DOM的过程中，对每个标签及其属性进行校验，依据就是xsd中的约束条件。由于是Spring的源码部分，这里不进行深入分析，感兴趣的胖友可以自行调试。 加载 spring.handlers 文件123456789101112/** * @param doc 配置文件对应的DOM对象 * @param resource 配置文件资源对象 */XmlBeanDefinitionReader#registerBeanDefinitions(Document doc, Resource resource)&#123; // 创建Bean定义的DOMReader，用来读取、解析DOM，接着创建对应的Bean BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader(); int countBefore = getRegistry().getBeanDefinitionCount(); // 读取、解析DOM、创建对应的Bean documentReader.registerBeanDefinitions(doc, createReaderContext(resource)); return getRegistry().getBeanDefinitionCount() - countBefore;&#125; registerBeanDefinitions方法是将Spring的XML配置文件中定义的有关标签进行创建并注册到Spring的注册表中。注意，这里所说的能够创建Bean的有关标签必须有对应的BeanDefinitionParser，否则不会对该标签进行处理。 1234567891011121314/** * @param resource 配置文件资源对象 */XmlBeanDefinitionReader#createReaderContext(Resource resource)&#123; return new XmlReaderContext( resource, this.problemReporter, this.eventListener, this.sourceExtractor, this, // 读取 META-INF/spring.handlers 文件 getNamespaceHandlerResolver() );&#125; createReaderContext 方法用来创建 XmlReaderContext，该对象中包含的核心属性如下： 由XmlReaderContext对象中的属性可知，在创建该对象的过程中对 META-INF/spring.handlers 文件进行了读取。现在有了配置文件的DOM对象、Bean定义工厂以及spring.handlers文件中各种NamespaceHandler，接下来就可以解析DOM树，创建并注册相应的Bean。 12345678DefaultBeanDefinitionDocumentReader#registerBeanDefinitions(Document doc, XmlReaderContext readerContext)&#123; this.readerContext = readerContext; logger.debug(\"Loading bean definitions\"); // 获取DOM的根元素，一般是 beans Element root = doc.getDocumentElement(); // 解析入口 doRegisterBeanDefinitions(root);&#125; 上面的代码主要是获取DOM对象的根元素，然后以这个根元素作为起点进行解析，下面我们接着解析代码。 123456789101112131415161718192021222324252627282930/*** Parse the elements at the root level in the document:* \"import\", \"alias\", \"bean\".* @param root DOM的根元素* @param delegate Bean定义解析器代理*/DefaultBeanDefinitionDocumentReader#parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) &#123; // 判读根元素是不是默认的命名空间 'http://www.springframework.org/schema/beans' if (delegate.isDefaultNamespace(root)) &#123; // 获取根元素下的子元素列表 NodeList nl = root.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); // 判断是否是元素 if (node instanceof Element) &#123; Element ele = (Element) node; // 当前元素的命名空间如果是默认的命名空间即Spring自身的命名空间，则通过Spring自身逻辑进行解析 if (delegate.isDefaultNamespace(ele)) &#123; parseDefaultElement(ele, delegate); &#125; // 当前元素的命名空间非默认的命名空间即自定义的标签，则通过自定义逻辑进行解析 else &#123; delegate.parseCustomElement(ele); &#125; &#125; &#125; &#125;else &#123; delegate.parseCustomElement(root); &#125;&#125; 上面代码的主要逻辑是判断要解析的DOM元素即标签，是否是Spring内置的，如果是Spring内置则整个解析逻辑使用Spring自身的那一套，如果是自定义的，则解析逻辑交给开发者。Spring自身的解析逻辑忽略，下面我们来分析下自定义的标签的处理流程。 1234567891011121314151617181920BeanDefinitionParserDelegate#parseCustomElement(org.w3c.dom.Element ele)&#123; return parseCustomElement(ele, null);&#125;/** * @param ele DOM的根元素 * @param containingBd */BeanDefinitionParserDelegate#parseCustomElement(org.w3c.dom.Element ele, org.springframework.beans.factory.config.BeanDefinition containingBd)&#123; // 获取元素即标签的命名空间 String namespaceUri = getNamespaceURI(ele); // 使用 XmlReaderContext中的 DefaultNamespaceHandlerResolver获取命名空间对应的 NamespaceHandler对象 NamespaceHandler handler = this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri); if (handler == null) &#123; error(\"Unable to locate Spring NamespaceHandler for XML schema namespace [\" + namespaceUri + \"]\", ele); return null; &#125; // 使用 NamespaceHandler 对象解析标签 return handler.parse(ele, new ParserContext(this.readerContext, this, containingBd));&#125; 上面代码先是获取当前元素的命名空间，然后通过该命名空间获取对应 NamespaceHandler对象，最后通过该对象解析当前元素。下面我们依次分析这两个步骤的代码。 1234567891011121314151617181920212223242526272829303132333435363738DefaultNamespaceHandlerResolver#resolve(String namespaceUri)&#123;// 获取 DefaultNamespaceHandlerResolver#handlerMappings属性，即命名空间到NamespaceHandler的映射，注意这里的NamespaceHandler可能是还没有进行实例化的字符串 Map&lt;String, Object&gt; handlerMappings = getHandlerMappings();// 从缓存中获取 NamespaceHandler Object handlerOrClassName = handlerMappings.get(namespaceUri); if (handlerOrClassName == null) &#123; return null; &#125;// 如果当前命名空间对应的 NamespaceHandler 就是 NamespaceHandler对象，则需要进行实例化，直接返回即可 else if (handlerOrClassName instanceof NamespaceHandler) &#123; return (NamespaceHandler) handlerOrClassName; &#125; // 当前命名空间对应的 NamespaceHandler 还是字符串，需要反射创建对象 else &#123; String className = (String) handlerOrClassName; try &#123; // 获取当前 当前命名空间对应的 NamespaceHandler 串 的 Class Class&lt;?&gt; handlerClass = ClassUtils.forName(className, this.classLoader); if (!NamespaceHandler.class.isAssignableFrom(handlerClass)) &#123; throw new FatalBeanException(\"Class [\" + className + \"] for namespace [\" + namespaceUri + \"] does not implement the [\" + NamespaceHandler.class.getName() + \"] interface\"); &#125; // 创建对象 NamespaceHandler namespaceHandler = (NamespaceHandler) BeanUtils.instantiateClass(handlerClass); // 执行 init 方法，进行标签和BeanDefinitionParser 的关联 namespaceHandler.init(); // 加入缓存 handlerMappings.put(namespaceUri, namespaceHandler); return namespaceHandler; &#125;catch (ClassNotFoundException ex) &#123; throw new FatalBeanException(\"NamespaceHandler class [\" + className + \"] for namespace [\" + namespaceUri + \"] not found\", ex); &#125;catch (LinkageError err) &#123; throw new FatalBeanException(\"Invalid NamespaceHandler class [\" + className + \"] for namespace [\" + namespaceUri + \"]: problem with handler class file or dependent class\", err); &#125; &#125;&#125; 上面代码核心是获取当前命名空间对应的 NamespaceHandler ，如果 NamespaceHandler 还是个字符串，那么就通过反射创建对象，接着调用该对象的 init(),进行标签和 BeanDefinitionParser 的关联 ，方法如果已经创建过了对象则直接返回该 NamespaceHandler 对象。由于Dubbo自定义标签的命名空间对应的NamespaceHandler是 DubboNamespaceHandler，我们在前面已经分析过了它的源码，这里再详细说明下。 1234567891011121314151617181920212223public class DubboNamespaceHandler extends NamespaceHandlerSupport &#123; static &#123; Version.checkDuplicate(DubboNamespaceHandler.class); &#125; /** * 方法中定义了每个&lt;xsd:element/&gt;对应的BeanDefinitionParser 【Dubbo Bean定义解析器】 */ @Override public void init() &#123; registerBeanDefinitionParser(\"application\", new DubboBeanDefinitionParser(ApplicationConfig.class, true)); registerBeanDefinitionParser(\"module\", new DubboBeanDefinitionParser(ModuleConfig.class, true)); registerBeanDefinitionParser(\"registry\", new DubboBeanDefinitionParser(RegistryConfig.class, true)); registerBeanDefinitionParser(\"monitor\", new DubboBeanDefinitionParser(MonitorConfig.class, true)); registerBeanDefinitionParser(\"provider\", new DubboBeanDefinitionParser(ProviderConfig.class, true)); registerBeanDefinitionParser(\"consumer\", new DubboBeanDefinitionParser(ConsumerConfig.class, true)); registerBeanDefinitionParser(\"protocol\", new DubboBeanDefinitionParser(ProtocolConfig.class, true)); registerBeanDefinitionParser(\"service\", new DubboBeanDefinitionParser(ServiceBean.class, true)); registerBeanDefinitionParser(\"reference\", new DubboBeanDefinitionParser(ReferenceBean.class, false)); registerBeanDefinitionParser(\"annotation\", new AnnotationBeanDefinitionParser()); &#125;&#125; 上面的代码比较直观，一个标签对应一个 DubboBeanDefinitionParser 对象，同时也对应这一个Dubbo的配置承载类。我们接下主要看registerBeanDefinitionParser方法是怎么把标签和DubboBeanDefinitionParser关联到一起的。 1234567891011121314public abstract class NamespaceHandlerSupport implements NamespaceHandler &#123; /** * 标签名 到 BeanDefinitionParser 映射集合 */ private final Map&lt;String, BeanDefinitionParser&gt; parsers = new HashMap&lt;String, BeanDefinitionParser&gt;(); /** * 关联 标签名 到 BeanDefinitionParser */ protected final void registerBeanDefinitionParser(String elementName, BeanDefinitionParser parser) &#123; this.parsers.put(elementName, parser); &#125;&#125; 原来如此简单，就是调用父类 NamespaceHandlerSupport 的registerBeanDefinitionParser方法，将标签名到BeanDefinitionParser的映射保存到缓存中。到了这里所有解析前的工作已经准备就绪，终于可以进入到这篇文章的核心部分了。之所以用了那么多的铺垫，就是想把整个过程串起来，如果一下子进入到Dubbo自定义标签的解析感觉还是挺奇怪的，毕竟笔者对Spring的源码也不熟悉，就按部就班吧。 解析标签解析准备是特意为解析标签做的铺垫，有了这个铺垫下面的解析逻辑就容易很多了。我们接着解析准备中的 parseCustomElement 方法继续分析。 123456789101112public BeanDefinition parseCustomElement(Element ele, BeanDefinition containingBd) &#123; // 1. 获取DOM元素即标签对应的命名空间 String namespaceUri = getNamespaceURI(ele); // 2. 获取命名空间映射的 NamespaceHandler对象 NamespaceHandler handler = this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri); if (handler == null) &#123; error(\"Unable to locate Spring NamespaceHandler for XML schema namespace [\" + namespaceUri + \"]\", ele); return null; &#125; // 3. 调用 NamespaceHandler对象 的parse方法进行解析 return handler.parse(ele, new ParserContext(this.readerContext, this, containingBd));&#125; 上面代码中的第3步才正式进入到标签的解析，这里的 NamespaceHandler 就 DubboNamespaceHandler对象，parse 方法是其父类 NamespaceHandlerSupport 中的方法，我们来看看逻辑。 123456789101112131415161718192021 @Overridepublic BeanDefinition parse(Element element, ParserContext parserContext) &#123; /* * 1. 获取标签的名称关联的 BeanDefinitionParser * 2. 使用 BeanDefinitionParser解析标签 */ return findParserForElement(element, parserContext).parse(element, parserContext);&#125;private BeanDefinitionParser findParserForElement(Element element, ParserContext parserContext) &#123; // 获取标签名 String localName = parserContext.getDelegate().getLocalName(element); // 从缓存中获取标签名对应的 BeanDefinitionParser对象，即 DubboBeanDefinitionParser对象 BeanDefinitionParser parser = this.parsers.get(localName); if (parser == null) &#123; parserContext.getReaderContext().fatal( \"Cannot locate BeanDefinitionParser for element [\" + localName + \"]\", element); &#125; return parser;&#125; 上面代码就是从 标签名 到 BeanDefinitionParser 映射集合parsers中获取标签名对应的BeanDefinitionParser对象，该映射集合是在 DubboNamespaceHandler#init 方法执行时维护的。下面我们接着分析DubboBeanDefinitionParser类。 Dubbo Bean定义解析器1234567891011121314151617181920212223242526272829303132333435public class DubboBeanDefinitionParser implements BeanDefinitionParser &#123; /** * 标签元素对应的对象类 */ private final Class&lt;?&gt; beanClass; /** * 是否需要Bean的 id 属性 */ private final boolean required; /** * @param beanClass Bean 对象的类 * @param required 是否需要在Bean对象的编号（id）不存在时自动生成编号。无需被其他应用引用的配置对象，无需自动生成编号。 eg：&lt;dubbo:reference/&gt; */ public DubboBeanDefinitionParser(Class&lt;?&gt; beanClass, boolean required) &#123; this.beanClass = beanClass; this.required = required; &#125; /** * Spring解析标签的入口方法 * * @param element 标签元素对象 * @param parserContext 解析上下文 * @return */ @Override public BeanDefinition parse(Element element, ParserContext parserContext) &#123; return parse(element, parserContext, beanClass, required); &#125; // $&#123;省略的代码&#125; &#125; DubboBeanDefinitionParser实现了Spring的BeanDefinitionParser接口，即Spring的Bean定义解析器。该类中有两个重要属性，beanClass 和 required，这两个属性的值是在创建Dubbo的Bean定义解析器时通过构造方法传入的，分别是标签元素对应的配置类和在创建配置Bean的时候可能需要i的d属性。parse方法是解析XML元素的主流程的入口，其中 parserContext 参数是XML解析的上下文，它包含了 XmlReaderContext 这个重要对象，而该对象中又包含了BeanFactory等信息，具体如下图: 有了BeanFactory就可以实现Bean的定义了，接下来我们继续分析Dubbo是如何处理自定义标签与对应的配置类之间的关系，以及怎样创建标签对应的Bean定义的。 创建Bean定义并注册到Spring上下文1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * @param element 标签对应的DOM * @param parserContext spring 解析上下文 * @param beanClass 标签对应的配置类 * @param required 在创建Bean定义的时候是否需要id * @return 标签对应的配置类的Bean定义 */ @SuppressWarnings(\"unchecked\") private static BeanDefinition parse(Element element, ParserContext parserContext, Class&lt;?&gt; beanClass, boolean required) &#123; // 生成Spring的Bean定义，指定beanClass交给Spring反射创建实例 RootBeanDefinition beanDefinition = new RootBeanDefinition(); beanDefinition.setBeanClass(beanClass); /** * 设置Bean初始化方式，默认设置为延迟加载。 * 需要说明的是，引用缺省是延迟初始化的，只有引用被注入到其它Bean或者getBean() 获取才会初始化。如果需要立即初始化可以配置： &lt;dubbo:reference init=\"true\"/&gt; */ beanDefinition.setLazyInit(false); //--------------------------- 确保Spring 容器中没有重复的Bean定义 开始 ------------------------/ // 解析标签对象的id属性 String id = element.getAttribute(\"id\"); // 标签没有设置id属性，并且创建的Bean定义需要id时，就执行生成id的逻辑。需要注意的是，Dubbo的reference标签对应Bean定义不需要id if ((id == null || id.length() == 0) &amp;&amp; required) &#123; // 1. 取name属性值 String generatedBeanName = element.getAttribute(\"name\"); if (generatedBeanName == null || generatedBeanName.length() == 0) &#123; // 2. 也没有设置name属性，此时如果当前标签是Protocol，那么id的值就直接设置为 'dubbo'，非Protocol协议则尝试取标签的interface属性值 if (ProtocolConfig.class.equals(beanClass)) &#123; generatedBeanName = \"dubbo\"; &#125; else &#123; generatedBeanName = element.getAttribute(\"interface\"); &#125; &#125; // 3. 以上过程都没有生成id，则最后使用标签对应的配置类的类名 if (generatedBeanName == null || generatedBeanName.length() == 0) &#123; generatedBeanName = beanClass.getName(); &#125; id = generatedBeanName; int counter = 2; // 检查Spring注册表中是否存在标识id，存在就通过自增序列继续处理id,使其唯一 while (parserContext.getRegistry().containsBeanDefinition(id)) &#123; id = generatedBeanName + (counter++); &#125; &#125; if (id != null &amp;&amp; id.length() &gt; 0) &#123; if (parserContext.getRegistry().containsBeanDefinition(id)) &#123; throw new IllegalStateException(\"Duplicate spring bean id \" + id); &#125; // 把标签对应的配置类的Bean定义注册到Spring，Bean 名称为id parserContext.getRegistry().registerBeanDefinition(id, beanDefinition); // 为Bean追加id属性 beanDefinition.getPropertyValues().addPropertyValue(\"id\", id); &#125; // $&#123;省略的代码&#125; &#125; 特殊处理protocol标签123456789101112131415161718192021222324252627282930313233343536373839/** * @param element 标签对应的DOM * @param parserContext spring 解析上下文 * @param beanClass 标签对应的配置类 * @param required 在创建Bean定义的时候是否需要id * @return 标签对应的配置类的Bean定义 */ @SuppressWarnings(\"unchecked\") private static BeanDefinition parse(Element element, ParserContext parserContext, Class&lt;?&gt; beanClass, boolean required) &#123; // $&#123;省略的代码&#125; if (ProtocolConfig.class.equals(beanClass)) &#123; /** * 以下代码逻辑需要满足： * 顺序需要这样： * 1 &lt;dubbo:service interface=\"com.xxx.xxxService protocol=\"dubbo\" ref=\"xxxServiceImpl\"/&gt; * 2 &lt;dubbo:protocol id =\"dubbo\" name=\"dubbo\" port=\"20880\"/&gt; */ // 获取Bean注册表中所有的Bean id for (String name : parserContext.getRegistry().getBeanDefinitionNames()) &#123; // 根据id获取Bean定义 BeanDefinition definition = parserContext.getRegistry().getBeanDefinition(name); // 获取当前Bean定义的属性对象集合，并尝试获取属性名为 'protocol' 的属性对象 PropertyValue property = definition.getPropertyValues().getPropertyValue(\"protocol\"); if (property != null) &#123; // 获取属性值 Object value = property.getValue(); // 如果当前遍历的Bean定义中的属性满足条件，就更新该Bean的 protocol 属性值，即名称为id的RuntimeBeanReference对象 if (value instanceof ProtocolConfig &amp;&amp; id.equals(((ProtocolConfig) value).getName())) &#123; definition.getPropertyValues().addPropertyValue(\"protocol\", new RuntimeBeanReference(id)); &#125; &#125; &#125; &#125; // $&#123;省略的代码&#125; &#125; 上面的代码用来处理框架中那些属性名为’protocol’且属性类型为为ProtocolConfig的Bean，如果该Bean符合条件就更新该Bean的protocol属性值。 特殊处理service标签1234567891011121314151617181920212223242526272829/** * @param element 标签对应的DOM * @param parserContext spring 解析上下文 * @param beanClass 标签对应的配置类 * @param required 在创建Bean定义的时候是否需要id * @return 标签对应的配置类的Bean定义 */ @SuppressWarnings(\"unchecked\") private static BeanDefinition parse(Element element, ParserContext parserContext, Class&lt;?&gt; beanClass, boolean required) &#123; // $&#123;省略的代码&#125; else if (ServiceBean.class.equals(beanClass)) &#123; // 如果&lt;dubbo:service&gt;配置了class属性，那么为具体class配置的类创建Bean定义，并且把该定义注入到Service的 ref属性。一般不这么使用。 // eg: &lt;dubbo:service interface=\"com.alibaba.dubbo.demo.DemoService class=\"com.alibaba.dubbo.demo.provider.DemoServiceImpl\"/&gt; String className = element.getAttribute(\"class\"); if (className != null &amp;&amp; className.length() &gt; 0) &#123; RootBeanDefinition classDefinition = new RootBeanDefinition(); classDefinition.setBeanClass(ReflectUtils.forName(className)); classDefinition.setLazyInit(false); // 解析 &lt;dubbo:service class=\"xxx\"/&gt; 情况下内嵌的&lt;property/&gt;标签，然后设置到classDefinition的属性中 parseProperties(element.getChildNodes(), classDefinition); // 设置ref属性，相当于设置 &lt;dubbo:service ref=\"\"/&gt;属性 beanDefinition.getPropertyValues().addPropertyValue(\"ref\", new BeanDefinitionHolder(classDefinition, id + \"Impl\")); &#125; &#125; // $&#123;省略的代码&#125; &#125; 上面的代码用来处理 service标签 中有 class 属性的情况，处理逻辑就是创建class对应的Bean定义，然后设置到 service标签 对应的Bean的ref属性中。我们再来看看对service的子标签 property 的解析。 123456789101112131415161718192021222324252627282930313233/** * 解析 &lt;dubbo:service class=\"xxx\"/&gt; 情况下内嵌的&lt;property/&gt; * * @param nodeList 子元素数组 * @param beanDefinition Bean定义对象 */private static void parseProperties(NodeList nodeList, RootBeanDefinition beanDefinition) &#123; if (nodeList != null &amp;&amp; nodeList.getLength() &gt; 0) &#123; for (int i = 0; i &lt; nodeList.getLength(); i++) &#123; Node node = nodeList.item(i); // 只解析&lt;property/&gt;标签 if (node instanceof Element) &#123; if (\"property\".equals(node.getNodeName()) || \"property\".equals(node.getLocalName())) &#123; String name = ((Element) node).getAttribute(\"name\"); // 优先使用value属性，其次使用ref属性 if (name != null &amp;&amp; name.length() &gt; 0) &#123; String value = ((Element) node).getAttribute(\"value\"); String ref = ((Element) node).getAttribute(\"ref\"); if (value != null &amp;&amp; value.length() &gt; 0) &#123; beanDefinition.getPropertyValues().addPropertyValue(name, value); &#125; else if (ref != null &amp;&amp; ref.length() &gt; 0) &#123; beanDefinition.getPropertyValues().addPropertyValue(name, new RuntimeBeanReference(ref)); &#125; else &#123; // 属性不全，抛出异常 throw new UnsupportedOperationException(\"Unsupported &lt;property name=\\\"\" + name + \"\\\"&gt; sub tag, Only supported &lt;property name=\\\"\" + name + \"\\\" ref=\\\"...\\\" /&gt; or &lt;property name=\\\"\" + name + \"\\\" value=\\\"...\\\" /&gt;\"); &#125; &#125; &#125; &#125; &#125; &#125;&#125; 上面的代码用来解析service的property标签，目的是为service标签的class属性对应的Bean定义设置属性，比较简单。 特殊处理provider/consumer标签1234567891011121314151617181920212223/** * @param element 标签对应的DOM * @param parserContext spring 解析上下文 * @param beanClass 标签对应的配置类 * @param required 在创建Bean定义的时候是否需要id * @return 标签对应的配置类的Bean定义 */ @SuppressWarnings(\"unchecked\") private static BeanDefinition parse(Element element, ParserContext parserContext, Class&lt;?&gt; beanClass, boolean required) &#123; // $&#123;省略的代码&#125; else if (ProviderConfig.class.equals(beanClass)) &#123; // 解析 &lt;dubbo:provider/&gt; 的内嵌子元素&lt;dubbo:service/&gt; parseNested(element, parserContext, ServiceBean.class, true, \"service\", \"provider\", id, beanDefinition); &#125;else if (ConsumerConfig.class.equals(beanClass)) &#123; // 解析 &lt;dubbo:consumer/&gt; 的内嵌子元素&lt;dubbo:reference/&gt; parseNested(element, parserContext, ReferenceBean.class, false, \"reference\", \"consumer\", id, beanDefinition); &#125; // $&#123;省略的代码&#125; &#125; 从上面的代码可以看出，特殊处理provider/consumer标签就是处理它有service/reference子标签的情况，代码过程如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * 解析内嵌的标签 * * @param element 父标签对象 - provider/consumer标签对象 * @param parserContext Spring解析上下文 * @param beanClass 内嵌子元素的Bean类 - ServiceBean/ReferenceBean * @param required 是否需要Bean的id属性 * @param tag 子元素标签名 service/reference * @param property 父Bean对象在子元素中的属性名 provider/consumer * @param ref 父Bean的id * @param beanDefinition 父Bean定义对象 */ private static void parseNested(Element element, ParserContext parserContext, Class&lt;?&gt; beanClass, boolean required, String tag, String property, String ref, BeanDefinition beanDefinition) &#123; // 获取子节点列表 NodeList nodeList = element.getChildNodes(); if (nodeList != null &amp;&amp; nodeList.getLength() &gt; 0) &#123; boolean first = true; for (int i = 0; i &lt; nodeList.getLength(); i++) &#123; // 获取子节点 Node node = nodeList.item(i); if (node instanceof Element) &#123; // 当前节点是否是指定的子节点，这里可能是service/reference节点 if (tag.equals(node.getNodeName()) || tag.equals(node.getLocalName())) &#123; if (first) &#123; first = false; // 获取父节点的default的属性值 [暂时不知道有什么用] String isDefault = element.getAttribute(\"default\"); if (isDefault == null || isDefault.length() == 0) &#123; beanDefinition.getPropertyValues().addPropertyValue(\"default\", \"false\"); &#125; &#125; // 解析子元素，创建BeanDefinition 对象 （递归） BeanDefinition subDefinition = parse((Element) node, parserContext, beanClass, required); // 设置子BeanDefinition的指向，指向父BeanDefinition if (subDefinition != null &amp;&amp; ref != null &amp;&amp; ref.length() &gt; 0) &#123; subDefinition.getPropertyValues().addPropertyValue(property, new RuntimeBeanReference(ref)); &#125; &#125; &#125; &#125; &#125; &#125; 上面的代码主要处理provider/consumer标签内部嵌套的标签，内部嵌套的标签对象会自动持有外层标签的对象。 设置标签的属性到 BeanDefinition前面处理的逻辑属于特殊的情况，接下来我们分析标签的属性是如何设置到配置对象中的。本质上是通过遍历配置对象的get、set和is前缀方法，通过反射将标签属性设置到配置对象中。总体上分为两种情况： 如果标签属性和方法名相同，则通过反射调用设置标签的值到配置对象中。 如果标签属性不能匹配到配置对象中的方法名称，则将标签属性当作parameter参数设置到配置对象中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194/** * @param element 标签对应的DOM * @param parserContext spring 解析上下文 * @param beanClass 标签对应的配置类 * @param required 在创建Bean定义的时候是否需要id * @return 标签对应的配置类的Bean定义 */ @SuppressWarnings(\"unchecked\") private static BeanDefinition parse(Element element, ParserContext parserContext, Class&lt;?&gt; beanClass, boolean required) &#123; // $&#123;省略的代码&#125; // 用来保存已遍历的配置对象的属性集合，用来判断标签中哪些属性没有匹配上 Set&lt;String&gt; props = new HashSet&lt;String&gt;(); // 专门存放&lt;dubbo:parameters/&gt; 标签下子标签属性信息。最后都设置到Bean定义中 ManagedMap parameters = null; // 1. 获取配置对象所有方法 for (Method setter : beanClass.getMethods()) &#123; String name = setter.getName(); // 2. 选择所有set前缀方法，并且只有一个参数的 public 方法 if (name.length() &gt; 3 &amp;&amp; name.startsWith(\"set\") &amp;&amp; Modifier.isPublic(setter.getModifiers()) &amp;&amp; setter.getParameterTypes().length == 1) &#123; // 获取方法的参数类型 Class&lt;?&gt; type = setter.getParameterTypes()[0]; // 3. 提取set对应的属性名字，eg: setTimeout-&gt;timeout,setBeanName-&gt;bean-name String property = StringUtils.camelToSplitName(name.substring(3, 4).toLowerCase() + name.substring(4), \"-\"); // 保存到属性 props 集合中 props.add(property); // 4. 尝试获取属性对应的getter方法 Method getter = null; try &#123; getter = beanClass.getMethod(\"get\" + name.substring(3), new Class&lt;?&gt;[0]); &#125; catch (NoSuchMethodException e) &#123; try &#123; // 没有setter对应的getter方法，尝试获取is方法，is方法在功能上是同getter getter = beanClass.getMethod(\"is\" + name.substring(3), new Class&lt;?&gt;[0]); &#125; catch (NoSuchMethodException e2) &#123; &#125; &#125; // 5. 校验属性是否有对应的getter/is前缀方法，没有就跳过 if (getter == null || !Modifier.isPublic(getter.getModifiers()) || !type.equals(getter.getReturnType())) &#123; continue; &#125; // 6. 解析 &lt;dubbo:parameter/&gt; 标签，将当前标签element的子标签 &lt;dubbo:parameter/&gt; 的属性键值对保存到parameters中 if (\"parameters\".equals(property)) &#123; parameters = parseParameters(element.getChildNodes(), beanDefinition); // 7. 解析 &lt;dubbo:method/&gt; 标签，将当前标签element的子标签 &lt;dubbo:method/&gt; 进行解析，将解析得到的对应BeanDefiniton放入到ManagedList集合中，最后作为 beanDefiniton的methods属性值。 &#125; else if (\"methods\".equals(property)) &#123; parseMethods(id, element.getChildNodes(), beanDefinition, parserContext); // 8. 解析 &lt;dubbo:argument/&gt;标签，将当前标签element的子标签 &lt;dubbo:argument/&gt; 进行解析，将解析得到的对应的BeanDefinition放入到ManagedList集合中，最后作为 beanDefinition的arguments属性值。 &#125; else if (\"arguments\".equals(property)) &#123; parseArguments(id, element.getChildNodes(), beanDefinition, parserContext); &#125; else &#123; // 9. 获取标签属性的值 【前面的步骤之所以单独处理，是因为当前配置配置对象对应的属性不是一个标签属性，而是一个子标签】 String value = element.getAttribute(property); if (value != null) &#123; value = value.trim(); if (value.length() &gt; 0) &#123; // 9.1 标签中配置了 registry=N/A, 不想注册到的情况 if (\"registry\".equals(property) &amp;&amp; RegistryConfig.NO_AVAILABLE.equalsIgnoreCase(value)) &#123; RegistryConfig registryConfig = new RegistryConfig(); // RegistryConfig的地址设置 N/A registryConfig.setAddress(RegistryConfig.NO_AVAILABLE); beanDefinition.getPropertyValues().addPropertyValue(property, registryConfig); // 9.2 多注册中心情况，将多个注册中心处理成一个集合，然后设置到 beanDefiniton 中，属性名为 'registries' &#125; else if (\"registry\".equals(property) &amp;&amp; value.indexOf(',') != -1) &#123; parseMultiRef(\"registries\", value, beanDefinition, parserContext); // 9.3 多服务提供者情况，将多个服务提供者处理成一个集合，然后设置到 beanDefinition 中，属性为 'providers' &#125; else if (\"provider\".equals(property) &amp;&amp; value.indexOf(',') != -1) &#123; parseMultiRef(\"providers\", value, beanDefinition, parserContext); // 9.4 多协议情况，将多个协议处理成一个集合，然后设置到 beanDefinition 中，属性为 'protocols' &#125; else if (\"protocol\".equals(property) &amp;&amp; value.indexOf(',') != -1) &#123; parseMultiRef(\"protocols\", value, beanDefinition, parserContext); &#125; else &#123; Object reference; // 10. 属性类型为基本类型的情况 if (isPrimitive(type)) &#123; // 兼容性处理【一些设置了但是意义不大的属性就把值设置为null】 if (\"async\".equals(property) &amp;&amp; \"false\".equals(value) || \"timeout\".equals(property) &amp;&amp; \"0\".equals(value) || \"delay\".equals(property) &amp;&amp; \"0\".equals(value) || \"version\".equals(property) &amp;&amp; \"0.0.0\".equals(value) || \"stat\".equals(property) &amp;&amp; \"-1\".equals(value) || \"reliable\".equals(property) &amp;&amp; \"false\".equals(value)) &#123; // backward compatibility for the default value in old version's xsd value = null; &#125; reference = value; //11. 处理在&lt;dubbo:provider/&gt; 或者 &lt;dubbo:service/&gt; 上定义了 protocol 属性的兼容性，目前已经不推荐这样使用了，应该单独配置 &lt;dubbo:protocol/&gt; &#125; else if (\"protocol\".equals(property) &amp;&amp; ExtensionLoader.getExtensionLoader(Protocol.class).hasExtension(value) &amp;&amp; (!parserContext.getRegistry().containsBeanDefinition(value) || !ProtocolConfig.class.getName().equals(parserContext.getRegistry().getBeanDefinition(value).getBeanClassName()))) &#123; if (\"dubbo:provider\".equals(element.getTagName())) &#123; logger.warn(\"Recommended replace &lt;dubbo:provider protocol=\\\"\" + value + \"\\\" ... /&gt; to &lt;dubbo:protocol name=\\\"\" + value + \"\\\" ... /&gt;\"); &#125; // backward compatibility ProtocolConfig protocol = new ProtocolConfig(); protocol.setName(value); reference = protocol; //------- 12. 事件通知: 在调用前，调用后，出现异常，会触发oninvoke，onreturn,onthrow三个事件，可以配置当事件发生时，通知哪个类的哪个方法 ------// /* // 格式：实现Bean.方法 &lt;bean id=\"demoCallBack\" class = \"com.alibaba.dubbo.callback.implicit.NofifyImpl\"/&gt; &lt;dubbo:reference id = \"demoService\" interface=\"com.alibaba.dubbo.IDemoService\"&gt; &lt;dubbo:method name=\"get\" onreturn=\"demoCallBack.xxxMethod\" onthrow=\"demoCallBack.xMethod\"/&gt; &lt;/dubbo:reference&gt; */ // 12.1 处理 onreturn 属性 &#125; else if (\"onreturn\".equals(property)) &#123; // 按照 . 拆分 int index = value.lastIndexOf(\".\"); // 获取实例名 String returnRef = value.substring(0, index); // 获取实例的方法 String returnMethod = value.substring(index + 1); // 创建 RuntimeBeanReference，指向回调的对象 reference = new RuntimeBeanReference(returnRef); // 设置 onreturnMethod 到 BeanDefinition 的属性值 beanDefinition.getPropertyValues().addPropertyValue(\"onreturnMethod\", returnMethod); // 12.2 处理 onthrow 属性 &#125; else if (\"onthrow\".equals(property)) &#123; int index = value.lastIndexOf(\".\"); String throwRef = value.substring(0, index); String throwMethod = value.substring(index + 1); // 创建 RuntimeBeanReference，指向回调的对象 reference = new RuntimeBeanReference(throwRef); // 设置 onthrowMethod 到 BeanDefinition 的属性值 beanDefinition.getPropertyValues().addPropertyValue(\"onthrowMethod\", throwMethod); //12.3 处理oninvoke 属性 &#125; else if (\"oninvoke\".equals(property)) &#123; int index = value.lastIndexOf(\".\"); String invokeRef = value.substring(0, index); String invokeRefMethod = value.substring(index + 1); reference = new RuntimeBeanReference(invokeRef); beanDefinition.getPropertyValues().addPropertyValue(\"oninvokeMethod\", invokeRefMethod); //----------------------------- 事件通知结束 ------------------------------// &#125; else &#123; // 13. 属性名没有匹配到对应的标签名，都会到这里 //13.1 如果属性名是ref, ref 对应的Bean 必须是单例的 if (\"ref\".equals(property) &amp;&amp; parserContext.getRegistry().containsBeanDefinition(value)) &#123; BeanDefinition refBean = parserContext.getRegistry().getBeanDefinition(value); if (!refBean.isSingleton()) &#123; throw new IllegalStateException(\"The exported service ref \" + value + \" must be singleton! Please set the \" + value + \" bean scope to singleton, eg: &lt;bean id=\\\"\" + value + \"\\\" scope=\\\"singleton\\\" ...&gt;\"); &#125; &#125; // 创建RuntimeBeanReference reference = new RuntimeBeanReference(value); &#125; // 设置Bean定义的属性 beanDefinition.getPropertyValues().addPropertyValue(property, reference); &#125; &#125; &#125; &#125; &#125; &#125; // 将标签中自定义的属性（不是Dubbo Schema 约定好的）也加入到 parameters 集合中 NamedNodeMap attributes = element.getAttributes(); int len = attributes.getLength(); for (int i = 0; i &lt; len; i++) &#123; Node node = attributes.item(i); String name = node.getLocalName(); if (!props.contains(name)) &#123; if (parameters == null) &#123; parameters = new ManagedMap(); &#125; String value = node.getNodeValue(); parameters.put(name, new TypedStringValue(value, String.class)); &#125; &#125; if (parameters != null) &#123; beanDefinition.getPropertyValues().addPropertyValue(\"parameters\", parameters); &#125; return beanDefinition; &#125; 上面的代码是把属性注入到标签对应的BeanDefinition，如果属性是引用对象，Dubbo默认会创建 RuntimeBeanReference 类型注入，运行时由Spring注入引用对象。 总结Dubbo框架解析配置文件生成BeanDefinition其实是生成标签对应的配置类的Bean定义，Bean定义中的属性值主要来源于标签的属性值，Dubbo对标签属性只是进行了提取，标签的内嵌标签处理也是如此，运行时属性注入和转换都还是Spring来完成的，Dubbo框架生成的BeanDefinition最终会委托Spring创建对应的对象，这个属于Spring的流程就不多说了。dubbo.xsd文件中定义的类型都会有与之对应的配置承载类中的属性，我们已经在API配置中介绍过了。XML配置解析还是挺复杂的，分支流比较多，下一章要分析的注解配置稍微比这个复杂一些。随着后面深入的分析就会发现这些东西都是基础，结合Dubbo的整个过程就很容易理解了。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"Dubbo源码分析 - API和属性配置","slug":"rpc/API配置","date":"2020-03-24T16:00:00.000Z","updated":"2020-09-03T03:12:53.647Z","comments":false,"path":"posts/1d3295e6/","link":"","permalink":"https://gentryhuang.com/posts/1d3295e6/","excerpt":"","text":"前言我们通过 Dubbo URL统一模型 已经了解了Dubbo URL是Duboo的配置总线，贯穿整个Dubbo的生命周期。虽然Dubbo URL直接决定了Dubbo组件的角色并控制Dubbo的行为，但是Dubbo URL中的信息需要Dubbo的配置承对象来提供，而配置承载对象中的数据来源于多种配置和设置。 目前Dubbo框架同时支持4种配置方式：API硬编码配置、XML配置、注解配置、属性配置。而所有的配置项分为三大类: 服务注册和发现：表示该配置项用于服务的注册和发现。 服务治理：表示该配置项用于治理服务间的关系，或为开发测试提供便利条件。 性能调优：表示该配置项用于调优性能，不同的选项对性能会产生影响。 注意：所有配置最终都会转换为Dubbo URL 配置承载对象不管是注解还是XML配置都需要配置对象来承载，XML配置、注解配置、属性配置都是和配置对象或其属性相映射的，为什么这里没有说API配置和配置对象的映射关系呢？其实API配置就是直接操作配置对象，而XML配置和注解配置都是由Spring来创建配置对象并设置属性的，而我们的属性配置是在配置对象已经存在的基础上，为其设置指定的属性值。下面是Dubbo的属性配置类的结构： 上图中我使用了黄色框和红色框分别对抽象配置类和配置实现类进行了标注，其中DubboShutdownHook先忽略。红色框中的配置类是直接的配置承载类，黄色框中的抽象配置类是配置承载类的父类。下面是配置承载类的UML图： 直观图 依赖关系图 通过上面的关系图我们可以很清楚地了解到每个配置之间的关系，我们接下来就顺着关系图分别介绍核心的配置类。 AbstractConfig 抽象配置类除了ArgumentConfig配置类，几乎其他的所有配置类都直接或间接继承该类，该类主要提供配置解析与校验相关的工具方法。 格式校验123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108public abstract class AbstractConfig implements Serializable &#123; // 省略其它代码 $&#123;&#125; //-------------------------- 格式检验 -----------------------------/ private static final int MAX_LENGTH = 200; private static final int MAX_PATH_LENGTH = 200; private static final Pattern PATTERN_NAME = Pattern.compile(\"[\\\\-._0-9a-zA-Z]+\"); private static final Pattern PATTERN_MULTI_NAME = Pattern.compile(\"[,\\\\-._0-9a-zA-Z]+\"); private static final Pattern PATTERN_METHOD_NAME = Pattern.compile(\"[a-zA-Z][0-9a-zA-Z]*\"); private static final Pattern PATTERN_PATH = Pattern.compile(\"[/\\\\-$._0-9a-zA-Z]+\"); private static final Pattern PATTERN_NAME_HAS_SYMBOL = Pattern.compile(\"[:*,/\\\\-._0-9a-zA-Z]+\"); private static final Pattern PATTERN_KEY = Pattern.compile(\"[*,\\\\-._0-9a-zA-Z]+\"); protected static void checkExtension(Class&lt;?&gt; type, String property, String value) &#123; checkName(property, value); if (value != null &amp;&amp; value.length() &gt; 0 &amp;&amp; !ExtensionLoader.getExtensionLoader(type).hasExtension(value)) &#123; throw new IllegalStateException(\"No such extension \" + value + \" for \" + property + \"/\" + type.getName()); &#125; &#125; protected static void checkMultiExtension(Class&lt;?&gt; type, String property, String value) &#123; checkMultiName(property, value); if (value != null &amp;&amp; value.length() &gt; 0) &#123; String[] values = value.split(\"\\\\s*[,]+\\\\s*\"); for (String v : values) &#123; if (v.startsWith(Constants.REMOVE_VALUE_PREFIX)) &#123; v = v.substring(1); &#125; if (Constants.DEFAULT_KEY.equals(v)) &#123; continue; &#125; if (!ExtensionLoader.getExtensionLoader(type).hasExtension(v)) &#123; throw new IllegalStateException(\"No such extension \" + v + \" for \" + property + \"/\" + type.getName()); &#125; &#125; &#125; &#125; protected static void checkLength(String property, String value) &#123; checkProperty(property, value, MAX_LENGTH, null); &#125; protected static void checkPathLength(String property, String value) &#123; checkProperty(property, value, MAX_PATH_LENGTH, null); &#125; protected static void checkName(String property, String value) &#123; checkProperty(property, value, MAX_LENGTH, PATTERN_NAME); &#125; protected static void checkNameHasSymbol(String property, String value) &#123; checkProperty(property, value, MAX_LENGTH, PATTERN_NAME_HAS_SYMBOL); &#125; protected static void checkKey(String property, String value) &#123; checkProperty(property, value, MAX_LENGTH, PATTERN_KEY); &#125; protected static void checkMultiName(String property, String value) &#123; checkProperty(property, value, MAX_LENGTH, PATTERN_MULTI_NAME); &#125; protected static void checkPathName(String property, String value) &#123; checkProperty(property, value, MAX_PATH_LENGTH, PATTERN_PATH); &#125; protected static void checkMethodName(String property, String value) &#123; checkProperty(property, value, MAX_LENGTH, PATTERN_METHOD_NAME); &#125; protected static void checkParameterName(Map&lt;String, String&gt; parameters) &#123; if (parameters == null || parameters.size() == 0) &#123; return; &#125; for (Map.Entry&lt;String, String&gt; entry : parameters.entrySet()) &#123; checkNameHasSymbol(entry.getKey(), entry.getValue()); &#125; &#125; protected static void checkProperty(String property, String value, int maxlength, Pattern pattern) &#123; if (value == null || value.length() == 0) &#123; return; &#125; if (value.length() &gt; maxlength) &#123; throw new IllegalStateException(\"Invalid \" + property + \"=\\\"\" + value + \"\\\" is longer than \" + maxlength); &#125; if (pattern != null) &#123; Matcher matcher = pattern.matcher(value); if (!matcher.matches()) &#123; throw new IllegalStateException(\"Invalid \" + property + \"=\\\"\" + value + \"\\\" contains illegal \" + \"character, only digit, letter, '-', '_' or '.' is legal.\"); &#125; &#125; &#125; // 省略其它代码 $&#123;&#125;&#125; AbstractConfig的子类会调用这里的方法进行相关的参数校验。 添加属性（属性和系统参数配置）读取启动参数变量和Properties配置文件中属性到配置承载对象中，该方法其实就是属性配置 和 系统参数配置的逻辑。这个逻辑非常重要，无论是API配置还是XML配置，以及注解配置，都会使用该逻辑为配置承载对象设置系统参数值以及配置属性值。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104public abstract class AbstractConfig implements Serializable &#123; // 省略其它代码 $&#123;&#125; /** * 1 id 属性，Bean定义的名称，适用于除了API配置之外的三种配置（属性配置，xml配置,注解配置）方式，可用于对象之间的引用 * 2 不适用API配置，是因为API配置直接setter(xxx)对象即可 */ protected String id; /** * 读取带有配置项名前缀的启动参数变量和properties配置到 配置承载对象中。 * 说明：在此之前配置承载对象中只可能有xml配置的属性值，或者注解配置的属性值 * * @param config 配置对象 */ protected static void appendProperties(AbstractConfig config) &#123; if (config == null) &#123; return; &#125; // 获得配置项前缀（使用配置类的类名，获得对应的属性标签）-&gt; dubbo.tag. String prefix = \"dubbo.\" + getTagName(config.getClass()) + \".\"; // 获得配置类的所有方法，用于下面通过反射获得配置项的属性名，再用属性名去读取启动参数变量和.properties配置到配置对象 Method[] methods = config.getClass().getMethods(); for (Method method : methods) &#123; try &#123; // 拿到方法名 String name = method.getName(); // 选择方法是 【public &amp;&amp; setter &amp;&amp; 唯一参数为基本类型】 的方法 if (name.length() &gt; 3 &amp;&amp; name.startsWith(\"set\") &amp;&amp; Modifier.isPublic(method.getModifiers()) &amp;&amp; method.getParameterTypes().length == 1 &amp;&amp; isPrimitive(method.getParameterTypes()[0])) &#123; // 获得属性名 如： ApplicationConfig#setName(...) 方法，对应的属性名为 name String property = StringUtils.camelToSplitName(name.substring(3, 4).toLowerCase() + name.substring(4), \".\"); //----------- 读取的覆盖策略： JVM -D &gt; XML &gt; .properties ----------/ String value = null; //【启动参数变量】优先从带有 id属性的XxxConfig的配置中获取，例如 dubbo.application.demo-provider.name if (config.getId() != null &amp;&amp; config.getId().length() &gt; 0) &#123; // id字段 String pn = prefix + config.getId() + \".\" + property; value = System.getProperty(pn); if (!StringUtils.isBlank(value)) &#123; logger.info(\"Use System Property \" + pn + \" to config dubbo\"); &#125; &#125; //【启动参数变量】获取不到，再从不带 id属性 的XxxConfig的配置中获取，例如：dubbo.application.name if (value == null || value.length() == 0) &#123; // 没有id字段 String pn = prefix + property; value = System.getProperty(pn); if (!StringUtils.isBlank(value)) &#123; logger.info(\"Use System Property \" + pn + \" to config dubbo\"); &#125; &#125; // 配置优先级以及覆盖： 启动参数变量 &gt; XML配置[注解/java配置] &gt; properties配置 。因此需要使用getter判断XML是否已经配置 if (value == null || value.length() == 0) &#123; Method getter; try &#123; getter = config.getClass().getMethod(\"get\" + name.substring(3)); &#125; catch (NoSuchMethodException e) &#123; try &#123; getter = config.getClass().getMethod(\"is\" + name.substring(3)); &#125; catch (NoSuchMethodException e2) &#123; getter = null; &#125; &#125; if (getter != null) &#123; // 使用getter 判断XML是否已经设置过，如果没有设置的话就从.properties文件中读取 if (getter.invoke(config) == null) &#123; // [properties配置] 优先从带有 id 属性的配置中获取，例如：dubbo.application.demo-provider.name if (config.getId() != null &amp;&amp; config.getId().length() &gt; 0) &#123; value = ConfigUtils.getProperty(prefix + config.getId() + \".\" + property); &#125; // [properties配置]获取不到，再从不带 id 属性的配置中获取，例如：dubbo.application.name if (value == null || value.length() == 0) &#123; value = ConfigUtils.getProperty(prefix + property); &#125; // [properties配置]获取不到，这里进行老版本兼容，从不带id属性的配置中获取 if (value == null || value.length() == 0) &#123; String legacyKey = legacyProperties.get(prefix + property); if (legacyKey != null &amp;&amp; legacyKey.length() &gt; 0) &#123; value = convertLegacyValue(legacyKey, ConfigUtils.getProperty(legacyKey)); &#125; &#125; &#125; &#125; &#125; // 获取到值（系统参数配置或者.properties文件中的，不包含xml配置，xml配置有单独的设置方法） if (value != null &amp;&amp; value.length() &gt; 0) &#123; method.invoke(config, convertPrimitive(method.getParameterTypes()[0], value)); &#125; &#125; &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; &#125; &#125; // 省略其它代码 $&#123;&#125;&#125; 上面的代码主要就是为已经实例化好的配置承载对象设置属性值，主要逻辑如下： 根据配置对象获取属性配置的前缀，如 dubbo.application. 遍历配置承载对象中的所有方法找到符合条件的setter方法 根据配置覆盖策略的优先级，设置配置承载对象的属性值 配置对象的属性到参数集合将配置承载对象的属性添加到参数集合中，用于构建Dubbo URL，如在服务暴露和引用是构建相关的URL。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111public abstract class AbstractConfig implements Serializable &#123; // 省略其它代码 $&#123;&#125; /** * 将配置对象的属性添加到参数集合 * * @param parameters * @param config */ protected static void appendParameters(Map&lt;String, String&gt; parameters, Object config) &#123; appendParameters(parameters, config, null); &#125; /** * 将配置对象的属性添加到参数集合，主要逻辑： * &lt;p&gt; * 1 通过反射获取目标对象的getter方法，并调用该方法获取属性值，然后再通过getter方法名解析出属性名，如：从方法名getName中可解析出属性name，如果用户传入了属性名前缀，此时需要将属性名加入前缀内容。 * 2 将 属性名-属性值 键值对存入到map中就可以了 * * @param parameters 参数集合，该集合会用于URL * @param config 配置对象 * @param prefix 属性前缀。用于配置项添加到参数集合中时的前缀 */ @SuppressWarnings(\"unchecked\") protected static void appendParameters(Map&lt;String, String&gt; parameters, Object config, String prefix) &#123; if (config == null) &#123; return; &#125; // 获得所有方法的数组，为下面通过反射获得配置项的值做准备 Method[] methods = config.getClass().getMethods(); for (Method method : methods) &#123; try &#123; String name = method.getName(); // 选择方法为 返回值为基本类型 + public的getter/is方法 （和解析到配置类的过滤添加呼应） if ((name.startsWith(\"get\") || name.startsWith(\"is\")) &amp;&amp; !\"getClass\".equals(name) &amp;&amp; Modifier.isPublic(method.getModifiers()) &amp;&amp; method.getParameterTypes().length == 0 &amp;&amp; isPrimitive(method.getReturnType())) &#123; // 尝试获取方法上的@Parameter注解 Parameter parameter = method.getAnnotation(Parameter.class); // 方法返回类型是Object的或者方法的@Parameter(excluded = true)的， 不统计对应的值到参数集合 if (method.getReturnType() == Object.class || parameter != null &amp;&amp; parameter.excluded()) &#123; continue; &#125; // 获得属性名 int i = name.startsWith(\"get\") ? 3 : 2; String prop = StringUtils.camelToSplitName(name.substring(i, i + 1).toLowerCase() + name.substring(i + 1), \".\"); String key; // @Parameter注解有配置key属性就取出该值 if (parameter != null &amp;&amp; parameter.key().length() &gt; 0) &#123; key = parameter.key(); &#125; else &#123; key = prop; &#125; // 利用反射获得属性的值 Object value = method.invoke(config); String str = String.valueOf(value).trim(); if (value != null &amp;&amp; str.length() &gt; 0) &#123; // 是否转移，默认不转译 if (parameter != null &amp;&amp; parameter.escaped()) &#123; str = URL.encode(str); &#125; // @Parameter注解有配置append属性，就进行拼接 if (parameter != null &amp;&amp; parameter.append()) &#123; // 1. 看参数集合中是否有key为： default.key的值(默认属性值),有就拼接到属性值前面 String pre = parameters.get(Constants.DEFAULT_KEY + \".\" + key); if (pre != null &amp;&amp; pre.length() &gt; 0) &#123; str = pre + \",\" + str; &#125; // 2. 看参数集合中是否有key对应的值，有就拼接到属性值前面 pre = parameters.get(key); if (pre != null &amp;&amp; pre.length() &gt; 0) &#123; str = pre + \",\" + str; &#125; &#125; // 如果指定了属性前缀就拼接上去，就在属性名前面加上前缀 if (prefix != null &amp;&amp; prefix.length() &gt; 0) &#123; key = prefix + \".\" + key; &#125; // 把最后处理的属性值加入参数集合中 parameters.put(key, str); // 当配置对象的属性getter方法加了@Parameter(required=true)时，校验配置项非空 &#125; else if (parameter != null &amp;&amp; parameter.required()) &#123; throw new IllegalStateException(config.getClass().getSimpleName() + \".\" + key + \" == null\"); &#125; // 当方法为public Map getParameters()&#123;...&#125;时，就以此将Map中的key-value加入到参数集合 &#125; else if (\"getParameters\".equals(name) &amp;&amp; Modifier.isPublic(method.getModifiers()) &amp;&amp; method.getParameterTypes().length == 0 &amp;&amp; method.getReturnType() == Map.class) &#123; // 通过 getParameters()方法，获取动态设置的配置项 Map&lt;String, String&gt; map = (Map&lt;String, String&gt;) method.invoke(config, new Object[0]); if (map != null &amp;&amp; map.size() &gt; 0) &#123; String pre = (prefix != null &amp;&amp; prefix.length() &gt; 0 ? prefix + \".\" : \"\"); for (Map.Entry&lt;String, String&gt; entry : map.entrySet()) &#123; parameters.put(pre + entry.getKey().replace('-', '.'), entry.getValue()); &#125; &#125; &#125; &#125; catch (Exception e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; &#125; &#125; // 省略其它代码 $&#123;&#125;&#125; 上面代码主要就是将配置承载对象中的属性设置到属性集合Map中，用于构建Dubbo URL。整个逻辑需要注意，配置承载对象的getter方法上标注的 @Parameter 注解，以及配置承载对象的getParameters方法。 添加事件通知属性12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public abstract class AbstractConfig implements Serializable &#123; // 省略其它代码 $&#123;&#125; protected static void appendAttributes(Map&lt;Object, Object&gt; parameters, Object config) &#123; appendAttributes(parameters, config, null); &#125; /** * * @param parameters 参数集合 * @param config 配置对象 * @param prefix 属性前缀。用于配置项添加到参数集合中时的前缀 */ protected static void appendAttributes(Map&lt;Object, Object&gt; parameters, Object config, String prefix) &#123; if (config == null) &#123; return; &#125; Method[] methods = config.getClass().getMethods(); for (Method method : methods) &#123; try &#123; String name = method.getName(); // 选择方法为 返回值为基本类型 + public的getter/is方法 （和解析到配置类的过滤添加呼应） if ((name.startsWith(\"get\") || name.startsWith(\"is\")) &amp;&amp; !\"getClass\".equals(name) &amp;&amp; Modifier.isPublic(method.getModifiers()) &amp;&amp; method.getParameterTypes().length == 0 &amp;&amp; isPrimitive(method.getReturnType())) &#123; // 选择带有@Parameter(attribute=true)的方法 Parameter parameter = method.getAnnotation(Parameter.class); if (parameter == null || !parameter.attribute()) &#123; continue; &#125; String key; parameter.key(); if (parameter.key().length() &gt; 0) &#123; key = parameter.key(); &#125; else &#123; int i = name.startsWith(\"get\") ? 3 : 2; key = name.substring(i, i + 1).toLowerCase() + name.substring(i + 1); &#125; // 获得属性值，存在则添加到参数集合中 Object value = method.invoke(config); if (value != null) &#123; if (prefix != null &amp;&amp; prefix.length() &gt; 0) &#123; key = prefix + \".\" + key; &#125; parameters.put(key, value); &#125; &#125; &#125; catch (Exception e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; &#125; &#125; // 省略其它代码 $&#123;&#125;&#125; 上面代码主要用于Dubbo的事件通知的，具体是标注在MethodConfig配置承载对象的 getOnreturn(),getOnreturnMethod(),getOnthrow()…方法上。 AbstractInterfaceConfig 抽象配置类继承关系如下： 123AbstractConfig - AbstractMethodConfig - AbstractInterfaceConfig AbstractConfig抽象类的核心逻辑已经分析过，AbstractMethodConfig抽象类中没有比较重要的逻辑，基本都是 配置属性的设置/获取方法，就不再分析，接下来我们一起看下AbstractInterfaceConfig抽象类的逻辑。 校验注册中心配置123456789101112131415161718192021222324252627282930313233343536public abstract class AbstractInterfaceConfig extends AbstractMethodConfig &#123;// 省略其它代码 $&#123;&#125;protected void checkRegistry() &#123; // for backward compatibility if (registries == null || registries.isEmpty()) &#123; String address = ConfigUtils.getProperty(\"dubbo.registry.address\"); if (address != null &amp;&amp; address.length() &gt; 0) &#123; registries = new ArrayList&lt;RegistryConfig&gt;(); String[] as = address.split(\"\\\\s*[|]+\\\\s*\"); for (String a : as) &#123; RegistryConfig registryConfig = new RegistryConfig(); registryConfig.setAddress(a); registries.add(registryConfig); &#125; &#125; &#125; if ((registries == null || registries.isEmpty())) &#123; throw new IllegalStateException((getClass().getSimpleName().startsWith(\"Reference\") ? \"No such any registry to refer service in consumer \" : \"No such any registry to export service in provider \") + NetUtils.getLocalHost() + \" use dubbo version \" + Version.getVersion() + \", Please add &lt;dubbo:registry address=\\\"...\\\" /&gt; to your spring config. If you want unregister, please set &lt;dubbo:service registry=\\\"N/A\\\" /&gt;\"); &#125; for (RegistryConfig registryConfig : registries) &#123; // 调用AbstractConfig中的方法 appendProperties(registryConfig); &#125; &#125;// 省略其它代码 $&#123;&#125;&#125; 校验应用配置123456789101112131415161718192021222324252627282930313233public abstract class AbstractInterfaceConfig extends AbstractMethodConfig &#123;// 省略其它代码 $&#123;&#125; protected void checkApplication() &#123; // for backward compatibility if (application == null) &#123; String applicationName = ConfigUtils.getProperty(\"dubbo.application.name\"); if (applicationName != null &amp;&amp; applicationName.length() &gt; 0) &#123; application = new ApplicationConfig(); &#125; &#125; if (application == null) &#123; throw new IllegalStateException( \"No such application config! Please add &lt;dubbo:application name=\\\"...\\\" /&gt; to your spring config.\"); &#125; // 调用AbstractConfig中的方法 appendProperties(application); String wait = ConfigUtils.getProperty(Constants.SHUTDOWN_WAIT_KEY); if (wait != null &amp;&amp; wait.trim().length() &gt; 0) &#123; System.setProperty(Constants.SHUTDOWN_WAIT_KEY, wait.trim()); &#125; else &#123; wait = ConfigUtils.getProperty(Constants.SHUTDOWN_WAIT_SECONDS_KEY); if (wait != null &amp;&amp; wait.trim().length() &gt; 0) &#123; System.setProperty(Constants.SHUTDOWN_WAIT_SECONDS_KEY, wait.trim()); &#125; &#125; &#125;// 省略其它代码 $&#123;&#125;&#125; 加载注册中心URL数组12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091public abstract class AbstractInterfaceConfig extends AbstractMethodConfig &#123;// 省略其它代码 $&#123;&#125; /** * 加载注册中心URL数组 * * @param provider 是否是服务提供者 * @return URL数组 */ protected List&lt;URL&gt; loadRegistries(boolean provider) &#123; // 校验RegistryConfig 配置数组，不存在会抛出异常，并且该方法会初始化RegistryConfig的配置属性 checkRegistry(); // 创建注册中心URL数组 List&lt;URL&gt; registryList = new ArrayList&lt;URL&gt;(); if (registries != null &amp;&amp; !registries.isEmpty()) &#123; // 遍历RegistryConfig 数组 for (RegistryConfig config : registries) &#123; // 获取注册中心的地址 String address = config.getAddress(); // 地址为空就使用 0.0.0.0 任意地址 if (address == null || address.length() == 0) &#123; address = Constants.ANYHOST_VALUE; &#125; // 如果配置了启动参数的注册中心地址，它的优先级最高，就进行覆盖 String sysaddress = System.getProperty(\"dubbo.registry.address\"); if (sysaddress != null &amp;&amp; sysaddress.length() &gt; 0) &#123; address = sysaddress; &#125; // 选择有效的注册中心地址 if (address.length() &gt; 0 &amp;&amp; !RegistryConfig.NO_AVAILABLE.equalsIgnoreCase(address)) &#123; // 创建参数集合map,用于Dubbo URL的构建 Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); // 将应用配置对象和注册中心配置对象的属性添加到参数集合map中 appendParameters(map, application); /** * 需要注意的是：RegistryConfig 的 getAddress方法上使用了 @Parameter(excluded = true)注解，因此它的address属性不会加入到参数集合map中 * @Parameter(excluded = true) * public String getAddress() &#123;return address;&#125; */ appendParameters(map, config); // 添加 path,dubbo,timestamp,pid 到参数集合map中 map.put(\"path\", RegistryService.class.getName()); // 这里的path要和服务暴露逻辑中的path区分，注册中心的URL中的path为RegistryService的全路径名 map.put(\"dubbo\", Version.getProtocolVersion()); map.put(Constants.TIMESTAMP_KEY, String.valueOf(System.currentTimeMillis())); if (ConfigUtils.getPid() &gt; 0) &#123; map.put(Constants.PID_KEY, String.valueOf(ConfigUtils.getPid())); &#125; // 参数集合map中不存在 protocol 参数【以上配置对象的属性中没有有效的协议protocol参数】，就默认 使用 dubbo 作为 协议protocol的值 if (!map.containsKey(\"protocol\")) &#123; // 不需考虑remote扩展实现的情况 if (ExtensionLoader.getExtensionLoader(RegistryFactory.class).hasExtension(\"remote\")) &#123; map.put(\"protocol\", \"remote\"); &#125; else &#123; map.put(\"protocol\", \"dubbo\"); &#125; &#125; // 解析地址，创建Dubbo URL数组，注意address可能包含多个注册中心ip, 【数组大小可以为一】 List&lt;URL&gt; urls = UrlUtils.parseURLs(address, map); // 循环 dubbo Register url for (URL url : urls) &#123; // 设置 registry=$&#123;protocol&#125;参数,设置到注册中心的 URL的参数部分的位置上，并且是追加式的添加 url = url.addParameter(Constants.REGISTRY_KEY, url.getProtocol()); // 重置 URL中的 protocol属性为 'registry',即将URL的协议头设置为'registry' url = url.setProtocol(Constants.REGISTRY_PROTOCOL); /** * 通过判断条件，决定是否添加url到registryList中，条件如下： * 1 如果是服务提供者,是否只订阅不注册，如果是就不添加到注册中心URL数组中 * 2 如果是服务消费者，是否是只注册不订阅，如果是就不添加到注册中心URL数组中 * */ if ((provider &amp;&amp; url.getParameter(Constants.REGISTER_KEY, true)) || (!provider &amp;&amp; url.getParameter(Constants.SUBSCRIBE_KEY, true))) &#123; registryList.add(url); &#125; &#125; &#125; &#125; &#125; return registryList; &#125;// 省略其它代码 $&#123;&#125;&#125; 加载监控中心URL12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394public abstract class AbstractInterfaceConfig extends AbstractMethodConfig &#123;// 省略其它代码 $&#123;&#125;/** * 加载监控中心URL * * @param registryURL 注册中心URL * @return 监控中心URL */ protected URL loadMonitor(URL registryURL) &#123; // 如果监控配置为空，就从属性配置中加载配置到MonitorConfig if (monitor == null) &#123; // 获取监控地址 String monitorAddress = ConfigUtils.getProperty(\"dubbo.monitor.address\"); // 获取监控协议 String monitorProtocol = ConfigUtils.getProperty(\"dubbo.monitor.protocol\"); // 没有配置就直接返回 if ((monitorAddress == null || monitorAddress.length() == 0) &amp;&amp; (monitorProtocol == null || monitorProtocol.length() == 0)) &#123; return null; &#125; // 创建MonitorConfig monitor = new MonitorConfig(); if (monitorAddress != null &amp;&amp; monitorAddress.length() &gt; 0) &#123; monitor.setAddress(monitorAddress); &#125; if (monitorProtocol != null &amp;&amp; monitorProtocol.length() &gt; 0) &#123; monitor.setProtocol(monitorProtocol); &#125; &#125; // 为MonitorConfig加载配置【启动参数变量和properties配置到配置对象】 appendProperties(monitor); // 添加 interface,dubbo,timestamp,pid 到 map 集合中 Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); map.put(Constants.INTERFACE_KEY, MonitorService.class.getName()); map.put(\"dubbo\", Version.getProtocolVersion()); map.put(Constants.TIMESTAMP_KEY, String.valueOf(System.currentTimeMillis())); if (ConfigUtils.getPid() &gt; 0) &#123; map.put(Constants.PID_KEY, String.valueOf(ConfigUtils.getPid())); &#125; //set ip String hostToRegistry = ConfigUtils.getSystemProperty(Constants.DUBBO_IP_TO_REGISTRY); if (hostToRegistry == null || hostToRegistry.length() == 0) &#123; hostToRegistry = NetUtils.getLocalHost(); &#125; else if (isInvalidLocalHost(hostToRegistry)) &#123; throw new IllegalArgumentException(\"Specified invalid registry ip from property:\" + Constants.DUBBO_IP_TO_REGISTRY + \", value:\" + hostToRegistry); &#125; map.put(Constants.REGISTER_IP_KEY, hostToRegistry); appendParameters(map, monitor); appendParameters(map, application); // 获得监控地址 String address = monitor.getAddress(); // 如果启动参数配置了监控中心地址，就进行覆盖，启动参数优先级最高 String sysaddress = System.getProperty(\"dubbo.monitor.address\"); if (sysaddress != null &amp;&amp; sysaddress.length() &gt; 0) &#123; address = sysaddress; &#125; // 直连监控中心服务器地址 if (ConfigUtils.isNotEmpty(address)) &#123; // 若监控地址不存在 protocol 参数，默认 dubbo 添加到 map 集合中 if (!map.containsKey(Constants.PROTOCOL_KEY)) &#123; // logstat这个拓展实现已经不存在了,可以忽略 if (ExtensionLoader.getExtensionLoader(MonitorFactory.class).hasExtension(\"logstat\")) &#123; map.put(Constants.PROTOCOL_KEY, \"logstat\"); &#125; else &#123; map.put(Constants.PROTOCOL_KEY, \"dubbo\"); &#125; &#125; // 解析地址，创建Dubbo URL 对象 return UrlUtils.parseURL(address, map); /** * 1 当 protocol=registry时，并且注册中心URL非空时，从注册中心发现监控中心地址，以注册中心URL为基础，创建监控中心URL * 2 基于注册中心创建的监控中心URL： protocol = dubbo,parameters.protocol=registry,parameter.refer=map */ &#125; else if (Constants.REGISTRY_PROTOCOL.equals(monitor.getProtocol()) &amp;&amp; registryURL != null) &#123; return registryURL.setProtocol(\"dubbo\").addParameter(Constants.PROTOCOL_KEY, \"registry\").addParameterAndEncoded(Constants.REFER_KEY, StringUtils.toQueryString(map)); &#125; return null; &#125;// 省略其它代码 $&#123;&#125;&#125; 校验接口和方法列表123456789101112131415161718192021222324252627282930313233343536373839404142434445public abstract class AbstractInterfaceConfig extends AbstractMethodConfig &#123;// 省略其它代码 $&#123;&#125; /** * 校验接口和方法： * 1 接口类必须非空并且必须是接口 * 2 方法在接口中已经定义 * * @param interfaceClass * @param methods */ protected void checkInterfaceAndMethods(Class&lt;?&gt; interfaceClass, List&lt;MethodConfig&gt; methods) &#123; // interface cannot be null if (interfaceClass == null) &#123; throw new IllegalStateException(\"interface not allow null!\"); &#125; // to verify interfaceClass is an interface if (!interfaceClass.isInterface()) &#123; throw new IllegalStateException(\"The interface class \" + interfaceClass + \" is not a interface!\"); &#125; // check if methods exist in the interface if (methods != null &amp;&amp; !methods.isEmpty()) &#123; for (MethodConfig methodBean : methods) &#123; String methodName = methodBean.getName(); if (methodName == null || methodName.length() == 0) &#123; throw new IllegalStateException(\"&lt;dubbo:method&gt; name attribute is required! Please check: &lt;dubbo:service interface=\\\"\" + interfaceClass.getName() + \"\\\" ... &gt;&lt;dubbo:method name=\\\"\\\" ... /&gt;&lt;/&lt;dubbo:reference&gt;\"); &#125; boolean hasMethod = false; for (java.lang.reflect.Method method : interfaceClass.getMethods()) &#123; if (method.getName().equals(methodName)) &#123; hasMethod = true; break; &#125; &#125; if (!hasMethod) &#123; throw new IllegalStateException(\"The interface \" + interfaceClass.getName() + \" not found method \" + methodName); &#125; &#125; &#125; &#125;// 省略其它代码 $&#123;&#125;&#125; 校验Stub和Mock相关的配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public abstract class AbstractInterfaceConfig extends AbstractMethodConfig &#123;// 省略其它代码 $&#123;&#125; /** * 校验Stub和Mock相关的配置 * * @param interfaceClass */ protected void checkStubAndMock(Class&lt;?&gt; interfaceClass) &#123; if (ConfigUtils.isNotEmpty(local)) &#123; Class&lt;?&gt; localClass = ConfigUtils.isDefault(local) ? ReflectUtils.forName(interfaceClass.getName() + \"Local\") : ReflectUtils.forName(local); if (!interfaceClass.isAssignableFrom(localClass)) &#123; throw new IllegalStateException(\"The local implementation class \" + localClass.getName() + \" not implement interface \" + interfaceClass.getName()); &#125; try &#123; ReflectUtils.findConstructor(localClass, interfaceClass); &#125; catch (NoSuchMethodException e) &#123; throw new IllegalStateException(\"No such constructor \\\"public \" + localClass.getSimpleName() + \"(\" + interfaceClass.getName() + \")\\\" in local implementation class \" + localClass.getName()); &#125; &#125; if (ConfigUtils.isNotEmpty(stub)) &#123; Class&lt;?&gt; localClass = ConfigUtils.isDefault(stub) ? ReflectUtils.forName(interfaceClass.getName() + \"Stub\") : ReflectUtils.forName(stub); if (!interfaceClass.isAssignableFrom(localClass)) &#123; throw new IllegalStateException(\"The local implementation class \" + localClass.getName() + \" not implement interface \" + interfaceClass.getName()); &#125; try &#123; ReflectUtils.findConstructor(localClass, interfaceClass); &#125; catch (NoSuchMethodException e) &#123; throw new IllegalStateException(\"No such constructor \\\"public \" + localClass.getSimpleName() + \"(\" + interfaceClass.getName() + \")\\\" in local implementation class \" + localClass.getName()); &#125; &#125; // mock 配置校验 if (ConfigUtils.isNotEmpty(mock)) &#123; // 如果mock以 'return' 开头，则去掉该前缀 if (mock.startsWith(Constants.RETURN_PREFIX)) &#123; // 获取return 指定的内容 String value = mock.substring(Constants.RETURN_PREFIX.length()); try &#123; // 解析return指定的内容，并转换成对应的返回类型 MockInvoker.parseMockValue(value); &#125; catch (Exception e) &#123; throw new IllegalStateException(\"Illegal mock json value in &lt;dubbo:service ... mock=\\\"\" + mock + \"\\\" /&gt;\"); &#125; // 不是以 'return' 开头 &#125; else &#123; // 获得Mock类 Class&lt;?&gt; mockClass = ConfigUtils.isDefault(mock) ? ReflectUtils.forName(interfaceClass.getName() + \"Mock\") : ReflectUtils.forName(mock); // 校验是否实现接口 if (!interfaceClass.isAssignableFrom(mockClass)) &#123; throw new IllegalStateException(\"The mock implementation class \" + mockClass.getName() + \" not implement interface \" + interfaceClass.getName()); &#125; // 校验是否有默认的构造方法 try &#123; mockClass.getConstructor(new Class&lt;?&gt;[0]); &#125; catch (NoSuchMethodException e) &#123; throw new IllegalStateException(\"No such empty constructor \\\"public \" + mockClass.getSimpleName() + \"()\\\" in mock implementation class \" + mockClass.getName()); &#125; &#125; &#125; &#125;// 省略其它代码 $&#123;&#125;&#125; ServiceConfig 配置类该类是 服务暴露 的核心类，我们在 Dubbo示例 - API配置 中已经使用API的方式创建一个Dubbo应用，最后通过调用 ServiceConfig#export()方法进行服务的导出，ServiceConfig 继承关系如下： 12345AbstractConfig - AbstractMethodConfig - AbstractInterfaceConfig - AbstractServiceConfig - ServiceConfig AbstractServiceConfig 抽象类中也没有核心的逻辑，主要就是配置属性的设置和获取方法，因此也不再分析。 ServiceConfig#export()方法主要做以下几件事： 进一步初始化Dubbo的配置承载对象，因为有的配置对象我们可能并没有显示创建或配置。 对配置对象们进行校验是否为空，为空则新建，或者抛出异常。 ServiceConfig聚集了Dubbo服务的的所有配置属性，使用它的属性构建Dubbo URL对象 进行服务暴露 ServiceConfig 属性1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class ServiceConfig&lt;T&gt; extends AbstractServiceConfig &#123; /** * 自适应 Protocol实现对象 */ private static final Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension(); /** * 自适应 ProxyFactory 实现对象 */ private static final ProxyFactory proxyFactory = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension(); /** * 随机端口集合 */ private static final Map&lt;String, Integer&gt; RANDOM_PORT_MAP = new HashMap&lt;String, Integer&gt;(); /** * 延迟暴露线程池 */ private static final ScheduledExecutorService delayExportExecutor = Executors.newSingleThreadScheduledExecutor(new NamedThreadFactory(\"DubboServiceDelayExporter\", true)); private final List&lt;URL&gt; urls = new ArrayList&lt;URL&gt;(); /** * 服务配置暴露的Exporter 集合 */ private final List&lt;Exporter&lt;?&gt;&gt; exporters = new ArrayList&lt;Exporter&lt;?&gt;&gt;(); /** * 服务接口全路径名 */ private String interfaceName; /** * 非配置，通过interfaceName 通过反射获得 */ private Class&lt;?&gt; interfaceClass; /** * 服务接口的实现对象 */ private T ref; /** * 服务名 */ private String path; /** * 服务方法配置对象集合 */ private List&lt;MethodConfig&gt; methods; /** * 服务提供者默认配置的配置对象 */ private ProviderConfig provider; private transient volatile boolean exported; private transient volatile boolean unexported; /** * 泛化 */ private volatile String generic; // 省略其它代码 $&#123;&#125;&#125; 进一步初始化配置承载对象123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182public class ServiceConfig&lt;T&gt; extends AbstractServiceConfig &#123; // 省略其它代码 $&#123;&#125; /** * 暴露服务入口，加jvm锁 */ public synchronized void export() &#123; // 当export 或者 delay 未配置时，从ProviderConfig对象读取 if (provider != null) &#123; if (export == null) &#123; export = provider.getExport(); &#125; if (delay == null) &#123; delay = provider.getDelay(); &#125; &#125; // 不暴露服务(export = false),则不进行暴露服务逻辑 if (export != null &amp;&amp; !export) &#123; return; &#125; // 延迟暴露的话，就是使用任务线程池ScheduledExecutorService处理 if (delay != null &amp;&amp; delay &gt; 0) &#123; delayExportExecutor.schedule(new Runnable() &#123; @Override public void run() &#123; doExport(); &#125; &#125;, delay, TimeUnit.MILLISECONDS); &#125; else &#123; doExport(); &#125; &#125; /** * 服务暴露，jvm锁 */ protected synchronized void doExport() &#123; // 检查是否可以暴露，若可以，标记已经暴露然后执行服务暴露逻辑 if (unexported) &#123; throw new IllegalStateException(\"Already unexported!\"); &#125; // 如果已经暴露了直接返回 if (exported) &#123; return; &#125; // 标记已经暴露过了 exported = true; // 校验interfaceName 是否合法，即接口名非空 if (interfaceName == null || interfaceName.length() == 0) &#123; throw new IllegalStateException(\"&lt;dubbo:service interface=\\\"\\\" /&gt; interface not allow null!\"); &#125; // 校验provider是否为空，为空则新建一个，并拼接属性配置（环境变量 + .properties文件中的 属性）到ProviderConfig对象 checkDefault(); // 检测application，module等核心配置类对象是否为空，若为空则尝试从其他配置类对象中获取对应的实例。即： 从ProviderConfig 对象中，读取application,module,registries,monitor,protocols配置对象 if (provider != null) &#123; if (application == null) &#123; application = provider.getApplication(); &#125; if (module == null) &#123; module = provider.getModule(); &#125; if (registries == null) &#123; registries = provider.getRegistries(); &#125; if (monitor == null) &#123; monitor = provider.getMonitor(); &#125; if (protocols == null) &#123; protocols = provider.getProtocols(); &#125; &#125; // 从ModuleConfig 对象中，读取registries,monitor配置对象 if (module != null) &#123; if (registries == null) &#123; registries = module.getRegistries(); &#125; if (monitor == null) &#123; monitor = module.getMonitor(); &#125; &#125; // 从ApplicationConfig 对象中，读取registries,monitor配置对象 if (application != null) &#123; if (registries == null) &#123; registries = application.getRegistries(); &#125; if (monitor == null) &#123; monitor = application.getMonitor(); &#125; &#125; // 检测ref是否泛化接口的实现 if (ref instanceof GenericService) &#123; // 设置 interfaceClass 为 GenericService.class interfaceClass = GenericService.class; if (StringUtils.isEmpty(generic)) &#123; // 设置 generic = \"true\" generic = Boolean.TRUE.toString(); &#125; // 普通接口的实现 &#125; else &#123; try &#123; // 通过反射获取对应的接口的Class interfaceClass = Class.forName(interfaceName, true, Thread.currentThread() .getContextClassLoader()); &#125; catch (ClassNotFoundException e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; // 检验接口和方法 （接口非空，方法都在接口中定义） checkInterfaceAndMethods(interfaceClass, methods); // 校验引用ref是否实现了当前接口 checkRef(); // 标记为非泛化实现 generic = Boolean.FALSE.toString(); &#125; /** 处理服务接口客户端本地代理,即本地存根（local 属性 -&gt; AbstractInterfaceConfig#setLocal）。目前已经废弃，此处主要用于兼容，使用stub属性. todo 服务端没有意义 &#123;@link StubProxyFactoryWrapper#getInvoker(java.lang.Object, java.lang.Class, com.alibaba.dubbo.common.URL)&#125; */ if (local != null) &#123; // 如果local属性设置为ture，表示使用缺省代理类名，即：接口名 + Local 后缀 if (\"true\".equals(local)) &#123; local = interfaceName + \"Local\"; &#125; Class&lt;?&gt; localClass; try &#123; // 获取本地存根类 localClass = ClassHelper.forNameWithThreadContextClassLoader(local); &#125; catch (ClassNotFoundException e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; // 检测本地存根类是否可赋值给接口类，若不可赋值则会抛出异常，提醒使用者本地存根类类型不合法 if (!interfaceClass.isAssignableFrom(localClass)) &#123; throw new IllegalStateException(\"The local implementation class \" + localClass.getName() + \" not implement interface \" + interfaceName); &#125; &#125; /** 处理服务接口客户端本地代理(stub 属性)相关，即本地存根。目的：想在客户端【服务消费方】执行需要的逻辑，不局限服务提供的逻辑。本地存根类编写方式是固定。todo 服务端没有意义 &#123;@link StubProxyFactoryWrapper#getInvoker(java.lang.Object, java.lang.Class, com.alibaba.dubbo.common.URL)&#125;*/ if (stub != null) &#123; // 如果stub属性设置为ture，表示使用缺省代理类名，即：接口名 + Stub 后缀 if (\"true\".equals(stub)) &#123; stub = interfaceName + \"Stub\"; &#125; Class&lt;?&gt; stubClass; try &#123; // 获取本地存根类 stubClass = ClassHelper.forNameWithThreadContextClassLoader(stub); &#125; catch (ClassNotFoundException e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; // 判断interfaceClass 是否是 stubClass 的接口，即 检测本地存根类是否可赋值给接口类，若不可赋值则会抛出异常，提醒使用者本地存根类类型不合法 if (!interfaceClass.isAssignableFrom(stubClass)) &#123; throw new IllegalStateException(\"The stub implementation class \" + stubClass.getName() + \" not implement interface \" + interfaceName); &#125; &#125; /* 检测各种对象是否为空，为空则新建，或者抛出异常*/ // 校验ApplicationConfig配置 checkApplication(); // 校验RegistryConfig配置 checkRegistry(); // 校验ProtocolConfig配置数组 checkProtocol(); // 读取环境变量和properties配置到ServiceConfig对象（自己） appendProperties(this); // 校验Stub和Mock相关的配置 checkStubAndMock(interfaceClass); // 服务路径，缺省是接口名 if (path == null || path.length() == 0) &#123; path = interfaceName; &#125; // 暴露服务 doExportUrls(); ProviderModel providerModel = new ProviderModel(getUniqueServiceName(), this, ref); ApplicationModel.initProviderModel(getUniqueServiceName(), providerModel); &#125; // 省略其它代码 $&#123;&#125;&#125; 多协议多注册中心123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196public class ServiceConfig&lt;T&gt; extends AbstractServiceConfig &#123; // 省略其它代码 $&#123;&#125; /** * Dubbo 允许我们使用不同的协议导出服务，也允许我们向多个注册中心注册服务。Dubbo 在 doExportUrls 方法中对多协议，多注册中心进行了支持 */ @SuppressWarnings(&#123;\"unchecked\", \"rawtypes\"&#125;) private void doExportUrls() &#123; // 加载注册中心URL 数组 【协议已经处理过，不再是配置的注册中心协议 如：zookeeper ,而是统一替换成了registry】 List&lt;URL&gt; registryURLs = loadRegistries(true); // 遍历协议集合，支持多协议暴露。 for (ProtocolConfig protocolConfig : protocols) &#123; doExportUrlsFor1Protocol(protocolConfig, registryURLs); &#125; &#125; /** * 使用不同的协议，逐个向注册中心分组暴露服务。该方法中包含了本地和远程两种暴露方式 * * @param protocolConfig 协议配置对象 * @param registryURLs 处理过的注册中心分组集合【已经添加了ApplicationConfig和RegistryConfig的参数】 */ private void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List&lt;URL&gt; registryURLs) &#123; // 协议名 String name = protocolConfig.getName(); // 协议名为空时，缺省设置为 dubbo if (name == null || name.length() == 0) &#123; name = \"dubbo\"; &#125; // 创建参数集合map，用于Dubbo URL 的构建（服务提供者URL） Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); // 将side,dubbo,timestamp,pid参数，添加到map集合中 map.put(Constants.SIDE_KEY, Constants.PROVIDER_SIDE); map.put(Constants.DUBBO_VERSION_KEY, Version.getProtocolVersion()); map.put(Constants.TIMESTAMP_KEY, String.valueOf(System.currentTimeMillis())); if (ConfigUtils.getPid() &gt; 0) &#123; map.put(Constants.PID_KEY, String.valueOf(ConfigUtils.getPid())); &#125; // 通过反射将各种配置对象中的属性添加到map集合中，map用于URL的构建【注意属性覆盖问题】 appendParameters(map, application); appendParameters(map, module); appendParameters(map, provider, Constants.DEFAULT_KEY); appendParameters(map, protocolConfig); appendParameters(map, this); // 将MethodConfig 对象数组添加到 map 集合中。就是将每个MethodConfig和其对应的ArgumentConfig对象数组添加到map中【处理方法相关的属性到map】 if (methods != null &amp;&amp; !methods.isEmpty()) &#123; // methods 为 MethodConfig 集合，MethodConfig 中存储了 &lt;dubbo:method&gt; 标签的配置信息 for (MethodConfig method : methods) &#123; /** * 将MethodConfig对象的属性添加到map集合中，其中属性键 = 方法名.属性名。如： * &lt;dubbo:method name=\"sleep\" retries=\"2\"&gt;&lt;/dubbo:method&gt;对应的MethodConfig，属性到map的格式 map=&#123;\"sleep.retries\":2,...&#125; */ appendParameters(map, method, method.getName()); // 当配置了 MehodConfig.retry = false 时，强制禁用重试 String retryKey = method.getName() + \".retry\"; if (map.containsKey(retryKey)) &#123; String retryValue = map.remove(retryKey); // 检测 MethodConfig retry 是否为 false，若是，则设置重试次数为0 if (\"false\".equals(retryValue)) &#123; map.put(method.getName() + \".retries\", \"0\"); &#125; &#125; // 将MethodConfig下的ArgumentConfig 对象数组，添加到 map 集合中 List&lt;ArgumentConfig&gt; arguments = method.getArguments(); if (arguments != null &amp;&amp; !arguments.isEmpty()) &#123; for (ArgumentConfig argument : arguments) &#123; // 检测type 属性是否为空， if (argument.getType() != null &amp;&amp; argument.getType().length() &gt; 0) &#123; // 通过反射取出接口的方法列表 Method[] methods = interfaceClass.getMethods(); // 遍历接口中的方法列表 if (methods != null &amp;&amp; methods.length &gt; 0) &#123; for (int i = 0; i &lt; methods.length; i++) &#123; String methodName = methods[i].getName(); // 比对方法名，查找目标方法 if (methodName.equals(method.getName())) &#123; // 通过反射取出目标方法的参数类型列表 Class&lt;?&gt;[] argtypes = methods[i].getParameterTypes(); // 若果配置index配置项，且值不为-1 if (argument.getIndex() != -1) &#123; // 从argtypes数组中获取下标index处的元素argType，并检测ArgumentConfig中的type属性与argType名称是否一致，不一致则抛出异常 if (argtypes[argument.getIndex()].getName().equals(argument.getType())) &#123; // 将ArgumentConfig对象的属性添加到map集合中，键前缀=方法名.index，如：map = &#123;\"sleep.2\":true&#125; appendParameters(map, argument, method.getName() + \".\" + argument.getIndex()); &#125; else &#123; throw new IllegalArgumentException(\"argument config error : the index attribute and type attribute not match :index :\" + argument.getIndex() + \", type:\" + argument.getType()); &#125; &#125; else &#123; // 遍历参数类型数组argtypes，查找argument.type类型的参数 for (int j = 0; j &lt; argtypes.length; j++) &#123; Class&lt;?&gt; argclazz = argtypes[j]; // 从参数类型列表中查找类型名称为argument.type的参数 if (argclazz.getName().equals(argument.getType())) &#123; // 将ArgumentConfig对象的属性添加到map集合中 appendParameters(map, argument, method.getName() + \".\" + j); if (argument.getIndex() != -1 &amp;&amp; argument.getIndex() != j) &#123; throw new IllegalArgumentException(\"argument config error : the index attribute and type attribute not match :index :\" + argument.getIndex() + \", type:\" + argument.getType()); &#125; &#125; &#125; &#125; &#125; &#125; &#125; // 用户未配置 type 属性，但配置了index属性，且index != -1 &#125; else if (argument.getIndex() != -1) &#123; // 指定单个参数的位置 // 将ArgumentConfig对象的属性添加到map集合中 appendParameters(map, argument, method.getName() + \".\" + argument.getIndex()); &#125; else &#123; throw new IllegalArgumentException(\"argument config must set index or type attribute.eg: &lt;dubbo:argument index='0' .../&gt; or &lt;dubbo:argument type=xxx .../&gt;\"); &#125; &#125; &#125; &#125; // end of methods for &#125; //------------------- 检测 generic 是否 为 true ,并根据检测结果向map中添加不同的信息 ---/ // 将 generic,methods,revision 加入到数组 if (ProtocolUtils.isGeneric(generic)) &#123; map.put(Constants.GENERIC_KEY, generic); map.put(Constants.METHODS_KEY, Constants.ANY_VALUE); &#125; else &#123; // 先从MAINFEST.MF 中获取版本号，若获取不到，再从jar包命名中可能带的版本号作为结果，如 2.6.5.RELEASE。若都不存在，返回默认版本号【源码运行可能会没有】 String revision = Version.getVersion(interfaceClass, version); if (revision != null &amp;&amp; revision.length() &gt; 0) &#123; map.put(\"revision\", revision); // 修订号 &#125; // 为接口生成包裹类 Wrapper，Wrapper 中包含了接口的详细信息，比如接口方法名数组，字段信息等【Dubbo 自定义功能类】 String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames(); // 添加方法名到 map 中，如果包含多个方法名，则用逗号隔开，比如：method=a,b if (methods.length == 0) &#123; logger.warn(\"NO method found in service interface \" + interfaceClass.getName()); // 没有方法名就添加 method=* map.put(Constants.METHODS_KEY, Constants.ANY_VALUE); &#125; else &#123; // 将逗号作为分隔符连接方法名，并将连接后的字符串放入 map 中 map.put(Constants.METHODS_KEY, StringUtils.join(new HashSet&lt;String&gt;(Arrays.asList(methods)), \",\")); &#125; &#125; // token 【使暴露出去的服务更安全，使用token做安全校验】 if (!ConfigUtils.isEmpty(token)) &#123; if (ConfigUtils.isDefault(token)) &#123; map.put(Constants.TOKEN_KEY, UUID.randomUUID().toString()); &#125; else &#123; map.put(Constants.TOKEN_KEY, token); &#125; &#125; // 协议为injvm时，不注册，不通知 if (Constants.LOCAL_PROTOCOL.equals(protocolConfig.getName())) &#123; protocolConfig.setRegister(false); map.put(\"notify\", \"false\"); &#125; // 获得基础路径 String contextPath = protocolConfig.getContextpath(); if ((contextPath == null || contextPath.length() == 0) &amp;&amp; provider != null) &#123; contextPath = provider.getContextpath(); &#125; // --------------------------- 主机绑定----------------------------/ // 获得注册到注册中心的服务提供者host，并为map设置bind.ip , anyhost 两个key String host = this.findConfigedHosts(protocolConfig, registryURLs, map); // 获取端口，并为map设置bing.port key Integer port = this.findConfigedPorts(protocolConfig, name, map); /** * 创建Dubbo URL对象 【注意这里的 path 的值】 * 1 name: 协议名 * 2 host: 主机名 * 3 port: 端口 * 4 path: 【基础路径】/path * 5 parameters: 属性集合map */ URL url = new URL(name, host, port, (contextPath == null || contextPath.length() == 0 ? \"\" : contextPath + \"/\") + path, map); // 省略服务暴露代码 &#125; // 省略其它代码 $&#123;&#125;&#125; ReferenceConfig 配置类该类是 服务引用 的核心类，我们在 Dubbo示例 - API配置 中已经使用API的方式创建一个Dubbo应用，最后通过调用 ReferenceConfig#get()方法引用服务，ReferenceConfig 继承关系如下： 12345AbstractConfig - AbstractMethodConfig - AbstractInterfaceConfig - AbstractReferenceConfig - ReferenceConfig AbstractReferenceConfig 抽象类中也没有核心的逻辑，主要就是配置属性的设置和获取方法，因此也不再分析。 ReferenceConfig#get()方法主要做以下几件事： 进一步初始化Dubbo的配置承载对象，因为有的配置对象我们可能并没有显示创建或配置。 对配置对象们进行校验是否为空，为空则新建，或者抛出异常。 ReferenceConfig聚集了Dubbo服务消费者的的所有配置属性，使用它的属性构建Dubbo URL对象 进行服务引用 ReferenceConfig 属性1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class ReferenceConfig&lt;T&gt; extends AbstractReferenceConfig &#123; /** * 自适应 Protocol 拓展实现 */ private static final Protocol refprotocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension(); /** * 自适应 Cluster 拓展实现 */ private static final Cluster cluster = ExtensionLoader.getExtensionLoader(Cluster.class).getAdaptiveExtension(); /** * 自适应 ProxyFactory 拓展实现 */ private static final ProxyFactory proxyFactory = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension(); /** * 服务引用URL数组 */ private final List&lt;URL&gt; urls = new ArrayList&lt;URL&gt;(); /** * 服务接口名 */ private String interfaceName; /** * 服务接口 */ private Class&lt;?&gt; interfaceClass; /** * 连接类型 */ private String client; /** * 直连服务提供者地址 * 1 可以是注册中心，也可以是服务提供者 * 2 可以配置多个，使用 \";\" 分割 */ private String url; /** * 方法配置对象集合 */ private List&lt;MethodConfig&gt; methods; /** * 消费者默认配置的配置对象 */ private ConsumerConfig consumer; /** * 协议 */ private String protocol; /** * 服务接口代理对象 */ private transient volatile T ref; /** * Invoker */ private transient volatile Invoker&lt;?&gt; invoker; private transient volatile boolean initialized; private transient volatile boolean destroyed; // 省略其它代码 $&#123;&#125;&#125; 进一步初始化配置承载对象123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230public class ReferenceConfig&lt;T&gt; extends AbstractReferenceConfig &#123; // 省略其它代码 $&#123;&#125; public synchronized T get() &#123; // 已销毁，不可获得 if (destroyed) &#123; throw new IllegalStateException(\"Already destroyed!\"); &#125; // 若未初始化，调用init()方法进行初始化 if (ref == null) &#123; init(); &#125; // 返回引用服务 return ref; &#125; private void init() &#123; // 已经初始化过，直接返回 if (initialized) &#123; return; &#125; initialized = true; // 校验接口名非空 if (interfaceName == null || interfaceName.length() == 0) &#123; throw new IllegalStateException(\"&lt;dubbo:reference interface=\\\"\\\" /&gt; interface not allow null!\"); &#125; // 拼接属性配置（环境变量 + .properties 中的属性）到 ConsumerConfig对象 checkDefault(); // 拼接属性配置（环境变量 + .properties 中的属性）到ReferenceConfig（自己） appendProperties(this); // 若未设置 generic 属性，就使用ConsumerConfig的generic属性 if (getGeneric() == null &amp;&amp; getConsumer() != null) &#123; setGeneric(getConsumer().getGeneric()); &#125; // 是否是泛化接口的实现，如果是泛化接口实现的话，就直接设置当前接口为 GenericService.class if (ProtocolUtils.isGeneric(getGeneric())) &#123; interfaceClass = GenericService.class; // 普通接口的实现 &#125; else &#123; try &#123; // 根据接口名，获得对应的接口类 interfaceClass = Class.forName(interfaceName, true, Thread.currentThread().getContextClassLoader()); &#125; catch (ClassNotFoundException e) &#123; throw new IllegalStateException(e.getMessage(), e); &#125; // 校验接口和方法 checkInterfaceAndMethods(interfaceClass, methods); &#125; // 直连提供者，第一优先级，通过 -D 参数（系统变量）指定 ，例如 java -Dcom.alibaba.xxx.XxxService=dubbo://localhost:20890 String resolve = System.getProperty(interfaceName); String resolveFile = null; // 直连提供者第二优先级，通过文件映射，例如 com.alibaba.xxx.XxxService=dubbo://localhost:20890 if (resolve == null || resolve.length() == 0) &#123; // 从系统属性中获取解析文件路径 resolveFile = System.getProperty(\"dubbo.resolve.file\"); if (resolveFile == null || resolveFile.length() == 0) &#123; // 默认先加载 $&#123;user.home&#125;/dubbo-resolve.properties 文件，无需配置，自动加载 File userResolveFile = new File(new File(System.getProperty(\"user.home\")), \"dubbo-resolve.properties\"); if (userResolveFile.exists()) &#123; // 获取文件绝对路径 resolveFile = userResolveFile.getAbsolutePath(); &#125; &#125; // 存在resolveFile,则进行文件读取加载 if (resolveFile != null &amp;&amp; resolveFile.length() &gt; 0) &#123; Properties properties = new Properties(); FileInputStream fis = null; try &#123; fis = new FileInputStream(new File(resolveFile)); // 从文件中加载配置 properties.load(fis); &#125; catch (IOException e) &#123; throw new IllegalStateException(\"Unload \" + resolveFile + \", cause: \" + e.getMessage(), e); &#125; finally &#123; try &#123; if (null != fis) &#123; fis.close(); &#125; &#125; catch (IOException e) &#123; logger.warn(e.getMessage(), e); &#125; &#125; // 根据服务全路径名获取对应的 直连提供者的url resolve = properties.getProperty(interfaceName); &#125; &#125; // 设置直连提供者的 url if (resolve != null &amp;&amp; resolve.length() &gt; 0) &#123; url = resolve; if (logger.isWarnEnabled()) &#123; if (resolveFile != null) &#123; logger.warn(\"Using default dubbo resolve file \" + resolveFile + \" replace \" + interfaceName + \"\" + resolve + \" to p2p invoke remote service.\"); &#125; else &#123; logger.warn(\"Using -D\" + interfaceName + \"=\" + resolve + \" to p2p invoke remote service.\"); &#125; &#125; &#125; // 不通过系统属性指定，就使用配置的直连（在配置的前提下），如：&lt;dubbo:reference id=\"xxxService\" interface=\"com.alibaba.xxx.XxxService\" url=\"dubbo://localhost:20890\" /&gt; // 尝试从ConsumerConfig 对象中，读取 application,module,registries,monitor 配置对象 if (consumer != null) &#123; if (application == null) &#123; application = consumer.getApplication(); &#125; if (module == null) &#123; module = consumer.getModule(); &#125; if (registries == null) &#123; registries = consumer.getRegistries(); &#125; if (monitor == null) &#123; monitor = consumer.getMonitor(); &#125; &#125; // 从ModuleConfig 对象中，读取registries,monitor配置对象 if (module != null) &#123; if (registries == null) &#123; registries = module.getRegistries(); &#125; if (monitor == null) &#123; monitor = module.getMonitor(); &#125; &#125; // 从ApplicationConfig对象中，读取registries,monitor配置对象 if (application != null) &#123; if (registries == null) &#123; registries = application.getRegistries(); &#125; if (monitor == null) &#123; monitor = application.getMonitor(); &#125; &#125; // 校验ApplicationConfig配置 checkApplication(); // 校验 Stub和 Mock 相关的配置 checkStubAndMock(interfaceClass); // 创建参数集合map，用于下面创建Dubbo URL Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); // 符合条件的方法对象的属性，主要用来Dubbo事件通知 Map&lt;Object, Object&gt; attributes = new HashMap&lt;Object, Object&gt;(); // 将 side，dubbo,timestamp,pid参数，添加到map集合中 map.put(Constants.SIDE_KEY, Constants.CONSUMER_SIDE); map.put(Constants.DUBBO_VERSION_KEY, Version.getProtocolVersion()); map.put(Constants.TIMESTAMP_KEY, String.valueOf(System.currentTimeMillis())); if (ConfigUtils.getPid() &gt; 0) &#123; map.put(Constants.PID_KEY, String.valueOf(ConfigUtils.getPid())); &#125; // 非泛化服务，设置revision,methods,interface加入到map集合中 if (!isGeneric()) &#123; String revision = Version.getVersion(interfaceClass, version); if (revision != null &amp;&amp; revision.length() &gt; 0) &#123; map.put(\"revision\", revision); &#125; // 获取接口方法列表，并添加到map中 String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames(); if (methods.length == 0) &#123; logger.warn(\"NO method found in service interface \" + interfaceClass.getName()); map.put(\"methods\", Constants.ANY_VALUE); &#125; else &#123; map.put(\"methods\", StringUtils.join(new HashSet&lt;String&gt;(Arrays.asList(methods)), \",\")); &#125; &#125; map.put(Constants.INTERFACE_KEY, interfaceName); // 将各种配置对象中的属性，添加到 map 集合中 appendParameters(map, application); appendParameters(map, module); appendParameters(map, consumer, Constants.DEFAULT_KEY); appendParameters(map, this); // 获得服务键，作为前缀 格式：group/interface:version String prefix = StringUtils.getServiceKey(map); // 将MethodConfig 对象数组中每个MethodConfig中的属性添加到map中 if (methods != null &amp;&amp; !methods.isEmpty()) &#123; // 遍历 MethodConfig 列表 for (MethodConfig method : methods) &#123; appendParameters(map, method, method.getName()); // 当配置了 MethodConfig.retry=false 时，强制禁用重试 String retryKey = method.getName() + \".retry\"; if (map.containsKey(retryKey)) &#123; String retryValue = map.remove(retryKey); if (\"false\".equals(retryValue)) &#123; // 添加重试次数配置 methodName.retries map.put(method.getName() + \".retries\", \"0\"); &#125; &#125; // 将带有@Parameter(attribute=true)配置对象的属性，添加到参数集合中 appendAttributes(attributes, method, prefix + \".\" + method.getName()); // 检查属性集合中的事件通知方法是否正确，若正确，进行转换 checkAndConvertImplicitConfig(method, map, attributes); &#125; &#125; // 以系统环境变量（DUBBO_IP_TO_REGISTRY）的值作为服务消费者ip地址,没有设置再取主机地址 String hostToRegistry = ConfigUtils.getSystemProperty(Constants.DUBBO_IP_TO_REGISTRY); if (hostToRegistry == null || hostToRegistry.length() == 0) &#123; hostToRegistry = NetUtils.getLocalHost(); &#125; else if (isInvalidLocalHost(hostToRegistry)) &#123; throw new IllegalArgumentException(\"Specified invalid registry ip from property:\" + Constants.DUBBO_IP_TO_REGISTRY + \", value:\" + hostToRegistry); &#125; map.put(Constants.REGISTER_IP_KEY, hostToRegistry); // 把attributes集合添加到StaticContext进行缓存，为了以后的事件通知 StaticContext.getSystemContext().putAll(attributes); try&#123; System.out.println(\" ref = createProxy(map); is begin.....\"); Thread.sleep(5000); &#125;catch (Exception ex)&#123; &#125; // 省略服务引用代码 &#125; // 省略其它代码 $&#123;&#125;&#125; 其它配置类前面只是针对Dubbo的核心配置类进行了分析，还很多其它的配置类并没有分析到(ServiceBean和ReferenceBean属于整合Spring的配置类，我们在XML配置中分析)，不过没有分析到的配置类中几乎都没有复杂的逻辑，大多是封装了配置属性的设置和获取操作。每个配置类中封装的配置属性都有所不同，那些抽象的配置类封装的都是可供不同子类复用的属性和方法，每个配置类可以设置那些属性我们可以参考官方文档，需要说明的是，官网给出的是XML配置形式，不过按照对应的规则转换就可以相通了。 总结Dubbo的配置相对比较枯燥，刚开始看的时候可能有点蒙圈，笔者也是硬着头皮看了好久，看完后也不是很理解，但是把整个流程看完后再回来看体会就更深了。XML配置和注解配置也是基于API配置和属性配置的，区别是XML配置和注解配置要解决和Spring融合问题，我们在接下来的文章中再详细分析。嘿咻，整篇文章都在贴代码！","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/tags/RPC/"}]},{"title":"Dubbo源码分析 - 动态编译","slug":"rpc/Dubbo动态编译","date":"2020-03-21T16:00:00.000Z","updated":"2021-02-18T09:59:43.253Z","comments":false,"path":"posts/68ac5094/","link":"","permalink":"https://gentryhuang.com/posts/68ac5094/","excerpt":"","text":"概述在Dubbo自适应扩展中，我们已经得到了自适应扩展类的字符串，需要通过编译才能得到真正的Class，本篇文章就来介绍将类的字符串编译成类的过程。 动态编译 dubbo 的动态编译的整体结构如上图所示。dubbo中的Compiler基于dubbo spi机制进行加载，目前支持jdk和javassist两种实现： 12&lt;dubbo:application compiler=\"jdk\" /&gt;&lt;dubbo:application compiler=\"javassist\" /&gt; 整体了解了dubbo的动态编译后，我们接着上一篇文章继续分析，dubbo动态编译入口的代码如下： 12345678910private Class&lt;?&gt; createAdaptiveExtensionClass() &#123; // 生成自适应拓展实现的代码字符串 String code = createAdaptiveExtensionClassCode(); // 获取类加载器 ClassLoader classLoader = findClassLoader(); // 获取Compiler自适应扩展对象 com.alibaba.dubbo.common.compiler.Compiler compiler = ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.common.compiler.Compiler.class).getAdaptiveExtension(); // 动态编译，生成Class return compiler.compile(code, classLoader);&#125; 该方法在编译阶段需要先获取自适应编译对象，然后调用该对象的compile方法进行代码的编译。其实这里并不是直接使用自适应对象进行代码编译，而是将具体的编译任务交给子类来完成，即JdkCompiler子类和JavassistCompiler子类，下面我们来看看dubbo 动态编译的成员及它们的用途。 Compiler 扩展接口12345678910111213141516/** * Compiler. (SPI, Singleton, ThreadSafe) * 使用Dubbo SPI机制，默认拓展名为javassist */@SPI(\"javassist\")public interface Compiler &#123; /** * 编译Java 代码 * * @param code Java代码字符串 * @param classLoader 类加载器 * @return Compiled class 编译后的类 */ Class&lt;?&gt; compile(String code, ClassLoader classLoader);&#125; AdaptiveCompiler 固定自适应扩展类12345678910111213141516171819202122232425262728293031323334353637383940/** * AdaptiveCompiler. (SPI, Singleton, ThreadSafe) * 实现Compiler接口，带有@Adaptive注解，是固定的自适应实现类 */@Adaptivepublic class AdaptiveCompiler implements Compiler &#123; /** * 默认编辑器的拓展名 */ private static volatile String DEFAULT_COMPILER; /** * 静态方法，设置默认编辑器的拓展名。该方法被 &#123;@link com.alibaba.dubbo.config.ApplicationConfig#setCompiler(java.lang.String)&#125;方法调用. * 在&lt;dubbo:application compiler=\"\"/&gt; 配置 可触发该方法 * * @param compiler */ public static void setDefaultCompiler(String compiler) &#123; DEFAULT_COMPILER = compiler; &#125; @Override public Class&lt;?&gt; compile(String code, ClassLoader classLoader) &#123; Compiler compiler; // 获得Compiler的ExtensionLoader对象 ExtensionLoader&lt;Compiler&gt; loader = ExtensionLoader.getExtensionLoader(Compiler.class); // 声明 name 变量 String name = DEFAULT_COMPILER; // 使用设置的拓展名，获得Compiler拓展对象 if (name != null &amp;&amp; name.length() &gt; 0) &#123; compiler = loader.getExtension(name); // 获得默认的Compiler拓展对象 &#125; else &#123; compiler = loader.getDefaultExtension(); &#125; // 使用真正的Compiler对象，动态编译代码 return compiler.compile(code, classLoader); &#125;&#125; 该类使用了@Adaptive注解，说明AdaptiveCompiler会固定为默认实现，通过代码的逻辑不难发现，该类主要用来管理其它的Compiler,每次调用compiler方法时会尝试根据扩展名获取Compiler的扩展对象，默认情况下使用JavassistCompiler扩展对象，然后使用编译对象进行动态编译代码串。 AbstractCompiler 抽象编译类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public abstract class AbstractCompiler implements Compiler &#123; /** * 包名的正则表达式，注意匹配组 */ private static final Pattern PACKAGE_PATTERN = Pattern.compile(\"package\\\\s+([$_a-zA-Z][$_a-zA-Z0-9\\\\.]*);\"); /** * 类名的正则表达式，注意匹配组 */ private static final Pattern CLASS_PATTERN = Pattern.compile(\"class\\\\s+([$_a-zA-Z][$_a-zA-Z0-9]*)\\\\s+\"); @Override public Class&lt;?&gt; compile(String code, ClassLoader classLoader) &#123; // 获得包名 code = code.trim(); Matcher matcher = PACKAGE_PATTERN.matcher(code); String pkg; if (matcher.find()) &#123; pkg = matcher.group(1); &#125; else &#123; pkg = \"\"; &#125; // 获得类名 matcher = CLASS_PATTERN.matcher(code); String cls; if (matcher.find()) &#123; cls = matcher.group(1); &#125; else &#123; throw new IllegalArgumentException(\"No such class name in \" + code); &#125; // 获得完整类名： 包名.类名 String className = pkg != null &amp;&amp; pkg.length() &gt; 0 ? pkg + \".\" + cls : cls; try &#123; // 使用类加载器尝试加载类，如果加载成功，说明已经存在（可能编译过了） return Class.forName(className, true, ClassHelper.getCallerClassLoader(getClass())); // 如果加载失败，可能类不存在，说明可能未编译过，就进行编译 &#125; catch (ClassNotFoundException e) &#123; // 代码格式验证 if (!code.endsWith(\"&#125;\")) &#123; throw new IllegalStateException(\"The java code not endsWith \\\"&#125;\\\", code: \\n\" + code + \"\\n\"); &#125; try &#123; // 使用具体的编译器进行代码编译，由子类实现 return doCompile(className, code); &#125; catch (RuntimeException t) &#123; throw t; &#125; catch (Throwable t) &#123; throw new IllegalStateException(\"Failed to compile class, cause: \" + t.getMessage() + \", class: \" + className + \", code: \\n\" + code + \"\\n, stack: \" + ClassUtils.toString(t)); &#125; &#125; &#125; /** * 编译代码 * * @param name 类名 * @param source 代码串 * @return 编译后的类 * @throws Throwable 异常 */ protected abstract Class&lt;?&gt; doCompile(String name, String source) throws Throwable;&#125; 该抽象类主要做两件事情，先获取要编译的字符串中的类的全路径名，根据类名尝试加载对应的类，如果加载成功说明已经编译过了，就直接返回即可，防止重复编译。如果加载失败，那么就需要进行编译处理。接下来将编译的任务交给具体的子类来完成。 JavassistCompiler 编译器在介绍JavassistCompiler编译器前，我们需要先简单了解下Javassist，这样就能很好理解JavassistCompiler的逻辑了。Javassist是用来处理java字节码的类库，可以进行分析、编辑和创建Java字节码，它提供了丰富的API，可以使开发人员很方便操作字节码。不仅如此，我们知道处理Java字节码的工具很多，如cglib，asm等，为什么选择Javassist呢？因为Javassist简单且快速，可以直接使用Java编码的方式而不需要了解虚拟机指令就能动态改变类的结构，或者动态生成类。下面我们来看下javassist的几个API，dubbo就是使用javassist的API来动态生成类的。 读取Class 1234567891011121314// 获取默认的ClassPool（搜索类路径只是JVM的同路径下的class），是一个Javassist的类池ClassPool pool = ClassPool.getDefault();//从classpath中查询类XxxCtClass cc = pool.get(\"Xxx\");//设置Xxx的父类Yyycc.setSuperclass(pool.get(\"Yyy\"));// 转为字节数组，进行CtClass的冻结byte[] b=cc.toBytecode();// 生成class 类，默认加载到当前线程的ClassLoader中，也可以选择输出的ClassLoader。Class clazz=cc.toClass();// 修改读取的Class的name，这样会创建一个新的Class，旧的不会删除cc.setName(\"XxxTemp\");// 其它api... 创建Class 12345678910111213ClassPool pool = ClassPool.getDefault();// 创建一个Xxx类CtClass cc = pool.makeClass(\"Xxx\");//新增方法CtMethod m = CtNewMethod.make(\"public void test()&#123;System.out.print(hello world)&#125;\",cc);cc.addMethod(m);//新增FieldCtField f = new CtField(CtClass.intType, \"a\", point);cc.addField(f);//引入包pool.importPackage(\"package\");// 其它api... 搜索路径 12345678910ClassPool pool = ClassPool.getDefault();//默认加载方式如pool.insertClassPath(new ClassClassPath(this.getClass()));//从文件加载classpathpool.insertClassPath(\"filepath\")//从URL中加载pool.insertClassPath(new URLClassPath(\"xxx\"));//追加 LoaderClassPathpool.appendClassPath(new LoaderClassPath(ClassHelper.getCallerClassLoader(getClass()))); 具体操作示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899public class JavassistCompilerDemo &#123; public static void main(String[] args) throws Exception &#123; // 创建 createStudentClass(); // 读取 readStudentClass(); &#125; /** * 创建字节码信息 * * @throws Exception */ private static void createStudentClass() throws Exception &#123; // 创建ClassPool ClassPool pool = ClassPool.getDefault(); // 创建 com.alibaba.dubbo.test.Student 类 CtClass ctClass = pool.makeClass(\"com.alibaba.dubbo.test.Student\"); // 创建属性(通用形式) CtField nameField = CtField.make(\"private String name;\", ctClass); ctClass.addField(nameField); // API形式创建属性 CtField ageField = new CtField(pool.getCtClass(\"int\"), \"age\", ctClass); ageField.setModifiers(Modifier.PRIVATE); ctClass.addField(ageField); // 创建方法 （通用方式） CtMethod setName = CtMethod.make(\"public void setName(String name)&#123;this.name = name;&#125;\", ctClass); CtMethod getName = CtMethod.make(\"public String getName()&#123;return name;&#125;\", ctClass); ctClass.addMethod(setName); ctClass.addMethod(getName); // api形式创建方法 ctClass.addMethod(CtNewMethod.getter(\"getAge\", ageField)); ctClass.addMethod(CtNewMethod.setter(\"setAge\", ageField)); //创建无参构造方法 CtConstructor ctConstructor = new CtConstructor(null, ctClass); ctConstructor.setBody(\"&#123;&#125;\"); ctClass.addConstructor(ctConstructor); // 创建有参构造方法 CtConstructor constructor = new CtConstructor(new CtClass[]&#123;CtClass.intType, pool.get(\"java.lang.String\")&#125;, ctClass); constructor.setBody(\"&#123;this.age=age;this.name=name;&#125;\"); ctClass.addConstructor(constructor); // api创建普通方法 CtMethod ctMethod = new CtMethod(CtClass.voidType, \"sayHello\", new CtClass[]&#123;&#125;, ctClass); ctMethod.setModifiers(Modifier.PUBLIC); ctMethod.setBody(new StringBuilder(\"&#123;\\n System.out.println(\\\"hello world!\\\"); \\n&#125;\").toString()); ctClass.addMethod(ctMethod); // 生成class 类 Class&lt;?&gt; clazz = ctClass.toClass(); // 反射创建对象 Object obj = clazz.newInstance(); //方法调用 obj.getClass().getMethod(\"sayHello\", new Class[]&#123;&#125;).invoke(obj); // 获取ctClass的字节码 byte[] codeByteArray = ctClass.toBytecode(); // 将字节码写入到class文件中 FileOutputStream fos = new FileOutputStream(new File(\"/opt/test/Student.class\")); fos.write(codeByteArray); fos.close(); &#125; /** * 访问已存在的字节码信息 * * @throws Exception */ private static void readStudentClass() throws Exception &#123; // 创建ClassPool ClassPool pool = ClassPool.getDefault(); CtClass ctClass = pool.get(\"com.alibaba.dubbo.test.Student\"); //得到字节码 byte[] bytes = ctClass.toBytecode(); System.out.println(Arrays.toString(bytes)); //获取类名 System.out.println(ctClass.getName()); //获取接口 System.out.println(Arrays.toString(ctClass.getInterfaces())); //获取方法列表 System.out.println(Arrays.toString(ctClass.getMethods())); &#125;&#125; 运行上面的代码会在本地/opt/test文件目录下生成了一个Student.class文件，我们通过 javap 命令进行反编译的结果如下：1234567891011$ javap Student.class Compiled from \"Student.java\"public class com.alibaba.dubbo.test.Student &#123; public void setName(java.lang.String); public java.lang.String getName(); public int getAge(); public void setAge(int); public com.alibaba.dubbo.test.Student(); public com.alibaba.dubbo.test.Student(int, java.lang.String); public void sayHello();&#125; 可以清楚地看到，通过Javassist把一个完整的class字符串编译成为一个Class，有了这个案例的铺垫我们就很容易理解JavassistCompiler的原理了，让我们一起来看看它的逻辑。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140/** * JavassistCompiler. (SPI, Singleton, ThreadSafe) * 基于 Javassist 实现的 Compiler */public class JavassistCompiler extends AbstractCompiler &#123; /** * 匹配import */ private static final Pattern IMPORT_PATTERN = Pattern.compile(\"import\\\\s+([\\\\w\\\\.\\\\*]+);\\n\"); /** * 匹配 extents */ private static final Pattern EXTENDS_PATTERN = Pattern.compile(\"\\\\s+extends\\\\s+([\\\\w\\\\.]+)[^\\\\&#123;]*\\\\&#123;\\n\"); /** * 匹配 implements */ private static final Pattern IMPLEMENTS_PATTERN = Pattern.compile(\"\\\\s+implements\\\\s+([\\\\w\\\\.]+)\\\\s*\\\\&#123;\\n\"); /** * 正则匹配方法/属性 */ private static final Pattern METHODS_PATTERN = Pattern.compile(\"\\n(private|public|protected)\\\\s+\"); /** * 正则匹配变量 */ private static final Pattern FIELD_PATTERN = Pattern.compile(\"[^\\n]+=[^\\n]+;\"); @Override public Class&lt;?&gt; doCompile(String name, String source) throws Throwable &#123; // 获得类名 int i = name.lastIndexOf('.'); String className = i &lt; 0 ? name : name.substring(i + 1); // 创建ClassPoll对象 ClassPool pool = new ClassPool(true); // 设置类搜索路径 pool.appendClassPath(new LoaderClassPath(ClassHelper.getCallerClassLoader(getClass()))); // 匹配import Matcher matcher = IMPORT_PATTERN.matcher(source); // 引入包名 List&lt;String&gt; importPackages = new ArrayList&lt;String&gt;(); // 引入类名 Map&lt;String, String&gt; fullNames = new HashMap&lt;String, String&gt;(); // 匹配import，导入依赖包 while (matcher.find()) &#123; String pkg = matcher.group(1); // 导入整个包下的类/接口 if (pkg.endsWith(\".*\")) &#123; String pkgName = pkg.substring(0, pkg.length() - 2); pool.importPackage(pkgName); importPackages.add(pkgName); // 导入指定类/接口 &#125; else &#123; int pi = pkg.lastIndexOf('.'); if (pi &gt; 0) &#123; String pkgName = pkg.substring(0, pi); pool.importPackage(pkgName); importPackages.add(pkgName); fullNames.put(pkg.substring(pi + 1), pkg); &#125; &#125; &#125; String[] packages = importPackages.toArray(new String[0]); // 匹配extends matcher = EXTENDS_PATTERN.matcher(source); CtClass cls; if (matcher.find()) &#123; String extend = matcher.group(1).trim(); String extendClass; // 内嵌的类，如： extends A.B if (extend.contains(\".\")) &#123; extendClass = extend; // 指定引用的类 &#125; else if (fullNames.containsKey(extend)) &#123; extendClass = fullNames.get(extend); // 引用整个包下的类 &#125; else &#123; extendClass = ClassUtils.forName(packages, extend).getName(); &#125; // 创建 CtClass 对象 cls = pool.makeClass(name, pool.get(extendClass)); &#125; else &#123; // 创建 CtClass 对象 cls = pool.makeClass(name); &#125; // 匹配 implements matcher = IMPLEMENTS_PATTERN.matcher(source); if (matcher.find()) &#123; String[] ifaces = matcher.group(1).trim().split(\"\\\\,\"); for (String iface : ifaces) &#123; iface = iface.trim(); String ifaceClass; // 内嵌的接口，例如：extends A.B if (iface.contains(\".\")) &#123; ifaceClass = iface; // 指定引用的接口 &#125; else if (fullNames.containsKey(iface)) &#123; ifaceClass = fullNames.get(iface); // 引用整个包下的接口 &#125; else &#123; ifaceClass = ClassUtils.forName(packages, iface).getName(); &#125; // 添加接口 cls.addInterface(pool.get(ifaceClass)); &#125; &#125; // 获得类中的内容，即 &#123; &#125; 内的内容 String body = source.substring(source.indexOf(\"&#123;\") + 1, source.length() - 1); // 匹配 方法、属性 String[] methods = METHODS_PATTERN.split(body); for (String method : methods) &#123; method = method.trim(); if (method.length() &gt; 0) &#123; // 构造方法 if (method.startsWith(className)) &#123; cls.addConstructor(CtNewConstructor.make(\"public \" + method, cls)); // 变量 &#125; else if (FIELD_PATTERN.matcher(method).matches()) &#123; cls.addField(CtField.make(\"private \" + method, cls)); // 方法 &#125; else &#123; cls.addMethod(CtNewMethod.make(\"public \" + method, cls)); &#125; &#125; &#125; // 生成类 return cls.toClass(ClassHelper.getCallerClassLoader(getClass()), JavassistCompiler.class.getProtectionDomain()); &#125;&#125; 整个逻辑下来就是按照编写一个类的步骤对自适应类的字符串进行正则匹配拆解，不断通过正则表达式匹配不同部分的代码，然后调用Javassist的API生成代表不同部分的对象，最终组装成一个完整的自适应扩展类，还是挺简单的。这里说一句，dubbo中很多地方都是采用拼接字符串方式，然后通过具体的技术手段生成目标对象，如dubbo 的服务暴露源码中Wrapper类的生成逻辑也是先拼接字符串，然后通过dubbo的ClassGenerator处理成Class，但是ClassGenerator内部也是封装了Javassist相关对象，具体生成Class还是Javassist来完成的。 JdkCompiler 编译器JdkCompiler使用的是jdk内置的编译器，主要使用三个不同功能的对象完成对字符串的编译: JavaFileObject对象将字符串代码包装成一个文件对象 JavaFileManager接口负责管理文件的读取和输出位置 JavaCompiler.CompilationTask 对象把JavaFileObject对象 编译成具体的类 1234567891011121314151617181920212223public Class&lt;?&gt; doCompile(String name, String sourceCode) throws Throwable &#123; int i = name.lastIndexOf('.'); String packageName = i &lt; 0 ? \"\" : name.substring(0, i); String className = i &lt; 0 ? name : name.substring(i + 1); // 1 创建JavaFileObject 对象 JavaFileObjectImpl javaFileObject = new JavaFileObjectImpl(className, sourceCode); // 2 JavaFileManager 管理类文件的输入和输出位置 javaFileManager.putFileForInput(StandardLocation.SOURCE_PATH, packageName, className + ClassUtils.JAVA_EXTENSION, javaFileObject); // 3 调用JavaCompiler.CompilationTask 的call方法 把JavaFileObject对象 编译成具体的类 Boolean result = compiler.getTask(null, javaFileManager, diagnosticCollector, options, null, Arrays.asList(javaFileObject)) .call(); if (result == null || !result) &#123; throw new IllegalStateException(\"Compilation failed. class: \" + name + \", diagnostics: \" + diagnosticCollector); &#125; // 加载生成的类 return classLoader.loadClass(name);&#125; 上面代码就是JdkCompiler编译的逻辑，使用的都是jdk的接口，想要了解更多可以自行查看源代码，其它的就不多做分析。 小结自此，dubbo spi分析完了。dubbo框架具有良好的扩展性得益于两个方面，第一个方面就是在不同的场景中，dubbo使用了不同的设计模式，第二个方面就是dubbo spi机制。可以说dubbo中几乎所有的组件都是通过dubbo spi机制串联起来的，串联的总线就是Dubbo URL，可见dubbo spi在整个框架中的重要性。在接下来的几篇文章中我们将一起了解下dubbo多样的配置，总体上不难，就是内容有点多。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Javassist","slug":"Javassist","permalink":"https://gentryhuang.com/tags/Javassist/"}]},{"title":"Dubbo源码分析 - 自适应扩展","slug":"rpc/Dubbo自适应扩展","date":"2020-03-17T16:00:00.000Z","updated":"2020-09-03T03:12:53.633Z","comments":false,"path":"posts/3e0b5964/","link":"","permalink":"https://gentryhuang.com/posts/3e0b5964/","excerpt":"","text":"前言上一篇文章中我们分析了dubbo spi机制，但是遗留了自适应扩展并没有展开说明，这篇文章就是来填坑的。上篇文章中也介绍了固定的自适应扩展类以及加载的流程，这篇文章主要专注于自动生成的自适应扩展类以及自适应扩展对象的创建，就不再过多介绍固定的自适应扩展。自适应扩展整体上需要讨论三部分内容：自适应扩展原理、自适应扩展类串的生成 和 动态编译 。 该篇文章将讨论前两个部分，动态编译会单独写一篇文章详细说明。 自适应扩展原理扩展点的扩展类一般会在框架启动时被加载，但我们这次的主角并不会在框架启动时被加载，只可能在获取自适应实现的时候被创建、编译和实例化。这里之所以说可能，是当一个扩展接口既有固定的自适应扩展类，又想实现自动生成自适应扩展类的情况下，只会以固定的自适应扩展类为准，不会去创建动态的自适应扩展类，在框架启动时就会加载固定扩展类并放入缓存。当缓存中不存在自适应扩展类时，dubbo没有直接使用代理模式实现自适应扩展，而是为扩展接口生成具有代理功能的代码，然后通过动态编译得到自适应类，整个过程最终的目的是为扩展点生成代理对象，而代理对象主要任务就是从URL中获取扩展名对应的扩展实。接下来我们通过对官网的例子稍加改动来说明自动生成的自适应扩展的原理。 车轮制造接口 WheelMaker 123public interface WheelMaker &#123; void makeWheel(URL url);&#125; WheelMaker 接口的普通实现类 123456// CommonWheelMaker对应的扩展名设置为 commonWheelMakerpublic class CommonWheelMaker implements WheelMaker &#123; public void makeWheel(URL url) &#123; System.out.println(\"打印url，制造全宇宙最好的车轮...\" + url); &#125;&#125; WheelMaker 接口的自适应实现类 12345678910111213141516171819public class AdaptiveWheelMaker implements WheelMaker &#123; public void makeWheel(URL url) &#123; if (url == null) &#123; throw new IllegalArgumentException(\"url == null\"); &#125; // 1.从 URL 中获取 WheelMaker 名称 String wheelMakerName = url.getParameter(\"wheel.maker\"); if (wheelMakerName == null) &#123; throw new IllegalArgumentException(\"wheelMakerName == null\"); &#125; // 2.通过 SPI 加载 WheelMaker 名称 对应WheelMaker具体实现。这里获取扩展实现还是使用getExtension方法。 WheelMaker wheelMaker = ExtensionLoader.getExtensionLoader(WheelMaker.class).getExtension(wheelMakerName); // 3.调用目标方法 wheelMaker.makeWheel(url); &#125;&#125; AdaptiveWheelMaker 是一个代理类[在dubbo框架中该类型的类是自动生成的,并发手动实现],与传统的代理逻辑不同，AdaptiveWheelMaker 所代理的对象是在 makeWheel 方法中通过 SPI 加载得到的。makeWheel 方法主要做了三件事情： 从 URL 中获取 WheelMaker 扩展名 通过 SPI 加载具体的 WheelMaker 实现类 调用目标方法 程序运行时，假设我们获取到了AdaptiveWheelMaker对象，然后调用它的makeWheel方法，然后有这样一个 url 参数传入： 1dubbo:&#x2F;&#x2F;192.168.0.101:20880&#x2F;XxxService?wheel.maker&#x3D;commonWheelMaker AdaptiveWheelMaker 的 makeWheel 方法从 url 中提取 wheel.maker 参数，得到扩展名 commonWheelMaker，之后再通过 SPI 加载扩展名为 commonWheelMaker 的实现类，最终得到具体的 WheelMaker 实例。 原理小结这个例子展示了自动生成的自适应扩展类的核心实现，即在扩展接口的方法被调用（dubbo中是使用自适应扩展对象调用的）时，通过SPI加载具体的扩展对象，并调用该扩展对象的同名方法。 自适应扩展类串的生成通过上面的例子，我们直观的认识了自适应扩展类的工作原理。通过上一篇文章我们知道@Adaptive 可注解在类或方法上，注解在类上时，Dubbo 不会为该类生成代理类。注解在扩展接口的方法上时，Dubbo 会为为该接口生成代理逻辑。接下来我们从上一篇文章提到的getAdaptiveExtension方法入口继续分析。 getAdaptiveExtension 方法12345678910111213141516171819202122232425262728293031323334353637public T getAdaptiveExtension() &#123; // 从缓存中获取扩展点对应的自适应扩展对象 Object instance = cachedAdaptiveInstance.get(); // 如果缓存未命中，则通过双重检锁获取/创建 if (instance == null) &#123; // 若之前创建的时候没有报错，即之前创建了并且没有抛出异常 if (createAdaptiveInstanceError == null) &#123; synchronized (cachedAdaptiveInstance) &#123; // 再次尝试从缓存中获取 instance = cachedAdaptiveInstance.get(); if (instance == null) &#123; try &#123; // 创建自适应拓展对象 instance = createAdaptiveExtension(); // 放入缓存中 cachedAdaptiveInstance.set(instance); &#125; catch (Throwable t) &#123; createAdaptiveInstanceError = t; throw new IllegalStateException(\"fail to create adaptive instance: \" + t.toString(), t); &#125; &#125; &#125; // 若之前创建的时候报错，则抛出异常 &#125; else &#123; throw new IllegalStateException(\"fail to create adaptive instance: \" + createAdaptiveInstanceError.toString(), createAdaptiveInstanceError); &#125; &#125; return (T) instance;&#125; 上面的代码用来获取扩展点的自适应对象，该方法先检查缓存，缓存中没有则调用 createAdaptiveExtension 方法尝试创建自适应对象。我们继续跟进 createAdaptiveExtension 方法。 12345678910111213private T createAdaptiveExtension() &#123; try &#123; /** * 1 getAdaptiveExtensionClass方法用来获得自适应扩展类【注意，获得的自适应扩展类可能是配置文件中的类，也可能是通过字节码创建的】 * 2 通过反射创建自适应扩展对象 * 3 调用injectExtension方法，向创建的自适应拓展对象注入依赖 */ return injectExtension((T) getAdaptiveExtensionClass().newInstance()); &#125; catch (Exception e) &#123; throw new IllegalStateException(\"Can not create adaptive extension \" + type + \", cause: \" + e.getMessage(), e); &#125; &#125; 上面的方法先获取自适应扩展类，然后利用反射创建自适应对象，接着会向创建的自适应对象注入依赖。现在，我们已经知道了自适应扩展类分为两类，固定的自适应扩展类中可能存在一些依赖，这时需要使用扩展工厂进行setter注入，自动生成的扩展实现一般不会依赖其它属性。接下来我们分析下自适应扩展类怎么获取的。 123456789101112private Class&lt;?&gt; getAdaptiveExtensionClass() &#123; // 刷新扩展点实现类集合 getExtensionClasses(); // 缓存中有扩展点的自适应类就直接返回 if (cachedAdaptiveClass != null) &#123; return cachedAdaptiveClass; &#125; // 没有就自动生成自适应拓展类的代码，编译后返回该类 return cachedAdaptiveClass = createAdaptiveExtensionClass(); &#125; 上面的代码先是刷新扩展点实现类集合，注意如果扩展接口的实现类中有标注@Adaptive注解的类，那么cachedAdaptiveClass缓存属性中保存的就是该类，即固定的自适应扩展类。如果没有的话，说明当前扩展接口的实现类中不存在固定的自适应扩展类，那么只能尝试创建该接口的自适应扩展类，代码逻辑如下： 1234567891011private Class&lt;?&gt; createAdaptiveExtensionClass() &#123; // 生成自适应拓展实现类的代码字符串 String code = createAdaptiveExtensionClassCode(); // 获取类加载器 ClassLoader classLoader = findClassLoader(); // 获取Compiler自适应扩展对象 com.alibaba.dubbo.common.compiler.Compiler compiler = ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.common.compiler.Compiler.class).getAdaptiveExtension(); // 动态编译，生成Class return compiler.compile(code, classLoader); &#125; createAdaptiveExtensionClass 方法包含三个步骤： 生成自适应扩展实现类的代码字符串 获取Compiler自适应扩展对象 动态编译 自适应拓展实现类的代码字符串 ，生成Class 后面两个步骤属于 动态编译 部分，不在本文范畴，我们主要关注 自适应扩展实现类的代码字符串 的生成逻辑。 自适应扩展类代码生成createAdaptiveExtensionClassCode方法代码非常多，不过总的逻辑大致可以分为八个逻辑分支，已经进行详细的注释，下面就直接贴上代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322private String createAdaptiveExtensionClassCode() &#123; StringBuilder codeBuilder = new StringBuilder(); //----------------- 1 检查扩展接口方法是否包含 Adaptive注解，要求至少有一个方法被 Adaptive 注解修饰 --------------------/ // 反射获取扩展点所有方法 Method[] methods = type.getMethods(); boolean hasAdaptiveAnnotation = false; // 遍历方法列表，检测是否标注 Adaptive 注解 for (Method m : methods) &#123; if (m.isAnnotationPresent(Adaptive.class)) &#123; hasAdaptiveAnnotation = true; break; &#125; &#125; // 若所有方法上都没有Adaptive注解，就抛出异常 if (!hasAdaptiveAnnotation) &#123; throw new IllegalStateException(\"No adaptive method on extension \" + type.getName() + \", refuse to create the adaptive class!\"); &#125; //------------------ 2 生成自适应扩展类的代码字符串，代码生成的顺序与 Java 文件内容顺序一致 ---------------------------/ // 生成package codeBuilder.append(\"package \").append(type.getPackage().getName()).append(\";\"); // 生成import，注意自适应类只依赖ExtensionLoader，其它的都不会依赖，因为使用的都是全路径名，不需要再导入包了 codeBuilder.append(\"\\nimport \").append(ExtensionLoader.class.getName()).append(\";\"); // 开始生成 class codeBuilder.append(\"\\npublic class \").append(type.getSimpleName()).append(\"$Adaptive\").append(\" implements \").append(type.getCanonicalName()).append(\" &#123;\"); //------------------ 3 生成自适应扩展类中的方法，接口中方法可以被 Adaptive 注解修饰，也可以不被修饰，但处理方式也不同 -------/ // 遍历方法列表，为类中填充方法 for (Method method : methods) &#123; // 方法返回类型 Class&lt;?&gt; rt = method.getReturnType(); // 方法参数类型 Class&lt;?&gt;[] pts = method.getParameterTypes(); // 方法异常类型 Class&lt;?&gt;[] ets = method.getExceptionTypes(); // 尝试获取方法的 Adaptive 注解，有无注解的区别体现在 生成方法字符串的差异上 Adaptive adaptiveAnnotation = method.getAnnotation(Adaptive.class); // 类中的方法字符串集 StringBuilder code = new StringBuilder(512); // 3.1 生成没有Adaptive注解的方法代码串。Dubbo不会为没有标注Adaptive注解的方法生成代理逻辑，仅仅生成一句抛出异常代码 if (adaptiveAnnotation == null) &#123; code.append(\"throw new UnsupportedOperationException(\\\"method \") .append(method.toString()).append(\" of interface \") .append(type.getName()).append(\" is not adaptive method!\\\");\"); // 3.2 生成有Adaptive注解的方法代码串。核心逻辑就是从方法的参数列表中直接或间接获取配置总线URL，然后结合Adaptive注解值及默认扩展名策略，从URL中得到扩展名，然后通过ExtensionLoader获取扩展名对应的扩展实现对象。 &#125; else &#123; int urlTypeIndex = -1; // 遍历方法参数类型数组 for (int i = 0; i &lt; pts.length; ++i) &#123; // 判断参数类型是不是URL，确定URL参数位置 if (pts[i].equals(URL.class)) &#123; urlTypeIndex = i; break; &#125; &#125; // urlTypeIndex != -1，表示参数列表中存在 URL类型的参数，即直接获取配置总线URL。如： &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException 方法 if (urlTypeIndex != -1) &#123; // 为 URL 类型参数生成判空代码，如：if (arg0 == null) throw new IllegalArgumentException(\"com.alibaba.dubbo.rpc.Invoker argument == null\"); String s = String.format(\"\\nif (arg%d == null) throw new IllegalArgumentException(\\\"url == null\\\");\", urlTypeIndex); code.append(s); // 为 URL 类型参数生成赋值代码，形如 URL url = arg0 s = String.format(\"\\n%s url = arg%d;\", URL.class.getName(), urlTypeIndex); code.append(s); &#125; // 参数列表中不存在 URL 类型参数，只能间接尝试获取配置总线URL。如：&lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException 方法，配置总线URL是从invoker中获取。 else &#123; // 目标方法名，这里如果存在就是 getUrl String attribMethod = null; // find URL getter method LBL_PTS: // 遍历方法的参数类型列表 for (int i = 0; i &lt; pts.length; ++i) &#123; // 获取当前方法的参数类型 的 全部方法 Method[] ms = pts[i].getMethods(); // 判断方法参数对象中是否有 public URL getUrl() 方法 for (Method m : ms) &#123; String name = m.getName(); if ((name.startsWith(\"get\") || name.length() &gt; 3) &amp;&amp; Modifier.isPublic(m.getModifiers()) &amp;&amp; !Modifier.isStatic(m.getModifiers()) &amp;&amp; m.getParameterTypes().length == 0 &amp;&amp; m.getReturnType() == URL.class) &#123; urlTypeIndex = i; attribMethod = name; // 找到方法参数列表中间接存在URL的参数，则结束寻找逻辑 break LBL_PTS; &#125; &#125; &#125; // 如果参数列表中没有一个参数有getUrl方法，则抛出异常 if (attribMethod == null) &#123; throw new IllegalStateException(\"fail to create adaptive class for interface \" + type.getName() + \": not found url parameter or url attribute in parameters of method \" + method.getName()); &#125; // 为可返回URL的参数生成判空代码，如：if (arg0 == null) throw new IllegalArgumentException(\"com.alibaba.dubbo.rpc.Invoker argument == null\"); String s = String.format(\"\\nif (arg%d == null) throw new IllegalArgumentException(\\\"%s argument == null\\\");\", urlTypeIndex, pts[urlTypeIndex].getName()); code.append(s); // 为可返回URL的参数 的getUrl方法返回 的URL生成判空代码，如：if (arg0.getUrl() == null) throw new IllegalArgumentException(\"com.alibaba.dubbo.rpc.Invoker argument getUrl() == null\"); s = String.format(\"\\nif (arg%d.%s() == null) throw new IllegalArgumentException(\\\"%s argument %s() == null\\\");\", urlTypeIndex, attribMethod, pts[urlTypeIndex].getName(), attribMethod); code.append(s); // 生成赋值语句，形如：URL url = argN.getUrl(); s = String.format(\"%s url = arg%d.%s();\", URL.class.getName(), urlTypeIndex, attribMethod); code.append(s); &#125; //----------------- 4 获取 Adaptive 注解值 ，Adaptive 注解值 value 类型为 String[]，可填写多个值，默认情况下为空数组 -------------/ /** * 获取@Adaptive注解的值，如果有值，这些值将作为获取扩展名的key，需要注意，Protocol扩展和其它扩展点是不同的，前者获取扩展名是取协议，后者获取扩展名是取参数的值 * 1 普通扩展点，如ProxyFactor： String extName = url.getParameter(\"proxy\", \"javassist\"); * 2 Protocol扩展点： String extName = ( url.getProtocol() == null ? \"dubbo\" : url.getProtocol() ); */ String[] value = adaptiveAnnotation.value(); // 如果@Adaptive注解没有指定值，则根据扩展接口名生成。如：SimpleExt -&gt; simple.ext，即将扩展接口名中的大写转小写，并使用'.'把它们连接起来 if (value.length == 0) &#123; // 获取扩展接口简单名称的字符数组 char[] charArray = type.getSimpleName().toCharArray(); StringBuilder sb = new StringBuilder(128); for (int i = 0; i &lt; charArray.length; i++) &#123; // 判断是否大写字母，如果是就使用 '.' 连接，并大写转小写 if (Character.isUpperCase(charArray[i])) &#123; if (i != 0) &#123; sb.append(\".\"); &#125; sb.append(Character.toLowerCase(charArray[i])); &#125; else &#123; sb.append(charArray[i]); &#125; &#125; value = new String[]&#123;sb.toString()&#125;; &#125; //--------------------- 5 检测方法参数列表中是否存在 Invocation 类型的参数，有则表示是调用方法 --------------------/ boolean hasInvocation = false; for (int i = 0; i &lt; pts.length; ++i) &#123; // 参数类型是Invocation if (pts[i].getName().equals(\"com.alibaba.dubbo.rpc.Invocation\")) &#123; // 为 Invocation 类型参数生成判空代码 String s = String.format(\"\\nif (arg%d == null) throw new IllegalArgumentException(\\\"invocation == null\\\");\", i); code.append(s); // 生成 String methodName = argN.getMethodName()； 代码，Invocation是调用信息，里面包含调用方法 s = String.format(\"\\nString methodName = arg%d.getMethodName();\", i); code.append(s); hasInvocation = true; break; &#125; &#125; //----------------------- 6 扩展名决策逻辑，@SPI、@Adaptive以及方法含有Invocation类型参数都会影响最终的扩展名 -------------------------/ // 设置默认拓展名，SPI注解值，默认情况下 SPI注解值为空串，此时cachedDefaultName = null String defaultExtName = cachedDefaultName; String getNameCode = null; /** * 遍历Adaptive 的注解值，用于生成从URL中获取拓展名的代码，最终的扩展名会赋值给 getNameCode 变量。 * 注意： * 1 这个循环的遍历顺序是由后向前遍历的，因为Adaptive注解可能配置了多个扩展名，而dubbo获取扩展名的策略是从前往后依次获取，找到即结束，以下代码拼接的时候也是从后往前拼接。 * 2 生成的扩展名代码大致有3大类，Adaptive的注解中属性值的数目决定了内嵌层级： *（1） String extName = (url.getProtocol() == null ? defaultExtName : url.getProtocol()); 获取协议扩展点的扩展名 *（2） String extName = url.getMethodParameter(methodName, Adaptive的注解值, defaultExtName); 获取方法级别的参数值作为扩展名，因为方法的参数列表中含有Invocation调用信息。 *（3） String extName = url.getParameter(Adaptive的注解值, defaultExtName); 获取参数值作为扩展名 *（4） 如果Adaptive的注解中属性值有多个，就进行嵌套获取。如配置两个，以(3)为例：String extName = url.getParameter(Adaptive的注解值[0],url.getParameter(Adaptive的注解值[1], defaultExtName)); * 3 参数如果是protocol，protocol是url主要部分，可通过getProtocol方法直接获取。如果是其他的需要是从URL参数部分获取。两者获取方法不一样。其中参数获取又可分为方法级别参数和非方法级别参数 */ for (int i = value.length - 1; i &gt;= 0; --i) &#123; // 第一次遍历分支 if (i == value.length - 1) &#123; if (null != defaultExtName) &#123; if (!\"protocol\".equals(value[i])) &#123; // 方法参数列表中有调用信息Invocation参数 if (hasInvocation) &#123; getNameCode = String.format(\"url.getMethodParameter(methodName, \\\"%s\\\", \\\"%s\\\")\", value[i], defaultExtName); &#125; else &#123; getNameCode = String.format(\"url.getParameter(\\\"%s\\\", \\\"%s\\\")\", value[i], defaultExtName); &#125; &#125; else &#123; getNameCode = String.format(\"( url.getProtocol() == null ? \\\"%s\\\" : url.getProtocol() )\", defaultExtName); &#125; &#125; else &#123; if (!\"protocol\".equals(value[i])) &#123; // 方法参数列表中有调用信息Invocation参数 if (hasInvocation) &#123; getNameCode = String.format(\"url.getMethodParameter(methodName, \\\"%s\\\", \\\"%s\\\")\", value[i], defaultExtName); &#125; else &#123; getNameCode = String.format(\"url.getParameter(\\\"%s\\\")\", value[i]); &#125; &#125; else &#123; getNameCode = \"url.getProtocol()\"; &#125; &#125; // 第二次开始都走该分支，用于嵌套获取扩展名 &#125; else &#123; if (!\"protocol\".equals(value[i])) &#123; // 方法参数列表中有调用信息Invocation参数 if (hasInvocation) &#123; getNameCode = String.format(\"url.getMethodParameter(methodName, \\\"%s\\\", \\\"%s\\\")\", value[i], defaultExtName); &#125; else &#123; getNameCode = String.format(\"url.getParameter(\\\"%s\\\", %s)\", value[i], getNameCode); &#125; &#125; else &#123; getNameCode = String.format(\"url.getProtocol() == null ? (%s) : url.getProtocol()\", getNameCode); &#125; &#125; &#125; // 生成扩展明 赋值代码 code.append(\"\\nString extName = \").append(getNameCode).append(\";\"); // 生成 扩展明 判空代码 String s = String.format(\"\\nif(extName == null) \" + \"throw new IllegalStateException(\\\"Fail to get extension(%s) name from url(\\\" + url.toString() + \\\") use keys(%s)\\\");\", type.getName(), Arrays.toString(value)); code.append(s); //---------------------------------------- 7 生成 获取扩展对象代码 以及 调用扩展对象的目标方法代码 ---------------------------------/ // 生成 extension扩展对象 赋值 代码 s = String.format(\"\\n%s extension = (%&lt;s)%s.getExtensionLoader(%s.class).getExtension(extName);\", type.getName(), ExtensionLoader.class.getSimpleName(), type.getName()); code.append(s); // 如果方法返回值类型非void，则生成return语句 if (!rt.equals(void.class)) &#123; code.append(\"\\nreturn \"); &#125; // 生成 extension扩展对象 调用目标方法逻辑，形如： extension.方法名(arg0, arg2, ..., argN); s = String.format(\"extension.%s(\", method.getName()); code.append(s); // 生成extension调用方法中的参数 拼接，注意和生成方法签名的参数名保持一直 for (int i = 0; i &lt; pts.length; i++) &#123; if (i != 0) &#123; code.append(\", \"); &#125; code.append(\"arg\").append(i); &#125; code.append(\");\"); &#125; //------------------------------------------- 8 生成方法签名，包裹方法体内容 ---------------------------------------/ // 生成方法签名，格式：public + 返回值全限定名 + 方法名 +( codeBuilder.append(\"\\npublic \").append(rt.getCanonicalName()).append(\" \").append(method.getName()).append(\"(\"); // 生成方法签名的参数列表 for (int i = 0; i &lt; pts.length; i++) &#123; if (i &gt; 0) &#123; codeBuilder.append(\", \"); &#125; codeBuilder.append(pts[i].getCanonicalName()); codeBuilder.append(\" \"); codeBuilder.append(\"arg\").append(i); &#125; codeBuilder.append(\")\"); // 生成异常抛出代码 if (ets.length &gt; 0) &#123; codeBuilder.append(\" throws \"); for (int i = 0; i &lt; ets.length; i++) &#123; if (i &gt; 0) &#123; codeBuilder.append(\", \"); &#125; codeBuilder.append(ets[i].getCanonicalName()); &#125; &#125; // 方法开始符号 codeBuilder.append(\" &#123;\"); // 包括方法体内容 codeBuilder.append(code.toString()); // 追加方法结束符号 codeBuilder.append(\"\\n&#125;\"); &#125; // 追加类的结束符号，生成自适应扩展类结束 codeBuilder.append(\"\\n&#125;\"); if (logger.isDebugEnabled()) &#123; logger.debug(codeBuilder.toString()); &#125; return codeBuilder.toString(); &#125; 上面的代码逻辑就一个任务，使用字符串拼接一个自适应扩展类串，梳理出来后并没有那么复杂，其实就是按照编写一个类的步骤进行拼接的。如果非要说复杂的话，那么就提体现在拼接扩展名的逻辑代码中，因为情况非常多，胖友们可以多调试多归类。想要观察生成的自适应扩展类有两种办法，日志级别设置成debug是一种简单粗暴的方式，还可以使用反编译工具进行查看。 总结本篇文章主要分析了自动生成的自适应扩展类的原理，以及详细分析了生成一个自适应扩展类的过程，总体来说还是很复杂的。至于为什么不直接使用代理的方式生成自适应扩展类，主要的原因是代理方式效率太低，更详细的可以参考梁飞大佬的博客 动态代理方案性能对比。自适应扩展还没结束，我们虽然有了一个自适应扩展类的字符串，但是还需要对这个字符串进行编译处理成Class，这样才能创建一个对象自适应扩展对象，下一篇文章中我们就来分析dubbo的动态编译原理。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"SPI","slug":"SPI","permalink":"https://gentryhuang.com/tags/SPI/"}]},{"title":"Dubbo源码分析 - Dubbo SPI","slug":"rpc/spi机制之dubbo","date":"2020-03-12T16:00:00.000Z","updated":"2021-02-26T01:46:13.504Z","comments":false,"path":"posts/5d81f464/","link":"","permalink":"https://gentryhuang.com/posts/5d81f464/","excerpt":"","text":"概述Dubbo并未使用jdk标准的SPI机制，而是对其进行了增强，优化了性能问题并且相比jdk spi更加健壮。 Dubbo SPI 对 JDK SPI的改进 JDK 标准的 SPI 会一次性实例化扩展点所有实现，如果有扩展实现初始化很耗时，但如果没用上也加载，会很浪费资源，而dubbo可以选择性实例化。 如果扩展点加载失败，连扩展点的名称都拿不到了。比如：JDK标准的 ScriptEngine，通过 getName() 获取脚本类型的名称，但如果RubyScriptEngine 因为所依赖的 jruby.jar 不存在，导致 RubyScriptEngine 类加载失败，这个失败原因被吃掉了，和 ruby 对应不起来，当用户执行 ruby 脚本时会报不支持ruby，而不是真正失败的原因。 对 JDK SPI 配置文件进行了扩展和修改，兼容了 JDK SPI 配置。 增加了对扩展点 IoC 和 AOP 的支持，一个扩展点可以直接 setter 注入其它扩展点。 原始jdk spi 不支持缓存，dubbo设计了多维度缓存，提高了框架的性能。 SPI 核心概念 扩展点：通过 SPI 机制查找并加载实现的接口成为扩展点，也叫做扩展接口 扩展(点)实现：实现了扩展点的实现类 Dubbo SPI 配置规范 spi配置文件路径 123META-INF&#x2F;dubbo&#x2F;internal : 主要用于 Dubbo 内部提供的拓展点实现META-INF&#x2F;dubbo : 主要用于自定义扩展点实现META-INF&#x2F;services : 用于兼容jdk的spi 说明: 上面的 SPI 配置文件路径是种规范，实际上在使用的时候写在哪个文件下都可以被加载到，但是实际开放种最好按照规范配置。 spi配置文件名称 1扩展点全路径名 文件内容 12key&#x3D;value形式，多个使用换行符分割，这是Dubbo配置的方式value形式，没有指定扩展名，这是jdk配置方式，Dubbo进行了兼容，会自动为扩展实现类生成默认的扩展名 说明: Dubbo SPI 通过键值对的方式进行配置，这样我们可以按需实例化扩展点的实现，而不是一次实例化所有的扩展实现类。此外，异常信息更加准确，便于定位问题，如在 Dubbo SPI 抛出异常时，一般会携带扩展名信息而不是直接抛出无法加载扩展实现类的异常信息。 加载扩展实现1Dubbo使用ExtensionLoader加载指定实现类，Dubbo SPI 的逻辑几乎都封装在该类中。 示例前面简单介绍了Dubbo SPI机制，下面我们通过一个例子来演示Dubbo SPI的简单用法。扩展点接口及实现复用 spi机制之jdk示例 中代码，区别是Dubbo SPI的接口使用@SPI注解进行标注。 定义扩展接口，使用@SPI注解进行标注 123456789package com.alibaba.dubbo.spi;@SPIpublic interface Command &#123; /** * 执行方法 */ void execute();&#125; 在META-INF/dubbo文件目录下创建一个文件，名称为Command的全路径名 com.alibaba.dubbo.spi.Command。 配置内容为扩展实现类及其扩展名，如下： 12start&#x3D;com.alibaba.dubbo.spi.impl.StartCommandshutdown&#x3D;com.alibaba.dubbo.spi.impl.ShutdownCommand 准备就绪后，最后写测试代码，如下： 123456789101112131415public class Main &#123; public static void main(String[] args) &#123; // ExtensionLoader是dubbo提供的，用来加载拓展实现类 ExtensionLoader&lt;Command&gt; extensionLoader = ExtensionLoader.getExtensionLoader(Command.class); // 加载指定扩展名对应的扩展实现对象（获取的时候会进行实例化） Command startCommand = extensionLoader.getExtension(\"start\"); startCommand.execute(); Command shutdownCommand = extensionLoader.getExtension(\"shutdown\"); shutdownCommand.execute(); &#125;&#125; 测试结果如下： 1234start commandshut down commandProcess finished with exit code 0 简单说明和演示Dubbo SPI后，我们对Dubbo SPI有了一定的认识，使用起来还是比较简单的，接下来进入源码分析阶段，让我们一起去看看Dubbo底层是怎么加载和选择扩展实现的。 Dubbo SPI 源码分析进行源码分析之前，我们先看下Dubbo SPI整体的代码结构，然后对核心注解和类进行说明。 代码结构 扩展点 SPI 注解扩展点接口标识，Dubbo的扩展点必须标注该注解，否则在执行SPI逻辑时框架会报异常。 1234567891011@Documented@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.TYPE&#125;)public @interface SPI &#123; /** * @return 缺省扩展名 */ String value() default \"\";&#125; SPI注解的value属性是用来指定扩展点的默认扩展名，如Protocol扩展接口： 12@SPI(\"dubbo\")public interface Protocol &#123;//...&#125; // dubbo对应的扩展实现类就是DubboProtocol，即Protocol默认的扩展实现类 扩展点 Adaptive 注解该注解用来实现适配器功能，标注该注解的可能时类或扩展点中的方法。前者一般不实现任何具体的功能仅用来适配扩展接口的实现，如 AdaptiveExtensionFactory 用来适配 ExtensionFactory 的 SpiExtensionFactory 和 SpringExtensionFactory 这两种实现，它会根据运行时的状态选择合适的 ExtensionFactory 的实现。后者会动态生成适配器类，生成的这个适配器类的逻辑同样是在运行时选择合适的扩展实现。 12345678910111213141516171819@Documented@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)public @interface Adaptive &#123; /** * 根据URL的Key获取对应的Value作为自适应拓展名。比如，&lt;code&gt;String[] &#123;\"key1\", \"key2\"&#125;&lt;/code&gt;，表示 * &lt;ul&gt; * &lt;li&gt;先在URL上找key1的Value作为自适应拓展名； * &lt;li&gt;key1没有value，则使用key2的value作为自适应拓展名。 * &lt;li&gt;key2没有value，就使用缺省的扩展，即： 如果&#123;@link URL&#125;这些Key都没有value，使用缺省的扩展（在接口的&#123;@link SPI&#125;中设定的值） * &lt;li&gt;如果没有设置缺省扩展名或者缺省扩展名也没有value，则方法调用会抛出&#123;@link IllegalStateException&#125;。 * &lt;/ul&gt; * 注意：如果没有使用Adaptive注解指定扩展名，扩展接口也没有指定@SPI默认值，则在加载扩展实现的时候dubbo会自动把扩展接口名称根据驼峰大小写分开，并使用 '.' 符号连接起来， * 以此名称作为默认扩展名。如：SimpleExt -&gt; simple.ext * * @return parameter key names in URL */ String[] value() default &#123;&#125;;&#125; 一个拓展接口，在框架中同时只能存在一个 Adaptive 拓展实现类，可能是固定的扩展实现类，也可能是自动生成、编译得到的扩展实现类。@Adaptive 注解，可添加类或方法上，分别代表了两种不同的使用方式。第一种，标记在类上（属于装饰类），整个实现类会作为自适应扩展类，Dubbo不会为该类生成代理类，它主要用于固定已知类。目前 Dubbo 项目里，只有 ExtensionFactory 拓展的实现类 AdaptiveExtensionFactory 和Compiler 拓展的实现AdaptiveCompiler这么使用。第二种，标记在扩展接口的方法上，代表自动生成、编译一个该接口的动态Adaptive拓展实现类（属于动态代理类，如Protocol$Adaptive），一般该类没有实际的工作，只是根据参数和运行状态加载其他的扩展实现来完成最终的工作。 扩展点 Activate 注解123456789101112131415161718192021222324252627282930313233343536@Documented@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)public @interface Activate &#123; /** * group过滤条件。在调用&#123;@link ExtensionLoader#getActivateExtension(URL, String, String)&#125; 方法时，如果传入的group参数符合该注解设置的group属性值，则匹配。 * 即 修饰的实现类是在 Provider 端被激活还是在 Consumer 端被激活 */ String[] group() default &#123;&#125;; /** * key过滤条件。在调用&#123;@link ExtensionLoader#getActivateExtension(URL, String, String)&#125; 方法时，如果url中的参数中存在该注解设置的key值，则激活。 */ String[] value() default &#123;&#125;; /** * 排序属性 * * @return extension list which should be put before the current one */ String[] before() default &#123;&#125;; /** * 排序属性 * * @return extension list which should be put after the current one */ String[] after() default &#123;&#125;; /** * 排序属性 * * @return absolute ordering info */ int order() default 0;&#125; 该注解用于设置扩展实现类被自动激活的加载条件，如：过滤器扩展点有多个实现，那么就可以使用该注解设置激活条件，在获取自动激活扩展实现时需要符合条件才能获取到。框架通过ExtensionLoader#getActivateExtension方法获得激活条件的扩展实现集合。 ExtensionLoaderDubbo的扩展加载器，功能类似于 JDK SPI 中的 ServiceLoader。Dubbo SPI 的相关逻辑几乎都被封装在该类中，该类是 Dubbo SPI 的 核心。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136public class ExtensionLoader&lt;T&gt; &#123; //========================================= 类属性，所有ExtensionLoader对象共享 ================================================ /** * dubbo扩展点目录 ，该目录是为了兼容jdk的spi */ private static final String SERVICES_DIRECTORY = \"META-INF/services/\"; /** * dubbo扩展点目录，主要用于自定义扩展点实现 */ private static final String DUBBO_DIRECTORY = \"META-INF/dubbo/\"; /** * dubbo扩展点目录，用于 Dubbo 内部提供的拓展点实现 */ private static final String DUBBO_INTERNAL_DIRECTORY = DUBBO_DIRECTORY + \"internal/\"; /** * 扩展点实现名的分隔符 正则表达式，多个扩展点名之间使用 ',' 进行分割 */ private static final Pattern NAME_SEPARATOR = Pattern.compile(\"\\\\s*[,]+\\\\s*\"); /** * 扩展点加载器集合 * key: 拓展点接口 * value: 扩展点加载器。 一个扩展点接口对应一个 扩展点加载器 */ private static final ConcurrentMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt; EXTENSION_LOADERS = new ConcurrentHashMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt;(); /** * 扩展点实现类集合 * key: 扩展点实现类 * value: 扩展点实现对象 * 说明： * 一个扩展点通过对应的ExtensionLoader去加载它的具体实现，考虑到性能和资源问题，在加载拓展配置后不会立马进行扩展实现的对象的初始化，而是先把扩展配置存起来。 * 等到真正使用对应的拓展实现时才进行扩展实现的对象的初始化，初始化后也进行缓存。即： * 1 缓存加载的拓展配置 * 2 缓存创建的拓展实现对象 */ private static final ConcurrentMap&lt;Class&lt;?&gt;, Object&gt; EXTENSION_INSTANCES = new ConcurrentHashMap&lt;Class&lt;?&gt;, Object&gt;(); // ============================== 实例属性 ，每个ExtensionLoader对象独有 ==================================================== /** * 扩展点，如：Protocol */ private final Class&lt;?&gt; type; /** * 扩展点实现工厂，用于向扩展对象中注入依赖属性，一般通过调用 &#123;@link #injectExtension(Object)&#125; 方法进行实现。 * 特别说明： * 除了ExtensionFactory扩展接口，其余的所有扩展接口的ExtensionLoader对象都会拥有一个自己的扩展工厂，即 objectFactory = AdaptiveExtensionFactory； * @see ExtensionLoader 构造方法 */ private final ExtensionFactory objectFactory; /** * 扩展点实现类 到 扩展名 的映射 * 如： * dubbo=dubbo=com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol ===&gt; &lt;DubboProtocol,dubbo&gt; */ private final ConcurrentMap&lt;Class&lt;?&gt;, String&gt; cachedNames = new ConcurrentHashMap&lt;Class&lt;?&gt;, String&gt;(); /** * 扩展名 到 扩展点实现类 的映射 * 不包括以下两种类型： * 1 自适应扩展实现类，如：AdaptiveExtensionFactory * 2 扩展点的Wrapper实现类，如：ProtocolFilterWrapper * 如： * dubbo=dubbo=com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol ===&gt; &lt;dubbo,DubboProtocol&gt; */ private final Holder&lt;Map&lt;String, Class&lt;?&gt;&gt;&gt; cachedClasses = new Holder&lt;Map&lt;String, Class&lt;?&gt;&gt;&gt;(); /** * 扩展名 到 @Activate注解 的映射， 如： ContextFilter -&gt; Activate */ private final Map&lt;String, Activate&gt; cachedActivates = new ConcurrentHashMap&lt;String, Activate&gt;(); /** * 扩展名 到 扩展点实现对象 的映射 * 如： * dubbo=dubbo=com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol ===&gt; &lt;dubbo,Holder&lt;DubboProtocol对象&gt;&gt; */ private final ConcurrentMap&lt;String, Holder&lt;Object&gt;&gt; cachedInstances = new ConcurrentHashMap&lt;String, Holder&lt;Object&gt;&gt;(); /** * 自适应扩展对象 * 注意: 一个扩展点最多只能有一个自适应扩展对象，&gt; 1 框架就会报错 */ private final Holder&lt;Object&gt; cachedAdaptiveInstance = new Holder&lt;Object&gt;(); /** * 自适应扩展实现类 &#123;@link #getAdaptiveExtensionClass()&#125; */ private volatile Class&lt;?&gt; cachedAdaptiveClass = null; /** * 扩展点的默认扩展名，通过 &#123;@link SPI&#125; 注解获得，即记录了 type 对应扩展接口上 @SPI 注解的 value 值。 */ private String cachedDefaultName; /** * 创建自适应对象时发生的异常 -&gt; &#123;@link #createAdaptiveExtension()&#125; */ private volatile Throwable createAdaptiveInstanceError; /** * 扩展点Wrapper实现类集合，如：ProtocolFilterWrapper */ private Set&lt;Class&lt;?&gt;&gt; cachedWrapperClasses; /** * 扩展名 到 加载对应扩展类发生的异常 的映射 */ private Map&lt;String, IllegalStateException&gt; exceptions = new ConcurrentHashMap&lt;String, IllegalStateException&gt;(); /** * 构造方法 * 说明： * 1 任意一个扩展点在获取对应的ExtensionLoader时，都会先尝试获取属于它的ExtensionFactory自适应扩展，即 AdaptiveExtensionFactory， * 它管理着SpiExtensionFactory和SpringExtensionFactory这两大扩展点工厂，用于调用 &#123;@link #injectExtension(Object)&#125;方法，向扩展实现中注入依赖属性， * 需要注意的是，SpiExtensionFactory和SpringExtensionFactory获得对象是不同的，前者获取自适应对象，后者从Spring容器中获取对象。 * 2 当扩展点是ExtensionFactory时，那么它的对应的ExtensionLoader的objectFactory 属性为null * * @param type 扩展点 */ private ExtensionLoader(Class&lt;?&gt; type) &#123; this.type = type; objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension()); &#125; // 省略其它代码...&#125; 基于性能的考虑，Dubbo SPI相比较与JDK SPI的一个改进就是使用了大量的缓存，Dubbo SPI 缓存从大的方向可分为 类缓存、实例缓存，这两种缓存又能根据扩展实现类的种类分为 普通扩展缓存、包装扩展缓存、自适应扩展缓存。 类缓存 Dubbo SPI在查询扩展类时，会先从缓存中获取，如果缓存中不存在，再加载配置文件并分类缓存，注意，这个过程不会进行初始化流程。 实例缓存 Dubbo SPI缓存的Class是按需进行实例化的，在查询实例时会先从缓存中获取，如果缓存不存在则会进行加载/初始化，然后缓存起来。 多类型的扩展点根据扩展实现类的特点及用途可以分为普通扩展类、自动激活扩展类、包装扩展类以及自适应扩展类，其中自动激活扩展类属于普通扩展类。需要注意的是，除了动态编译得到的自适应扩展类，其它的所有扩展类都需要在配置文件中进行配置，否则框架无法加载到。下面我们简单说明下各个类型的扩展类及其特点。 普通扩展类属于最基础的扩展类，一般通过扩展名获取对应的扩展实现就是该类型。在配置普通扩展类时需要指定扩展名，不指定会按规则自动生成，因为普通扩展实现都是根据扩展名获取的。 包装扩展类包括扩展类又叫 Wrapper类，一般不是扩展点的真正实现，主要用来对扩展实现进行功能增强或通用逻辑处理。Wrapper类有两个特征：实现扩展接口、存在一个参数类型是扩展点的构造方法。Wrapper类是Dubbo AOP的实现。在配置Wrapper类时，可以不指定扩展名，即使指定了也不会使用，但一般情况根据Dubbo SPI的约定还是统一配置。 自适应类自适应类非常灵活，也叫 Adaptive类，更直观的称为适配器类，有两种实现方式。Adaptive类的两个特征：实现扩展接口、实现类或扩展接口的方法上需要使用 @Adaptive 标注。类上标注@Adaptive是一个Adaptive类可以理解，但是扩展接口的方法上标注@Adaptive怎么会是一个类呢？是因为标注在扩展接口的方法上，Dubbo SPI机制在获取自适应扩展实现类时，如果当前环境中没有自适应扩展实现类就会对标注的方法所在接口进行javassist操作，生成自适应扩展类的字符串，然后通过动态编译成一个自适应类。@Adaptive标注在扩展接口的方法上的方式，可以动态地通过URL中的参数来确定使用哪个扩展实现。在配置文件中可以不指定扩展名，即使指定了也不会使用，但一般情况根据Dubbo SPI的约定还是统一配置。需要注意，自适应扩展类什么实际工作都不做，只是根据参数和状态选择其它实现而已。 自动激活类自动激活类属于特殊的普通扩展类，该类的两个特征：实现接口、类上使用 @Activate 标注。它支持某个扩展点需要同时激活多个实现的特性，如 Dubbo中的过滤器扩展点，需要激活多个扩展实现。 ExtensionLoader 工作流程ExtensionLoader封装了Dubbo SPI的主要逻辑，配置的加载、扩展类缓存、扩展实现的实例化及缓存、自适应类的生成与编译及缓存、自适应对象的实例化及缓存以及Dubbo IOC 和 AOP 的实现等。这些逻辑主要体现在三个入口方法中，每个入口方法获取到的扩展实现类型会有所不同，但是方法内部逻辑有相同之处。下面我们分别从三个入口方法开始详细分析Dubbo SPI的整个流程，需要说明的是，getExtension方法是最核心的方法，其它两个入口方法都会依赖该方法中的部分流程，因此我们会先分析getExtension方法，在分析其它两个方法的时候涉及重复的流程就不再分析。 getExtension 方法ExtensionLoader中最核心的方法，因为它实现了一个完整的查询扩展实现的逻辑。获取过程中的每一步都会先检查缓存是否命中，命中就直接返回或进行赋值，没有命中则加载配置文件，然后缓存配置文件中的扩展实现。 12345678910111213141516171819202122232425262728293031323334353637383940/** * 获得指定扩展名的扩展对象 * * @param name 扩展名 * @return */ @SuppressWarnings(\"unchecked\") public T getExtension(String name) &#123; if (name == null || name.length() == 0) &#123; throw new IllegalArgumentException(\"Extension name == null\"); &#125; // 如果当前扩展名是 'true'，就获取默认的扩展对象 if (\"true\".equals(name)) &#123; // 方法简化为 getExtension(cachedDefaultName) , cacheDefaultName的值参见 @SPI注解 return getDefaultExtension(); &#125; // 从缓存中获得对应的扩展对象 Holder&lt;Object&gt; holder = cachedInstances.get(name); if (holder == null) &#123; cachedInstances.putIfAbsent(name, new Holder&lt;Object&gt;()); holder = cachedInstances.get(name); &#125; Object instance = holder.get(); // 缓存中没有， 双重检锁获取扩展名对应扩展实现对象 if (instance == null) &#123; synchronized (holder) &#123; instance = holder.get(); if (instance == null) &#123; // 缓存中确实没有，就创建扩展名对应的扩展实现对象 instance = createExtension(name); // 将扩展实现对象放入缓存中 holder.set(instance); &#125; &#125; &#125; return (T) instance; &#125; 上面的代码逻辑比较简单，根据扩展名获取扩展对象，先检查缓存中是否有目标对象，没有则调用 createExtension方法开始创建扩展对象。需要特被说明的是，如果name是true的情况，加载的就是默认扩展类。那么下面我们来分析createExtension方法流程。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * 创建扩展名对应的扩展点实现对象并缓存到类属性的集合中 * * @param name * @return */ @SuppressWarnings(\"unchecked\") private T createExtension(String name) &#123; // 获取扩展名对应的扩展点实现类，先尝试从缓存中取对应的扩展实现类，没有的话就加载配置文件然后再次获取 Class&lt;?&gt; clazz = getExtensionClasses() .get(name); // 没有找到扩展名对应的扩展点实现类，则报错 if (clazz == null) &#123; throw findException(name); &#125; try &#123; // 从类属性缓存集合中尝试获取扩展点实现类对应的对象 T instance = (T) EXTENSION_INSTANCES.get(clazz); // 当缓存中没有，就通过反射创建扩展点实现类对象并放入缓存 if (instance == null) &#123; EXTENSION_INSTANCES.putIfAbsent(clazz, clazz.newInstance()); instance = (T) EXTENSION_INSTANCES.get(clazz); &#125; // dubbo ioc实现，进行setter注入 injectExtension(instance); /** * dubbo aop实现 * 注意： * 如果当前扩展点存在 Wrapper类，那么从ExtensionLoader 中获得的实际上是 Wrapper 类的实例，Wrapper 持有了实际的扩展点实现类，因此调用方法时调用的是Wrapper类中的方法，并非直接调用扩展点的真正实现。 * 即 如果在Wrapper的方法中不显示调用扩展点的真正实现的话，那么结果一定不是预期的。 */ Set&lt;Class&lt;?&gt;&gt; wrapperClasses = cachedWrapperClasses; if (wrapperClasses != null &amp;&amp; !wrapperClasses.isEmpty()) &#123; for (Class&lt;?&gt; wrapperClass : wrapperClasses) &#123; // 创建 Wrapper 实例，然后进行 setter注入依赖属性 instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); &#125; &#125; return instance; &#125; catch (Throwable t) &#123; throw new IllegalStateException(\"Extension instance(name: \" + name + \", class: \" + type + \") could not be instantiated: \" + t.getMessage(), t); &#125; &#125; createExtension(String name)方法的逻辑代码中已经详细注释说明，下面小结关键的步骤： 调用getExtensionClasses()刷新扩展点实现类集合 通过反射创建扩展点的扩展对象并放入类缓存中 使用Dubbo的setter注入向扩展对象中注入依赖属性 使用扩展点的Wrapper对扩展对象实现Dubbo的aop处理逻辑 通过扩展名获取扩展对象时可能不能命中缓存，此时就要创建扩展对象，创建扩展对象需要扩展实现类，下面我们看下Dubbo获取扩展名到扩展实现类的映射集合。 123456789101112131415161718192021222324/** * 获取扩展点实现类的集合，先从缓存中获取，没有命中缓存就从配置文件中加载并分类放入缓存。 * * @return */ private Map&lt;String, Class&lt;?&gt;&gt; getExtensionClasses() &#123; // 先从缓存中获取 Map&lt;String, Class&lt;?&gt;&gt; classes = cachedClasses.get(); // 双重检锁，获取扩展点的扩展实现类集合 if (classes == null) &#123; synchronized (cachedClasses) &#123; classes = cachedClasses.get(); if (classes == null) &#123; // 加载扩展类 classes = loadExtensionClasses(); // 将 扩展名到扩展点实现类的映射 加入到 cachedClasses 集合中，缓存起来 cachedClasses.set(classes); &#125; &#125; &#125; return classes; &#125; 如果缓存不能命中扩展名对应的扩展实现类就只能加载配置文件刷新扩展点实现类集合,下面我们看下Dubbo是如何加载配置文件的。 123456789101112131415161718192021222324252627282930313233343536private Map&lt;String, Class&lt;?&gt;&gt; loadExtensionClasses() &#123; //1、 通过@SPI注解获得扩展点的默认扩展名（前提是当前拓展点需要有@SPI注解，其实程序执行到这里type一定是有@SPI注解的，因为在获取扩展点的扩展加载器的时候已经判断了） final SPI defaultAnnotation = type.getAnnotation(SPI.class); //1.1 如果扩展点的@SPI注解设置了默认值 if (defaultAnnotation != null) &#123; // @SPI注解的值就是扩展点的默认扩展名 String value = defaultAnnotation.value(); if ((value = value.trim()).length() &gt; 0) &#123; // 对默认扩展名进行分隔处理，以逗号分隔为字符串数组 String[] names = NAME_SEPARATOR.split(value); // 检测 SPI 注解内容是否合法，不合法则抛出异常 if (names.length &gt; 1) &#123; throw new IllegalStateException(\"more than 1 default extension name on extension \" + type.getName() + \": \" + Arrays.toString(names)); &#125; /** 设置默认名称，cachedDefaultName 是用来加载扩展点的默认实现 &#123;@link #getDefaultExtension()&#125; */ if (names.length == 1) &#123; cachedDefaultName = names[0]; &#125; &#125; &#125; //2、 从配置文件中加载拓展实现类集合，这里分别对应三类文件（1. Dubbo内置的 2. Dubbo自定义 3. JDK SPI） Map&lt;String, Class&lt;?&gt;&gt; extensionClasses = new HashMap&lt;String, Class&lt;?&gt;&gt;(); loadDirectory(extensionClasses, DUBBO_INTERNAL_DIRECTORY); loadDirectory(extensionClasses, DUBBO_DIRECTORY); loadDirectory(extensionClasses, SERVICES_DIRECTORY); return extensionClasses;&#125; 我们可以看到该方法没有太多的逻辑，主要处理扩展点的默认扩展名，如果存在的化就放入缓存中，具体加载配置文件的逻辑由loadDirectory方法实现。 需要注意的是，唯一调用该方法的入口 {@link #getExtensionClasses()} 已经加过了锁，因此此处无需再次加锁。接下来继续分析Dubbo如何加载配置文件。 123456789101112131415161718192021222324252627282930313233private void loadDirectory(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, String dir) &#123; // 拼接完整的文件名（相对路径）： 目录 + type全类名 String fileName = dir + type.getName(); try &#123; Enumeration&lt;java.net.URL&gt; urls; // 类加载器 ClassLoader classLoader = findClassLoader(); /** 获得文件名对应的所有文件数组（可能同一个文件名在不同的目录结构中，这样就会获取多个文件）,每个文件内容封装到一个java.net.URL中*/ if (classLoader != null) &#123; urls = classLoader.getResources(fileName); &#125; else &#123; urls = ClassLoader.getSystemResources(fileName); &#125; // 遍历java.net.URL集合 if (urls != null) &#123; while (urls.hasMoreElements()) &#123; java.net.URL resourceURL = urls.nextElement(); // 加载java.net.URL loadResource(extensionClasses, classLoader, resourceURL); &#125; &#125; &#125; catch (Throwable t) &#123; logger.error(\"Exception when load extension class(interface: \" + type + \", description file: \" + fileName + \").\", t); &#125;&#125; 通过上面代码可以看出,loadDirectory方法主要就做一件事，加载配置文件并将每个配置文件内容封装到java.net.URL集合中，接下来在loadResource方法中就可以从该URL中依次解析扩展名和扩展实现类。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/** * 加载配置文件内容（已经封装成了java.net.URL） * * @param extensionClasses 扩展类集合 * @param classLoader 类加载器 * @param resourceURL 文件内容资源 */ private void loadResource(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, ClassLoader classLoader, java.net.URL resourceURL) &#123; try &#123; // 读取文件内容 BufferedReader reader = new BufferedReader(new InputStreamReader(resourceURL.openStream(), \"utf-8\")); try &#123; String line; // 一行一行的读取。会跳过当前被注释掉行，例如：#dubbo=xxx while ((line = reader.readLine()) != null) &#123; // 如果有#注释，那么ci为0，没有就为-1 final int ci = line.indexOf('#'); // 在有#注释的情况下，此时line的长度为0 if (ci &gt;= 0) &#123; line = line.substring(0, ci); &#125; // 去除前后端空格，防止自定义扩展点实现时配置不规范 line = line.trim(); // 没有#注释的情况 if (line.length() &gt; 0) &#123; try &#123; /** * 拆分 key=value ，name为拓展名 line为拓展实现类名。注意： * 1 这里name可能为空,这种情况扩展名会自动生成（因为Dubbo SPI兼容Java SPI，Dubbo SPI配置强调key=value格式，应该尽可能遵守规则） * 2 扩展名只对普通扩展才有意义，对自适应扩展、Wrapper是没用的，之所以要配置，是为了统一dubbo spi配置规则 */ String name = null; // i &gt; 0，有扩展名； i &lt; 0 没有配置扩展名，即兼容Java SPI int i = line.indexOf('='); if (i &gt; 0) &#123; /** 获取 = 左边的key 即扩展名 */ name = line.substring(0, i).trim(); /** 获取 = 右边的value 即拓展点的实现的全限定性类名 */ line = line.substring(i + 1).trim(); &#125; // 加载当前行对应的扩展点配置 if (line.length() &gt; 0) &#123; /** * 1 通过反射，根据名称获取扩展点实现类 * 2 对扩展实现类进行分类缓存 */ loadClass(extensionClasses, resourceURL, Class.forName(line, true, classLoader), name); &#125; &#125; catch (Throwable t) &#123; IllegalStateException e = new IllegalStateException(\"Failed to load extension class(interface: \" + type + \", class line: \" + line + \") in \" + resourceURL + \", cause: \" + t.getMessage(), t); exceptions.put(line, e); &#125; &#125; &#125; &#125; finally &#123; reader.close(); &#125; &#125; catch (Throwable t) &#123; logger.error(\"Exception when load extension class(interface: \" + type + \", class file: \" + resourceURL + \") in \" + resourceURL, t); &#125; &#125; loadResource方法用于将配置文件中的每行记录读取出来，经过解析和反射处理就能拿到扩展名和对应的扩展实现类，扩展名和扩展实现类的获取逻辑已经在代码中详细注释。最后调用loadClass方法进行分类缓存，这些缓存很多，我们来看下Dubbo是如何处理实例缓存的分类的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102/** * 对扩展点实现类进行分类缓存 * * @param extensionClasses 扩展实现类集合 * @param resourceURL 文件内容资源 * @param clazz 扩展点实现类 * @param name 扩展名 【只对普通扩展才有意义】 * @throws NoSuchMethodException */private void loadClass(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, java.net.URL resourceURL, Class&lt;?&gt; clazz, String name) throws NoSuchMethodException &#123; // 判断拓展点实现类，是否实现了当前type接口，没有实现就会报错 if (!type.isAssignableFrom(clazz)) &#123; throw new IllegalStateException(\"Error when load extension class(interface: \" + type + \", class line: \" + clazz.getName() + \"), class \" + clazz.getName() + \"is not subtype of interface.\"); &#125; //-------------------------------------- 根据扩展点实现类的类型可分为三大类 ，在进行分类缓存中有优先级，即同一个实现类只能归属到某个分类中 --------------------------------/ /** * 1、自适应扩展类 * 说明： * （1）当前扩展点实现类是否标注@Adaptive注解，标记的话就是自适应扩展类，直接缓存到 cachedAdaptiveClass 属性中，然后结束逻辑，即不会进行下面的 Wrapper、普通扩展类以及自动激活类逻辑判断。 * （2）自适应固定扩展实现类其实不需要配置扩展名，即使配置了也用不到，因为自适应扩展类和自适应扩展对象整个转换闭环都用不到扩展名。之所以配置，是为了统一规则。 */ if (clazz.isAnnotationPresent(Adaptive.class)) &#123; // 一个扩展点有且仅允许一个自适应扩展实现类，如果符合条件就加入到缓存中，否则抛出异常 if (cachedAdaptiveClass == null) &#123; cachedAdaptiveClass = clazz; &#125; else if (!cachedAdaptiveClass.equals(clazz)) &#123; throw new IllegalStateException(\"More than 1 adaptive class found: \" + cachedAdaptiveClass.getClass().getName() + \", \" + clazz.getClass().getName()); &#125; /** * 2、Wrapper类型 （该类需要有有一个参数的构造方法，且这个参数类型是当前的扩展点type） * 说明： * （1）当前扩展点实现类如果是Wrapper类，直接缓存到 cachedWrapperClasses 属性集合中，然后结束逻辑，即不会进行下面的 普通扩展类以及自动激活类逻辑判断。 * （2）Wrapper类其实不需要配置扩展名，即使配置了也用不到。之所以配置，是为了统一规则。 */ &#125; else if (isWrapperClass(clazz)) &#123; Set&lt;Class&lt;?&gt;&gt; wrappers = cachedWrapperClasses; if (wrappers == null) &#123; cachedWrapperClasses = new ConcurrentHashSet&lt;Class&lt;?&gt;&gt;(); wrappers = cachedWrapperClasses; &#125; wrappers.add(clazz); /** * 3、普通的扩展实现类，注意Activate自动激活类从大的方面也属于普通的扩展实现类 */ &#125; else &#123; // 判断是否有默认的构造方法，没有会抛出异常 clazz.getConstructor(); // 未配置扩展名，则自动生成。适用于Java SPI的配置方式（Dubbo SPI 兼容Java SPI） 例如： xxx.yyy.DemoFilter生成的拓展名为demo if (name == null || name.length() == 0) &#123; // 自动生成扩展名 name = findAnnotationName(clazz); if (name.length() == 0) &#123; throw new IllegalStateException(\"No such extension name for the class \" + clazz.getName() + \" in the config \" + resourceURL); &#125; &#125; // 对扩展名进行分割处理，dubbo支持配置多个扩展名。如果配置多个扩展名需要以','分割 String[] names = NAME_SEPARATOR.split(name); if (names != null &amp;&amp; names.length &gt; 0) &#123; // 3.1、 如果当前类标注了@Activate，就缓存到 cachedActivates集合。需要注意的是，即使扩展点配置多个，cachedActivates 的key 只取第一个。 Activate activate = clazz.getAnnotation(Activate.class); if (activate != null) &#123; // 拓展名与 @Activate的映射 cachedActivates.put(names[0], activate); &#125; /** * 3.2、缓存当前扩展点分类到 cachedNames 集合 和 cachedClasses 集合 * 说明： * （1）cachedNames 缓存集合中的数据特点：同一个扩展点实现类对应的扩展名即使在配置多个扩展名的情况下也只取第一个 * （2）cachedClasses 缓存集合的数据特点：同一个扩展点实现类对应的扩展名可能存在多个 */ for (String n : names) &#123; // 缓存扩展类到扩展名的映射 if (!cachedNames.containsKey(clazz)) &#123; cachedNames.put(clazz, n); &#125; // 缓存扩展名到扩展类的映射，注意如果在不同的文件中配置同一个扩展点实现，并且扩展名有相同的情况，这时以解析的第一个为准 Class&lt;?&gt; c = extensionClasses.get(n); if (c == null) &#123; extensionClasses.put(n, clazz); &#125; else if (c != clazz) &#123; throw new IllegalStateException(\"Duplicate extension \" + type.getName() + \" name \" + n + \" on \" + c.getName() + \" and \" + clazz.getName()); &#125; &#125; &#125; &#125;&#125; 通过上面的代码可知，loadClass方法主要就是分类缓存不同扩展实现类，这个过程不涉及扩展实现类的实例化，这也验证了前面的结论，Dubbo SPI是按需实例化对象。到这里getExtension方法主要过就分析完了，前面也说到该方法是加载扩展实现的完整逻辑，其它的两个入口中的逻辑也会使用上面过程中的部分逻辑，在下面的代码分析中我们可以看到。 getActivateExtension 方法该方法只是根据不同的条件同时激活多个普通扩展实现类，即会做一些通用的判断来筛选是否是激活扩展扩展对象。前面多次提到该法会依赖getExtension方法中的逻辑，下面我就一起来看看。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687/** * 获得激活条件的扩展实现对象集合 * * @param url url * @param values 激活的扩展名数组，可能为空。如：获取dubbo内置的过滤器时，key=service.filter，url中没有对应的值 * @param group 过滤分组名 * @return 被激活的扩展实现对象集合 * @see com.alibaba.dubbo.common.extension.Activate */ public List&lt;T&gt; getActivateExtension(URL url, String[] values, String group) &#123; // 激活扩展实现对象结果集 List&lt;T&gt; exts = new ArrayList&lt;T&gt;(); // 激活的扩展名集合 List&lt;String&gt; names = values == null ? new ArrayList&lt;String&gt;(0) : Arrays.asList(values); // 判断扩展名集合中是否有 '-default' , 如： &lt;dubbo:service filter=\"-default\"/&gt; 代表移出所有默认的过滤器。注意，names是个空的List是符合条件的 if (!names.contains(Constants.REMOVE_VALUE_PREFIX + Constants.DEFAULT_KEY)) &#123; // 获取/刷新 扩展点实现类的集合 getExtensionClasses(); /** * 遍历cachedActivates (拓展名 到 @Activate 的映射) * 1 匹配分组，匹配成功则继续逻辑，否则不处理 加载配置文件时收集到的激活扩展类 * 2 对激活扩展类进行实例化[初次才会，以后就从缓存中取] * 3 判断当前缓存中的激活扩展类是否和传入的激活扩展类冲突，如果有冲突，就忽略缓存中的激活扩展类，以传入的扩展类为主 */ for (Map.Entry&lt;String, Activate&gt; entry : cachedActivates.entrySet()) &#123; // 扩展名 String name = entry.getKey(); // Activate Activate activate = entry.getValue(); // 匹配分组，判断Activate注解的group属性值是否包含当前传入的group，包含就符合分组条件 if (isMatchGroup(group, activate.group())) &#123; // 获取扩展名对应的扩展点实现对象 T ext = getExtension(name); // 是否忽略 加载配置文件时收集到的激活扩展类 if (!names.contains(name) // 匹配扩展名 &amp;&amp; !names.contains(Constants.REMOVE_VALUE_PREFIX + name) // 如果包含 '-' 表示不激活该扩展实现 &amp;&amp; isActive(activate, url)) // 检测URL中是否出现了指定的key &#123; exts.add(ext); &#125; &#125; &#125; // 对扩展对象进行排序（根据注解的before、after、order属性） Collections.sort(exts, ActivateComparator.COMPARATOR); &#125; // z执行到此步骤的时候Dubbo原生的Filter已经添加完毕了，下面处理自定义的Filter List&lt;T&gt; usrs = new ArrayList&lt;T&gt;(); // 遍历传入的激活扩展名集合 for (int i = 0; i &lt; names.size(); i++) &#123; // 获取激活扩展名 String name = names.get(i); // 判断是否是 移除激活扩展名，如果是就忽略。 如： &lt;dubbo:service filter=\"-demo\"/&gt;，那么此时demo对应的扩展实现就是属于无效的 if (!name.startsWith(Constants.REMOVE_VALUE_PREFIX) &amp;&amp; !names.contains(Constants.REMOVE_VALUE_PREFIX + name)) &#123; // 处理 自定义的激活扩展配置在默认的激活扩展前面的情况, 如： &lt;dubbo:service filter=\"demo,default\"/&gt;，那么自定义的demo激活扩展就优先默认的激活扩展。主要是exts中的值变化，前面已经处理了默认的激活扩展(加载配置文件时收集到的激活扩展类) if (Constants.DEFAULT_KEY.equals(name)) &#123; if (!usrs.isEmpty()) &#123; exts.addAll(0, usrs); usrs.clear(); &#125; &#125; else &#123; // 获得激活扩展实现对象 T ext = getExtension(name); usrs.add(ext); &#125; &#125; &#125; if (!usrs.isEmpty()) &#123; exts.addAll(usrs); &#125; return exts; &#125; 获取激活的扩展对象逻辑在代码中已经详细注释说明，获取扩展实现对象还是调用了getExtension方法。该方法主要步骤： 如果触发获取扩展实现类动作时，会检查缓存，如果缓存中没有，就加载配置文件来刷新扩展实现类集合。 遍历缓存中的激活集合（这个缓存内容是加载的带有@Activate注解的扩展类信息），根据传入的URL匹配条件筛选出符合激活条件的扩展类实现，然后进行排序操作。 遍历传入的激活扩展名集合，根据设置的顺序调整扩展点激活顺序，其中default代表的是所有@Activate标注并且配置在配置文件中的扩展实现类 通过getExtension(name)获取激活扩展名对应的扩展对象并加入结果集合 返回符合条件的激活类集合 getAdaptiveExtension 方法获取自适应扩展对象的入口，即适配器对象。如果获取的自适应扩展类属于固定的，那么该方法相对独立，几乎不依赖getExtension方法的逻辑。如果属于动态生成则内部也会调用getExtension方法。由于该方法会涉及到javassist、动态编译等技术，内容较多且比较复杂，这里不再进行分析，我会单独写一篇文章进行详细说明。下面先给出固定的自适应扩展类和自动生成的自适应扩展类的示例，让胖友们有个概念。 固定的自适应扩展类，以编译扩展接口为例： 12345678910111213141516171819202122232425262728293031323334353637383940/** * AdaptiveCompiler. (SPI, Singleton, ThreadSafe) * 实现Compiler接口，自适应Compiler实现类 */@Adaptivepublic class AdaptiveCompiler implements Compiler &#123; /** * 默认编辑器的拓展名 */ private static volatile String DEFAULT_COMPILER; /** * 静态方法，设置默认编辑器的拓展名。该方法被 &#123;@link com.alibaba.dubbo.config.ApplicationConfig#setCompiler(java.lang.String)&#125;方法调用. * 在&lt;dubbo:application compiler=\"\"/&gt; 配置下可触发该方法 * * @param compiler */ public static void setDefaultCompiler(String compiler) &#123; DEFAULT_COMPILER = compiler; &#125; @Override public Class&lt;?&gt; compile(String code, ClassLoader classLoader) &#123; Compiler compiler; // 获得Compiler的ExtensionLoader对象 ExtensionLoader&lt;Compiler&gt; loader = ExtensionLoader.getExtensionLoader(Compiler.class); // 声明 name 变量，引用 DEFAULT_COMPILER 的值，避免下面的值变了 String name = DEFAULT_COMPILER; // 使用设置的拓展名，获得Compiler拓展对象 if (name != null &amp;&amp; name.length() &gt; 0) &#123; compiler = loader.getExtension(name); // 获得默认的Compiler拓展对象 &#125; else &#123; compiler = loader.getDefaultExtension(); &#125; // 使用真正的Compiler对象，动态编译代码 return compiler.compile(code, classLoader); &#125;&#125; 动态生成的自适应扩展类，以ZookeeperTransporter扩展接口为例 12345678910111213141516171819import com.alibaba.dubbo.common.extension.ExtensionLoader;public class ZookeeperTransporter$Adaptive implements com.alibaba.dubbo.remoting.zookeeper.ZookeeperTransporter &#123; public com.alibaba.dubbo.remoting.zookeeper.ZookeeperClient connect(com.alibaba.dubbo.common.URL arg0) &#123; if (arg0 == null) &#123; throw new IllegalArgumentException(\"url == null\"); &#125; com.alibaba.dubbo.common.URL url = arg0; String extName = url.getParameter(\"client\", url.getParameter(\"transporter\", \"curator\")); if (extName == null) &#123; throw new IllegalStateException(\"Fail to get extension(com.alibaba.dubbo.remoting.zookeeper.ZookeeperTransporter) name from url(\" + url.toString() + \") use keys([client, transporter])\"); &#125; com.alibaba.dubbo.remoting.zookeeper.ZookeeperTransporter extension = (com.alibaba.dubbo.remoting.zookeeper.ZookeeperTransporter) ExtensionLoader .getExtensionLoader(com.alibaba.dubbo.remoting.zookeeper.ZookeeperTransporter.class) .getExtension(extName); return extension.connect(arg0); &#125;&#125; hasExtension 方法123456789101112131415161718/** * 判断是否有对应的扩展实现类 * * @param name 扩展名 * @return */ public boolean hasExtension(String name) &#123; if (name == null || name.length() == 0) &#123; throw new IllegalArgumentException(\"Extension name == null\"); &#125; try &#123; // 没有name对应的扩展实现类就抛出异常，即最后返回false this.getExtensionClass(name); return true; &#125; catch (Throwable t) &#123; return false; &#125; &#125; 上面代码比较简单，根据扩展名判断是否有对应的扩展实现类，之所以单独拿出来介绍是Dubbo的很多流程会用到该方法，有个印象就可以了。 Dubbo IOC 实现Dubbo IOC 实现目前仅支持setter注入，严谨来说，Dubbo IOC 实现方式还可以通过构造注入，即Wrapper类的实现。Dubbo的setter注入要求是，如果某个扩展类是另外一个扩展点实现类的成员属性，并且拥有对应的setter方法，那么Dubbo就会自动注入对应的扩展点实现对象。这个功能在上面创建扩展实现的时候需要用到，当时没有详细说明，下面我们单独来分析。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * 依赖注入 * * @param instance 扩展实现对象 （注意，可能会是一个Wrapper） * @return */ private T injectExtension(T instance) &#123; try &#123; // 只有ExtensionFactory扩展点对应的ExtensionLoader对象的该属性为null，其它扩展点的ExtensionLoader对象的该属性必然不为null if (objectFactory != null) &#123; // 反射获得扩展实现对象中的所有方法 for (Method method : instance.getClass().getMethods()) &#123; // 过滤规则为 ' set开头 + 仅有一个参数 + public ' 的方法 if (method.getName().startsWith(\"set\") &amp;&amp; method.getParameterTypes().length == 1 &amp;&amp; Modifier.isPublic(method.getModifiers())) &#123; /** * 检查方法是否有 @DisableInject 注解，有该注解就忽略依赖注入 */ if (method.getAnnotation(DisableInject.class) != null) &#123; continue; &#125; // 获取setter方法参数类型 Class&lt;?&gt; pt = method.getParameterTypes()[0]; try &#123; // 获得属性名，如：setXxx -&gt; xxx String property = method.getName().length() &gt; 3 ? method.getName().substring(3, 4).toLowerCase() + method.getName().substring(4) : \"\"; /** * 通过扩展工厂获得属性值，即 方法参数类型作为扩展点，属性名作为扩展名。 * ExtensionFactory的实现有三个,AdaptiveExtensionFactory是对其它两个工厂的管理，getExtension方法的真正调用的是其它两个工厂的方法: * 1）SpringExtensionFactory * getExtension方法会返回容器中名称为property并且类型为pt的bean对象 * 2）SpiExtensionFactory * getExtension方法会返回类型为pt的自适应拓展对象，因为该方法会校验pt是接口类型并且有@SPI注解，然后pt有拓展类的情况下，就会获取pt的自适应拓展对象，property没用到 */ Object object = objectFactory.getExtension(pt, property); // 通过反射设置属性值 if (object != null) &#123; method.invoke(instance, object); &#125; &#125; catch (Exception e) &#123; logger.error(\"fail to inject via method \" + method.getName() + \" of interface \" + type.getName() + \": \" + e.getMessage(), e); &#125; &#125; &#125; &#125; &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; return instance; &#125; Dubbo的ioc基于setter方法注入依赖的，注入的依赖来源则需要通过扩展工厂提供，接下来我们来分析Dubbo的扩展工厂。 扩展工厂接口123456789101112@SPIpublic interface ExtensionFactory &#123; /** * Get extension. 获得扩展对象 * * @param type object type. 扩展接口 * @param name object name. 扩展名 * @return object instance. 扩展实现实例 */ &lt;T&gt; T getExtension(Class&lt;T&gt; type, String name);&#125; ExtensionFactory 扩展工厂，是Dubbo的一个扩展点。主要用于获取扩展实现对象所需的依赖，然后完成依赖注入，该接口的uml关系如下： 由uml图可知，该接口有三个扩展实现类。AdaptiveExtensionFactory是它的自适应实现类，只是用来管理SpiExtensionFactory和SpringExtensionFactory，具体依赖的查找还是由这两个类完成，下面我们分别来分析。 AdaptiveExtensionFactory 工厂12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Adaptivepublic class AdaptiveExtensionFactory implements ExtensionFactory &#123; /** * ExtensionFactory扩展实现对象集合 */ private final List&lt;ExtensionFactory&gt; factories; /** * AdaptiveExtensionFactory也是ExtensionFactory的扩展实现类，只是比较特殊，是自适应扩展类，不同于普通的扩展类 */ public AdaptiveExtensionFactory() &#123; ExtensionLoader&lt;ExtensionFactory&gt; loader = ExtensionLoader.getExtensionLoader(ExtensionFactory.class); List&lt;ExtensionFactory&gt; list = new ArrayList&lt;ExtensionFactory&gt;(); // 使用ExtensionLoader 加载拓展点实现类，getSupportedExtensions() 返回的是ExtensionFactory扩展点实现类对应的扩展名集合 for (String name : loader.getSupportedExtensions()) &#123; // 根据扩展名获取 ExtensionFactory 的扩展实现对象 并加入缓存中 list.add(loader.getExtension(name)); &#125; factories = Collections.unmodifiableList(list); &#125; /** * 获取目标对象，主要用于 &#123;@link ExtensionLoader#injectExtension(java.lang.Object)&#125; 方法中，用于获取扩展实现对象所需要的依赖属性值 * * @param type object type. 扩展接口 * @param name object name. 扩展名 * @param &lt;T&gt; * @return */ @Override public &lt;T&gt; T getExtension(Class&lt;T&gt; type, String name) &#123; // 遍历扩展工厂对象，获取指定的扩展对象或Spring中的Bean对象 for (ExtensionFactory factory : factories) &#123; T extension = factory.getExtension(type, name); if (extension != null) &#123; return extension; &#125; &#125; return null; &#125;&#125; AdaptiveExtensionFactory 自适应扩展工厂，内部维护了一个 ExtensionFactory 列表，用来管理其它的ExtensionFactory。在用户没有自定义ExtensionFactory的情况下，Dubbo目前提供了两种 ExtensionFactory，分别是 SpiExtensionFactory 和 SpringExtensionFactory。前者用于创建 自适应的拓展，后者从Spring容器中获取所需依赖。 SpiExtensionFactory 工厂12345678910111213141516171819202122232425public class SpiExtensionFactory implements ExtensionFactory &#123; /** * 获取自适应扩展对象 * * @param type object type. 扩展接口 * @param name object name. 扩展名 * @param &lt;T&gt; * @return */ @Override public &lt;T&gt; T getExtension(Class&lt;T&gt; type, String name) &#123; // 校验是接口类型并且有@SPI注解 if (type.isInterface() &amp;&amp; type.isAnnotationPresent(SPI.class)) &#123; // 加载拓展接口对应的 ExtensionLoader ExtensionLoader&lt;T&gt; loader = ExtensionLoader.getExtensionLoader(type); // 判断当前扩展点是否有普通的扩展实现类，注意：当前扩展点存在普通的扩展实现类才会去获取对应的自适应扩展对象 if (!loader.getSupportedExtensions().isEmpty()) &#123; // 获取自适应扩展对象 return loader.getAdaptiveExtension(); &#125; &#125; return null; &#125;&#125; SpiExtensionFactory 是根据扩展接口获取相应的自适应扩展对象，也就是适配器，其中的属性名称没有用到。 SpringExtensionFactory 工厂将属性名称作为 Spring Bean 的名称，从 Spring 容器中获取 Bean。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class SpringExtensionFactory implements ExtensionFactory &#123; private static final Logger logger = LoggerFactory.getLogger(SpringExtensionFactory.class); /** * Spring上下文 */ private static final Set&lt;ApplicationContext&gt; contexts = new ConcurrentHashSet&lt;ApplicationContext&gt;(); /** * 保存Spring上下文 * * @param context */ public static void addApplicationContext(ApplicationContext context) &#123; contexts.add(context); &#125; public static void removeApplicationContext(ApplicationContext context) &#123; contexts.remove(context); &#125; // currently for test purpose public static void clearContexts() &#123; contexts.clear(); &#125; @Override @SuppressWarnings(\"unchecked\") public &lt;T&gt; T getExtension(Class&lt;T&gt; type, String name) &#123; // 遍历SpringContext上下集合 for (ApplicationContext context : contexts) &#123; // 判断容器中是否包含名称为name的bean if (context.containsBean(name)) &#123; // 获得bean对象 Object bean = context.getBean(name); // 判断获得的bean类型是否是type类型 if (type.isInstance(bean)) &#123; return (T) bean; &#125; &#125; &#125; logger.warn(\"No spring extension (bean) named:\" + name + \", try to find an extension (bean) of type \" + type.getName()); if (Object.class == type) &#123; return null; &#125; for (ApplicationContext context : contexts) &#123; try &#123; return context.getBean(type); &#125; catch (NoUniqueBeanDefinitionException multiBeanExe) &#123; logger.warn(\"Find more than 1 spring extensions (beans) of type \" + type.getName() + \", will stop auto injection. Please make sure you have specified the concrete parameter type and there's only one extension of that type.\"); &#125; catch (NoSuchBeanDefinitionException noBeanExe) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Error when get spring extension(bean) for type:\" + type.getName(), noBeanExe); &#125; &#125; &#125; logger.warn(\"No spring extension (bean) named:\" + name + \", type:\" + type.getName() + \" found, stop get bean.\"); return null; &#125;&#125; Dubbo使用Spring容器管理的依赖为扩展对象注入依赖属性。Dubbo是如何与Spring容器打通的呢？有两处结合点，分别是服务暴露和服务引用的时候，利用ApplicationContextAware的回调方法设置spring上下文。 服务暴露结合点 123456789101112131415161718192021222324252627282930313233public class ServiceBean&lt;T&gt; extends ServiceConfig&lt;T&gt; implements InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener&lt;ContextRefreshedEvent&gt;, BeanNameAware, ApplicationEventPublisherAware &#123; // 省略无关代码 @Override public void setApplicationContext(ApplicationContext applicationContext) &#123;// 当前加载的上下文 this.applicationContext = applicationContext; // 为Spring拓展工厂注入上下文 , dubbo和Spring容器打通 SpringExtensionFactory.addApplicationContext(applicationContext); if (applicationContext != null) &#123; SPRING_CONTEXT = applicationContext; try &#123; Method method = applicationContext.getClass().getMethod(\"addApplicationListener\", new Class&lt;?&gt;[]&#123;ApplicationListener.class&#125;); // backward compatibility to spring 2.0.1 method.invoke(applicationContext, new Object[]&#123;this&#125;); supportedApplicationListener = true; // 当前Spring容器是否支持上下文监听 &#125; catch (Throwable t) &#123; if (applicationContext instanceof AbstractApplicationContext) &#123; try &#123; Method method = AbstractApplicationContext.class.getDeclaredMethod(\"addListener\", new Class&lt;?&gt;[]&#123;ApplicationListener.class&#125;); // backward compatibility to spring 2.0.1 if (!method.isAccessible()) &#123; method.setAccessible(true); &#125; method.invoke(applicationContext, new Object[]&#123;this&#125;); supportedApplicationListener = true; &#125; catch (Throwable t2) &#123; &#125; &#125; &#125; &#125; &#125;&#125; 服务引用结合点123456789public class ReferenceBean&lt;T&gt; extends ReferenceConfig&lt;T&gt; implements FactoryBean, ApplicationContextAware, InitializingBean, DisposableBean &#123; // 省略无关代码 @Override public void setApplicationContext(ApplicationContext applicationContext) &#123; this.applicationContext = applicationContext; // dubbo 和 spring容器打通 SpringExtensionFactory.addApplicationContext(applicationContext); &#125;&#125; Dubbo AOP 实现Dubbo AOP 实现需要Wrapper类，关于Wrapper类前面已经介绍过了，这里不再说明。关于Dubbo AOP 的功能也在前面的流程中体现出来了，单独把Dubbo AOP 拿出来进行说明是考虑到前面的篇幅没有具体到Wrapper类，只是阐述了其功能和实现。实现一个Wrapper类的基本步骤如下： 定义一个Wrapper类并实现扩展接口，然后编写AOP逻辑。 在配置文件配置自定义的Wrapper类 定义 Wrapper类123456789101112131415161718192021public class CommandWrapper implements Command &#123; Command command; /** * 构造方法的参数必须是扩展点类型 * * @param command */ public CommandWrapper(Command command) &#123; this.command = command; &#125; @Override public void execute() &#123; System.out.println(\"CommandWrapper is running ...\"); // 执行扩展实现对象，注意，如果不显示调用扩展实现，那么就达不到目标结果，只会执行这个并没有真正实现的Wrapper command.execute(); &#125;&#125; 定义Wrapper类很简单，只要按照Wrapper类的要求进行实现即可。需要说明的是，我们所说的Wrapper类其实不强制类名以Wrapper结尾，只要符合Wrapper类的要求就是一个Wrapper类，并不是用名字进行区分是否Wrapper类，只是这样写是Dubbo的一种约定罢了。 配置 Wrapper类 Dubbo 内置的Wrapper 举例123456789101112131415161718192021222324252627/** * 实现 Cluster接口，MockClusterWrapper实现类，注意它是个Wrapper类，对应的Cluster对象都会被它所包装。 */public class MockClusterWrapper implements Cluster &#123; /** * 真正的Cluster 对象 */ private Cluster cluster; public MockClusterWrapper(Cluster cluster) &#123; this.cluster = cluster; &#125; /** * 创建MockClusterInvoker对象 * * @param directory Directory 对象 * @param &lt;T&gt; * @return * @throws RpcException */ @Override public &lt;T&gt; Invoker&lt;T&gt; join(Directory&lt;T&gt; directory) throws RpcException &#123; return new MockClusterInvoker&lt;T&gt;(directory, this.cluster.join(directory)); &#125;&#125; 总结本篇文章简单介绍了Dubbo SPI 用法，并对 Dubbo SPI 的核心源码进行了分析，总体上不算复杂但很繁琐，细节点很多，比如，扩展名生成的规则，扩展类的种类区别，自动激活扩展生效条件。想要掌握整个流程需要耐心调试源码，笔者差点被spi及接下来要分析的Dubbo配置给劝退了。另外，由于Dubbo SPI自适应机制涉及到的代码量较多，逻辑比较复杂，我将会在下一篇文章中单独进行分析。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"SPI","slug":"SPI","permalink":"https://gentryhuang.com/tags/SPI/"}]},{"title":"Java SPI","slug":"rpc/SPI机制之JDK","date":"2020-03-10T16:00:00.000Z","updated":"2021-01-04T10:56:56.234Z","comments":false,"path":"posts/a9c33b8c/","link":"","permalink":"https://gentryhuang.com/posts/a9c33b8c/","excerpt":"","text":"SPI概述SPI（Service Provider Interface）是JDK内置的一种服务提供发现机制。一个服务(Service)通常指的是已知的接口或者抽象类，服务提供方就是对这个接口或者抽象类的实现，然后按照SPI标准存放到资源路径META-INF/services目录下，文件的命名为该服务接口的全限定名。Java SPI使用了策略模式，一个接口多种实现，我们只声明接口，具体的实现并不在程序中直接确定，而是由配置决定。 约定 服务的提供者的接口，它的多种实现一般会在jar包的META-INF/services 目录下，在这个目录下创建服务提供者接口同名文件，这个文件中就是接口的具体实现类的全限定性类名。而当外部加载这个服务提供功能时，就能通过该jar包META-INF/services/下的配置文件得到具体的实现类名，并加载实例化，完成功能的装配。 实现步骤 定义接口 编写接口实现类 在META-INF/services 目录下创建一个以接口全路径名的文件 文件内容是接口实现类的全路径名，可以有多个，如果多个需要使用分行符分割 在代码中使用jdk的ServiceLoader来加载接口的具体实现类 示例服务提供者接口1234567package com.alibaba.dubbo.spi;public interface Command &#123; /** * 执行方法 */ void execute();&#125; 服务提供者实现类1234567package com.alibaba.dubbo.spi.impl;public class StartCommand implements Command&#123; @Override public void execute() &#123; System.out.println(\"start....\"); &#125; &#125; 1234567package com.alibaba.dubbo.spi.impl;public class ShutdownCommand implements Command&#123; @Override public void execute() &#123; System.out.println(\"shutdown....\"); &#125; &#125; 在META-INF/services下创建 com.alibaba.dubbo.spi.Command文件123# 内容com.alibaba.dubbo.spi.impl.StartCommandcom.alibaba.dubbo.spi.impl.ShutdownCommand 加载扩展实现123456789101112131415public class Main &#123; public static void main(String[] args) &#123; // ServiceLoader是JDK的，用来加载接口的实现类（通过配置文件加载） ServiceLoader&lt;Command&gt; serviceLoader = ServiceLoader.load(Command.class); for (Command command : serviceLoader) &#123; if (command instanceof StartCommand) &#123; System.out.println(\"判断出是Start：\" + command.getClass().getSimpleName()); &#125; if (command instanceof ShutdownCommand) &#123; System.out.println(\"判断出是Shutdown：\" + command.getClass().getSimpleName()); &#125; command.execute(); &#125; &#125;&#125; JDK SPI 源码分析属性123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public final class ServiceLoader&lt;S&gt; implements Iterable&lt;S&gt;&#123; /** * 服务的配置文件路径前缀 */ private static final String PREFIX = \"META-INF/services/\"; /** * 服务接口 */ private final Class&lt;S&gt; service; /** * 类加载器 */ private final ClassLoader loader; // The access control context taken when the ServiceLoader is created private final AccessControlContext acc; /** * 服务缓存 * key: 实现类的全路径名 * value: 实现类对象 */ private LinkedHashMap&lt;String,S&gt; providers = new LinkedHashMap&lt;&gt;(); /** * 延迟查找迭代器，即只有获取服务实现的时候才会加载配置资源然后初始化。这是最核心的对象 */ private LazyIterator lookupIterator; /** * Clear this loader's provider cache so that all providers will be * reloaded. * * &lt;p&gt; After invoking this method, subsequent invocations of the &#123;@link * #iterator() iterator&#125; method will lazily look up and instantiate * providers from scratch, just as is done by a newly-created loader. * * &lt;p&gt; This method is intended for use in situations in which new providers * can be installed into a running Java virtual machine. */ public void reload() &#123; // 清理服务缓存 providers.clear(); // 创建延迟查找迭代器，用于读取 SPI 配置文件并实例化实现类对象 lookupIterator = new LazyIterator(service, loader); &#125; // 构造方法 private ServiceLoader(Class&lt;S&gt; svc, ClassLoader cl) &#123; service = Objects.requireNonNull(svc, \"Service interface cannot be null\"); loader = (cl == null) ? ClassLoader.getSystemClassLoader() : cl; acc = (System.getSecurityManager() != null) ? AccessController.getContext() : null; reload(); &#125; /** * 通过指定的服务接口和类加载起创建 ServiceLoader * * @param 服务接口 * @param 类加载器 * * @return A new service loader */ public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service, ClassLoader loader) &#123; return new ServiceLoader&lt;&gt;(service, loader); &#125; /** * 通过指定的服务接口和当前线程的类加载器创建 ServiceLoader * * @param 服务接口 * @return A new service loader */ public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) &#123; ClassLoader cl = Thread.currentThread().getContextClassLoader(); return ServiceLoader.load(service, cl); &#125; // $&#123;省略其它代码&#125;&#125; 通过使用例子，我们可以看到 JDK SPI 的入口是 ServiceLoader.load() 方法，结合上面的 ServiceLoader 的部分源码可知这个入口方法会创建 ServiceLoader 对象，创建对象的过程完成两个任务，一个是服务缓存的清理以保证服务是最新的，另一是创建 LazyIterator 迭代器对象，这个对象是 ServiceLoader 的核心，下面我们来看看这个迭代器类。 LazyIterator123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173public final class ServiceLoader&lt;S&gt; implements Iterable&lt;S&gt;&#123; /** * 服务的配置文件路径前缀 */ private static final String PREFIX = \"META-INF/services/\"; /** * 服务接口 */ private final Class&lt;S&gt; service; /** * 类加载器 */ private final ClassLoader loader; // The access control context taken when the ServiceLoader is created private final AccessControlContext acc; /** * 服务缓存 * key: 实现类的全路径名 * value: 实现类对象 */ private LinkedHashMap&lt;String,S&gt; providers = new LinkedHashMap&lt;&gt;(); /** * 延迟查找迭代器，即只有获取服务实现的时候才会加载配置资源然后初始化 */ private LazyIterator lookupIterator; /** * * &lt;p&gt; After invoking this method, subsequent invocations of the &#123;@link * #iterator() iterator&#125; method will lazily look up and instantiate * providers from scratch, just as is done by a newly-created loader. * * &lt;p&gt; This method is intended for use in situations in which new providers * can be installed into a running Java virtual machine. */ public void reload() &#123; // 清理服务缓存 providers.clear(); // 创建延迟查找迭代器，用于读取 SPI 配置文件并实例化实现类对象 lookupIterator = new LazyIterator(service, loader); &#125; // 私有内部类，用于读取服务配置文件和实例化服务 private class LazyIterator implements Iterator&lt;S&gt; &#123; // 服务接口 Class&lt;S&gt; service; // 类加载器 ClassLoader loader; // 服务配置文件读取内容 Enumeration&lt;URL&gt; configs = null; // 服务配置文件中的服务全路径名集合迭代器 Iterator&lt;String&gt; pending = null; // 记录 pending.next() 的值 String nextName = null; // 构造方法 private LazyIterator(Class&lt;S&gt; service, ClassLoader loader) &#123; this.service = service; this.loader = loader; &#125; // 查找配置文件，并进行遍历 private boolean hasNextService() &#123; // 服务实现类全路径名是否为空 if (nextName != null) &#123; return true; &#125; // 服务配置缓存为空，尝试加载配置文件 if (configs == null) &#123; try &#123; // 拼接服务的配置文件完整路径 String fullName = PREFIX + service.getName(); // 使用类加载器获取服务配置文件内容 if (loader == null) configs = ClassLoader.getSystemResources(fullName); else configs = loader.getResources(fullName); &#125; catch (IOException x) &#123; fail(service, \"Error locating configuration files\", x); &#125; &#125; while ((pending == null) || !pending.hasNext()) &#123; if (!configs.hasMoreElements()) &#123; return false; &#125; // 将服务配置文件内容，即服务接口实现类的全路径名加载到缓存集合中 pending = parse(service, configs.nextElement()); &#125; // 取出集合中的一个元素 nextName = pending.next(); return true; &#125; // 根据服务实现类全路径名实例化对象 private S nextService() &#123; if (!hasNextService()) throw new NoSuchElementException(); String cn = nextName; nextName = null; Class&lt;?&gt; c = null; try &#123; // 由类名获取对应的类 c = Class.forName(cn, false, loader); &#125; catch (ClassNotFoundException x) &#123; fail(service, \"Provider \" + cn + \" not found\"); &#125; if (!service.isAssignableFrom(c)) &#123; fail(service, \"Provider \" + cn + \" not a subtype\"); &#125; try &#123; // 反射创建对象，并类型转换 S p = service.cast(c.newInstance()); // 将服务实例加入缓存 providers.put(cn, p); return p; &#125; catch (Throwable x) &#123; fail(service, \"Provider \" + cn + \" could not be instantiated\", x); &#125; throw new Error(); // This cannot happen &#125; // 是否还有元素 public boolean hasNext() &#123; if (acc == null) &#123; return hasNextService(); &#125; else &#123; PrivilegedAction&lt;Boolean&gt; action = new PrivilegedAction&lt;Boolean&gt;() &#123; public Boolean run() &#123; return hasNextService(); &#125; &#125;; return AccessController.doPrivileged(action, acc); &#125; &#125; // 获取元素 public S next() &#123; if (acc == null) &#123; return nextService(); &#125; else &#123; PrivilegedAction&lt;S&gt; action = new PrivilegedAction&lt;S&gt;() &#123; public S run() &#123; return nextService(); &#125; &#125;; return AccessController.doPrivileged(action, acc); &#125; &#125; public void remove() &#123; throw new UnsupportedOperationException(); &#125; &#125; // $&#123;省略其它代码&#125;&#125; 通过代码可以看出 LazyIterator 是用来加载服务的配置文件，以及实例化配置文件中服务实现类，此外还提供了判断和获取服务的方法。总得来说， LazyIterator 有两个上层方法，hashNext() 方法和 next() 方法，而前者最终会调用 hasNextService() 方法，后者最终会调用 nextService() 方法，关系如下： 1234ServiceLoader.hasNext() - ServiceLoader.hasNextService()ServiceLoader.next() - ServiceLoader.nextService() hasNextService() 方法用于加载配置文件内容到缓存，nextService() 方法用于实例化hasNextService()方法加载的实现类，并将实例化的对象放到 providers 集合中缓存起来。 以上就是 ServiceLoader 底层实现，即创建 ServiceLoader 的同时会创建内部的 LazyIterator 对象，ServiceLoader 把配置文件的加载、配置文件中的服务类实例化以及对服务对象的操作都交给该类。下面我们继续根据例子看 ServiceLoader 的迭代器实现。 123456789101112131415161718192021222324252627282930313233public Iterator&lt;S&gt; iterator() &#123; // 创建匿名Iterator 对象 return new Iterator&lt;S&gt;() &#123; // providers 缓存同步过来 Iterator&lt;Map.Entry&lt;String,S&gt;&gt; knownProviders = providers.entrySet().iterator(); // 判断是否存在元素 public boolean hasNext() &#123; // 缓存中是否存在 if (knownProviders.hasNext()) return true; // 缓存中不存则调用 LazyIterator 的方法 return lookupIterator.hasNext(); &#125; // 获取元素 public S next() &#123; // 缓存中是否存在 if (knownProviders.hasNext()) return knownProviders.next().getValue(); // 缓存中不存则调用 LazyIterator 的方法 return lookupIterator.next(); &#125; public void remove() &#123; throw new UnsupportedOperationException(); &#125; &#125;; &#125; 至此，我们知道了 ServiceLoader获取的迭代器（for 循环内部使用的就是迭代器，这里相当于 ServiceLoader.iterator()方法）是如何实现的，这个匿名迭代器是对LazyIterator包装，本质上还是使用 LazyIterator 中的方法。 使用jdk的spi的依赖mysql驱动 JDK 中只定义了一个 java.sql.Driver 接口，具体的实现是由不同数据库厂商来提供的，比如上图的 MySQL 提供的实现。我们在通过 JDK 的 DriverManager 获取连接时，会优先通过 ServiceLoader 加载具体的驱动。 12345678910111213141516171819--- DriverManager static &#123; loadInitialDrivers(); println(\"JDBC DriverManager initialized\"); &#125; private static void loadInitialDrivers() &#123; String drivers = System.getProperty(\"jdbc.drivers\") // 使用 ServiceLoader 加载所有 java.sql.Driver实现类 ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator(); while(driversIterator.hasNext()) &#123; driversIterator.next(); &#125; // &#123;省略其它代码&#125;&#125; SpringServletContainer初始化器 小结jdk的spi机制虽然实现了服务发现机制，即在模块装配的时候不在模块中写死代码就能够发现服务，但是存在性能和健壮性问题，具体的问题及解决方案在dubbo spi中说明。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"SPI","slug":"SPI","permalink":"https://gentryhuang.com/tags/SPI/"}]},{"title":"URL统一模型","slug":"rpc/dubbo之url统一模型","date":"2020-03-09T16:00:00.000Z","updated":"2020-10-17T10:36:28.342Z","comments":false,"path":"posts/46f95e97/","link":"","permalink":"https://gentryhuang.com/posts/46f95e97/","excerpt":"","text":"URL 定义URL 的全名即统一资源定位符，因特网上的可用资源是使用字符串来表示的，而这些具有特定格式和语义的字符串就是URL。 标准的URL格式: 12组成：协议、账号&#x2F;密码、主机、端口、路径 [大多数url不需要账号&#x2F;密码,需要安全认证的才会需要]格式：protocol:&#x2F;&#x2F;[username:password@]host:port&#x2F;path?key&#x3D;value&amp;key&#x3D;value Dubbo中的 URLDubbo中也使用了类似的 URL，它是整个 Dubbo 中非常基础又非常核心的一个组件，Dubbo URL 中的每个参数几乎都有各自的用途，它们往往对应着特定的功能或实现。Dubbo中对这个 URL 做了封装，大体上分为主要参数和键值对参数。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394/** * url 例子: * &lt;ul&gt; * &lt;li&gt;http://www.facebook.com/friends?param1=value1&amp;amp;param2=value2 * &lt;li&gt;http://username:password@10.20.130.230:8080/list?version=1.0.0 * &lt;li&gt;ftp://username:password@192.168.1.7:21/1/read.txt * &lt;li&gt;registry://192.168.1.7:9090/com.alibaba.service1?param1=value1&amp;amp;param2=value2 * &lt;/ul&gt; * 一些特别的url: * &lt;ul&gt; * &lt;li&gt;192.168.1.3:20880&lt;br&gt; * for this case, url protocol = null, url host = 192.168.1.3, port = 20880, url path = null * &lt;li&gt;file:///home/user1/router.js?type=script&lt;br&gt; * for this case, url protocol = file, url host = null, url path = home/user1/router.js * &lt;li&gt;file://home/user1/router.js?type=script&lt;br&gt; * for this case, url protocol = file, url host = home, url path = user1/router.js * &lt;li&gt;file:///D:/1/router.js?type=script&lt;br&gt; * for this case, url protocol = file, url host = null, url path = D:/1/router.js * &lt;li&gt;file:/D:/1/router.js?type=script&lt;br&gt; * 同上： file:///D:/1/router.js?type=script * &lt;li&gt;/home/user1/router.js?type=script &lt;br&gt; * 对于这些例子： url protocol = null, url host = null, url path = home/user1/router.js * &lt;li&gt;home/user1/router.js?type=script &lt;br&gt; * 对于这些例子： url protocol = null, url host = home, url path = user1/router.js * &lt;/ul&gt; * * @see java.net.URL * @see java.net.URI */public final class URL implements Serializable &#123; private static final long serialVersionUID = -1985165475234910535L; /** * 协议名 */ private final String protocol; /** * 用户名 */ private final String username; /** * 密码 */ private final String password; /** by default, host to registry * 地址 */ private final String host; /** by default, port to registry * 端口 */ private final int port; /** * 路径（服务名） */ private final String path; /** * 参数集合，键值对形式 */ private final Map&lt;String, String&gt; parameters; // 省略其它属性及构造函数 public URL(String protocol, String username, String password, String host, int port, String path, Map&lt;String, String&gt; parameters) &#123; if ((username == null || username.length() == 0) &amp;&amp; password != null &amp;&amp; password.length() &gt; 0) &#123; throw new IllegalArgumentException(\"Invalid url, password without username!\"); &#125; this.protocol = protocol; this.username = username; this.password = password; this.host = host; this.port = (port &lt; 0 ? 0 : port); // trim the beginning \"/\" while (path != null &amp;&amp; path.startsWith(\"/\")) &#123; path = path.substring(1); &#125; this.path = path; if (parameters == null) &#123; parameters = new HashMap&lt;String, String&gt;(); &#125; else &#123; parameters = new HashMap&lt;String, String&gt;(parameters); &#125; this.parameters = Collections.unmodifiableMap(parameters); &#125; // 省略其它方法 &#125; 通过上面的代码也可以看出，Dubbo 使用 URL 来统一描述了所有对象和配置信息，并贯穿整个 Dubbo 框架中。 Dubbo中常见的 URL Dubbo协议的服务 1dubbo:&#x2F;&#x2F;192.168.21.50:20880&#x2F;com.alibaba.dubbo.demo.DemoService?anyhost&#x3D;true&amp;application&#x3D;demo-provider&amp;bean.name&#x3D;com.alibaba.dubbo.demo.DemoService&amp;bind.ip&#x3D;10.1.14.50&amp;bind.port&#x3D;20880&amp;dubbo&#x3D;2.0.2&amp;generic&#x3D;false&amp;interface&#x3D;com.alibaba.dubbo.demo.DemoService&amp;methods&#x3D;sayHello&amp;owner&#x3D;gentryhuang&amp;pid&#x3D;3272&amp;qos.port&#x3D;22222&amp;side&#x3D;provider&amp;timestamp&#x3D;1596611769521 服务提供者 1provider:&#x2F;&#x2F;192.168.21.50:20880&#x2F;com.alibaba.dubbo.demo.DemoService?anyhost&#x3D;true&amp;application&#x3D;demo-provider&amp;bean.name&#x3D;com.alibaba.dubbo.demo.DemoService&amp;category&#x3D;configurators&amp;check&#x3D;false&amp;dubbo&#x3D;2.0.2&amp;generic&#x3D;false&amp;interface&#x3D;com.alibaba.dubbo.demo.DemoService&amp;methods&#x3D;sayHello&amp;owner&#x3D;gentryhuang&amp;pid&#x3D;3272&amp;side&#x3D;provider&amp;timestamp&#x3D;1596611769521 服务消费者 1consumer:&#x2F;&#x2F;192.168.21.50&#x2F;com.alibaba.dubbo.demo.DemoService?application&#x3D;demo-consumer&amp;category&#x3D;consumers&amp;check&#x3D;false&amp;dubbo&#x3D;2.0.2&amp;interface&#x3D;com.alibaba.dubbo.demo.DemoService&amp;methods&#x3D;sayHello&amp;pid&#x3D;3363&amp;qos.port&#x3D;33333&amp;side&#x3D;consumer&amp;timestamp&#x3D;1596612621336 服务暴露过程临时协议 1registry:&#x2F;&#x2F;127.0.0.1:2181&#x2F;com.alibaba.dubbo.registry.RegistryService?application&#x3D;demo-provider&amp;dubbo&#x3D;2.0.2&amp;owner&#x3D;gentryhuang&amp;pid&#x3D;3272&amp;qos.port&#x3D;22222&amp;registry&#x3D;zookeeper&amp;timestamp&#x3D;1596611658802 zk注册中心 1zookeeper:&#x2F;&#x2F;127.0.0.1:2181&#x2F;com.alibaba.dubbo.registry.RegistryService?application&#x3D;demo-provider&amp;dubbo&#x3D;2.0.2&amp;interface&#x3D;com.alibaba.dubbo.registry.RegistryService&amp;owner&#x3D;gentryhuang&amp;pid&#x3D;3272&amp;qos.port&#x3D;22222&amp;timestamp&#x3D;1596611658802 说明: 除此之外还有很多类型的 URL ，不同的协议[如：dubbo协议、http协议等]对应不同的URL、不同的角色[如：提供者、消费者、注册中心、路由器等]对应不同的URL、不同的功能流程[如：服务暴露、服务引用、服务路由等]对应不同的URL…这些在后面的源码解析中都有对应。 Dubbo URL 举例说明 Dubbo URL 统一模型的意义Dubbo中的 URL 可以说是Dubbo的配置总线，它贯穿整个Dubbo的生命周期。上下文的信息传递需要 URL 来提供，特定功能的实现需要 URL 的支持[如：所有扩展点参数都包含url参数，url作为上下文信息贯穿整个拓展点体系]。 Dubbo URL 应用Dubbo URL 在 Dubbo SPI 中的应用在 Dubbo 的自适应扩展实现中，即扩展接口中的方法被 @Adaptive 注解标注会生成一个自适应扩展实现类，这个实现类中的逻辑会根据 Dubbo URL 中的参数选择合适的扩展实现。以ZookeeperTransporter扩展接口为例，下面是生成的自适应扩展实现。 12345678910111213141516171819import com.alibaba.dubbo.common.extension.ExtensionLoader;public class ZookeeperTransporter$Adaptive implements com.alibaba.dubbo.remoting.zookeeper.ZookeeperTransporter &#123; public com.alibaba.dubbo.remoting.zookeeper.ZookeeperClient connect(com.alibaba.dubbo.common.URL arg0) &#123; if (arg0 == null) &#123; throw new IllegalArgumentException(\"url == null\"); &#125; com.alibaba.dubbo.common.URL url = arg0; String extName = url.getParameter(\"client\", url.getParameter(\"transporter\", \"curator\")); if (extName == null) &#123; throw new IllegalStateException(\"Fail to get extension(com.alibaba.dubbo.remoting.zookeeper.ZookeeperTransporter) name from url(\" + url.toString() + \") use keys([client, transporter])\"); &#125; com.alibaba.dubbo.remoting.zookeeper.ZookeeperTransporter extension = (com.alibaba.dubbo.remoting.zookeeper.ZookeeperTransporter) ExtensionLoader .getExtensionLoader(com.alibaba.dubbo.remoting.zookeeper.ZookeeperTransporter.class) .getExtension(extName); return extension.connect(arg0); &#125;&#125; 我们可以看到，生成的自适应扩展实现类 ZookeeperTransporter$Adaptive 会实现 ZookeeperTransporter 中的 connect 方法，内部逻辑会根据传入的 URL 中的参数来确定具体的扩展实现类。 Dubbo URL 在服务注册中应用服务提供者在启动后，将自己的服务地址和相关配置信息封装成 Dubbo URL 添加到注册中心中，即在注册中心写入的是服务提供者的 URL 字符串，如下： 1dubbo: &#x2F;&#x2F;192.168.21.50:20880&#x2F;com.alibaba.dubbo.demo.DemoService?anyhost&#x3D;true&amp;application&#x3D;demo-provider&amp;bean.name&#x3D;com.alibaba.dubbo.demo.DemoService&amp;bind.ip&#x3D;10.1.14.50&amp;bind.port&#x3D;20880&amp;dubbo&#x3D;2.0.2&amp;generic&#x3D;false&amp;interface&#x3D;com.alibaba.dubbo.demo.DemoService&amp;methods&#x3D;sayHello&amp;owner&#x3D;gentryhuang&amp;pid&#x3D;3272&amp;qos.port&#x3D;22222&amp;side&#x3D;provider&amp;timestamp&#x3D;1583841600000 Dubbo URL 在服务订阅中的应用服务消费者在启动后会进行注册操作，此外还会向注册中心进行订阅操作，用于监听自己关注的 Provider、Configurator、Router，注册中心正是通过 Dubbo URL 来确定消费者需要关注的哪些路径。服务消费者订阅传入的 Dubbo URL 如下： 1consumer:&#x2F;&#x2F;192.168.21.50&#x2F;com.alibaba.dubbo.demo.DemoService?application&#x3D;demo-consumer&amp;category&#x3D;providers,configurators,routers&amp;&amp;interface&#x3D;com.alibaba.dubbo.demo.DemoService&amp;... 根据上面的 Dubbo URL 可知： protocol 为 consumer，表示是 Consumer 的订阅协议，如果 protocol 为 provider 则表示是 Provider 的订阅协议。category 参数表示要订阅的分类，Consumer 一般会订阅 providers、configurators 以及 routers 三个分类，Provider一般会订阅 configurators 分类。interface 参数表示订阅哪个服务接口，这里是 com.alibaba.dubbo.demo.DemoService。 订阅就是 ZookeeperRegistry 会将上面的 URL 解析成一个 Zookeeper 路径，然后调用 Zookeeper 客户端在该路径上添加监听器。 除了上面例举外，Dubbo URL 还用在很多地方，如进行服务治理时的动态配置、路由、黑白名单等。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/tags/RPC/"}]},{"title":"Dubbo源码环境","slug":"rpc/Dubbo源码环境搭建","date":"2020-03-08T16:00:00.000Z","updated":"2020-10-17T08:18:12.124Z","comments":false,"path":"posts/ba7cbd3a/","link":"","permalink":"https://gentryhuang.com/posts/ba7cbd3a/","excerpt":"","text":"前言上一篇文章中对 Dubbo 的整个项目结构进行了说明，本篇文章我们来进行源码搭建及核心模块说明。 Dubbo 架构 节点角色说明以下说明中注册中心以 Zookeeper 为例，不同的注册中心的注册和订阅是不同的。 Registry 注册中心注册中心负责服务地址的注册与查找，服务提供者和消费者只在启动时与注册中心交互（以客户端形式），注册中心不转发请求，压力较小。注册中心通过长连接感知服务提供者的存在，服务提供者宕机，注册中心将立即推送事件通知消费者。注册中心，服务提提供者，服务消费者三者之间均为长连接。 Provider 服务提供者启动的时候向注册中心进行注册操作，将自己的服务地址和相关配置信息封装成 Dubbo URL 添加到注册中心中。服务提供者无状态，任意一台宕机后不影响使用，全部宕机后服务消费者应用将无法使用。 Consumer 服务消费者启动的时候向注册中心进行注册和订阅操作，注册操作会将自己的服务地址和相关配置信息封装成 Dubbo URL 添加到注册中心中。订阅操作会从注册中心中获取服务提供者注册的URL，并在注册中心中添加相应的监听器。获取到服务提供者URL列表后，消费者会根据负载均衡算法从多个服务提供者中选择一个服务提供者并与其建立连接，最后对服务提供者发起远程调用。如果服务提供者 URL 发生变更，消费者将会通过之前订阅过程中在注册中心添加的监听器，获取到最新的服务提供者URL列表，然后更新服务目录。消费者与提供者建立的是长连接，且消费者会在本地缓存服务提供者列表，所以一旦连接建立，即使注册中心宕机，服务提供者和服务消费者仍能通过本地缓存通讯。 Monitor 监控中心 统计服务的调用次数和调用时间。服务提供者和服务消费者在运行过程中，会在内存中统计调用次数和调用时间，定时发送统计数据到监控中心。监控中心在架构图中不是必要角色，监控中心宕机只会丢失监控数据而已，其它的没有影响。 调用关系 服务容器负责启动，加载，运行服务提供者。 服务提供者在启动时，向注册中心注册自己提供的服务。 服务消费者在启动时，向注册中心注册自己的信息并订阅自己所需的服务。 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。 源码环境搭建 直接从官方仓库克隆源代码1https:&#x2F;&#x2F;github.com&#x2F;apache&#x2F;dubbo.git 切换分支，使用 Dubbo 2.6.5 版本1git checkout -b dubbo-2.6.5 dubbo-2.6.5 编译1mvn clean install -Dmaven.test.skip&#x3D;true Dubbo 源码核心模块说明编译完成后我们可以看到项目结构如下图所示： 下面我们简单介绍上图中的核心模块，每个模块的分析将在后面的文章中详细说明。 dubbo-common 模块 Dubbo 的一个公共模块，里面包含了动态编译相关实现、Dubbo SPI的核心实现、日志框架集成，线程池相关的工具类等。 dubbo-remoting 模块 Dubbo 的远程通信模块，其中的子模块依赖各种开源组件实现远程通信。dubbo-remoting-api 子模块中定义了远程通信的抽象概念，其它子模块依赖开源组件进行实现，如 dubbo-remoting-netty 子模块依赖 Netty 3 实现远程通信。 dubbo-rpc 模块 Dubbo 的远程调用协议模块，其中抽象了各种协议，依赖于远程通信模块的远程调用功能。dubbo-rpc-api 子模块中定义了调用协议的抽象，其它子模块是针对具体协议的实现，如 dubbo-rpc-dubbo 子模块是对 Dubbo 协议的实现，依赖了 dubbo-remoting 模块中的 Netty 等子模块。注意，dubbo-rpc 模块的实现中只包含一对一的调用，不关心集群的内容。 dubbo-cluster 模块 Dubbo 中负责管理集群的模块，提供了负载均衡、路由、容错等集群相关的功能。 dubbo-registry 模块 Dubbo 中负责与多种注册中心交互的模块，提供注册中心的能力。dubbo-registry-api 子模块是对注册中心的抽象，其它子模块是针对具体注册中心的实现，如 dubbo-registry-zookeeper 子模块是 Dubbo 接入 Zookeeper 的具体实现。 dubbo-config 模块 Dubbo 的配置信息是由该模块定义和解析的。dubbo-config-api 子模块负责处理 API 方式的相关配置，dubbo-config-spring 子模块负责处理与 Spring 集成方式的相关配置。有了配置模块，开发者只需要根据 Dubbo 的配置规则去实现功能即可，底层实现交给 Dubbo 的各个模块去完成。 dubbo-serialization 模块 Dubbo 的序列化模块，是 Dubbo 设计的最后一层，负责管理整个框架网络传输时的序列化和反序列化工作。 dubbo-serialization-api 子模块是对序列化和反序列抽象定义，包含了很多的接口，其它子模块针对具体的序列化方式进行实现，如 dubbo-serialization-fastjson 子模块是对 fastjson 的具体实现。 小结本篇文章简单介绍了 Dubbo 的核心架构及核心组件的功能，说明了搭建 Dubbo 源码环境步骤，最后介绍了 Dubbo 核心模块，为后续分析 Dubbo 源码做准备。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"}]},{"title":"Dubbo项目结构总览","slug":"rpc/dubbo项目结构总览","date":"2020-03-07T16:00:00.000Z","updated":"2020-10-17T05:29:32.637Z","comments":false,"path":"posts/e2577ca1/","link":"","permalink":"https://gentryhuang.com/posts/e2577ca1/","excerpt":"","text":"前言dubbo源码分析相关文章使用的dubbo版本为2.6.5，如使用其它版本会显示说明。参考文档以官方文档 为主【官网文档写的太好了】，参考书籍《深入理解Apache Dubbo与实战》。 框架设计由于dubbo官方文档写的非常好，这里会大量引用相关的图片及说明，点我 进入官方文档。 整体设计 图例说明： 图中左边淡蓝背景的为服务消费方使用的接口，右边淡绿色背景的为服务提供方使用的接口，位于中轴线上的为双方都用到的接口。 图中从下至上分为十层，各层均为单向依赖，右边的黑色箭头代表层之间的依赖关系，每一层都可以剥离上层被复用，其中，Service 和 Config 层为 API，其它各层均为 SPI。 图中绿色小块的为扩展接口，蓝色小块为实现类，图中只显示用于关联各层的实现类。 图中蓝色虚线为初始化过程，即启动时组装链，红色实线为方法调用过程，即运行时调时链，紫色三角箭头为继承，可以把子类看作父类的同一个节点，线上的文字为调用的方法。 总体分层从整体设计设计图可知悉，dubbo的总体分为业务层(Business)、RPC层、Remote三层，每一层细分共可分成十层。Service和Config两层可以认为是API层，主要提供给API使用者，使用者无须关心底层的实现，只需要配置和完成业务代码即可。其它八层合在一起可以认为是SPI层，用于扩展，即开放者可以基于SPI层自定义一些组件来完成具体业务，也可以基于dubbo框架做定制性的二次开发。 dubbo核心组件dubbo中每层都代表了不同的逻辑实现，它们是一个个组件，这些组件构成了整个dubbo体系。对于使用方来说更多接触到的是配置，按照dubbo配置规则选择适合当前业务的配置项即可轻松实现rpc调用。正是由于dubbo的各个组件职责分明的设计，才使得dubbo框架能够做到高扩展性。dubbo核心组件如下表： 分层名 作用 service 业务层：包括业务代码的接口与实现，即开发者实现的业务代码。 config 配置层：主要围绕ServiceConfig（服务提供方配置）和ReferenceConfig（服务消费方）展开，初始化配置信息。可以理解为该层管理了整个dubbo的配置 proxy 服务代理层：在dubbo中，无论提供者还是消费者，框架都会生成一个代理类，整个过程对上层是透明的。当调用一个远程接口时，看起来就像是调用了一个本地接口一样，代理层会自动做远程调用并返回结果，即让业务层对远程调用完全无感知 registry 注册中心层：负责dubbo框架的服务注册与发现。当有新的服务加入或旧服务下线时，注册中心都会感知并通知给所有订阅方 cluster 集群容错层：提供多种容错策略、封装多个提供者的路由及负载均衡，并桥接注册中心，以 Invoker 为中心，扩展接口为 Cluster, Directory, Router, LoadBalance以及Mock monitor 监控层：RPC 调用次数和调用时间监控等 protocol 远程调用层：封装RPC调用具体过程，以 Invocation, Result 为中心，是 Invoker 暴露和引用的主功能入口，它负责 Invoker 的生命周期管理。 exchange 信息交换层：建立Request-Response模型，封装请求响应模式，以 Request, Response 为中心 transport 网络传输层：把网络传输抽象为统一接口，以 Message 为中心，如Mina和Netty虽然接口不一样，但是Dubbo在它们上面封装了统一的接口。用户可以根据其扩展接口添加更多的网络传输方式。 serialize 序列化层：如果数据要通过网络进行传输，则需要先做序列化，转成二进制流。序列化层负责管理整个框架网络传输时的序列化和反序列化工作 关系说明 在 RPC 中，Protocol 是核心层，也就是只要有 Protocol + Invoker + Exporter 就可以完成非透明的 RPC 调用，然后在 Invoker 的主过程上 Filter 拦截点。 图中的 Consumer 和 Provider 是抽象概念，只是想让看图者更直观的了解哪些类分属于客户端与服务器端，不用 Client 和 Server 的原因是 Dubbo 在很多场景下都使用 Provider, Consumer, Registry, Monitor 划分逻辑拓普节点，保持统一概念。 而 Cluster 是外围概念，所以 Cluster 的目的是将多个 Invoker 伪装成一个 Invoker，这样其它人只要关注 Protocol 层 Invoker 即可，加上 Cluster 或者去掉 Cluster 对其它层都不会造成影响，因为只有一个提供者时，是不需要 Cluster 的。 Proxy 层封装了所有接口的透明化代理，而在其它层都以 Invoker 为中心，只有到了暴露给用户使用时，才用 Proxy 将 Invoker 转成接口，或将接口实现转成 Invoker，也就是去掉 Proxy 层 RPC 是可以 Run 的，只是不那么透明，不那么看起来像调本地服务一样调远程服务。 而Remoting 实现是 Dubbo 协议的实现，如果你选择 RMI 协议，整个 Remoting 都不会用上，Remoting 内部再划为 Transport 传输层和 Exchange 信息交换层，Transport 层只负责单向消息传输，是对 Mina, Netty, Grizzly 的抽象，它也可以扩展 UDP 传输，而 Exchange 层是在传输层之上封装了 Request-Response 语义。 Registry 和 Monitor 实际上不算一层，而是一个独立的节点，只是为了全局概览，用层的方式画在一起。 领域模型 Protocol 是服务域，它是 Invoker 暴露和引用的主功能入口，它负责 Invoker 的生命周期管理。 Invoker 是实体域，它是 Dubbo 的核心模型，其它模型都向它靠扰，或转换成它，它代表一个可执行体，可向它发起 invoke 调用，它有可能是一个本地的实现，也可能是一个远程的实现，也可能一个集群实现。 Invocation 是会话域，它持有调用过程中的变量，比如方法名，参数等。 特别说明: protocol是对数据格式的一种约定，它可以把我们对接口的配置，根据具体的协议转换成不同的Invoker对象。 基本设计原则 Dubbo 自身的功能也是通过扩展点实现的，也就是 Dubbo 的所有功能点都可被用户自定义扩展所替换 采用 URL 作为配置信息的统一格式，所有扩展点都通过传递 URL 携带配置信息 源码分析范围除了架构图中的Monitor模块不会详细分析，其它都会详细分析。 小结本文主要简单介绍了dubbo的总体架构图和核心组件，这样在阅读源码之前有整体的概念。更详细的介绍可以参考官网文档。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/tags/RPC/"}]},{"title":"Dubbo示例 - 注解配置","slug":"rpc/Dubbo第三例","date":"2020-03-05T16:00:00.000Z","updated":"2020-09-01T12:12:42.307Z","comments":false,"path":"posts/7202a9c0/","link":"","permalink":"https://gentryhuang.com/posts/7202a9c0/","excerpt":"","text":"快速启动使用注解的方式进行配置 定义服务接口12345678910package com.alibaba.dubbo.examples.annotation.api;/** * AnnotationService */public interface AnnotationService &#123; String sayHello(String name);&#125; 服务提供方123456789101112131415161718package com.alibaba.dubbo.examples.annotation.impl;import com.alibaba.dubbo.config.annotation.Service;import com.alibaba.dubbo.examples.annotation.api.AnnotationService;/** * AnnotationServiceImpl，注意，这里 @Service 注解是Dubbo的注解，用来进行服务暴露的 */@Servicepublic class AnnotationServiceImpl implements AnnotationService &#123; @Override public String sayHello(String name) &#123; System.out.println(\"async provider received: \" + name); return \"annotation: hello, \" + name; &#125;&#125; 服务提供方属性配置12345# dubbo-provider.propertiesdubbo.application.name&#x3D;annotation-providerdubbo.registry.address&#x3D;zookeeper:&#x2F;&#x2F;127.0.0.1:2181dubbo.protocol.name&#x3D;dubbodubbo.protocol.port&#x3D;20880 说明: 使用dubbo注解形式一般结合属性配置，用来配置应用共享的配置项。 指定扫描路径，启动容器并暴露服务12345678910111213141516171819202122232425262728293031323334353637383940package com.alibaba.dubbo.examples.annotation;import com.alibaba.dubbo.config.ProviderConfig;import com.alibaba.dubbo.config.spring.context.annotation.EnableDubbo;import org.springframework.context.annotation.AnnotationConfigApplicationContext;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.PropertySource;/** * AnnotationProvider * * Java Config + 注解的方式 */public class AnnotationProvider &#123; public static void main(String[] args) throws Exception &#123; AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(ProviderConfiguration.class); context.start(); System.in.read(); &#125; @Configuration @EnableDubbo(scanBasePackages = \"com.alibaba.dubbo.examples.annotation.impl\") @PropertySource(\"classpath:/com/alibaba/dubbo/examples/annotation/dubbo-provider.properties\") static public class ProviderConfiguration &#123; /** * 这里通过Java Config显示组装出Bean，会注入给Dubbo服务，即标注有@Service的类。如果不显示装配，Dubbo会默认创建内置的配置类定义，创建内置的配置类定义的前提是配置了相关的属性，否则不会创建。其他配置类似。 */ @Bean public ProviderConfig providerConfig() &#123; ProviderConfig providerConfig = new ProviderConfig(); providerConfig.setTimeout(5000); return providerConfig; &#125; &#125;&#125; 服务消费方123456789101112131415161718192021package com.alibaba.dubbo.examples.annotation.action;import com.alibaba.dubbo.config.annotation.Reference;import com.alibaba.dubbo.examples.annotation.api.AnnotationService;import org.springframework.stereotype.Component;/** * AnnotationAction，注意，@Reference注解用来引用服务 */@Component(\"annotationAction\")public class AnnotationAction &#123; @Reference private AnnotationService annotationService; public String doSayHello(String name) &#123; return annotationService.sayHello(name); &#125;&#125; 服务消费方属性配置1234# dubbo-consumer.propertiesdubbo.application.name&#x3D;annotation-consumerdubbo.registry.address&#x3D;zookeeper:&#x2F;&#x2F;127.0.0.1:2181dubbo.consumer.timeout&#x3D;3000 说明: 使用dubbo注解形式一般结合属性配置，用来配置应用共享的配置项。 扫描路径，启动容器并调用服务123456789101112131415161718192021222324252627282930313233343536373839404142package com.alibaba.dubbo.examples.annotation;import com.alibaba.dubbo.config.spring.context.annotation.EnableDubbo;import com.alibaba.dubbo.examples.annotation.action.AnnotationAction;import org.springframework.context.annotation.AnnotationConfigApplicationContext;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.PropertySource;/** * AnnotationConsumer */public class AnnotationConsumer &#123; public static void main(String[] args) throws Exception &#123; AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(ConsumerConfiguration.class); context.start(); final AnnotationAction annotationAction = (AnnotationAction) context.getBean(\"annotationAction\"); String hello = annotationAction.doSayHello(\"world\"); System.out.println(\"result :\" + hello); System.in.read(); &#125; @Configuration @EnableDubbo(scanBasePackages = \"com.alibaba.dubbo.examples.annotation.action\") @PropertySource(\"classpath:/com/alibaba/dubbo/examples/annotation/dubbo-consumer.properties\") @ComponentScan(value = &#123;\"com.alibaba.dubbo.examples.annotation.action\"&#125;) static public class ConsumerConfiguration &#123; /** * 这里通过Java Config显示组装出Bean，会注入给Dubbo服务，即标注有@Reference的类。如果不显示装配，Dubbo会默认创建内置的配置类定义，创建内置的配置类定义的前提是配置了相关的属性，否则不会创建。其他配置类似。 */ @Bean public ConsumerConfig consumerConfig() &#123; ConsumerConfig consumerConfig = new ConsumerConfig(); consumerConfig.setTimeout(3000); return consumerConfig; &#125; &#125;&#125; 小结注解实现使代码更整洁，开发效率更高，随着注解和配置化的盛行，xml的方式会渐渐地淡出舞台。但使用注解对开放者的要求更高，具体的dubbo注解如何与Spring融合，在后面的章节中会进行说明。使用注解的方式，配置对象的创建及配置对象属性设置也都是Spring完成的，注意这里Spring完成配置属性地设置是指启动加载的配置属性，如上面例子中的@PropertySource注解引入的配置文件内容，此外@Service、@Reference注解中的属性Spring会自动绑定到配置对象中，至于系统参数、dubbo.properties中的配置参数等是dubbo框架自动加载并配置的，我们可在服务暴露和服务引用中看到具体的过程。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/tags/RPC/"}]},{"title":"Dubbo示例 - XML配置","slug":"rpc/Dubbo第二例","date":"2020-03-03T16:00:00.000Z","updated":"2020-08-15T15:30:22.534Z","comments":false,"path":"posts/3f1c0a92/","link":"","permalink":"https://gentryhuang.com/posts/3f1c0a92/","excerpt":"","text":"快速启动使用xml的方式进行配置，详细配置项：配置参考手册 定义服务接口12345package com.alibaba.dubbo.demo;public interface DemoService &#123; String sayHello(String name);&#125; 服务提供方实现接口12345678910111213141516package com.alibaba.dubbo.demo.provider;import com.alibaba.dubbo.demo.DemoService;import com.alibaba.dubbo.rpc.RpcContext;import java.text.SimpleDateFormat;import java.util.Date;public class DemoServiceImpl implements DemoService &#123; @Override public String sayHello(String name) &#123; System.out.println(\"[\" + new SimpleDateFormat(\"HH:mm:ss\").format(new Date()) + \"] Hello \" + name + \", request from consumer: \" + RpcContext.getContext().getRemoteAddress()); return \"Hello \" + name + \", response from provider: \" + RpcContext.getContext().getLocalAddress(); &#125;&#125; 服务提供方服务暴露配置1234567891011121314151617181920212223&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://dubbo.apache.org/schema/dubbo\" xmlns=\"http://www.springframework.org/schema/beans\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.3.xsd http://dubbo.apache.org/schema/dubbo http://dubbo.apache.org/schema/dubbo/dubbo.xsd\"&gt; &lt;!-- 提供方应用信息，用于计算依赖关系 --&gt; &lt;dubbo:application name=\"demo-provider\" owner=\"gentryhuang\"/&gt; &lt;!-- 使用zookeeper注册中心暴露服务地址 --&gt; &lt;dubbo:registry address=\"zookeeper://127.0.0.1:2181\"/&gt; &lt;!-- 用dubbo协议在20880端口暴露服务 --&gt; &lt;dubbo:protocol name=\"dubbo\" port=\"20880\"/&gt; &lt;!-- 声明需要暴露的服务接口 --&gt; &lt;bean id=\"demoService\" class=\"com.alibaba.dubbo.demo.provider.DemoServiceImpl\"/&gt; &lt;!-- 和本地bean一样实现服务 --&gt; &lt;dubbo:service interface=\"com.alibaba.dubbo.demo.DemoService\" ref=\"demoService\"/&gt;&lt;/beans&gt; 启动Spring容器，进行服务暴露12345678910111213package com.alibaba.dubbo.demo.provider;import org.springframework.context.support.ClassPathXmlApplicationContext;public class Provider &#123; public static void main(String[] args) throws Exception &#123; ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(new String[]&#123;\"META-INF/spring/dubbo-demo-provider.xml\"&#125;); context.start(); System.in.read(); // press any key to exit &#125;&#125; 服务消费者引用服务配置1234567891011121314151617&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://dubbo.apache.org/schema/dubbo\" xmlns=\"http://www.springframework.org/schema/beans\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.3.xsd http://dubbo.apache.org/schema/dubbo http://dubbo.apache.org/schema/dubbo/dubbo.xsd\"&gt; &lt;!-- 消费方应用名，用于计算依赖关系，不是匹配条件，不要与提供方一样 --&gt; &lt;dubbo:application name=\"demo-consumer\"/&gt; &lt;!-- 使用zookeeper注册中心暴露发现服务地址 --&gt; &lt;dubbo:registry address=\"zookeeper://127.0.0.1:2181\"/&gt; &lt;!-- 生成远程服务代理，可以和本地bean一样使用demoService --&gt; &lt;dubbo:reference id=\"demoService\" check=\"false\" interface=\"com.alibaba.dubbo.demo.DemoService\"/&gt;&lt;/beans&gt; 加载Spring配置，并调用远程服务123456789101112131415161718192021222324package com.alibaba.dubbo.demo.consumer;import com.alibaba.dubbo.demo.DemoService;import org.springframework.context.support.ClassPathXmlApplicationContext;public class Consumer &#123; public static void main(String[] args) &#123; ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(new String[]&#123;\"META-INF/spring/dubbo-demo-consumer.xml\"&#125;); context.start(); DemoService demoService = (DemoService) context.getBean(\"demoService\"); // get remote service proxy while (true) &#123; try &#123; Thread.sleep(5000); String hello = demoService.sayHello(\"world\"); // call remote method System.out.println(hello); // get result &#125; catch (Throwable throwable) &#123; throwable.printStackTrace(); &#125; &#125; &#125;&#125; 小结dubbo自定义了很多的xml标签，这些标签就对应了API配置中的配置对象，标签的属性就对应配置对象的属性，API的方式是手动创建配置对象并设置属性值，xml的方式是创建配置对象和设置属性值都交给Spring来完成，注意DubboBeanDefinitionParser设置的属性值不包括系统参数、dubbo.properties等，而是xml中配置对象的属性。这些标签是怎么和pring融合的在spring自定义标签中已经介绍了实现原理，在后面的dubbo配置解析中会继续说明。更多的配置请参考：配置参考手册。下一篇文章中我们介绍使用注解的方式进行配置,这种方式更简洁，效率更高。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/tags/RPC/"}]},{"title":"Dubbo示例 - API配置","slug":"rpc/Dubbo第一例","date":"2020-03-02T16:00:00.000Z","updated":"2020-08-15T08:43:51.063Z","comments":false,"path":"posts/f0ae64a/","link":"","permalink":"https://gentryhuang.com/posts/f0ae64a/","excerpt":"","text":"快速启动使用API的方式进行启动、调用。API 属性与配置项一对一，各属性含义，请参见：配置参考手册，比如：ApplicationConfig.setName(“xxx”) 对应 &lt;dubbo:application name=”xxx” /&gt; 定义服务接口1234567891011121314151617package com.code.resorce.api;/** * DemoService * * @author shunhua * @since 2020/03/03 * &lt;p&gt; * desc： */public interface DemoService &#123; /** * @return */ String hello();&#125; 服务提供方实现接口123456789101112131415161718package com.code.resource.reading.api;import com.code.resorce.api.DemoService;/** * DemoServiceImpl * * @author shunhua * @since 2020/03/03 * &lt;p&gt; * desc： */public class DemoServiceImpl implements DemoService &#123; @Override public String hello() &#123; return \"hello world\"; &#125;&#125; 使用API配置声明暴露服务123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * ApiProvider * * @author shunhua * @since 2020/03/03 * &lt;p&gt; * desc： */public class ApiProvider &#123; public static void main(String[] args) throws IOException &#123; // 服务对象 DemoService demoService = new DemoServiceImpl(); // 应用配置 ApplicationConfig applicationConfig = new ApplicationConfig(); applicationConfig.setName(\"api-config-demo-provider\"); // 连接注册中心配置 RegistryConfig registryConfig = new RegistryConfig(); registryConfig.setAddress(\"zookeeper://127.0.0.1:2181\"); // 服务提供者协议配置 ProtocolConfig protocolConfig = new ProtocolConfig(); protocolConfig.setName(\"dubbo\"); protocolConfig.setPort(20880); //省略ServiceConfig的其它配置项，如Module、Provider、Monitor等 // 服务提供者暴露服务配置，注意：ServiceConfig为重对象，内部封装了与注册中心的连接，以及开启服务端口，请自行缓存，否则可能造成内存和连接泄漏 ServiceConfig&lt;DemoService&gt; serviceConfig = new ServiceConfig&lt;DemoService&gt;(); serviceConfig.setApplication(applicationConfig); serviceConfig.setRegistry(registryConfig); serviceConfig.setProtocol(protocolConfig); serviceConfig.setInterface(DemoService.class); serviceConfig.setRef(demoService); // 暴露及注册服务 serviceConfig.export(); // 阻主线程，防止服务关闭，用于消费者的调用 System.in.read(); &#125;&#125; 使用API配置服务引用123456789101112131415161718192021222324252627282930313233343536373839/** * ApiConsumer * * @author shunhua * @since 2020/03/03 * &lt;p&gt; * desc： */public class ApiConsumer &#123; public static void main(String[] args) throws InterruptedException &#123; // 当前应用配置 ApplicationConfig applicationConfig = new ApplicationConfig(); applicationConfig.setName(\"api-config-demo-provider\"); // 连接注册中心配置 RegistryConfig registryConfig = new RegistryConfig(); registryConfig.setAddress(\"zookeeper://127.0.0.1:2181\"); // 省略ReferenceConfig的其它配置项，如 Module、Consumer、Monitor等 // 引用远程服务，注意：ReferenceConfig为重对象，内部封装了与注册中心的连接，以及与服务提供方的连接，请自行缓存，否则可能造成内存和连接泄漏 ReferenceConfig&lt;DemoService&gt; referenceConfig = new ReferenceConfig&lt;DemoService&gt;(); referenceConfig.setApplication(applicationConfig); referenceConfig.setRegistry(registryConfig); referenceConfig.setInterface(DemoService.class); // 获取代理对象 DemoService demoService = referenceConfig.get(); while (true) &#123; String ping = demoService.sayHello(\"ping\"); System.out.println(ping); Thread.sleep(3000); &#125; &#125;&#125; 小结使用API硬编码的方式简单、直观，无需关注其它细节（如不需要关心和Spring整合的细节），让使用者更容器理解dubbo的各个组件及其之间的联系，编写服务提供者与消费者更加容易。默认情况下dubbo框架只需要依赖Netty通信框架就可以实现RPC调用，注册中心也可以不需要，即只要有服务提供者、服务消费者 以及 架起消费者连接到提供者的通信桥梁即可实现一个完整的RPC调用。 虽然使用API的方式简单易懂，但是对于应用、服务的管理就需要很大的成本，对于每个应用、服务都需编写大量重复的代码，并且是硬编码，显然是不合理的。Spring本身的一大特性就是依赖管理，而我们这些API中的配置承载对象完全可以交给Spring来管理，这样就实现了配置化，虽然引入了Spring这个第三方框架，但是是非常合理的，毕竟Spring是主流。下一篇文章我们使用Spring的xml配置方式实现RPC调用。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/tags/RPC/"}]},{"title":"Spring自定义标签","slug":"rpc/Spring自定义标签","date":"2020-03-01T16:00:00.000Z","updated":"2020-09-03T01:33:46.285Z","comments":false,"path":"posts/eee3e639/","link":"","permalink":"https://gentryhuang.com/posts/eee3e639/","excerpt":"","text":"spring自定义标签Spring除了很多内置的xml标签外，还支持自定义xml标签，开发者只需要按照Spring的约定规则就可以实现自定义标签，这样开发者就可以把自定义的Bean交给Spring管理。自定义标签包结构如下： 自定义标签的规则编写模型1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.code.resource.reading.xml.schema.model;/** * Hero * * @author shunhua * @since 2020/03/02 * &lt;p&gt; * desc： */public class Hero &#123; /** * name */ private String name; /** * age */ private int age; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; @Override public String toString() &#123; return \"Hero&#123;\" + \"name='\" + name + '\\'' + \", age=\" + age + '&#125;'; &#125;&#125; 定义模型的xsd文件12345678910111213141516171819202122232425262728293031&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;xsd:schema xmlns=\"http://gentryhuang.site/schema/people\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" targetNamespace=\"http://gentryhuang.com/schema/people\"&gt; &lt;!-- 定义元素的复杂类型 --&gt; &lt;xsd:complexType name=\"elementComplexType\"&gt; &lt;!-- 定义模型类中的属性 --&gt; &lt;xsd:attribute name=\"name\" type=\"xsd:string\"&gt; &lt;xsd:annotation&gt; &lt;xsd:documentation&gt;&lt;![CDATA[ The element name. ]]&gt;&lt;/xsd:documentation&gt; &lt;/xsd:annotation&gt; &lt;/xsd:attribute&gt; &lt;xsd:attribute name=\"age\" type=\"xsd:int\"&gt; &lt;xsd:annotation&gt; &lt;xsd:documentation&gt;&lt;![CDATA[ The element age. ]]&gt;&lt;/xsd:documentation&gt; &lt;/xsd:annotation&gt; &lt;/xsd:attribute&gt; &lt;/xsd:complexType&gt; &lt;!-- 定义在xml文件中用到的元素名称 --&gt; &lt;xsd:element name=\"hero\" type=\"elementComplexType\"&gt; &lt;xsd:annotation&gt; &lt;xsd:documentation&gt;&lt;![CDATA[ 定义标签 ]]&gt;&lt;/xsd:documentation&gt; &lt;/xsd:annotation&gt; &lt;/xsd:element&gt;&lt;/xsd:schema&gt; 说明: 该文件要放在 resources的META-INF目录下。该文件是用来约束使用xml配置时的标签和对应的属性。 编写spring.schemas文件1http\\:&#x2F;&#x2F;gentryhuang.com&#x2F;schema&#x2F;people&#x2F;hero.xsd&#x3D;META-INF&#x2F;hero.xsd 说明: http://gentryhuang.com/schema/people 就是模型对应的xsd中的targetNamespace的值，它指定了约束文件的具体路径。 编写BeanDefinitionParser12345678910111213141516171819202122232425262728293031323334353637383940414243package com.code.resource.reading.xml.schema;import org.springframework.beans.factory.config.BeanDefinition;import org.springframework.beans.factory.support.BeanDefinitionRegistry;import org.springframework.beans.factory.support.RootBeanDefinition;import org.springframework.beans.factory.xml.BeanDefinitionParser;import org.springframework.beans.factory.xml.ParserContext;import org.w3c.dom.Element;/** * HeroBeanDefinitionParser * * @author shunhua * @since 2020/03/02 * &lt;p&gt; * desc： */public class HeroBeanDefinitionParser implements BeanDefinitionParser &#123; /** * 标签对应的类 */ private final Class&lt;?&gt; beanClass; public HeroBeanDefinitionParser(Class&lt;?&gt; beanClass) &#123; this.beanClass = beanClass; &#125; @Override public BeanDefinition parse(Element element, ParserContext parserContext) &#123; RootBeanDefinition beanDefinition = new RootBeanDefinition(); beanDefinition.setBeanClass(beanClass); beanDefinition.setLazyInit(false); beanDefinition.getPropertyValues().add(\"name\",element.getAttribute(\"name\")); beanDefinition.getPropertyValues().add(\"age\",element.getAttribute(\"age\")); // 获取Bean定义注册表 BeanDefinitionRegistry registry = parserContext.getRegistry(); // 注册Bean registry.registerBeanDefinition(\"hero\",beanDefinition); return beanDefinition; &#125;&#125; 说明: 用来解析自定义的xml标签 编写命名空间处理器123456789101112131415161718192021222324package com.code.resource.reading.xml.schema;import com.code.resource.reading.xml.schema.model.Hero;import org.springframework.beans.factory.xml.NamespaceHandlerSupport;/** * HeroNamespaceHandler * * @author shunhua * @since 2020/03/02 * &lt;p&gt; * desc： */public class HeroNamespaceHandler extends NamespaceHandlerSupport &#123; /** * 定义了&lt;xsd:element/&gt;对应的BeanDefinitionParser */ @Override public void init() &#123; registerBeanDefinitionParser(\"hero\",new HeroBeanDefinitionParser(Hero.class)); &#125;&#125; 说明:一般情况下 一个&lt;xsd:element/&gt; 对应一个BeanDefinitionParser 编写spring.handlers文件1http\\:&#x2F;&#x2F;gentryhuang.com&#x2F;schema&#x2F;people&#x3D;com.code.resource.reading.xml.schema.HeroNamespaceHandler 说明: 这是一个键值对，key是xsd文件中的 targetNamespace，该文件指明了使用哪个类来解析自定义的标签。 使用spring的自定义标签12345678910111213141516&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:people=\"http://gentryhuang.com/schema/people\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://gentryhuang.com/schema/people http://gentryhuang.com/schema/people/hero.xsd\"&gt; &lt;!-- 1 xmlns:people的值是xsd文件中的targetNamespace 2 xmlns:hero 可以写成xmlns:xxx,此时标签前缀也要是 &lt;xxx:hero/&gt; --&gt; &lt;people:hero name=\"hlb\" age=\"18\"/&gt;&lt;/beans&gt; 测试123456789101112131415161718192021package com.code.resource.reading.xml.schema;import com.code.resource.reading.xml.schema.model.Hero;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;/** * Client * * @author shunhua * @since 2020/03/02 * &lt;p&gt; * desc： */public class Client &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"hero.xml\"); Hero hero = (Hero) applicationContext.getBean(\"hero\"); System.out.println(hero); &#125;&#125; 小结spring在解析到自定义的namespace标签时，比如 &lt;people:hero /&gt;，会查找对应的spring.schemas和spring.handlers文件，通过spring.schemas文件确定需要加载的标签及属性，然后会触发spring.handlers文件中指定的类来进行初始化和解析。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/tags/RPC/"},{"name":"Spring","slug":"Spring","permalink":"https://gentryhuang.com/tags/Spring/"}]},{"title":"初识RPC","slug":"rpc/初识RPC","date":"2020-02-29T16:00:00.000Z","updated":"2021-03-09T09:08:49.501Z","comments":false,"path":"posts/626d9676/","link":"","permalink":"https://gentryhuang.com/posts/626d9676/","excerpt":"","text":"基本概念RPC（Remote Procedure Call）远程过程调用，简单来说就是一个节点请求另一个节点提供的服务，像本地方法调用一样调用远程的服务。详细说明：请求方没有服务实现的细节，执行目标行为还是服务提供的节点。请求服务的节点和服务提供的节点以某种方式进行通信，请求方把行为及行为参数传递给服务提供方，服务提供方会根据请求方传递的数据找到对应的服务实现然后执行目标行为，最后再把执行结果返回给请求方。 本地过程调用发起请求和响应结果都在同一个服务节点上，在Java中就是同一个JVM中的方法调用过程。 远程过程调用请求的发起者和请求的处理者不在同一个节点上，它们之间需要进行网络通信才能完成请求和响应。 简单RPC实现说明: 例子是使用梁飞大佬的 技术博客 中的案例 服务接口及实现12345678910111213141516171819202122232425262728293031package com.alibaba.study.rpc.service;/** * HelloService */public interface HelloService &#123; /** * 服务方法 * * @param name * @return */ String hello(String name);&#125;---package com.alibaba.study.rpc.service.impl;import com.alibaba.study.rpc.service.HelloService;/** * HelloServiceImpl */public class HelloServiceImpl implements HelloService &#123; @Override public String hello(String name) &#123; return \"Hello \" + name; &#125;&#125; RPC框架123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177package com.alibaba.study.rpc.framework;import java.io.ObjectInputStream;import java.io.ObjectOutputStream;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.net.ServerSocket;import java.net.Socket;/** * RpcFramework */public class RpcFramework &#123; /** * 暴露服务 * * @param service 服务实现 * @param port 服务端口 * @throws Exception */ public static void export(final Object service, int port) throws Exception &#123; if (service == null) &#123; throw new IllegalArgumentException(\"service instance == null\"); &#125; if (port &lt;= 0 || port &gt; 65535) &#123; throw new IllegalArgumentException(\"Invalid port \" + port); &#125; System.out.println(\"Export service \" + service.getClass().getName() + \" on port \" + port); // 以指定端口创建ServerSocket ServerSocket server = new ServerSocket(port); for (; ; ) &#123; try &#123; // 等待接收请求 final Socket socket = server.accept(); new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; try &#123; // 获取请求的数据流 ObjectInputStream input = new ObjectInputStream(socket.getInputStream()); try &#123; // 获取客户端请求的方法名 String methodName = input.readUTF(); // 获取客户端请求的参数类型列表 Class&lt;?&gt;[] parameterTypes = (Class&lt;?&gt;[]) input.readObject(); // 获取客户端请求的参数列表 Object[] arguments = (Object[]) input.readObject(); // 创建对象输出流对象，用于响应结果给客户端 ObjectOutputStream output = new ObjectOutputStream(socket.getOutputStream()); try &#123; // 通过反射，获取服务接口指定的方法 Method method = service.getClass().getMethod(methodName, parameterTypes); // 反射调用 Object result = method.invoke(service, arguments); // 将结果响应给客户端 output.writeObject(result); &#125; catch (Throwable t) &#123; output.writeObject(t); &#125; finally &#123; output.close(); &#125; &#125; finally &#123; input.close(); &#125; &#125; finally &#123; socket.close(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; /** * 引用服务 * * @param &lt;T&gt; 接口泛型 * @param interfaceClass 接口类型 * @param host 服务器主机名 * @param port 服务器端口 * @return 远程服务 * @throws Exception */ @SuppressWarnings(\"unchecked\") public static &lt;T&gt; T refer(final Class&lt;T&gt; interfaceClass, final String host, final int port) throws Exception &#123; if (interfaceClass == null) &#123; throw new IllegalArgumentException(\"Interface class == null\"); &#125; if (!interfaceClass.isInterface()) &#123; throw new IllegalArgumentException(\"The \" + interfaceClass.getName() + \" must be interface class!\"); &#125; if (host == null || host.length() == 0) &#123; throw new IllegalArgumentException(\"Host == null!\"); &#125; if (port &lt;= 0 || port &gt; 65535) &#123; throw new IllegalArgumentException(\"Invalid port \" + port); &#125; System.out.println(\"Get remote service \" + interfaceClass.getName() + \" from server \" + host + \":\" + port); /** * 使用JDK的动态代理创建接口的代理对象 * 说明： * 在 InvocationHandler#invoke方法内部实现Socket与ServerSocket的通信。当使用代理对象调用方法时，内部使用Socket进行通信，然后把通信的结果返回。 */ return (T) Proxy.newProxyInstance( interfaceClass.getClassLoader(), new Class&lt;?&gt;[]&#123;interfaceClass&#125;, new InvocationHandler() &#123; @Override public Object invoke(Object proxy, Method method, Object[] arguments) throws Throwable &#123; // 创建Socket，用于连接ServerSocket Socket socket = new Socket(host, port); try &#123; // 创建用于发送数据到ServerSocket的输出流 ObjectOutputStream output = new ObjectOutputStream(socket.getOutputStream()); try &#123; //--------------------- 数据契约 ----------------------------/ // 方法名 output.writeUTF(method.getName()); // 参数类型 output.writeObject(method.getParameterTypes()); // 参数值 output.writeObject(arguments); //------------------------ 数据契约 --------------------------/ // 创建用于接收ServerSocket的输入流 ObjectInputStream input = new ObjectInputStream(socket.getInputStream()); try &#123; // 读取ServerSocket响应的数据 Object result = input.readObject(); if (result instanceof Throwable) &#123; throw (Throwable) result; &#125; // 返回结果 return result; &#125; finally &#123; input.close(); &#125; &#125; finally &#123; output.close(); &#125; &#125; finally &#123; socket.close(); &#125; &#125; &#125;); &#125;&#125; 服务暴露1234567891011121314151617package com.alibaba.study.rpc.provider;import com.alibaba.study.rpc.framework.RpcFramework;import com.alibaba.study.rpc.service.HelloService;import com.alibaba.study.rpc.service.impl.HelloServiceImpl;/** * RpcProvider */public class RpcProvider &#123; public static void main(String[] args) throws Exception &#123; // 服务实现 HelloService service = new HelloServiceImpl(); // 暴露服务 RpcFramework.export(service, 1234); &#125;&#125; 引用服务1234567891011121314151617181920package com.alibaba.study.rpc.consumer;import com.alibaba.study.rpc.framework.RpcFramework;import com.alibaba.study.rpc.service.HelloService;/** * RpcConsumer */public class RpcConsumer &#123; public static void main(String[] args) throws Exception &#123; // 引用服务【代理对象】 HelloService service = RpcFramework.refer(HelloService.class, \"127.0.0.1\", 1234); while (true) &#123; String hello = service.hello(\"World\"); System.out.println(hello); Thread.sleep(1000); &#125; &#125;&#125; 小结这个例子中，通信是使用同步阻塞的Socket来实现的，采用端对端的方式。远程调用使用的是JDK的动态代理，在invoke方法中实现网络通信。参数序列化使用的是JDK的ObjectStream。一个完善的RPC框架其实就是在这例子的基础上进行多方位扩展和改进。比如，网络通信可以使用性能更好的NIO框架Netty，动态代理可以使用javaassist字节码生成方式[注意：不是javaassist提供的动态代理接口，该接口比JDK自带的还慢]，序列化方式可以采用fastjson、hession2以及kryo等技术。如果服务数量达到一定规模，可以引进注册中心进行服务的治理。节点间的通信方式可以有多种，因此可以扩展多协议。除此之外，性能和健壮性也是一个优秀的RPC框架所必须的，如集群容错、负载均衡、重试机制、服务降级…这些都会在后面分析的Dubbo框架中得到很好的体现。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/tags/RPC/"}]},{"title":"CAP理论","slug":"architecture/CAP理论","date":"2019-10-12T13:03:22.000Z","updated":"2021-05-27T12:39:11.852Z","comments":false,"path":"posts/6940af88/","link":"","permalink":"https://gentryhuang.com/posts/6940af88/","excerpt":"","text":"概述分布式系统中在可用性和一致性之间没有一个完美的方案，如何构建一个兼容可用性和一致性的分布式系统成为了一个非常棘手的问题。基于此，出现了诸如 CAP 和 BASE 这样的分布式理论和算法。本篇文章将对 CAP 理论进行介绍。 CAP 定理CAP 理论对分布式系统的特性做了高度抽象，抽象成了一致性、可用性和分区容错性，并且证明一个分布式系统不可能同时满足这三个特性，最多只能同时满足其中的两项。 基本特性一致性（Consistency）在分布式环境中，一致性是指数据在多个副本节点之间是否能够保持一致的特性。当一个系统在数据一致性的状态下执行更新操作后，应该保证系统的数据仍然处于一致的状态。如果能够做到针对一个数据项的更新操作成功后，客户端不管访问哪个节点都能读取到最新的数据，那么该系统就被认为具有强一致性。一致性强调的是数据的正确性。 可用性（Availability）可用性是指系统提供的服务必须一直处于可用的状态，对于客户端的每个操作请求总是能够在有限的时间内给出响应。其中，有限时间内一般是一个在系统设计之初就设定好的系统运行指标，通常不同的系统之间会有很大的不同，如果超过设定的响应时间范围，那么系统就被认为是不可用的。可用性强调的是服务可用，但不保证数据正确。 分区容错性（Partition Tolerance）网络分区是指在分布式系统中，不同的服务节点分布在不同的子网（机房/异地网络）中，如果这些子网之间出现网络不连通的状况，但各个子网内部网络是正常的，这样整个系统的网络环境就被分割成了若干个孤立的区。注意，组成一个分布式系统的每个服务节点的加入与退出都可以看作是一个特殊的网络分区。 分区容错性要求：在分布式系统遇到任何网络分区故障时，仍然需要能够保证对外提供服务，除非是整个网络环境发生了故障。分区容错性强调的是对分区故障的容错能力。 必要特性对于一个分布式系统而言，分区容错性是最基本的要求，因为既然是一个分布式系统，那么系统中的组件必然需要被部署到不同的节点，否则也就无所谓分布式系统了。而对分布式系统来说，网络问题又是一个必定会出现的异常情况，因此网络分区也就成为了一个分布式系统必然要解决的问题。 一致性和可用性的矛盾分区容错无法避免，因此可以认为 CAP 中的分区容错性（P）总是成立，同时 CAP 告诉我们，剩下的一致性（C）和可用性（A）无法同时满足，因为可能出现网络分区。这也是 CAP 不能同时满足 3 个特性的主要原因，具体证明可以参考相关论文。 如何使用 CAP通过前文我们知道，分区容错性（P）是分布式系统最基本的保证，因为存在网络分区，因此一致性（C）和可用性（A）无法同时满足，那么分布式系统只能是 CP 或 AP 模型。 选择一致性(C): 会读取到正确的数据（最新的数据），但如果发生网络分区时，为了不破坏一致性，可能会因为无法响应正确的数据而返回异常信息给客户端。 选择可用性(A): 系统始终可以处理客户端的操作请求，但如果发生网络分区时，为了保证系统的可用性，可能会返回脏数据给客户端。 注意：理论上来说并不是在任何情况下，分布式系统都只能在一致性(C)和可用性(A)中选择其中一个。在不存在网络分区的情况下，就是说在不需要分区容错性(P)时，一致性(C)和可用性(A)能够同时保证。只有当发生分区故障的时候，也就是说需要分区容错性(P)时，才会在一致性(C)和可用性(A)之间做出选择。而且如果读操作会读到脏数据，影响到了系统运行或业务逻辑，推荐选择一致性(C)，否则选可用性(A)。 小结CAP 理论描述了存在网络分区的情况下，分区容错性(P)是前提，一致性(C)和可用性(A)根据具体场景权衡折中选择一个，也就是在系统架构设计时只需要根据业务特性在一致性和可用性之间寻求平衡即可。CAP 理论之所以没法做到一致性(C)和可用性(A)同时满足，根本在于这里的一致性(C)是强一致性，如果在强一致性和可用性之间权衡，就可以同时满足了，这正是 BASE 理论的原理。","categories":[{"name":"分布式","slug":"分布式","permalink":"https://gentryhuang.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[]},{"title":"命令模式","slug":"design_pattern/behaviour_type/命令模式","date":"2019-10-04T16:00:00.000Z","updated":"2020-08-09T09:26:57.923Z","comments":true,"path":"posts/78134e07/","link":"","permalink":"https://gentryhuang.com/posts/78134e07/","excerpt":"","text":"定义命令模式又叫指令模式，是将“请求”封装成对象，以便使用不同的请求。我们可以把不同的请求封装成不同请求对象，对于接收者来说这些类型都能识别，然后根据不同的请求对象执行不同的行为。 说明命令模式解决了应用程序中对象的职责以及它们之间的通信方式，命令模式可以使命令发送者和接收者完全解耦，发送者和接收者之间没有直接的引用关系。发送命令的对象只知道如何下命令，不需要知道如何完成命令。 类型行为型 使用场景121. 请求调用者和请求接收者需要解耦，使得调用者和接收者不直接交互2. 需要抽象出等待执行的行为 优点1231. 降低耦合 - 通过命令模式把请求的发送者和请求的接收者进行解耦2. 容易扩展新命令或者一组命令 缺点12命令的无限扩展会增加类的数量，提高系统实现复杂度 - 针对每一个命令我们都要设计并开发一个具体的命令类 相关的设计模式命令模式和备忘录模式 1可以把两者结合使用，使用备忘录模式保存命令的历史记录，这样可以调用之前的命令 简单需求一创业公司为了抢占市场，老板对开发部前后下达了两个命令，先使用单例架构快速开发出产品，等到抢占了市场后再扩大规模把单体结构拆成微服务架构。 命令模式演练 把命令抽象成对象，这是命令模式实现的核心 1命令扩展很容易，增加命令只需封装一个命令类。如果有命令行为体根据情况修改命令行为体。 命令行为体 1每个命令执行的具体行为在行为体中，但不是必须的，也可以不要行为体，让命令执行变得更灵活。 123456789101112131415161718192021222324252627282930313233343536package com.design.pattern.command;import lombok.extern.slf4j.Slf4j;/** * Project 项目 * * @author shunhua * @date 2019-10-04 */@Slf4jpublic class Project &#123; /** * 项目名称 */ private String name; public Project(String name)&#123; this.name = name; &#125; /** * 使用单体架构开发项目 */ public void monomer()&#123; log.info(String.format(\"%s项目使用单体架构开发\",this.name)); &#125; /** * 使用微服务架构开发项目 */ public void microservice()&#123; log.info(String.format(\"%s项目使用微服务架构开发\",this.name)); &#125;&#125; 命令接口 1234567891011121314package com.design.pattern.command;/** * Command 命令接口 * * @author shunhua * @date 2019-10-04 */public interface Command &#123; /** * 执行命令 */ void execute();&#125; 单体架构开发命令 123456789101112131415161718192021222324252627282930package com.design.pattern.command;/** * MonomerCommand 单体架构开发命令类，执行的是单体架构开发 * * @author shunhua * @date 2019-10-04 */public class MonomerCommand implements Command &#123; /** * 组合，命令对应的行为体 (非必须的，命令的行为可以根据具体业务编写) */ private Project project; /** * 构造方法 * @param project */ public MonomerCommand(Project project)&#123; this.project = project; &#125; /** * 执行命令 */ @Override public void execute() &#123; project.monomer(); &#125;&#125; 微服务架构开发命令 12345678910111213141516171819202122232425262728293031package com.design.pattern.command;/** * MicroserviceCommand 微服务架构开发命令类，执行的是微服务架构开发 * * @author shunhua * @date 2019-10-04 */public class MicroserviceCommand implements Command &#123; /** * 组合，命令对应的行为体 (非必须的，命令的行为可以根据具体业务编写) */ private Project project; /** * 构造方法 * @param project */ public MicroserviceCommand(Project project)&#123; this.project = project; &#125; /** * 执行命令 */ @Override public void execute() &#123; project.microservice(); &#125;&#125; 命令接收者 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.design.pattern.command;import java.util.ArrayList;import java.util.List;/** * Staff 命令执行者 * * @author shunhua * @date 2019-10-04 */public class Staff &#123; /** * 命令集合，可以接收多个命令 */ private List&lt;Command&gt; commands = new ArrayList&lt;&gt;(); /** * 接收命令 * @param command */ public void addCommand(Command command)&#123; commands.add(command); &#125; /** * 移除命令 * @param command */ public void removeCommand(Command command)&#123; commands.remove(command); &#125; /** * 执行指定的名 * @param command */ public void execureCommand(Command command)&#123; command.execute(); &#125; /** * 执行命令集 */ public void executeCommandList()&#123; this.commands.stream().forEach(Command::execute); commands.clear(); &#125;&#125; 应用层 1234567891011121314151617181920212223242526272829303132333435363738package com.design.pattern.command;import org.junit.Test;/** * Boss 命令的下达者 * * @author shunhua * @date 2019-10-04 */public class Boss &#123; @Test public void test() throws InterruptedException &#123; // 创建命令的行为体 Project projectDevelopment = new Project(\"带你飞\"); // 创建命令对象(老板下达命令) MicroserviceCommand microserviceCommand = new MicroserviceCommand(projectDevelopment); MonomerCommand monomerCommand = new MonomerCommand(projectDevelopment); System.out.println(\"//-----------------------分别执行命令---------------------------/\"); // 员工接收并执行命令 Staff staff = new Staff(); staff.execureCommand(microserviceCommand); staff.execureCommand(monomerCommand); Thread.sleep(2000); System.out.println(\"//-----------------------统一执行命令集-------------------------/\"); // 员工接收多个命令,统一执行 staff.addCommand(microserviceCommand); staff.addCommand(monomerCommand); staff.executeCommandList(); &#125;&#125; 命令模式在源码中的使用Runnable接口的实现类 1Runnable可以看成一个抽象的命令，它的实现可以理解为具体的命令实现","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"状态模式","slug":"design_pattern/behaviour_type/状态模式","date":"2019-10-04T16:00:00.000Z","updated":"2020-08-09T09:28:21.142Z","comments":true,"path":"posts/8acb1976/","link":"","permalink":"https://gentryhuang.com/posts/8acb1976/","excerpt":"","text":"定义允许一个对象在其内部状态改变时，改变它的行为，如果行为不需要改变就不要改变。一般这个存在多个状态的对象是一个“上下文”。 类型行为型 使用场景1一个对象存在多个状态（不同状态下行为不同），且状态可相互转换 优点12341. 将不同的状态隔离 - 每个状态都是一个类2. 把各种状态的转换逻辑分布到State的子类中，减少相互间依赖 3. 增加新的状态非常简单（也就增加一个状态类，如果还要满足相互转换，其他已有的状态内部也需要修改） 缺点1状态多的业务场景导致类数目增加，系统变得复杂 相关的设计模式状态模式和享元模式 1它们有时可以配合使用 简单需求播放视频的时候，有播放状态、快进播放状态、暂停状态以及停止状态，这些状态大都可以相互转换。当状态发生改变时对应的播放行为也发生了改变。 状态父类 1234567891011121314151617181920212223242526272829303132333435363738package com.design.pattern.state;import lombok.Setter;/** * VideoState 视频状态 * * @author shunhua * @date 2019-10-05 */@Setterpublic abstract class VideoState &#123; /** * 视频资源上下文 */ protected VideoContext videoContext; /** * 播放 */ public abstract void play(); /** * 快进 */ public abstract void speed(); /** * 暂停 */ public abstract void pause(); /** * 停止 */ public abstract void stop(); &#125; 播放状态类 123456789101112131415161718192021222324252627282930313233343536373839404142package com.design.pattern.state;import lombok.extern.slf4j.Slf4j;/** * PlayState 视频播放状态 * * @author shunhua * @date 2019-10-05 */@Slf4jpublic class PlayState extends VideoState &#123; @Override public void play() &#123; log.info(\"视频正常播放状态\"); &#125; /** * 可切换快进 */ @Override public void speed() &#123; super.videoContext.setVideoState(VideoContext.SPEED_STATE); &#125; /** * 可切换暂停 */ @Override public void pause() &#123; super.videoContext.setVideoState(VideoContext.PAUSE_STATE); &#125; /** * 可切换停止 */ @Override public void stop() &#123; super.videoContext.setVideoState(VideoContext.STOP_STATE); &#125;&#125; 暂停播放状态类 123456789101112131415161718192021222324252627282930313233package com.design.pattern.state;import lombok.extern.slf4j.Slf4j;/** * PauseState 视频暂停状态 * * @author shunhua * @date 2019-10-05 */@Slf4jpublic class PauseState extends VideoState &#123; @Override public void play() &#123; super.videoContext.setVideoState(VideoContext.PLAY_STATE); &#125; @Override public void speed() &#123; super.videoContext.setVideoState(VideoContext.SPEED_STATE); &#125; @Override public void pause() &#123; log.info(\"视频暂停播放状态\"); &#125; @Override public void stop() &#123; super.videoContext.setVideoState(VideoContext.STOP_STATE); &#125;&#125; 快进播放状态类 123456789101112131415161718192021222324252627282930313233package com.design.pattern.state;import lombok.extern.slf4j.Slf4j;/** * SpeedState 视频加速状态 * * @author shunhua * @date 2019-10-05 */@Slf4jpublic class SpeedState extends VideoState &#123; @Override public void play() &#123; super.videoContext.setVideoState(VideoContext.PLAY_STATE); &#125; @Override public void speed() &#123; log.info(\"视频快进播放状态\"); &#125; @Override public void pause() &#123; super.videoContext.setVideoState(VideoContext.PAUSE_STATE); &#125; @Override public void stop() &#123; super.videoContext.setVideoState(VideoContext.STOP_STATE); &#125;&#125; 停止状态类 123456789101112131415161718192021222324252627282930313233package com.design.pattern.state;import lombok.extern.slf4j.Slf4j;/** * StopState 视频停止状态 * * @author shunhua * @date 2019-10-05 */@Slf4jpublic class StopState extends VideoState &#123; @Override public void play() &#123; super.videoContext.setVideoState(VideoContext.PLAY_STATE); &#125; @Override public void speed() &#123; log.info(\"停止状态不能快进\"); &#125; @Override public void pause() &#123; log.info(\"停止状态不能暂停\"); &#125; @Override public void stop() &#123; log.info(\"视频停止播放状态\"); &#125;&#125; 状态对应的上下文 123456789101112131415161718192021222324252627282930313233package com.design.pattern.state;import lombok.extern.slf4j.Slf4j;import org.junit.Test;/** * Client * * @author shunhua * @date 2019-10-04 */@Slf4jpublic class Client &#123; @Test public void test()&#123; // 声明一个上下文 VideoContext videoContext = new VideoContext(); videoContext.setVideoState(new PlayState()); log.info(\"当前状态：\" + videoContext.getVideoState().getClass().getSimpleName()); videoContext.pause(); log.info(\"当前状态：\" + videoContext.getVideoState().getClass().getSimpleName()); videoContext.speed(); log.info(\"当前状态：\" + videoContext.getVideoState().getClass().getSimpleName()); videoContext.stop(); log.info(\"当前状态：\" + videoContext.getVideoState().getClass().getSimpleName()); &#125;&#125; 状态模式在源码中的使用 状态模式和业务场景更紧密相关，比如电商中订单的状态、根据业务设置状态机、办公系统流程的状态等，源码中相对很少使用","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"访问者模式","slug":"design_pattern/behaviour_type/访问者模式","date":"2019-10-04T16:00:00.000Z","updated":"2020-08-09T09:30:13.914Z","comments":true,"path":"posts/64b51ed9/","link":"","permalink":"https://gentryhuang.com/posts/64b51ed9/","excerpt":"","text":"定义封装作用于某数据结构(如List/Set/Map等)中的各元素的操作。可以在不改变各元素的类的前提下，定义作用于这些元素的操作。即当访问某个资源时，不去修改资源本身而是定义访问资源的操作 类型行为型 使用场景121. 一个数据结构如（List&#x2F;Set&#x2F;Map等）包含很多类型对象2. 数据结构于数据操作分离 优点1增加新的操作很容易，即增加一个新的访问者 缺点1231. 增加新的数据结构困难，需要修改的地方比较多2. 具体元素变更比较麻烦 - 增加或者删除元素里面的属性都算变更 相关的设计模式访问者模式和迭代器模式 121. 它们都是在某种数据结构上进行处理2. 访问者模式主要对保存在数据结构中的元素进行某种特定的处理，迭代器用于逐个遍历保存在数据结构中的一些元素 简单需求网络课程有免费的也有付费的，免费的课程普通用户都可以访问，付费的课程需要购买称为Vip用户才能访问。相同的资源不同的用户身份，访问的结果不同 访问者模式演练 当访问某个资源时，不去修改资源本身而是定义访问资源的操作。相同的资源不同的访问身份，产生不同的操作行为 抽象课程资源 12345678910111213141516171819202122232425262728package com.design.pattern.visitor;import lombok.Getter;import lombok.Setter;/** * Course 被访问的资源 * * 不改变Course,而是定义访问Course的操作，这里体现在IVisitor的方法上 * * @author shunhua * @date 2019-10-05 */@Getter@Setterpublic abstract class Course &#123; /** * 课程名称 */ private String name; /** * 接受访问 把访问者传入 * @param visitor */ public abstract void accept(IVisitor visitor); &#125; 免费课程资源 12345678910111213141516171819package com.design.pattern.visitor;/** * FreeCourse * * @author shunhua * @date 2019-10-05 */public class FreeCourse extends Course &#123; /** * 接受访问 * @param visitor */ @Override public void accept(IVisitor visitor) &#123; visitor.visit(this); &#125;&#125; 付费课程资源 12345678910111213141516171819202122232425262728package com.design.pattern.visitor;import lombok.Getter;import lombok.Setter;/** * PayCourse * * @author shunhua * @date 2019-10-05 */@Getter@Setterpublic class PayCourse extends Course &#123; /** * 价格 */ private int price; /** * 接受访问 * @param visitor */ @Override public void accept(IVisitor visitor) &#123; visitor.visit(this); &#125;&#125; 访问者抽象 12345678910111213141516171819202122232425package com.design.pattern.visitor;/** * IVisitor 访问接口 * * 这里定义了访问资源的操作，具体的访问细节体现在实现类中，不同的实现类对相同的资源产生不同的操作行为，这是访问者的核心 * * @author shunhua * @date 2019-10-05 */public interface IVisitor &#123; /** * 访问免费课程 * @param freeCourse */ void visit(FreeCourse freeCourse); /** * 访问付费课程 * @param payCourse */ void visit(PayCourse payCourse);&#125; 普通访问者 12345678910111213141516171819202122232425262728293031package com.design.pattern.visitor;import lombok.extern.slf4j.Slf4j;/** * GeneralVisitor 普通访问者 * * @author shunhua * @date 2019-10-05 */@Slf4jpublic class GeneralVisitor implements IVisitor &#123; /** * 访问免费课程 * @param freeCourse */ @Override public void visit(FreeCourse freeCourse) &#123; log.info(\"免费课程名：\" + freeCourse.getName()); &#125; /** * 访问付费课程 * @param payCourse */ @Override public void visit(PayCourse payCourse) &#123; log.info(\"这是付费课程，你还没有购买，没有访问权限\"); &#125;&#125; Vip访问者 12345678910111213141516171819202122232425262728293031package com.design.pattern.visitor;import lombok.extern.slf4j.Slf4j;/** * VipVisitor Vip访问者 * * @author shunhua * @date 2019-10-05 */@Slf4jpublic class VipVisitor implements IVisitor&#123; /** * 访问免费课程 * @param freeCourse */ @Override public void visit(FreeCourse freeCourse) &#123; log.info(\"免费课程名：\" + freeCourse.getName()); &#125; /** * 访问付费课程 * @param payCourse */ @Override public void visit(PayCourse payCourse) &#123; log.info(\"付费课程名：\" + payCourse.getName() + \" 价格为：\" + payCourse.getPrice()); &#125;&#125; 客户端 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.design.pattern.visitor;import org.junit.Test;import java.util.ArrayList;import java.util.List;/** * Client * * @author shunhua * @date 2019-10-05 */public class Client &#123; @Test public void test()&#123; List&lt;Course&gt; courseList = new ArrayList&lt;&gt;(); FreeCourse freeCourse = new FreeCourse(); freeCourse.setName(\"这是一个免费的课程\"); PayCourse payCourse = new PayCourse(); payCourse.setName(\"这是一个付费的课程\"); payCourse.setPrice(300); courseList.add(freeCourse); courseList.add(payCourse); // 普通访问者 GeneralVisitor generalVisitor = new GeneralVisitor(); // Vip用户 VipVisitor vipVisitor = new VipVisitor(); System.out.println(\"//----------普通访问者----------------/\"); courseList.stream().forEach(course -&gt; &#123; course.accept(generalVisitor); &#125;); System.out.println(\"//----------vip用户------------------/\"); courseList.stream().forEach(course -&gt; &#123; course.accept(vipVisitor); &#125;); &#125;&#125; 访问者模式在源码中的使用FileVisitor 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283package java.nio.file;import java.nio.file.attribute.BasicFileAttributes;import java.io.IOException;import java.util.Objects;/** * 资源是文件 * * @since 1.7 */public class SimpleFileVisitor&lt;T&gt; implements FileVisitor&lt;T&gt; &#123; /** * Initializes a new instance of this class. */ protected SimpleFileVisitor() &#123; &#125; /** * Invoked for a directory before entries in the directory are visited. * * &lt;p&gt; Unless overridden, this method returns &#123;@link FileVisitResult#CONTINUE * CONTINUE&#125;. */ @Override public FileVisitResult preVisitDirectory(T dir, BasicFileAttributes attrs) throws IOException &#123; Objects.requireNonNull(dir); Objects.requireNonNull(attrs); return FileVisitResult.CONTINUE; &#125; /** * Invoked for a file in a directory. * * &lt;p&gt; Unless overridden, this method returns &#123;@link FileVisitResult#CONTINUE * CONTINUE&#125;. */ @Override public FileVisitResult visitFile(T file, BasicFileAttributes attrs) throws IOException &#123; Objects.requireNonNull(file); Objects.requireNonNull(attrs); return FileVisitResult.CONTINUE; &#125; /** * Invoked for a file that could not be visited. * * &lt;p&gt; Unless overridden, this method re-throws the I/O exception that prevented * the file from being visited. */ @Override public FileVisitResult visitFileFailed(T file, IOException exc) throws IOException &#123; Objects.requireNonNull(file); throw exc; &#125; /** * Invoked for a directory after entries in the directory, and all of their * descendants, have been visited. * * &lt;p&gt; Unless overridden, this method returns &#123;@link FileVisitResult#CONTINUE * CONTINUE&#125; if the directory iteration completes without an I/O exception; * otherwise this method re-throws the I/O exception that caused the iteration * of the directory to terminate prematurely. */ @Override public FileVisitResult postVisitDirectory(T dir, IOException exc) throws IOException &#123; Objects.requireNonNull(dir); if (exc != null) throw exc; return FileVisitResult.CONTINUE; &#125;&#125; BeanDefinitionVisitor 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package org.springframework.beans.factory.config;import java.util.LinkedHashMap;import java.util.LinkedHashSet;import java.util.List;import java.util.Map;import java.util.Set;import org.springframework.beans.MutablePropertyValues;import org.springframework.beans.PropertyValue;import org.springframework.lang.Nullable;import org.springframework.util.Assert;import org.springframework.util.ObjectUtils;import org.springframework.util.StringValueResolver;/** * 资源：Bean的定义 * * @author Juergen Hoeller * @author Sam Brannen * @since 1.2 * @see BeanDefinition * @see BeanDefinition#getPropertyValues * @see BeanDefinition#getConstructorArgumentValues * @see PropertyPlaceholderConfigurer */public class BeanDefinitionVisitor &#123; @Nullable private StringValueResolver valueResolver; /** * Create a new BeanDefinitionVisitor, applying the specified * value resolver to all bean metadata values. * @param valueResolver the StringValueResolver to apply */ public BeanDefinitionVisitor(StringValueResolver valueResolver) &#123; Assert.notNull(valueResolver, \"StringValueResolver must not be null\"); this.valueResolver = valueResolver; &#125; /** * Create a new BeanDefinitionVisitor for subclassing. * Subclasses need to override the &#123;@link #resolveStringValue&#125; method. */ protected BeanDefinitionVisitor() &#123; &#125; /** * Traverse the given BeanDefinition object and the MutablePropertyValues * and ConstructorArgumentValues contained in them. * @param beanDefinition the BeanDefinition object to traverse * @see #resolveStringValue(String) */ public void visitBeanDefinition(BeanDefinition beanDefinition) &#123; visitParentName(beanDefinition); visitBeanClassName(beanDefinition); visitFactoryBeanName(beanDefinition); visitFactoryMethodName(beanDefinition); visitScope(beanDefinition); if (beanDefinition.hasPropertyValues()) &#123; visitPropertyValues(beanDefinition.getPropertyValues()); &#125; if (beanDefinition.hasConstructorArgumentValues()) &#123; ConstructorArgumentValues cas = beanDefinition.getConstructorArgumentValues(); visitIndexedArgumentValues(cas.getIndexedArgumentValues()); visitGenericArgumentValues(cas.getGenericArgumentValues()); &#125; &#125; &#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"备忘录模式","slug":"design_pattern/behaviour_type/备忘录模式","date":"2019-10-03T16:00:00.000Z","updated":"2020-08-09T09:27:24.516Z","comments":true,"path":"posts/c3176455/","link":"","permalink":"https://gentryhuang.com/posts/c3176455/","excerpt":"","text":"定义保存一个对象的某个状态，以便在适当的时候恢复对象。这里的状态可以理解为对象的一个快照。 类型行为型 适用场景121 保存及恢复数据相关业务场景2 后悔的时候，即想恢复到之前的状态 优点121 为用户提供一种可恢复机制2 存档信息的封装 缺点12资源占用 - 如果暂存的对象比较多，而且对象的属性也比较多，那么肯定会对资源造成一定的消耗，占用大量的资源。 相关的设计模式备忘录模式和状态模式 1备忘录模式中是用实例来表示状态的，我们存档的是一个对象实例。状态模式中是使用类来表示状态。 简单需求在写文档时，间断性地保存，然后可以撤销回退到上一个版本 备忘录模式演练 文章 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package com.design.pattern.memento;import lombok.AllArgsConstructor;import lombok.Data;import java.io.Serializable;/** * Article 文章 * * @author shunhua * @date 2019-10-04 */@Data@AllArgsConstructorpublic class Article implements Serializable &#123; private static final long serialVersionUID = -321234774998152556L; /** * 文章标题 */ private String title; /** * 文章内容 */ private String content; /** * 图片 */ private String img; /** * 把文章保存起来 * @return */ public ArticleMemento saveToMemento()&#123; ArticleMemento articleMemento = new ArticleMemento(this.title,this.content,this.img); return articleMemento; &#125; /** * 把保存的文章标题、内容以及图片回退回来 * @param articleMemento */ public void undoFromMemento(ArticleMemento articleMemento)&#123; this.title = articleMemento.getTitle(); this.content = articleMemento.getContent(); this.img = articleMemento.getImg(); &#125;&#125; 文章快照 123456789101112131415161718192021222324252627282930package com.design.pattern.memento;import lombok.AllArgsConstructor;import lombok.Getter;import lombok.ToString;/** * ArticleMemento 文章快照,对于快照不需要Setter方法，只用于保存 * * @author shunhua * @date 2019-10-04 */@Getter@ToString@AllArgsConstructorpublic class ArticleMemento &#123; /** * 标题 */ private String title; /** * 内容 */ private String content; /** * 图片 */ private String img;&#125; 文章快照暂存管理 12345678910111213141516171819202122232425262728293031323334package com.design.pattern.memento;import java.util.Stack;/** * ArticleMementoManager 文章快照管理者 * * @author shunhua * @date 2019-10-04 */public class ArticleMementoManager &#123; /** * 保存 文章快照 的栈，在回退的时候回退的是最新的状态 */ private final Stack&lt;ArticleMemento&gt; ARTICLE_MEMENTO_STACK = new Stack&lt;&gt;(); /** * 获取文章快照 * @return */ public ArticleMemento getMemento()&#123; ArticleMemento articleMemento = ARTICLE_MEMENTO_STACK.pop(); return articleMemento; &#125; /** * 把文章保存为快照 * @param articleMemento */ public void addMemento(ArticleMemento articleMemento)&#123; ARTICLE_MEMENTO_STACK.push(articleMemento); &#125;&#125; 备忘录模式在源码中的使用spring-webflow中的使用 123456789101112131415161718192021222324252627282930313233343536373839package org.springframework.binding.message;import java.io.Serializable;import org.springframework.context.MessageSource;/** * A message context whose internal state can be managed by an external care-taker. State management employs the GOF * Memento pattern. This context can produce a serializable memento representing its internal state at any time. A * care-taker can then use that memento at a later time to restore any context instance to a previous state. * * @author Keith Donald */public interface StateManageableMessageContext extends MessageContext &#123; /** * 存档 * Create a serializable memento, or token representing a snapshot of the internal state of this message context. * @return the messages memento */ Serializable createMessagesMemento(); /** * 回退 * Set the state of this context from the memento provided. After this call, the messages in this context will match * what is encapsulated inside the memento. Any previous state will be overridden. * @param messagesMemento the messages memento */ void restoreMessages(Serializable messagesMemento); /** * Configure the message source used to resolve messages added to this context. May be set at any time to change how * coded messages are resolved. * @param messageSource the message source * @see MessageContext#addMessage(MessageResolver) */ void setMessageSource(MessageSource messageSource);&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"中介者模式","slug":"design_pattern/behaviour_type/中介者模式","date":"2019-10-03T16:00:00.000Z","updated":"2020-08-09T09:26:26.731Z","comments":true,"path":"posts/d036071c/","link":"","permalink":"https://gentryhuang.com/posts/d036071c/","excerpt":"","text":"定义定义了一个封装一组对象如何交互的对象（这个对象用来协调这一组对象（“同事类”））。通过使对象明确地相互引用来促进松散耦合，并允许独立地改变它们的交互。 类型行为型 适用场景121. 系统中对象之间存在复杂的引用关系，产生的相互依赖关系结构混乱难以理解，使用中介者进行协调2. 交互的公共行为，如果需要改变行为则可以增加新的中介者类 优点121. 将一对多转化成了一对一、降低程序复杂度2. 类之间的解耦 缺点1中介者过多，导致系统复杂 相关的设计模式中介者模式和观察者模式 1两者有时结合使用，使用观察者模式实现中介者模式中角色间的通信 简单需求公司的员工之间发送公有消息，使用工作群统一发送，不需要发送者逐一发给其他员工 中介者模式演练 中介者 12345678910111213141516171819202122232425package com.design.pattern.mediator;import lombok.extern.slf4j.Slf4j;import java.util.Date;/** * WorkGroup 中介者 - 工作群 * * @author shunhua * @date 2019-10-04 */@Slf4jpublic class WorkGroup &#123; /** * 中介者显示员工发送的消息 * @param worker * @param msg */ public static void showMsg(Worker worker, String msg)&#123; log.info(String.format(\"%s 【%s】: %s\",new Date().toString(),worker.getName(),msg)); &#125;&#125; 参与交互的对象类 123456789101112131415161718192021222324252627package com.design.pattern.mediator;import lombok.AllArgsConstructor;import lombok.Data;/** * Worker 员工 通常称为“同事类” * * @author shunhua * @date 2019-10-04 */@Data@AllArgsConstructorpublic class Worker &#123; /** * 花名 */ private String name; /** * 员工只和中介者（工作群）打交道，这是中介者模式的核心 * @param msg */ public void sendMsg(String msg)&#123; WorkGroup.showMsg(this,msg); &#125;&#125; 应用层 12345678910111213141516171819202122232425package com.design.pattern.mediator;import org.junit.Test;/** * Client * * @author shunhua * @date 2019-10-04 */public class Client &#123; @Test public void test()&#123; Worker worker = new Worker(\"舜华\"); Worker worker1= new Worker(\"高斯林\"); worker1.sendMsg(\"小伙子，就你还想学我的Java！！！\"); worker.sendMsg(\"有句话不知当讲不当讲？\"); &#125;&#125; 中介者模式在源码中的使用Timer 1Timer是一个中介者，它协调TimerTask任务 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package java.util;import java.util.Date;import java.util.concurrent.atomic.AtomicInteger;public class Timer &#123; /** * The timer task queue. This data structure is shared with the timer * thread. The timer produces tasks, via its various schedule calls, * and the timer thread consumes, executing timer tasks as appropriate, * and removing them from the queue when they're obsolete. */ private final TaskQueue queue = new TaskQueue(); /** * The timer thread. */ private final TimerThread thread = new TimerThread(queue); /** * Timer中有多个schedule重载方法，里面都调用了sched方法 */ public void schedule(TimerTask task, long delay) &#123; if (delay &lt; 0) throw new IllegalArgumentException(\"Negative delay.\"); sched(task, System.currentTimeMillis()+delay, 0); &#125; /** * * Timer是一个中介者，通过sched方法统一协调TimerTask * * @param task 被协调的对象 * @param time * @param period */ private void sched(TimerTask task, long time, long period) &#123; if (time &lt; 0) throw new IllegalArgumentException(\"Illegal execution time.\"); // Constrain value of period sufficiently to prevent numeric // overflow while still being effectively infinitely large. if (Math.abs(period) &gt; (Long.MAX_VALUE &gt;&gt; 1)) period &gt;&gt;= 1; synchronized(queue) &#123; if (!thread.newTasksMayBeScheduled) throw new IllegalStateException(\"Timer already cancelled.\"); synchronized(task.lock) &#123; if (task.state != TimerTask.VIRGIN) throw new IllegalStateException( \"Task already scheduled or cancelled\"); task.nextExecutionTime = time; task.period = period; task.state = TimerTask.SCHEDULED; &#125; queue.add(task); if (queue.getMin() == task) queue.notify(); &#125; &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"责任链模式","slug":"design_pattern/behaviour_type/责任链模式","date":"2019-10-03T16:00:00.000Z","updated":"2020-08-09T09:30:40.577Z","comments":true,"path":"posts/6208627e/","link":"","permalink":"https://gentryhuang.com/posts/6208627e/","excerpt":"","text":"定义责任链模式又叫职责链模式。为请求创建一个接收此次请求的对象的链，这个链条由多个对象组成。 类型行为型 适用场景1一个请求的处理需要链中一个或多个协作处理 优点1231.请求的发送者和接收者（请求的处理者）解耦 2.责任链可以动态组合3.责任链方便扩展和收缩（增加或减少处理对象） 缺点121. 责任链太长或者处理时间过长会影响性能2. 责任链有可能过多 相关的设计模式责任链模式和状态模式 1责任链模式中各个对象不会指定下一个处理对象是谁，只有在客户端设定链条中的顺序以及元素直到被某个元素处理或整条链结束。状态模式是让每个状态对象知道自己下一个处理的对象是谁，在编译时就设定好了。 简单需求在注册网站的时候，我们需要提供用户名、邮箱以及密码，网站会有一个校验流程，分别对用户名、邮箱以及密码进行校验，如果任何一个步骤没有通过就不能注册，只有全部校验通过才能完成注册。 责任链模式演练 责任链的构建是由客户端决定的，责任链的入口也是客户端决定的 待处理的对象 12345678910111213141516171819202122232425262728package com.design.pattern.chain;import lombok.AllArgsConstructor;import lombok.Data;/** * User 待校验的用户 * * @author shunhua * @date 2019-10-04 */@Data@AllArgsConstructorpublic class User &#123; /** * 用户名 */ private String name; /** * 邮箱 */ private String email; /** * 密码 */ private String password;&#125; 处理器父类 1234567891011121314151617181920212223242526272829303132package com.design.pattern.chain;/** * Handler 责任链模式的核心 * * 注意：构造责任链是客户端的任务,并且入口也是客户单选择的 * * @author shunhua * @date 2019-10-04 */public abstract class Handler &#123; /** * 一个自己类型的对象，一般是子类对象 */ protected Handler handler; /** * 设置下一个处理器 * @param handler */ public void setNextHandler(Handler handler)&#123; this.handler = handler; &#125; /** * 交给子类实现，用来校验用户信息是否符合 * @param user */ protected abstract void handle(User user);&#125; 名称处理器 1234567891011121314151617181920212223242526272829303132333435package com.design.pattern.chain;import lombok.extern.slf4j.Slf4j;import org.apache.commons.lang3.StringUtils;import org.springframework.util.ObjectUtils;/** * NameHandler 用户名处理器 * * @author shunhua * @date 2019-10-04 */@Slf4jpublic class NameHandler extends Handler &#123; /** * 校验用户名 * @param user */ @Override protected void handle(User user) &#123; if(StringUtils.isNotBlank(user.getName()))&#123; log.info(\"用户名符合要求\"); // 如果有下一个校验器就继续执行，注意这个链的顺序是由客户端决定的 if(!ObjectUtils.isEmpty(super.handler))&#123; super.handler.handle(user); return; &#125;else &#123; log.info(\"完成注册\"); &#125; return; &#125; log.info(\"用户名校验不通过，结束校验\"); &#125;&#125; 邮箱处理器 123456789101112131415161718192021222324252627282930package com.design.pattern.chain;import lombok.extern.slf4j.Slf4j;import org.apache.commons.lang3.StringUtils;import org.springframework.util.ObjectUtils;/** * EmailHandler 邮箱校验器 * * @author shunhua * @date 2019-10-04 */@Slf4jpublic class EmailHandler extends Handler&#123; @Override protected void handle(User user) &#123; if(StringUtils.isNotBlank(user.getEmail()))&#123; log.info(\"邮箱符合要求\"); if(!ObjectUtils.isEmpty(super.handler))&#123; super.handler.handle(user); return; &#125;else &#123; log.info(\"完成注册\"); &#125; return; &#125; log.info(\"邮箱验证不通过，验证结束\"); &#125;&#125; 密码处理器 123456789101112131415161718192021222324252627282930package com.design.pattern.chain;import lombok.extern.slf4j.Slf4j;import org.apache.commons.lang3.StringUtils;import org.springframework.util.ObjectUtils;/** * PasswordHandler 密码验证器 * * @author shunhua * @date 2019-10-04 */@Slf4jpublic class PasswordHandler extends Handler &#123; @Override protected void handle(User user) &#123; if(StringUtils.isNotBlank(user.getPassword()) &amp;&amp; user.getPassword().length() &gt;5)&#123; log.info(\"密码符合要求\"); if(!ObjectUtils.isEmpty(super.handler))&#123; super.handler.handle(user); return; &#125;else &#123; log.info(\"完成注册\"); &#125; return; &#125; log.info(\"密码验证不通过，验证结束\"); &#125;&#125; 客户端 12345678910111213141516171819202122232425262728293031323334353637package com.design.pattern.chain;import org.junit.Test;/** * Client * * @author shunhua * @date 2019-10-04 */public class Client &#123; @Test public void test()&#123; // 创建待验证的用户 User user = new User(\"shunhua\",\"gentryhuang.xw@gmail.com\",\"123456\"); // 姓名验证器 NameHandler nameHandler = new NameHandler(); // 邮箱验证器 EmailHandler emailHandler = new EmailHandler(); // 密码验证器 PasswordHandler passwordHandler = new PasswordHandler(); /** * 注意：构造责任链是客户端决定的 * * 构建责任链 : NameHandler -&gt; EmailHandler -&gt; PasswordHandler */ nameHandler.setNextHandler(emailHandler); emailHandler.setNextHandler(passwordHandler); /** * 处理请求入口 */ nameHandler.handle(user); &#125;&#125; 责任链在源码中的使用过滤器-Filter 123456789101112131415161718192021222324252627282930313233// 以OncePerRequestFilter为例public abstract class OncePerRequestFilter extends GenericFilterBean &#123; public static final String ALREADY_FILTERED_SUFFIX = \".FILTERED\"; public OncePerRequestFilter() &#123; &#125; public final void doFilter(ServletRequest request, ServletResponse response, FilterChain filterChain) throws ServletException, IOException &#123; if (request instanceof HttpServletRequest &amp;&amp; response instanceof HttpServletResponse) &#123; HttpServletRequest httpRequest = (HttpServletRequest)request; HttpServletResponse httpResponse = (HttpServletResponse)response; String alreadyFilteredAttributeName = this.getAlreadyFilteredAttributeName(); boolean hasAlreadyFilteredAttribute = request.getAttribute(alreadyFilteredAttributeName) != null; if (!hasAlreadyFilteredAttribute &amp;&amp; !this.skipDispatch(httpRequest) &amp;&amp; !this.shouldNotFilter(httpRequest)) &#123; request.setAttribute(alreadyFilteredAttributeName, Boolean.TRUE); try &#123; this.doFilterInternal(httpRequest, httpResponse, filterChain); &#125; finally &#123; request.removeAttribute(alreadyFilteredAttributeName); &#125; &#125; else &#123; // 待下一个过滤器处理 filterChain.doFilter(request, response); &#125; &#125; else &#123; throw new ServletException(\"OncePerRequestFilter just supports HTTP requests\"); &#125; &#125; // ... &#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"代理模式","slug":"design_pattern/structure_type/代理模式","date":"2019-10-02T16:00:00.000Z","updated":"2020-09-30T07:05:03.261Z","comments":true,"path":"posts/7b510e10/","link":"","permalink":"https://gentryhuang.com/posts/7b510e10/","excerpt":"","text":"定义为其他对象提供一种代理，以控制对这个对象的访问。代理对象在客户端和目标对象之间起到中介的作用。 举例：租房子，目标对象代表房东，客户端代表用户，房屋中介代表中介。房屋中介起到代理的作用，签合同和缴纳水电费直接找中介就可以了，不需要和房东直接接触，即中介代理房东。 类型结构型 使用场景12◆ 保护目标对象◆ 增强目标对象 优点1234◆ 代理模式能将代理对象与真实被调用的目标对象分离◆ 一定程度上降低了系统的耦合度，扩展性好◆ 保护目标对象◆ 在不修改目标类的前提下，增强目标对象 缺点123◆ 代理模式会造成系统设计中类的数目增加◆ 在客户端和目标对象增加一个代理对象，会造成请求处理速度变慢◆ 增加系统的复杂度 扩展 根据代理对象与目标对象代理关系的创建时机的不同，可以分为静态代理和动态代理。动态代理又根据实现技术的不同分为JDK的Proxy动态代理和CGLIB动态代理。 静态代理 1静态代理就是在代码中指定显式的代理,在编译之前代理关系就已经确定了。在代理类中对同名的方法进行包装，用户通过对代理类的被包装过的方法来调用目标对象的业务方法，同时对目标对象的业务方法进行增强。 JDK动态代理 1jdk的动态代理是通过接口中的方法名对在动态生成的代理类中，调用业务实现类的同名方法。注意:必须是接口,因为jdk底层先创建一个代理类，然后再创建代理类的实例，它的类型是接口类型，不是目标类的类型。JDK动态代理底层也是使用的字节码技术。 CGLIB代理 1cglib是通过继承来实现的，生成的代理类是业务类的子类，通过重写业务方法执行代理。使用CGLib进行代理时一定要注意final修改的类和方法以及是否有无参构造器。CGLib底层使用asm字节码生成的。 代理模式相关的设计模式代理模式和装饰者模式 1目的不同，装饰者模式是为对象加上行为，而代理模式是控制访问，代理模式更加关注通过控制代理人的方式来增强目标对象。增强对象的方式一般是增强对象的某些行为。 代理模式和适配器模式 1适配器模式主要改变所要考虑对象的接口，代理模式不可以改变所代理类的接口。 代理模式演练静态代理 静态代理的代理类是手动编写的，代理关系在编译之前就确立了。通常目标对象在代理类中创建。 目标类接口 1234567891011121314package com.design.pattern.proxy.staticproxy;/** * IRentalHouseService * * @author shunhua * @date 2019-10-03 */public interface IRentalHouseService &#123; /** * 租房方法 */ void rent();&#125; 目标类 123456789101112131415161718192021222324package com.design.pattern.proxy.jdkproxy;import com.design.pattern.proxy.staticproxy.IRentalHouseService;import lombok.extern.slf4j.Slf4j;/** *RentalHouseServiceImpl * * @author shunhua * @date 2019-10-03 */@Slf4jpublic class RentalHouseService implements IRentalHouseService &#123; /** * 出租房子，目标方法 * @return */ @Override public void rent()&#123; log.info(\"1800/月，2室1厅1厨1卫！\"); &#125;&#125; 代理类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.design.pattern.proxy.staticproxy;import lombok.extern.slf4j.Slf4j;/** * RentalHouseServiceProxy 代理类 * * @author shunhua * @date 2019-10-03 */@Slf4jpublic class RentalHouseServiceProxy &#123; /** * 代理对象需要目标对象 */ private RentalHouseService rentalHouseService; /** * 构造方法 */ public RentalHouseServiceProxy()&#123; rentalHouseService = new RentalHouseService(); &#125; /** * 代理方法 */ public void rent()&#123; dialNumber(); rentalHouseService.rent(); signContract(); &#125; /** * 需要房租请联系我，目标方法的前置方法 */ private void dialNumber() &#123; log.info(\"需要租房请致电：123456\"); &#125; /** * 签合同，目标方法的后置方法 */ private void signContract() &#123; log.info(\"房子还满意就可以签合同了！\"); &#125;&#125; 应用层 1234567891011121314151617181920package com.design.pattern.proxy.staticproxy;import org.junit.Test;/** * Client * * @author shunhua * @date 2019-10-03 */public class Client &#123; @Test public void test()&#123; // 租房直接找代理 RentalHouseServiceProxy proxy = new RentalHouseServiceProxy(); proxy.rent(); &#125;&#125; jdk动态代理 jdk动态代理用于目标类有接口的情况。代理类不是手动创建，而是程序运行时动态生成。有时目标对象需要在客户端中创建，这样情况下不能够保护和隐藏目标对象，只是增强了目标方法功能。代理类的名称由三部分构成：$ + Proxy + 数字，数字表示当前JDK的Proxy所生成的代理类的索引，索引从0开始计数。 目标类接口 1234567891011121314package com.design.pattern.proxy.jdkproxy;/** * IRentalHouseService * * @author shunhua * @date 2019-10-03 */public interface IRentalHouseService &#123; /** * 租房方法 */ void rent();&#125; 目标类 123456789101112131415161718192021222324package com.design.pattern.proxy.jdkproxy;import com.design.pattern.proxy.staticproxy.IRentalHouseService;import lombok.extern.slf4j.Slf4j;/** * RentalHouseServiceImpl 目标类 * * @author shunhua * @date 2019-10-03 */@Slf4jpublic class RentalHouseServiceImpl implements IRentalHouseService &#123; /** * 出租房子，目标方法 * @return */ @Override public void rent()&#123; log.info(\"1800/月，2室1厅1厨1卫！\"); &#125;&#125; InvocationHandler实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package com.design.pattern.proxy.jdkproxy;import lombok.extern.slf4j.Slf4j;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;/** * RentalHouseServiceProxy * * @author shunhua * @date 2019-10-03 */@Slf4jpublic class RentalHouseServiceProxy implements InvocationHandler &#123; private IRentalHouseService target; public RentalHouseServiceProxy(IRentalHouseService target) &#123; this.target = target; &#125; /** * 当执行代理对象的代理方法时，代理方法会调用该invoke() * * @param proxy 代理对象 * @param method 目标方法 * @param args 目标方法的参数列表 * @return * @throws Throwable */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; // 调用目标方法前 dialNumber(); // 执行目标方法 Object result = method.invoke(target, args); // 调用目标方法后 signContract(); return result; &#125; /** * 需要房租请联系我，目标方法的前置方法 */ private void dialNumber() &#123; log.info(\"需要租房请致电：123456\"); &#125; /** * 签合同，目标方法的后置方法 */ private void signContract() &#123; log.info(\"房子还满意就可以签合同了！\"); &#125;&#125; 客户端 123456789101112131415161718192021222324252627282930313233package com.design.pattern.proxy.jdkproxy;import org.junit.Test;import java.lang.reflect.Proxy;/** * Client * * @author shunhua * @date 2019-10-04 */public class Client &#123; @Test public void test()&#123; // 创建目标对象 IRentalHouseService target = new RentalHouseServiceImpl(); // 创建代理对象（接口实现类的代理对象） IRentalHouseService proxy = (IRentalHouseService) Proxy.newProxyInstance( target.getClass().getClassLoader(), target.getClass().getInterfaces(), new RentalHouseServiceProxy(target) ); /** * 调用代理对象的代理方法,注意当调用代理对象的代理方法时，InvocationHandler的invoke方法会被自动调用 */ proxy.rent(); &#125;&#125; CGLIB动态代理 CGLIB的底层是通过使用字节码处理框架ASM来转换字节码并生成新的类，代理的目标类可以没有实现接口，也可以有实现的接口。CGLIB使用子类扩展父类的方式来生成代理对象，即CGLIB会动态生成目标类的子类作为代理类，并创建其对象即代理对象。 目标类 123456789101112131415161718192021222324package com.design.pattern.proxy.cglibproxy;import com.design.pattern.proxy.staticproxy.IRentalHouseService;import lombok.extern.slf4j.Slf4j;/** * RentalHouseServiceImpl 目标类 * * @author shunhua * @date 2019-10-03 */@Slf4jpublic class RentalHouseServiceImpl implements IRentalHouseService &#123; /** * 出租房子，目标方法 * @return */ @Override public void rent()&#123; log.info(\"1800/月，2室1厅1厨1卫！\"); &#125;&#125; MethodInterceptor的实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.design.pattern.proxy.cglibproxy;import lombok.extern.slf4j.Slf4j;import net.sf.cglib.proxy.MethodInterceptor;import net.sf.cglib.proxy.MethodProxy;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;/** * RentalHouseServiceProxy * * @author shunhua * @date 2019-10-03 */@Slf4jpublic class RentalHouseServiceProxy implements MethodInterceptor &#123; /** * * @param o 代理对象 * @param method 目标方法 * @param objects 目标方法参数列表 * @param methodProxy 目标方法的代理对象 * @return * @throws Throwable */ @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; return null; &#125; /** * 需要房租请联系我，目标方法的前置方法 */ private void dialNumber() &#123; log.info(\"需要租房请致电：123456\"); &#125; /** * 签合同，目标方法的后置方法 */ private void signContract() &#123; log.info(\"房子还满意就可以签合同了！\"); &#125;&#125; 生成代理类的逻辑类 1234567891011121314151617181920212223242526272829303132333435package com.design.pattern.proxy.cglibproxy;import net.sf.cglib.proxy.Enhancer;import net.sf.cglib.proxy.MethodInterceptor;/** * CglibProxy 手动创建 * * @author shunhua * @date 2019-10-04 */public class CglibProxy &#123; /** * 创建Cglib的代理对象 * * @param targetClass 目标类 * @param callBack 委托类对象 * @return */ public static IRentalHouseService createCglibProxy(Class targetClass, MethodInterceptor callBack)&#123; // 创建增强其 Enhancer enhancer = new Enhancer(); // 指定目标类 enhancer.setSuperclass(targetClass); // 设置回调接口 enhancer.setCallback(callBack); // 创建并返回代理对象，即目标类的子类对象 return (IRentalHouseService) enhancer.create(); &#125;&#125; 客户端 12345678910111213141516171819202122232425262728293031package com.design.pattern.proxy.cglibproxy;import org.junit.Test;/** * Client * * @author shunhua * @date 2019-10-04 */public class Client &#123; @Test public void test() &#123; // 创建目标对象 IRentalHouseService target = new RentalHouseServiceImpl(); // 创建委托对象 RentalHouseServiceProxy rentalHouseServiceProxy = new RentalHouseServiceProxy(); // 创建代理对象（接口实现类的代理对象） IRentalHouseService cglibProxy = CglibProxy.createCglibProxy(target.getClass(), rentalHouseServiceProxy); /** * 调用代理对象的代理方法,注意当调用代理对象的代理方法时，InvocationHandler的invoke方法会被自动调用 */ cglibProxy.rent(); &#125;&#125; 代理模式在源码中的使用jdk中的应用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490package java.lang.reflect;import java.lang.ref.WeakReference;import java.security.AccessController;import java.security.PrivilegedAction;import java.util.Arrays;import java.util.IdentityHashMap;import java.util.Map;import java.util.Objects;import java.util.concurrent.atomic.AtomicLong;import java.util.function.BiFunction;import sun.misc.ProxyGenerator;import sun.misc.VM;import sun.reflect.CallerSensitive;import sun.reflect.Reflection;import sun.reflect.misc.ReflectUtil;import sun.security.util.SecurityConstants;public class Proxy implements java.io.Serializable &#123; private static final long serialVersionUID = -2222568056686623797L; /** parameter types of a proxy class constructor */ private static final Class&lt;?&gt;[] constructorParams = &#123; InvocationHandler.class &#125;; /** * a cache of proxy classes */ private static final WeakCache&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt; proxyClassCache = new WeakCache&lt;&gt;(new KeyFactory(), new ProxyClassFactory()); /** * the invocation handler for this proxy instance. * @serial */ protected InvocationHandler h; /** * Prohibits instantiation. */ private Proxy() &#123; &#125; /** * Constructs a new &#123;@code Proxy&#125; instance from a subclass * (typically, a dynamic proxy class) with the specified value * for its invocation handler. * * @param h the invocation handler for this proxy instance * * @throws NullPointerException if the given invocation handler, &#123;@code h&#125;, * is &#123;@code null&#125;. */ protected Proxy(InvocationHandler h) &#123; Objects.requireNonNull(h); this.h = h; &#125; @CallerSensitive public static Class&lt;?&gt; getProxyClass(ClassLoader loader, Class&lt;?&gt;... interfaces) throws IllegalArgumentException &#123; final Class&lt;?&gt;[] intfs = interfaces.clone(); final SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; checkProxyAccess(Reflection.getCallerClass(), loader, intfs); &#125; return getProxyClass0(loader, intfs); &#125; /* * Check permissions required to create a Proxy class. * * To define a proxy class, it performs the access checks as in * Class.forName (VM will invoke ClassLoader.checkPackageAccess): * 1. \"getClassLoader\" permission check if loader == null * 2. checkPackageAccess on the interfaces it implements * * To get a constructor and new instance of a proxy class, it performs * the package access check on the interfaces it implements * as in Class.getConstructor. * * If an interface is non-public, the proxy class must be defined by * the defining loader of the interface. If the caller's class loader * is not the same as the defining loader of the interface, the VM * will throw IllegalAccessError when the generated proxy class is * being defined via the defineClass0 method. */ private static void checkProxyAccess(Class&lt;?&gt; caller, ClassLoader loader, Class&lt;?&gt;... interfaces) &#123; SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; ClassLoader ccl = caller.getClassLoader(); if (VM.isSystemDomainLoader(loader) &amp;&amp; !VM.isSystemDomainLoader(ccl)) &#123; sm.checkPermission(SecurityConstants.GET_CLASSLOADER_PERMISSION); &#125; ReflectUtil.checkProxyPackageAccess(ccl, interfaces); &#125; &#125; /** * 生成代理类的核心方法 */ private static Class&lt;?&gt; getProxyClass0(ClassLoader loader, Class&lt;?&gt;... interfaces) &#123; if (interfaces.length &gt; 65535) &#123; throw new IllegalArgumentException(\"interface limit exceeded\"); &#125; // 如果缓存中有对应的代理类就直接获取，没有就创建然后放入缓存 return proxyClassCache.get(loader, interfaces); &#125; /* * a key used for proxy class with 0 implemented interfaces */ private static final Object key0 = new Object(); /* * Key1 and Key2 are optimized for the common use of dynamic proxies * that implement 1 or 2 interfaces. */ /* * a key used for proxy class with 1 implemented interface */ private static final class Key1 extends WeakReference&lt;Class&lt;?&gt;&gt; &#123; private final int hash; Key1(Class&lt;?&gt; intf) &#123; super(intf); this.hash = intf.hashCode(); &#125; @Override public int hashCode() &#123; return hash; &#125; @Override public boolean equals(Object obj) &#123; Class&lt;?&gt; intf; return this == obj || obj != null &amp;&amp; obj.getClass() == Key1.class &amp;&amp; (intf = get()) != null &amp;&amp; intf == ((Key1) obj).get(); &#125; &#125; /* * a key used for proxy class with 2 implemented interfaces */ private static final class Key2 extends WeakReference&lt;Class&lt;?&gt;&gt; &#123; private final int hash; private final WeakReference&lt;Class&lt;?&gt;&gt; ref2; Key2(Class&lt;?&gt; intf1, Class&lt;?&gt; intf2) &#123; super(intf1); hash = 31 * intf1.hashCode() + intf2.hashCode(); ref2 = new WeakReference&lt;Class&lt;?&gt;&gt;(intf2); &#125; @Override public int hashCode() &#123; return hash; &#125; @Override public boolean equals(Object obj) &#123; Class&lt;?&gt; intf1, intf2; return this == obj || obj != null &amp;&amp; obj.getClass() == Key2.class &amp;&amp; (intf1 = get()) != null &amp;&amp; intf1 == ((Key2) obj).get() &amp;&amp; (intf2 = ref2.get()) != null &amp;&amp; intf2 == ((Key2) obj).ref2.get(); &#125; &#125; /* * a key used for proxy class with any number of implemented interfaces * (used here for 3 or more only) */ private static final class KeyX &#123; private final int hash; private final WeakReference&lt;Class&lt;?&gt;&gt;[] refs; @SuppressWarnings(\"unchecked\") KeyX(Class&lt;?&gt;[] interfaces) &#123; hash = Arrays.hashCode(interfaces); refs = (WeakReference&lt;Class&lt;?&gt;&gt;[])new WeakReference&lt;?&gt;[interfaces.length]; for (int i = 0; i &lt; interfaces.length; i++) &#123; refs[i] = new WeakReference&lt;&gt;(interfaces[i]); &#125; &#125; @Override public int hashCode() &#123; return hash; &#125; @Override public boolean equals(Object obj) &#123; return this == obj || obj != null &amp;&amp; obj.getClass() == KeyX.class &amp;&amp; equals(refs, ((KeyX) obj).refs); &#125; private static boolean equals(WeakReference&lt;Class&lt;?&gt;&gt;[] refs1, WeakReference&lt;Class&lt;?&gt;&gt;[] refs2) &#123; if (refs1.length != refs2.length) &#123; return false; &#125; for (int i = 0; i &lt; refs1.length; i++) &#123; Class&lt;?&gt; intf = refs1[i].get(); if (intf == null || intf != refs2[i].get()) &#123; return false; &#125; &#125; return true; &#125; &#125; /** * A function that maps an array of interfaces to an optimal key where * Class objects representing interfaces are weakly referenced. */ private static final class KeyFactory implements BiFunction&lt;ClassLoader, Class&lt;?&gt;[], Object&gt; &#123; @Override public Object apply(ClassLoader classLoader, Class&lt;?&gt;[] interfaces) &#123; switch (interfaces.length) &#123; case 1: return new Key1(interfaces[0]); // the most frequent case 2: return new Key2(interfaces[0], interfaces[1]); case 0: return key0; default: return new KeyX(interfaces); &#125; &#125; &#125; /** * A factory function that generates, defines and returns the proxy class given * the ClassLoader and array of interfaces. */ private static final class ProxyClassFactory implements BiFunction&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt; &#123; // prefix for all proxy class names private static final String proxyClassNamePrefix = \"$Proxy\"; // next number to use for generation of unique proxy class names private static final AtomicLong nextUniqueNumber = new AtomicLong(); @Override public Class&lt;?&gt; apply(ClassLoader loader, Class&lt;?&gt;[] interfaces) &#123; Map&lt;Class&lt;?&gt;, Boolean&gt; interfaceSet = new IdentityHashMap&lt;&gt;(interfaces.length); for (Class&lt;?&gt; intf : interfaces) &#123; /* * Verify that the class loader resolves the name of this * interface to the same Class object. */ Class&lt;?&gt; interfaceClass = null; try &#123; interfaceClass = Class.forName(intf.getName(), false, loader); &#125; catch (ClassNotFoundException e) &#123; &#125; if (interfaceClass != intf) &#123; throw new IllegalArgumentException( intf + \" is not visible from class loader\"); &#125; /* * Verify that the Class object actually represents an * interface. */ if (!interfaceClass.isInterface()) &#123; throw new IllegalArgumentException( interfaceClass.getName() + \" is not an interface\"); &#125; /* * Verify that this interface is not a duplicate. */ if (interfaceSet.put(interfaceClass, Boolean.TRUE) != null) &#123; throw new IllegalArgumentException( \"repeated interface: \" + interfaceClass.getName()); &#125; &#125; String proxyPkg = null; // package to define proxy class in int accessFlags = Modifier.PUBLIC | Modifier.FINAL; /* * Record the package of a non-public proxy interface so that the * proxy class will be defined in the same package. Verify that * all non-public proxy interfaces are in the same package. */ for (Class&lt;?&gt; intf : interfaces) &#123; int flags = intf.getModifiers(); if (!Modifier.isPublic(flags)) &#123; accessFlags = Modifier.FINAL; String name = intf.getName(); int n = name.lastIndexOf('.'); String pkg = ((n == -1) ? \"\" : name.substring(0, n + 1)); if (proxyPkg == null) &#123; proxyPkg = pkg; &#125; else if (!pkg.equals(proxyPkg)) &#123; throw new IllegalArgumentException( \"non-public interfaces from different packages\"); &#125; &#125; &#125; if (proxyPkg == null) &#123; // if no non-public proxy interfaces, use com.sun.proxy package proxyPkg = ReflectUtil.PROXY_PACKAGE + \".\"; &#125; /* * Choose a name for the proxy class to generate. */ long num = nextUniqueNumber.getAndIncrement(); String proxyName = proxyPkg + proxyClassNamePrefix + num; /* * Generate the specified proxy class. */ byte[] proxyClassFile = ProxyGenerator.generateProxyClass( proxyName, interfaces, accessFlags); try &#123; return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length); &#125; catch (ClassFormatError e) &#123; /* * A ClassFormatError here means that (barring bugs in the * proxy class generation code) there was some other * invalid aspect of the arguments supplied to the proxy * class creation (such as virtual machine limitations * exceeded). */ throw new IllegalArgumentException(e.toString()); &#125; &#125; &#125; // 该方法最终返回一个新的对象（目标对象） @CallerSensitive public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException &#123; Objects.requireNonNull(h); final Class&lt;?&gt;[] intfs = interfaces.clone(); final SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; checkProxyAccess(Reflection.getCallerClass(), loader, intfs); &#125; /* * 生成代理类的核心方法 */ Class&lt;?&gt; cl = getProxyClass0(loader, intfs); /* * Invoke its constructor with the designated invocation handler. */ try &#123; if (sm != null) &#123; checkNewProxyPermission(Reflection.getCallerClass(), cl); &#125; final Constructor&lt;?&gt; cons = cl.getConstructor(constructorParams); final InvocationHandler ih = h; if (!Modifier.isPublic(cl.getModifiers())) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; cons.setAccessible(true); return null; &#125; &#125;); &#125; return cons.newInstance(new Object[]&#123;h&#125;); &#125; catch (IllegalAccessException|InstantiationException e) &#123; throw new InternalError(e.toString(), e); &#125; catch (InvocationTargetException e) &#123; Throwable t = e.getCause(); if (t instanceof RuntimeException) &#123; throw (RuntimeException) t; &#125; else &#123; throw new InternalError(t.toString(), t); &#125; &#125; catch (NoSuchMethodException e) &#123; throw new InternalError(e.toString(), e); &#125; &#125; private static void checkNewProxyPermission(Class&lt;?&gt; caller, Class&lt;?&gt; proxyClass) &#123; SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; if (ReflectUtil.isNonPublicProxyClass(proxyClass)) &#123; ClassLoader ccl = caller.getClassLoader(); ClassLoader pcl = proxyClass.getClassLoader(); // do permission check if the caller is in a different runtime package // of the proxy class int n = proxyClass.getName().lastIndexOf('.'); String pkg = (n == -1) ? \"\" : proxyClass.getName().substring(0, n); n = caller.getName().lastIndexOf('.'); String callerPkg = (n == -1) ? \"\" : caller.getName().substring(0, n); if (pcl != ccl || !pkg.equals(callerPkg)) &#123; sm.checkPermission(new ReflectPermission(\"newProxyInPackage.\" + pkg)); &#125; &#125; &#125; &#125; /** * Returns true if and only if the specified class was dynamically * generated to be a proxy class using the &#123;@code getProxyClass&#125; * method or the &#123;@code newProxyInstance&#125; method. * * &lt;p&gt;The reliability of this method is important for the ability * to use it to make security decisions, so its implementation should * not just test if the class in question extends &#123;@code Proxy&#125;. * * @param cl the class to test * @return &#123;@code true&#125; if the class is a proxy class and * &#123;@code false&#125; otherwise * @throws NullPointerException if &#123;@code cl&#125; is &#123;@code null&#125; */ public static boolean isProxyClass(Class&lt;?&gt; cl) &#123; return Proxy.class.isAssignableFrom(cl) &amp;&amp; proxyClassCache.containsValue(cl); &#125; /** * Returns the invocation handler for the specified proxy instance. * * @param proxy the proxy instance to return the invocation handler for * @return the invocation handler for the proxy instance * @throws IllegalArgumentException if the argument is not a * proxy instance * @throws SecurityException if a security manager, &lt;em&gt;s&lt;/em&gt;, is present * and the caller's class loader is not the same as or an * ancestor of the class loader for the invocation handler * and invocation of &#123;@link SecurityManager#checkPackageAccess * s.checkPackageAccess()&#125; denies access to the invocation * handler's class. */ @CallerSensitive public static InvocationHandler getInvocationHandler(Object proxy) throws IllegalArgumentException &#123; /* * Verify that the object is actually a proxy instance. */ if (!isProxyClass(proxy.getClass())) &#123; throw new IllegalArgumentException(\"not a proxy instance\"); &#125; final Proxy p = (Proxy) proxy; final InvocationHandler ih = p.h; if (System.getSecurityManager() != null) &#123; Class&lt;?&gt; ihClass = ih.getClass(); Class&lt;?&gt; caller = Reflection.getCallerClass(); if (ReflectUtil.needsPackageAccessCheck(caller.getClassLoader(), ihClass.getClassLoader())) &#123; ReflectUtil.checkPackageAccess(ihClass); &#125; &#125; return ih; &#125; private static native Class&lt;?&gt; defineClass0(ClassLoader loader, String name, byte[] b, int off, int len);&#125; Spring中的应用12345678910111213141516public class ProxyFactoryBean extends ProxyCreatorSupport implements FactoryBean&lt;Object&gt;, BeanClassLoaderAware, BeanFactoryAware &#123; //如果不声明，默认单例对象，注解声明多例，则声明多例对象 public Object getObject() throws BeansException &#123; this.initializeAdvisorChain(); if (this.isSingleton()) &#123; return this.getSingletonInstance(); &#125; else &#123; if (this.targetName == null) &#123; this.logger.warn(\"Using non-singleton proxies with singleton targets is often undesirable. Enable prototype proxies by setting the 'targetName' property.\"); &#125; return this.newPrototypeInstance(); &#125; &#125;&#125; 12JdkDynamicAopProxy:对jdk动态代理的封装CglibAopProxy:对类进行代理增强 MyBatis中的应用1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677package org.apache.ibatis.binding;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.util.Map;import java.util.concurrent.ConcurrentHashMap;import org.apache.ibatis.session.SqlSession;/** * @author Lasse Voss */public class MapperProxyFactory&lt;T&gt; &#123; private final Class&lt;T&gt; mapperInterface; private final Map&lt;Method, MapperMethod&gt; methodCache = new ConcurrentHashMap&lt;&gt;(); public MapperProxyFactory(Class&lt;T&gt; mapperInterface) &#123; this.mapperInterface = mapperInterface; &#125; public Class&lt;T&gt; getMapperInterface() &#123; return mapperInterface; &#125; public Map&lt;Method, MapperMethod&gt; getMethodCache() &#123; return methodCache; &#125; @SuppressWarnings(\"unchecked\") protected T newInstance(MapperProxy&lt;T&gt; mapperProxy) &#123; // 生成一个代理对象并返回 return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] &#123; mapperInterface &#125;,); &#125; public T newInstance(SqlSession sqlSession) &#123; final MapperProxy&lt;T&gt; mapperProxy = new MapperProxy&lt;&gt;(sqlSession, mapperInterface, methodCache); return newInstance(mapperProxy); &#125;&#125;/** * MapperProxy代理类的信息 */public class MapperProxy&lt;T&gt; implements InvocationHandler, Serializable &#123; private static final long serialVersionUID = -6424540398559729838L; private final SqlSession sqlSession; private final Class&lt;T&gt; mapperInterface; private final Map&lt;Method, MapperMethod&gt; methodCache; public MapperProxy(SqlSession sqlSession, Class&lt;T&gt; mapperInterface, Map&lt;Method, MapperMethod&gt; methodCache) &#123; this.sqlSession = sqlSession; this.mapperInterface = mapperInterface; this.methodCache = methodCache; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; try &#123; if (Object.class.equals(method.getDeclaringClass())) &#123; return method.invoke(this, args); &#125; else if (isDefaultMethod(method)) &#123; return invokeDefaultMethod(proxy, method, args); &#125; &#125; catch (Throwable t) &#123; throw ExceptionUtil.unwrapThrowable(t); &#125; final MapperMethod mapperMethod = cachedMapperMethod(method); return mapperMethod.execute(sqlSession, args); &#125; private MapperMethod cachedMapperMethod(Method method) &#123; return methodCache.computeIfAbsent(method, k -&gt; new MapperMethod(mapperInterface, method, sqlSession.getConfiguration())); &#125; // ... 等等 ｝","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"单例模式","slug":"design_pattern/creation_type/单例模式","date":"2019-10-01T16:00:00.000Z","updated":"2020-07-04T16:28:45.963Z","comments":true,"path":"posts/f1601c3e/","link":"","permalink":"https://gentryhuang.com/posts/f1601c3e/","excerpt":"","text":"单例模式定义保证一个类仅有一个实例，并提供一个全局访问点。 类型创建型 适用场景12想确保任何情况下都绝对只有一个实例 - 数据库连接池、线程池以及计数器等 优点1234561. 在内存里只有一个实例，减少了内存开销 - 特别是一个对象频繁的创建和销毁，而且在创建和销毁时性能又不能很好的优化2. 可以避免对资源的多重占用 - 如对一个文件进行写操作，由于只有一个实例存在内存中，可以避免对同一个资源文件同时写操作3. 设置全局访问点，严格控制访问 - 对外控制创建的入口 缺点1没有接口，扩展困难，想要扩展需要修改源代码 拓展点1234567891011121. 私有构造器 - 为了禁止从单例类外部调用构造函数创建对象，为了达到目的必须设置构造函数为私有的2. 线程安全 - 线程安全在单例模式设计的过程中非常重要3. 延迟加载 - 延时创建对象4. 序列化和反序列化安全 - 对于单例对象一旦序列化和反序列化，就会对单例进行破坏5. 反射 - 单例模式也要防止反射攻击6. 双重检锁机制7. 单例静态内部类的实现方案 单例模式相关的设计模式单例模式和工厂模式 1在一些业务场景中，我们可以把工厂类设置为单例的 单例模式和享元模式 1在一些业务场景中，要管理很多单例对象，通过享元模式和单例模式结合来完成单例对象的获取，在这种结合场景下，享元模式的应用就类似于单例对象的一个工厂，只不过会获取已经创建好的对象而不会重新创建新的对象。 单例模式类型懒汉式单例模式-非安全 1234567891011121314151617181920212223242526272829303132333435363738394041package com.design.pattern.singleton.lazynosafe;/** * LazyDoubleCheckSingleton 懒汉式-线程不安全 * * @author shunhua * @date 2019-10-02 */public class LazySingleton &#123; /** * 定义LazySingleton属性 */ private static LazySingleton lazySingleton = null; /** * 指定构造方法是私有的 */ private LazySingleton()&#123;&#125; /** * 全局控制点 * @return */ public static LazySingleton getInstance()&#123; /** * 在没有断点干预的情况下，多线程执行和CPU分配有关。为了更清楚的观看多线程执行，可以使用多线程debug来达到控制多个线程的目的 * * 在多线程下有以下几种可能，这里以两个线程解释，线程A和线程B * * 1 当线程B走到if(lazySingleton == null)时，线程A已经执行创建好了对象，此时线程B直接返回线程A创建的对象 * 2 当线程B走到if(lazySingleton == null)时，线程A还没有创建好对象即LazySingleton仍然为空，紧接着线程B的if判断通过，当A创建完对象准备返回lazySingleton即执行return lazySingleton时，线程B创建好了对象并赋值给lazySingleton，此时lazySingleton变量的值是线程B创建的对象引用，会覆盖线程A创建的对象对应的引用，最终线程A和线程B返回的虽然是指向同一个对象（线程B创建的）的引用，但是实质上对象已经创建了两次。 * 3 当线程B走到if(lazySingleton == null)时，线程A还没有创建好对象即LazySingleton仍然为空，仅接着线程B的if判断通过，线程A在线程B创建对象之前返回了，那么最终线程A和线程B都会创建对象，并且返回的对象引用不会相同，它们指向各自创建的对象。 * */ if(lazySingleton == null)&#123; lazySingleton = new LazySingleton(); &#125; return lazySingleton; &#125;&#125; 123456789101112131415161718192021package com.design.pattern.singleton.lazynosafe;import lombok.extern.slf4j.Slf4j;/** * MyThread 实现Runnable接口，实现多线程 * * @author shunhua * @date 2019-10-02 */@Slf4jpublic class MyThread implements Runnable &#123; @Override public void run() &#123; // 获取目标对象 LazySingleton lazySingleton = LazySingleton.getInstance(); // 打印当前执行的线程信息和目标对象信息 log.info(Thread.currentThread().getName() +\" \"+ lazySingleton); &#125;&#125; 懒汉式单例模式安全-锁粒度较大 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.design.pattern.singleton.lazysafebutlockisbig;/** * LazyDoubleCheckSingleton 懒汉式-线程安全但是锁的粒度太大 * * @author shunhua * @date 2019-10-02 */public class LazySingleton &#123; /** * 定义LazySingleton属性 */ private static LazySingleton lazySingleton = null; /** * 指定构造方法是私有的 */ private LazySingleton()&#123;&#125; /** * 全局控制点 * * synchronize加锁的位置不同，线程持有的对象也会不同 * 1 加在静态方法上，持有的是类的class文件，即当前类 * 2 加在非静态方法上，持有的是堆内存中的对象，即执行当前方法的对象 * * @return */ public synchronized static LazySingleton getInstance()&#123; /** * synchronize加锁在静态方法上等同于锁代码块时LazySingleton.class作为持有对象： * * public static LazyDoubleCheckSingleton getInstance()&#123; * synchronized(LazyDoubleCheckSingleton.class)&#123; * if (lazySingleton == null) &#123; * lazySingleton = new LazyDoubleCheckSingleton(); * &#125; * &#125; * return lazySingleton; * &#125; */ if(lazySingleton == null)&#123; lazySingleton = new LazySingleton(); &#125; return lazySingleton; &#125;&#125; 懒汉式单例模式-双重检锁 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768package com.design.pattern.singleton.lazysafedoublecheck;/** * LazyDoubleCheckSingleton 双重检锁，兼顾了性能和线程安全 * * @author shunhua * @date 2019-10-03 */public class LazyDoubleCheckSingleton &#123; /** * 定义LazySingleton属性 ,这里加volatile关键字防止指令重排序和内存可见 */ private volatile static LazyDoubleCheckSingleton lazySingleton = null; /** * 指定构造方法是私有的 */ private LazyDoubleCheckSingleton()&#123;&#125; /** * 全局控制点 * * 双重检锁指的就是两次判断 * * @return */ public static LazyDoubleCheckSingleton getInstance()&#123; /** * 1 这一层if判断如果不使用也能保证线程安全，但是锁的粒度又回到了大粒度版本。使用这一层判断是为了缩小synchronized锁的粒度 * 2 引入了这一层会增加一个隐患-由于指令重排序，走到该层if判断lazySingleton可能确实不为空，但是它指向的对象可能还没有初始化完成，当使用这个对象的时候可能会导致系统异常 */ if(lazySingleton == null)&#123; /** * 加锁 */ synchronized (LazyDoubleCheckSingleton.class)&#123; /** * 这一层if必须要有，因为synchronized锁的粒度小了，不是整个方法，当出现线程进入第一个if块中但被阻塞在同步代码块外时（别的线程拿到了锁在里面创建对象）， * 如果不加该if判断该线程还会创建一个对象，而不会直接返回已经创建好的对象的引用。 */ if(lazySingleton == null)&#123; /** LazyDoubleCheckSingleton = new LazyDoubleCheckSingleton() JVM主要做的事粗略步骤如下： * * 1. 在堆空间里分配内存给这个对象 * 2. 执行构造方法进行初始化，注意此初始化不是类加载过程中的初始化 * 3. 设置lazySingleton指向分配好的内存地址 * 注意：在没有处理指令重排序的情况下2、3两步由于重排序可能步骤会倒置（因为Java语言规范，允许那些在单线程内不会改变单线程程序执行结果的重排序，因为有的重排序可以提高程序执行性能 ），这会可能会造成线程拿到的引用指向的是一个还没有初始化完成的对象，虽然不为空但它还没有执行构造方法，如果恰巧构造方法里面需要对某些参数进行初始化，当使用这个对象还没有初始化的参数时会导致系统异常 * * 详细的步骤如下： * 1. 当遇到new指令时，会先检查这个指定的参数也就是LazyDoubleCheckSingleton能否在常量池中定位到该类的符号引用，并且检查这个符号引用代表的类是否已经执行过类的加载（加载、解析、准备和初始化），如果没有就执行下一步，如果执行了接着虚拟机为新生对象分配内存（此时从虚拟机的视角来说一个新对象已经产生了），紧接着执行new指令执行之后的调用&lt;init&gt;方法。 * 2. 加载 （1 通过类的全限定名获取定义此类的二进制字节流 2 将这个字节流代表的静态存储结构转化为方法区的运行时数据结构即Class中的常量池进入方法区的运行时常量池中 3 在方法区生成一个代表这个类的Class对象） * 3. 验证 （确保Class文件的字节流中包含的信息符合当前虚拟机的要求，确保虚拟机自身安全） * 4. 准备 （在方法区中为类变量分配内存并设置类变量初始值） * 5. 解析 （可能会发生，因为它也可能发生在初始化阶段之后。 主要作用就是将常量池中的符号引用替换为直接引用） * 6. 初始化 （这是类加载过程的最后一步，主要就是执行类构造器&lt;clinit&gt;方法，初始化类变量） * * 最后：设置lazySingleton指向分配好的内存地址 */ lazySingleton = new LazyDoubleCheckSingleton(); &#125; &#125; &#125; return lazySingleton; &#125;&#125; 枚举式单例模式 12345678910111213141516171819202122232425262728293031323334353637383940package com.design.pattern.singleton.enuminstance;/** * EnumInstance 使用枚举的方式实现单例模式 * * 1. 枚举实际上是一个继承Enum的被final修饰的类，它的构造方法（只有有参构造方法）也是私有的。其中枚举常量也是static final的，并且在static代码块中实例化（和恶汉式很像） * 2. 枚举实现的单例防止了序列化攻击（readObject方法执行获取的对象是已经存在的枚举常量）和反射攻击（枚举类的构造函数会判断，如果通过反射调用就抛出异常）以及线程安全 * 3. 推荐使用枚举实现单例 * * @author shunhua * @date 2019-10-03 */public enum EnumInstance &#123; /** * 枚举常量 */ INSTANCE; /** * 枚举的成员变量 */ private Object data; public Object getData() &#123; return data; &#125; public void setData(Object data) &#123; this.data = data; &#125; /** * 暴露给外部的全局点 * * @return */ public static EnumInstance getInstance() &#123; return INSTANCE; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105package com.design.pattern.singleton.enuminstance;import lombok.extern.slf4j.Slf4j;import java.io.*;import java.lang.reflect.Constructor;/** * EnumInstanceTest * * @author shunhua * @date 2019-10-03 */@Slf4jpublic class EnumInstanceTest &#123; public static void main(String[] args) &#123; EnumInstance instance = EnumInstance.getInstance(); instance.setData(new Object()); try &#123; //------------------ 枚举实现的单例，是不受序列化破坏的影响---------------------/ File file = new File(\"singleton\"); // 使用ObjectOutputStream对象输出流，把单例对象写入文件中。注意文件的后缀名带不带都行。如果不指定文件的路径，就默认使用当前工程的目录作为路径 ObjectOutputStream objectOutputStream = new ObjectOutputStream(new FileOutputStream(file)); // 将单例对象写入文件中 objectOutputStream.writeObject(instance); // 使用ObjectInputStream对象输入流，把文件中的单例对象读到内存中 ObjectInputStream objectInputStream = new ObjectInputStream(new FileInputStream(file)); EnumInstance newInstance = (EnumInstance) objectInputStream.readObject(); /** readObject方法调用的核心方法：这个逻辑保证了取出的枚举对象的唯一性 private Enum&lt;?&gt; readEnum(boolean unshared) throws IOException &#123; if (bin.readByte() != TC_ENUM) &#123; throw new InternalError(); &#125; ObjectStreamClass desc = readClassDesc(false); if (!desc.isEnum()) &#123; throw new InvalidClassException(\"non-enum class: \" + desc); &#125; int enumHandle = handles.assign(unshared ? unsharedMarker : null); ClassNotFoundException resolveEx = desc.getResolveException(); if (resolveEx != null) &#123; handles.markException(enumHandle, resolveEx); &#125; // 获取枚举对象的名称，这个是唯一的，它对应一个枚举常量 String name = readString(false); Enum&lt;?&gt; result = null; // 获取枚举对象的Class Class&lt;?&gt; cl = desc.forClass(); if (cl != null) &#123; try &#123; // 通过枚举对象的Class和枚举对象的名称获取对应的枚举常量，没有创建新的对象 @SuppressWarnings(\"unchecked\") Enum&lt;?&gt; en = Enum.valueOf((Class)cl, name); result = en; &#125; catch (IllegalArgumentException ex) &#123; throw (IOException) new InvalidObjectException( \"enum constant \" + name + \" does not exist in \" + cl).initCause(ex); &#125; if (!unshared) &#123; handles.setObject(enumHandle, result); &#125; &#125; handles.finish(enumHandle); passHandle = enumHandle; return result; &#125; */ log.info(\"instance: \" + instance); log.info(\"newInstance: \" + newInstance); log.info(String.format(\"instance [%s] newInstance\", instance == newInstance)); System.out.println(\"------------------------------------------\"); log.info(\"instance: \" + instance.getData()); log.info(\"newInstance: \" + newInstance.getData()); log.info(String.format(\"instance.data [%s] newInstance.data\", instance.getData() == newInstance.getData())); //-------------------------- 枚举实现的单例,不受反射破坏的影响， ----------------/ Class enumClass = EnumInstance.class; Constructor constructor = enumClass.getDeclaredConstructor(); constructor.setAccessible(true); /** * 通过反射调用枚举的构造器（构造器只有有参构造）会抛出异常，防止了反射攻击 */ &#125; catch (Exception e) &#123; log.info(e.getMessage()); &#125; &#125;&#125; 容器单例模式 123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.design.pattern.singleton.containersingleton;import org.apache.commons.lang3.StringUtils;import org.springframework.util.ObjectUtils;import java.util.Map;import java.util.concurrent.ConcurrentHashMap;/** * ContainerSingleton 容器单例模式 * * 统一管理多个实例，节省资源 * * @author shunhua * @date 2019-10-03 */public class ContainerSingleton &#123; /** * 存放对象，相当于一个缓存 */ private static Map&lt;String,Object&gt; SINGLETON_MAP = new ConcurrentHashMap&lt;&gt;(); /** * 多线程情况下不安全，可能导致值的覆盖 * @param key * @param instance */ public static void putInstance(String key,Object instance)&#123; if(StringUtils.isNotBlank(key) &amp;&amp; !ObjectUtils.isEmpty(instance))&#123; if(!SINGLETON_MAP.containsKey(key))&#123; SINGLETON_MAP.put(key,instance); &#125; &#125; &#125; /** * 获取对象 * @param key * @return */ public static Object getInstance(String key)&#123; return SINGLETON_MAP.get(key); &#125;&#125; 饿汉式单例模式 1234567891011121314151617181920212223242526272829303132333435363738394041package com.design.pattern.singleton.hungry;/** * HungrySingleton 饿汉式 * &lt;p&gt; * 1 优点 * 写法简单，类加载（严格来说是类加载过程的初始化阶段以及调用构造函数）的时候就完成了对象的创建，避免了线程同步问题 * 2 缺点 * 类加载的时候就完成了对象的创建，没有延迟效果，如果类的对象从始至终都没有用过，或者只是想获取类的某个类变量，那么还是会创建对象，这无疑造成了内存的浪费 * * * @author shunhua * @date 2019-10-03 */public class HungrySingleton &#123; /** * 私有构造函数 */ private HungrySingleton() &#123; &#125; /** * 声明为final的变量必须在类加载完成时（准确的是类加载初始化的时候，singleton就需要被赋值即HungrySingleton对象的引用）就已经赋值 */ // private final static HungrySingleton singleton = new HungrySingleton(); private final static HungrySingleton singleton; static &#123; singleton = new HungrySingleton(); &#125; /** * 全局访问点 * @return */ public static HungrySingleton getInstance() &#123; return singleton; &#125;&#125; 破坏饿汉式单例-方式1 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.design.pattern.singleton.reflectattackresolve;/** * HungrySingleton 饿汉式 * &lt;p&gt; * 1 优点 * 写法简单，类加载（严格来说是类加载过程的初始化阶段以及调用构造函数）的时候就完成了对象的创建，避免了线程同步问题 * 2 缺点 * 类加载的时候就完成了对象的创建，没有延迟效果，如果类的对象从始至终都没有用过，或者只是想获取类的某个类变量，那么还是会创建对象，这无疑造成了内存的浪费 * * * @author shunhua * @date 2019-10-03 */public class HungrySingleton &#123; // private final static HungrySingleton singleton = new HungrySingleton(); private final static HungrySingleton singleton; /** * 私有构造函数 */ private HungrySingleton() &#123; if(singleton == null)&#123; System.out.println(\"调用构造方法在赋值引用给singleton之前，这是指令重排序带来的可能\"); &#125;else &#123; System.out.println(\"调用构造方法在赋值引用给singleton之后，这是指令重排序带来的可能\"); &#125; &#125; /** * 声明为final的变量必须在类加载完成时（准确的是类加载初始化的时候，singleton就需要被赋值即HungrySingleton对象的引用）就已经赋值 */ static &#123; singleton = new HungrySingleton(); &#125; /** * 全局访问点 * @return */ public static HungrySingleton getInstance() &#123; return singleton; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package com.design.pattern.singleton.reflectattackresolve;import lombok.extern.slf4j.Slf4j;import java.lang.reflect.Constructor;/** * HungrySingletonTest * * 反射破坏单例模式不容易彻底阻止，没有特别好的方式。 * * @author shunhua * @date 2019-10-03 */@Slf4jpublic class HungrySingletonTest &#123; /** * 对于在类加载的整个过程实例就能创建好的单例模式（恶汉式、静态内部类），为了防止反射攻击，可以在构造方法中进行判断，如果是通过反射创建对象就抛出异常 * * * @param args */ public static void main(String[] args) &#123; try &#123; // 获取hungrySingleton的Class对象 Class objectClass = HungrySingleton.class; // 通过全局访问点拿到单例对象 HungrySingleton instance = HungrySingleton.getInstance(); // 获取声明的构造器 Constructor constructor = objectClass.getDeclaredConstructor(); // 强制设置声明的构造器是可以访问的 constructor.setAccessible(true); // 通过构造器反射创建对象 HungrySingleton newInstance = (HungrySingleton) constructor.newInstance(); log.info(\"instance: \" + instance); log.info(\"newInstance： \" + newInstance); log.info(String.format(\"instance [%s] newInstance\",instance == newInstance)); &#125;catch (Exception e)&#123; log.info(e.getMessage()); &#125; &#125;&#125; 破坏饿汉式单例-方式2 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package com.design.pattern.singleton.serializationdestroysingleton;import java.io.Serializable;/** * HungrySingleton 饿汉式 * &lt;p&gt; * 1 优点 * 写法简单，类加载（严格来说是类加载过程的初始化阶段以及调用构造函数）的时候就完成了对象的创建，避免了线程同步问题 * 2 缺点 * 类加载的时候就完成了对象的创建，没有延迟效果，如果类的对象从始至终都没有用过，或者只是想获取类的某个类变量，那么还是会创建对象，这无疑造成了内存的浪费 * 3 实现Serializable，为了实现序列化 * * @author shunhua * @date 2019-10-03 */public class HungrySingleton implements Serializable &#123; private static final long serialVersionUID = 1136799709809340054L; /** * 私有构造函数 */ private HungrySingleton() &#123; &#125; /** * 声明为final的变量必须在类加载完成时（准确的是类加载初始化的时候，singleton就需要被赋值即HungrySingleton对象的引用）就已经赋值 */ // private final static HungrySingleton singleton = new HungrySingleton(); private final static HungrySingleton singleton; static &#123; singleton = new HungrySingleton(); &#125; /** * 全局访问点 * @return */ public static HungrySingleton getInstance() &#123; return singleton; &#125; /** * 1. 对于使用序列化和反序列化产生新的实例的方式破坏了单例，可以在类中增加readResolve()方法来预防，readResolve（）方法返回单例对象即可 * 2. 这是反序列化机制决定的，在反序列化的时候会判断类如果实现了Serializable或者Externalizable接口又包含readResolve()方法的话，会直接 * 调用readResolve（）方法来获取实例。值得注意的是，readObject方法底层会先通过反射创建一个新的单例实例，然后再通过反射调用readResolve方 * 法获取单例对象。即虽然最后通过readResolve拿到的是已经创建好的对象，但本质上还是通过反射创建了一个新的对象，只是这个新的对象是用来调用readResolve方法 * 返回单例对象而已。 * * * @return */ public Object readResolve()&#123; return singleton; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.design.pattern.singleton.serializationdestroysingleton;import lombok.extern.slf4j.Slf4j;import java.io.*;/** * HungrySingletonTest * * @author shunhua * @date 2019-10-03 */@Slf4jpublic class HungrySingletonTest &#123; public static void main(String[] args) &#123; HungrySingleton instance = HungrySingleton.getInstance(); try &#123; File file = new File(\"singleton\"); // 使用ObjectOutputStream对象输出流，把单例对象写入文件中。注意文件的后缀名带不带都行。如果不指定文件的路径，就默认使用当前工程的目录作为路径 ObjectOutputStream objectOutputStream = new ObjectOutputStream(new FileOutputStream(file)); // 将单例对象写入文件中 objectOutputStream.writeObject(instance); // 使用ObjectInputStream对象输入流，把文件中的单例对象读到内存中 ObjectInputStream objectInputStream = new ObjectInputStream(new FileInputStream(file)); /** * * 如果HungrySingleton类实现了Serializable或者Externalizable接口，那么readObject方法底层会使用反射，调用ObjectStreamClass#newInstance方法创建一个新的单例对象, * 这个单例对象是为了调用它对应的类中的readResolve方法，如果没有实现那两个接口中的任何一个就会返回null。即接着会判断这个新创建的单例对象中有没有readResolve方法，如果 * 有就会通过反射调用这个readResolve方法，最终readObject方法返回的是readResolve方法返回的对象 * */ HungrySingleton newInstance = (HungrySingleton) objectInputStream.readObject(); log.info(\"instance: \" + instance); log.info(\"newInstance: \" + newInstance); log.info(String.format(\"instance [%s] newInstance\", instance == newInstance)); &#125; catch (Exception e) &#123; &#125; &#125;&#125; 静态内部类的单例模式 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package com.design.pattern.singleton.staticinnerclass;/** * StaticInnerClassSingleton 静态内部类的单例模式 ，使用静态内部类也是做延迟初始化单例对象，来降低单例实例的开销即在需要的时候才进行初始化 * * @author shunhua * @date 2019-10-03 */public class StaticInnerClassSingleton &#123; /** * 私有构造器不能少，防止外部创建对象，让外部只能通过全局访问点拿到单例对象 */ private StaticInnerClassSingleton()&#123;&#125; /** * 1. 这个静态内部类要声明为私有的，因为创建对象在它里面，不能让外面访问它 * 2. 如果类没有初始化，需要类立即初始化的常见情况： * （1）new 一个对象 * （2）类中声明的静态方法被调用 * （3）类中声明的一个静态成员被赋值 * （4）类中声明的一个静态成员被使用，并且这个成员不是一个常量（被final修饰，已在编译期把结果放入常量池中的静态字段） * （5）对类进行反射调用 * （6）作为父类（包括接口），其子类被初始化了，那么父类需要先初始化 * （7）执行的主类（包含main方法的类） * * 3.使用静态内部类创建单例对象利用了类加载过程中的初始化阶段的特性： * 虚拟机会保证一个类的类构造器&lt;clinit&gt;方法在多线程环境中被正确地加类的对象初始化锁（这是JVM帮我们自动完成的）、同步，如果多个线程同时去初始化一个类， * 那么只会有一个线程去执行这个类的类构造器方法&lt;clinit&gt;，其他线程都需要阻塞等待，直到活动线程执行&lt;clinit&gt;方法完毕。 * 因此，即使在多线程环境下执行 private static StaticInnerClassSingleton staticInnerClassSingleton = new StaticInnerClassSingleton()语句 * 也不需要关心指令重排序的情况，因为初始化阶段在对类变量赋值的时候只会有一个线程可以执行&lt;clinit&gt;方法，而单线程执行的情况下，指令是否重排序是没有影响的。 */ private static class InnerClass &#123; /** * 1. 初始化时，需要staticInnerClassSingleton赋值，即 new StaticInnerClassSingleton()会被执行。这些都是&lt;clinit&gt;方法执行的结果，而&lt;clinit&gt;方法在多线程环境下只会有一个线程执行，即使这个方法内部涉及重排序也关系。 * 2. 活跃线程初始化类（执行&lt;clinit&gt;方法）后,类已经初始化完成，不会再进行初始化，其他线程直接访问类成员即可 */ private static StaticInnerClassSingleton staticInnerClassSingleton = new StaticInnerClassSingleton(); &#125; /** * 全局访问点 * * 当执行getInstance方法时就去调用InnerClass内部类里面的staticInnerClassSingleton实例，此时InnerClass内部类会被加载到内存里，在类加载的时候就创建对象，和饿汉式一个道理，保证了只有一个实例， * 而且在调用getInstance方法时才进行单例的创建，又具有懒汉式的部分特性。 * @return */ public static StaticInnerClassSingleton getInstance() &#123; /** * 外部访问getInstance这个全局访问点时，会间接访问InnerClass的静态成员，这会导致静态内部类被初始化 */ return InnerClass.staticInnerClassSingleton; &#125;&#125; 单例模式在源码中的使用jdk-RunTime 12345678910111213141516171819202122232425262728293031package java.lang;import java.io.*;import java.util.StringTokenizer;import sun.reflect.CallerSensitive;import sun.reflect.Reflection;/** * Every Java application has a single instance of class * &lt;code&gt;Runtime&lt;/code&gt; that allows the application to interface with * the environment in which the application is running. The current * runtime can be obtained from the &lt;code&gt;getRuntime&lt;/code&gt; method. * &lt;p&gt; * An application cannot create its own instance of this class. * * @author unascribed * @see java.lang.Runtime#getRuntime() * @since JDK1.0 */public class Runtime &#123; private static Runtime currentRuntime = new Runtime(); public static Runtime getRuntime() &#123; return currentRuntime; &#125; private Runtime() &#123;&#125; // ... 省略其他方法&#125; Spring-AbstractFactoryBean 12345678910111213141516171819202122232425262728@Overridepublic final T getObject() throws Exception &#123; if (isSingleton()) &#123; return (this.initialized ? this.singletonInstance : getEarlySingletonInstance()); &#125; else &#123; return createInstance(); &#125;&#125;/** * Determine an 'early singleton' instance, exposed in case of a * circular reference. Not called in a non-circular scenario. */@SuppressWarnings(\"unchecked\")private T getEarlySingletonInstance() throws Exception &#123; Class&lt;?&gt;[] ifcs = getEarlySingletonInterfaces(); if (ifcs == null) &#123; throw new FactoryBeanNotInitializedException( getClass().getName() + \" does not support circular references\"); &#125; if (this.earlySingletonInstance == null) &#123; this.earlySingletonInstance = (T) Proxy.newProxyInstance( this.beanClassLoader, ifcs, new EarlySingletonInvocationHandler()); &#125; return this.earlySingletonInstance;&#125; MyBatis-ErrorContext 12345678910111213141516171819202122232425262728293031323334public class ErrorContext &#123; private static final String LINE_SEPARATOR = System.getProperty(\"line.separator\",\"\\n\"); // 基于ThreadLocal的单例模式，它不是整个应用全局唯一而是线程级别唯一，保证了每个线程各自的错误上下文 private static final ThreadLocal&lt;ErrorContext&gt; LOCAL = new ThreadLocal&lt;&gt;(); private ErrorContext stored; private String resource; private String activity; private String object; private String message; private String sql; private Throwable cause; /** * 私有构造器 */ private ErrorContext() &#123; &#125; /** * 每个线程获取各自的对象 * @return */ public static ErrorContext instance() &#123; ErrorContext context = LOCAL.get(); if (context == null) &#123; context = new ErrorContext(); LOCAL.set(context); &#125; return context; &#125; // ... 等等&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"观察者模式","slug":"design_pattern/behaviour_type/观察者模式","date":"2019-10-01T16:00:00.000Z","updated":"2020-08-09T09:29:21.271Z","comments":true,"path":"posts/9a246216/","link":"","permalink":"https://gentryhuang.com/posts/9a246216/","excerpt":"","text":"定义定义了对象之间的一对多依赖，让多个观察者对象同时监听某一个主题对象，当主题对象发生变化时，它的所有依赖者（观察者）都会收到通知并更新。 类型行为型 适用场景1关联行为场景，建立一套触发机制。如：注某个产品的价格，然后进行通知，其中价格的变动可能会影响一条链，就像是一个触发链条。这样就可以使用观察者模式创建一个种链式发机制。 优点12341. 观察者和被观察者之间建立一个抽象的耦合 - 因为是抽象的耦合关系，不管是增加观察者还是被观察者都很容易扩展2. 支持广播通信 - 类似消息广播，需要监听主题的只需要注册就可以了 缺点123451. 观察者之间有过多的细节依赖、提高了时间消耗及程序复杂度 - 过多的依赖：触发机制和触发链条 - 提高了时间消耗及程序复杂度：如果一个被观察对象有多个直接或间接观察者，一旦被观察者变化，然后发出通知，将所有观察者都通知到会花费一些时间2. 使用要得当，避免循环调用 - 如果在观察者和被观察者之间有循环依赖的话，被观察者（主题对象）会触发它们之间进行循环调用，这样会导致系统崩溃 简单需求学生在学习课程的时候可能会提出问题，而老师则是关注自己的课程，有学生提出自己课程的问题就给出解答 观察者模式演练 被观察者需要继承的类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109package java.util;/** * @since JDK1.0 */public class Observable &#123; private boolean changed = false; private Vector&lt;Observer&gt; obs; /** Construct an Observable with zero Observers. */ public Observable() &#123; obs = new Vector&lt;&gt;(); &#125; /** * * 在观察者列表中增加一个观察者 * * @param o 要添加的观察者对象 * @throws NullPointerException 如果参数传入null会抛出异常 */ public synchronized void addObserver(Observer o) &#123; if (o == null) throw new NullPointerException(); if (!obs.contains(o)) &#123; obs.addElement(o); &#125; &#125; /** * 从观察者列表中删除指定的观察者 * * @param o 要被移出的观察者 出入为null不会抛出异常 */ public synchronized void deleteObserver(Observer o) &#123; obs.removeElement(o); &#125; /** * 通知观察者们，主题对象（被观察者发生了改变），该方法不传参数给观察者们 */ public void notifyObservers() &#123; notifyObservers(null); &#125; /** * 通知观察者们，主题对象（被观察者发生了改变），该方法传参数给观察者们 */ public void notifyObservers(Object arg) &#123; /* * a temporary array buffer, used as a snapshot of the state of * current Observers. */ Object[] arrLocal; synchronized (this) &#123; /* * 在通知观察者们之前会先校验标识主题对象（被观察者）改变的属性，如果没有改变就直接返回不进行通知 */ if (!changed) return; arrLocal = obs.toArray(); clearChanged(); &#125; for (int i = arrLocal.length-1; i&gt;=0; i--) // 通过调用观察者的update方法通知观察者，会把当前主题对象（被观察者对象）传给观察者 ((Observer)arrLocal[i]).update(this, arg); &#125; /** * 清除观察者列表 */ public synchronized void deleteObservers() &#123; obs.removeAllElements(); &#125; /** * 调用这个方法就是说明了主题对象（被观察者发生了改变），设置标识对象为true */ protected synchronized void setChanged() &#123; changed = true; &#125; /** * * 调用这个方法说明主题对象（被观察者）已经不再改变了或者要通知的观察者都通知完了。这个方法会在调用notifyObservers方法自动调用 */ protected synchronized void clearChanged() &#123; changed = false; &#125; /** * 获取主题对象是否改变的标识 */ public synchronized boolean hasChanged() &#123; return changed; &#125; /** * 返回关注主题对象的观察的个数 * * @return the number of observers of this object. */ public synchronized int countObservers() &#123; return obs.size(); &#125;&#125; 观察者需要实现的接口 123456789101112package java.util;/** * @since JDK1.0 */public interface Observer &#123; /** * * 当订阅的主题对象（被观察者）发生改变时，会通过调用 notifyObservers方法来通知所有设计到的观察者，就是通过调用观察者的update方法进行通知的 */ void update(Observable o, Object arg);&#125; 主题类（被观察者） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package com.design.pattern.observer;import lombok.Data;import lombok.extern.slf4j.Slf4j;import java.util.ArrayList;import java.util.List;import java.util.Observable;/** * Course * 1 它下面有问题，Course属于被观察者，也就是主题对象 * 2 作为被观察者必须继承Observable类，标志是可观察的 * * @author shunhua * @date 2019-10-02 */@Data@Slf4jpublic class Course extends Observable &#123; /** * 课程名 */ private String name; /** * 课程对应的问题列表 */ private List&lt;Question&gt; questions = new ArrayList&lt;&gt;(); public Course(String name) &#123; this.name = name; &#125; public void addQuestion(Question question) &#123; questions.add(question); &#125; /** * 主题改变方法 * * @param course */ public void produceQuestion(Course course) &#123; questions.stream().forEach(question -&gt; &#123; log.info(String.format(\"%s在%s提出了问题\", question.getUserName(), course.getName())); /** * 调用父类Observabel中的setChanged方法，把changed标识设置为true,表示主题对象发生了改变,此时观察者和被观察者之间进行通信 */ setChanged(); /** * 通知观察者 */ notifyObservers(question); &#125; ); &#125;&#125; 观察者 123456789101112131415161718192021222324252627282930313233343536373839package com.design.pattern.observer;import lombok.AllArgsConstructor;import lombok.Data;import lombok.extern.slf4j.Slf4j;import java.util.Observable;import java.util.Observer;/** * Teacher * * 1 观察的是课程，而不是问题，问题属于课程 。 Teacher属于观察者 * 2 必须实现Observer接口，表示它是一个观察者 * * @author shunhua * @date 2019-10-02 */@Data@AllArgsConstructor@Slf4jpublic class Teacher implements Observer &#123; /** * 老师名称 */ private String name; /** * * @param o 被观察对象 * @param arg 被观察者的notifyObservers方法传递过来的对象 */ @Override public void update(Observable o, Object arg) &#123; Course course = (Course) o; Question question = (Question) arg; log.info(String.format(\"%s课程被%s同学提出%s的问题，需要%s解答\",course.getName(),question.getUserName(),question.getQuestionContent(),name)); &#125;&#125; 应用辅助类 1234567891011121314151617181920212223package com.design.pattern.observer;import lombok.Builder;import lombok.Data;/** * Question * * @author shunhua * @date 2019-10-02 */@Data@Builderpublic class Question &#123; /** * 问题提问者名称 */ private String userName; /** * 具体问题 */ private String questionContent;&#125; 应用层 123456789101112131415161718192021222324252627282930313233343536package com.design.pattern.observer;import org.junit.Test;/** * Client * * @author shunhua * @date 2019-10-02 */public class Client &#123; @Test public void test()&#123; Course course = new Course(\"《Java从入门到放弃》\"); Teacher teacher = new Teacher(\"Java学院老师\"); Teacher teacher1 = new Teacher(\"鼓励师\"); // 为课程添加观察者 course.addObserver(teacher); course.addObserver(teacher1); // 添加课程的问题 course.addQuestion(Question.builder() .userName(\"gentryhuang\") .questionContent(\"Java学不完，需要放弃吗？\") .build()); course.addQuestion(Question.builder() .userName(\"xw\") .questionContent(\"快看，又一个学Java的转行了，要跑路吗？\") .build()); // 主题对象发生变化（有问题提出了） course.produceQuestion(course); &#125;&#125; 观察者模式源码解析监听器实现方案就是观察者模式实现的一种 Guava中观察者模式的使用 使用@Subscribe进行方法标注 12345678910111213141516171819package com.design.pattern.observer.guava;import com.google.common.eventbus.Subscribe;import lombok.extern.slf4j.Slf4j;/** * GuavaEvent * * @author shunhua * @date 2019-10-02 */@Slf4jpublic class GuavaEvent &#123; @Subscribe public void subscribe(String event)&#123; log.info(\"执行subscribe方法，传入参数是：\" + event); &#125;&#125; 在应用层把订阅者进行注册 12345678910111213141516171819202122232425262728293031323334package com.design.pattern.observer.guava;import com.google.common.eventbus.EventBus;import org.junit.Test;/** * GuavaEventTest * * @author shunhua * @date 2019-10-02 */public class GuavaEventTest &#123; @Test public void test() &#123; /** * Guava实现观察者模式的核心类 */ EventBus eventBus = new EventBus(); /** * GuavaEvent中有使用@Subscribe注解标注的方法 */ GuavaEvent guavaEvent = new GuavaEvent(); /** * GuavaEvent的@Subscribe标注的方法 加入到观察者模式中，作为订阅者即观察者 */ eventBus.register(guavaEvent); /** * 调用EventBus的post方法会回调Subscribe标注的方法 */ eventBus.post(\"post的内容\"); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"解释器模式","slug":"design_pattern/behaviour_type/解释器模式","date":"2019-10-01T16:00:00.000Z","updated":"2020-08-09T09:29:48.704Z","comments":true,"path":"posts/30cf0cd2/","link":"","permalink":"https://gentryhuang.com/posts/30cf0cd2/","excerpt":"","text":"定义给定一个语言，定义它的文法（语法）的一种表示，并定义一个解释器，这个解释器使用该表示来解释语言中的句子。即 为了解释一种语言（语言的语法），而为语言创建的解释器 类型行为型 适用场景1在处理日志的时候，由于多个服务产生的日志格式不一定统一，但是数据里面的要素是相同的，这种情况下我们就可以通过程序来解决该问题，而这个程序我们就可以理解为解释器，只不过可以解释不同日志格式。在实际项目中解释器模式使用的比较少，多使用开源包。 优点1语法由很多类表示，容易改变及扩展此“语言”（涉及的代码还不足以说明是种语言） 缺点1当语法规则数目太多时，增加了系统复杂度 简单需求自定义一套可以加法、乘法的语法，使用栈来表示，这和日常的加法和乘法是不一样的。然后定义加法和乘法解释器，解释对应的表达式然后拿到最终的结果。 解释器模式演练 解释器接口 123456789101112131415package com.design.pattern.interpreter;/** * Interpreter 解释接口 * * @author shunhua * @date 2019-10-02 */public interface Interpreter &#123; /** * 解释方法 * @return */ int interpret();&#125; 加法解释器 123456789101112131415161718192021222324252627282930313233343536373839package com.design.pattern.interpreter;/** * AddInterpreter 加法解释器 * * @author shunhua * @date 2019-10-02 */public class AddInterpreter implements Interpreter &#123; /** * 它们的方法返回值作为加数和被加数 */ private Interpreter firstExpression,secondeExpression; /** * 加法需要 加数和被加数 * @param firstExpression * @param secondeExpression */ public AddInterpreter(Interpreter firstExpression,Interpreter secondeExpression)&#123; this.firstExpression = firstExpression; this.secondeExpression = secondeExpression; &#125; /** * 返回两个表达式结果的和 * @return */ @Override public int interpret() &#123; return this.firstExpression.interpret() + this.secondeExpression.interpret(); &#125; @Override public String toString() &#123; return \"+\"; &#125;&#125; 乘法解释器 1234567891011121314151617181920212223242526272829303132333435363738package com.design.pattern.interpreter;/** * MultiInterpreter 乘法解释器 * * @author shunhua * @date 2019-10-02 */public class MultiInterpreter implements Interpreter &#123; /** * 它们的表达式结果作为乘数和被乘除数 */ private Interpreter firstExpression,secondExpression; /** * 乘法需要 乘数和被乘数 * @param firstExpression * @param secondExpression */ public MultiInterpreter(Interpreter firstExpression,Interpreter secondExpression)&#123; this.firstExpression = firstExpression; this.secondExpression = secondExpression; &#125; /** * 乘法解释器的解释方法 * @return */ @Override public int interpret() &#123; return this.firstExpression.interpret() * this.secondExpression.interpret(); &#125; @Override public String toString() &#123; return \"*\"; &#125;&#125; 表达式处理解释器 1234567891011121314151617181920212223242526272829303132333435363738394041// 注意这个解释器就是简单转换数据的package com.design.pattern.interpreter;/** * NumberInterpreter 表达式处理解释器 * * @author shunhua * @date 2019-10-02 */public class NumberInterpreter implements Interpreter &#123; /** * 表达式要返回的值 */ private int number; /** * 数值构造器 * @param number */ public NumberInterpreter(int number)&#123; this.number = number; &#125; /** * 字符串转换构造器 * @param number */ public NumberInterpreter(String number)&#123; this.number = Integer.parseInt(number); &#125; /** * 解释方法 * @return */ @Override public int interpret() &#123; return this.number; &#125;&#125; 封装解释器的处理类–暴露给用户的解释器（它内部是对几个解释器的封装） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.design.pattern.interpreter;import lombok.extern.slf4j.Slf4j;import java.util.Arrays;import java.util.Stack;/** * ExpressionParse * * @author shunhua * @date 2019-10-02 */@Slf4jpublic class ExpressionParse &#123; /** * 定义一个栈，这里是解释器类型栈 */ private Stack&lt;Interpreter&gt; stack = new Stack&lt;&gt;(); public int parse(String str)&#123; String[] strItemArray = str.split(\" \"); Arrays.stream(strItemArray).forEach(symbol -&gt;&#123; // 不是运算符，需要入栈 if(!OperatorUtil.isOperator(symbol))&#123; Interpreter numberExpression = new NumberInterpreter(symbol); stack.push(numberExpression); log.info(String.format(\"入栈：%d\",numberExpression.interpret())); &#125;else &#123; // 是运算符，可以进行计算 Interpreter firstExpression = stack.pop(); Interpreter secondExpression = stack.pop(); log.info(String.format(\"出栈： %d 和 %d\",firstExpression.interpret(),secondExpression.interpret())); Interpreter operator = OperatorUtil.getExpressionObject(firstExpression,secondExpression,symbol); log.info(String.format(\"解释器类型：%s\",operator.toString())); int result = operator.interpret(); NumberInterpreter resultExpression = new NumberInterpreter(result); stack.push(resultExpression); log.info(String.format(\"阶段结果入栈： %d\",resultExpression.interpret())); &#125; &#125;); int result = stack.pop().interpret(); return result; &#125;&#125; 工具类 1234567891011121314151617181920212223242526272829303132333435package com.design.pattern.interpreter;/** * OperatorUtil * * @author shunhua * @date 2019-10-02 */public class OperatorUtil &#123; /** * 是否可操作 * @param symbol * @return */ public static boolean isOperator(String symbol)&#123; return \"+\".equals(symbol) || \"*\".equals(symbol); &#125; /** * 使用解释器进行解释，表达式的结果 * @param firstExpression * @param secondExpression * @param symbol * @return */ public static Interpreter getExpressionObject(Interpreter firstExpression,Interpreter secondExpression,String symbol)&#123; if(\"+\".equals(symbol))&#123; return new AddInterpreter(firstExpression,secondExpression); &#125; else if (\"*\".equals(symbol))&#123; return new MultiInterpreter(firstExpression,secondExpression); &#125; return null; &#125;&#125; 应用 12345678910111213141516171819202122232425package com.design.pattern.interpreter;import lombok.extern.slf4j.Slf4j;import org.junit.Test;/** * Client * * @author shunhua * @date 2019-10-02 */@Slf4jpublic class Client &#123; @Test public void test()&#123; // 输入表达式 String inputStr = \"18 70 12 + *\"; // 对表达式进行解释 ExpressionParse expressionParse = new ExpressionParse(); int result = expressionParse.parse(inputStr); log.info(\"最终解释结果：\" + result); &#125;&#125; 解释器模式在源码中的使用java.util.regex.Pattern 1正则表达式就是一种语法，通过jdk中的正则解释器把它解释出来 123456789101112131415161718192021222324252627282930package com.design.pattern.interpreter;import lombok.extern.slf4j.Slf4j;import org.junit.Test;import java.util.regex.Matcher;import java.util.regex.Pattern;/** * PatternTest * * @author shunhua * @date 2019-10-02 */@Slf4jpublic class PatternTest &#123; @Test public void test()&#123; String str = \"china\"; String patternStr = \"\\\\s+\" + str + \"\\\\s+\"; // 正则解释器，解释正则表达式 Pattern pattern = Pattern.compile(patternStr); String content = \" china becames more and more beautiful! \"; Matcher matcher = pattern.matcher(content); if (matcher.find()) &#123; String content_new = matcher.replaceAll(\"China \"); log.info(String.format(\"old: %s, new: %s\",content,content_new)); &#125; &#125;&#125; Spring的EL解释器 1El表达式是一种语法，通过Spring的解释器去解释 12345678910111213141516171819202122232425262728293031package com.design.pattern.interpreter.resource;import lombok.extern.slf4j.Slf4j;import org.junit.Test;import org.springframework.expression.Expression;import org.springframework.expression.ExpressionParser;import org.springframework.expression.spel.standard.SpelExpressionParser;/** * SpelParserTest * * @author shunhua * @date 2019-10-02 */@Slf4jpublic class SpelParserTest &#123; /** * 使用Spring的语言解释器(ExpressionParser) 解释Spring的EL（解释语言）表达式 */ @Test public void test() &#123; // 创建Spring的语言解释器 ExpressionParser parser = new SpelExpressionParser(); // 使用解释解析Spring的El表达式 Expression expression = parser.parseExpression(\"2 * 100 * 10 + 19\"); // 取出结果 int result = (Integer) expression.getValue(); log.info(\"解释后的结果：\" + result); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"策略模式","slug":"design_pattern/behaviour_type/策略模式","date":"2019-09-27T16:00:00.000Z","updated":"2020-08-09T09:28:54.518Z","comments":true,"path":"posts/72e3b671/","link":"","permalink":"https://gentryhuang.com/posts/72e3b671/","excerpt":"","text":"定义定义了算法家族，分别封装起来，让它们之间可以互相替换，此模式让算法的变化不会影响到使用算法的用户。即把不同的算法封装到不同的类里面，让它们之间可以相互替换， 应用层不会受到影响。 类型行为型 使用场景12341 系统有很多类，而他们的区别仅仅在于它们的行为不同 - 使用策略模式就可以动态地让一个对象在多个行为中选择一种行为，也就是说我们把这个对象不同的行为放到不同的类里面，而每一种行为对应着一种策略2 一个系统需要动态地在几种算法中选择一种 - 这里算法就是策略，策略里面封装的就是一系列逻辑以及计算方式 优点1234561 符合开闭原则 - 策略模式提供了对开闭原则的完美支持，我们可以在不修改原有系统的基础上选择具体的行为2 避免使用多重条件转移语句 - 大量的if...else, switch。 我们把具体的策略行为分离为一个一个的单独的类来替换if...else里面的逻辑，这样写也可以降低代码的耦合3 提高算法的保密性和安全性 - 在使用的时候我们只知道策略的功能，不需要知道具体的细节。在具体的策略类中封装了不同的行为和算法以及相关的数据结构，对于应用层来说，是不需要知道内部的细节的。比如使用Dubbo的服务提供者，不需要知道内部逻辑的细节。 缺点121 应用层必须知道所有的策略类，并自行决定使用哪一个策略类2 产生很多策略类 策略模式相关的设计模式策略模式和工厂模式 121 工厂模式是创建型的设计模式，策略模式是行为型的设计模式2 工厂模式接受指令，创建符合要求的对象。策略模式接受创建好的对象，从而实现不同的行为 策略模式和状态模式 121 使用策略模式的时候，应用层需要知道应该选择哪一种策略。在使用状态模式的时候，应用层是不需要关心具体的状态，这些状态会自动转换2 如果系统中某个类的对象存在多种状态，不同状态下行为又有差异，而且这些状态可以发生转换时可以使用状态模式。如果系统中某个类的某种行为存在多种实现方式，如促销是个行为，这种行为就有多种实现方式，这种情况下应该使用策略模式。 简单需求当当网在双十一或者618的时候会有很多的促销活动，促销是书籍的一个行为，这个促销行为有多种实现。 策略模式演练最基本的使用 策略父类型（这里是接口的方式） 12345678910111213package com.design.pattern.strategy.base;/** * PromotionStrategy 促销策略父类型 * @author shunhua * @date 2019-09-28 */public interface PromotionStrategy &#123; /** * 进行促销 */ void doPromotion();&#125; 具体策略实例 发现策略 123456789101112131415161718192021package com.design.pattern.strategy.base;import lombok.extern.slf4j.Slf4j;/** * FanXianPromotionStrategy 返现（支付金额达到一定数额进行返现到账号）策略 * * @author shunhua * @date 2019-09-28 */@Slf4jpublic class FanXianPromotionStrategy implements PromotionStrategy &#123; /** * 促销 */ @Override public void doPromotion() &#123; log.info(\"返现促销，返回的金额存放到账号的余额中\"); &#125;&#125; 立减优惠策略 123456789101112131415161718192021package com.design.pattern.strategy.base;import lombok.extern.slf4j.Slf4j;/** * LiJianPromotionStrategy 立减（下单立减一定的金额）策略 * * @author shunhua * @date 2019-09-28 */@Slf4jpublic class LiJianPromotionStrategy implements PromotionStrategy &#123; /** * 促销 */ @Override public void doPromotion() &#123; log.info(\"立减促销，书籍的价格直接减去立减活动设置的价格\"); &#125;&#125; 满减策略 123456789101112131415161718192021package com.design.pattern.strategy.base;import lombok.extern.slf4j.Slf4j;/** * ManJianPromotionStrategy 满减（当支付金额达到规定的最低数就进行优惠）策略 * * @author shunhua * @date 2019-09-28 */@Slf4jpublic class ManJianPromotionStrategy implements PromotionStrategy &#123; /** * 促销 */ @Override public void doPromotion() &#123; log.info(\"满减促销，满200减50\"); &#125;&#125; 策略包装类 1234567891011121314151617181920212223242526package com.design.pattern.strategy.base;/** * PromotionActivity 促销活动，包装（使用）策略模式 * * @author shunhua * @date 2019-09-28 */public class PromotionActivity &#123; /** * 促销策略 */ private PromotionStrategy promotionStrategy; public PromotionActivity(PromotionStrategy promotionStrategy)&#123; this.promotionStrategy = promotionStrategy; &#125; /** * 执行具体的促销策略 */ public void execute()&#123; promotionStrategy.doPromotion(); &#125;&#125; 应用层 12345678910111213141516171819202122232425262728293031package com.design.pattern.strategy.base;import com.design.pattern.strategy.base.FanXianPromotionStrategy;import com.design.pattern.strategy.base.ManJianPromotionStrategy;import com.design.pattern.strategy.base.PromotionActivity;import org.junit.Test;/** * Client * * @author shunhua * @date 2019-09-28 */public class Client &#123; @Test public void test()&#123; /** * 618满减活动策略 */ PromotionActivity activity618 = new PromotionActivity(new ManJianPromotionStrategy()); /** * 双11 返现活动策略 */ PromotionActivity activity11 = new PromotionActivity(new FanXianPromotionStrategy()); activity618.execute(); activity11.execute(); &#125;&#125; 小结 1这是策略模式的简单使用，整体上扩展性比较好，想增加策略很方便。 基本使用演进应用层 123456789101112131415161718192021222324252627282930313233343536package com.design.pattern.strategy.v1;import org.junit.Test;import org.springframework.util.ObjectUtils;/** * Client * * @author shunhua * @date 2019-09-28 */public class Client &#123; @Test public void test()&#123; PromotionActivity activity ; // 应用层参数 String promotion = \"FANXIAN\"; switch (promotion)&#123; case \"FANXIAN\" : activity = new PromotionActivity(new FanXianPromotionStrategy()); break; case \"LIJIAN\": activity = new PromotionActivity(new LiJianPromotionStrategy()); break; case \"MANJIAN\": activity = new PromotionActivity(new ManJianPromotionStrategy()); break; default: activity = null; &#125; if(!ObjectUtils.isEmpty(activity))&#123; activity.execute(); &#125; &#125;&#125; 小结 12这种方式和应用交互容易使代码过于臃肿，因为每次需要的时候都会创建策略对象和包装策略的对象，并且过多的选择判断，整个代码看起来不优雅。 优化后版本策略工厂 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package com.design.pattern.strategy.v2;import java.util.Map;import java.util.concurrent.ConcurrentHashMap;/** * PromotionStrategyFactory 促销策略工厂 * * @author shunhua * @date 2019-09-28 */public class PromotionStrategyFactory &#123; /** * 策略集合 */ private final static Map&lt;String,PromotionStrategy&gt; PROMOTION_STRATEGY_MAP = new ConcurrentHashMap&lt;&gt;(); /** * 类加载的时候就开始创建对象 */ static &#123; PROMOTION_STRATEGY_MAP.put(PromotionKey.LIJIAN_STRATEGY,new LiJianPromotionStrategy()); PROMOTION_STRATEGY_MAP.put(PromotionKey.FANXIAN_STRATEGY,new FanXianPromotionStrategy()); PROMOTION_STRATEGY_MAP.put(PromotionKey.MANJIAN_STRATEGY,new ManJianPromotionStrategy()); &#125; /** * 单例的 */ private PromotionStrategyFactory()&#123;&#125; /** * 根据策略模式名获取对应的策略 * @param strategy * @return */ public static PromotionStrategy getPromotionStrategy(String strategy)&#123; return PROMOTION_STRATEGY_MAP.get(strategy); &#125; private interface PromotionKey&#123; /** * 立减策略 */ String LIJIAN_STRATEGY = \"LIJIAN\"; /** * 满减策略 */ String MANJIAN_STRATEGY = \"LIJIAN\"; /** * 返现策略 */ String FANXIAN_STRATEGY = \"FANXIAN\"; &#125;&#125; 应用层 123456789101112131415161718192021222324package com.design.pattern.strategy.v2;import org.junit.Test;import org.springframework.util.ObjectUtils;/** * Client * * @author shunhua * @date 2019-09-28 */public class Client &#123; @Test public void test()&#123; // 应用层参数 String promotion = \"FANXIAN\"; // 使用工厂模式 PromotionActivity activity = new PromotionActivity(PromotionStrategyFactory.getPromotionStrategy(promotion)); if(!ObjectUtils.isEmpty(activity))&#123; activity.execute(); &#125; &#125;&#125; 小结 121. 使用策略工厂防止策略对象频繁创建2. 策略模式常常结合单例、工厂以及享元模式等使用 策略模式源码解析jdk的Comparator 1Comparator就是一个比较策略接口，它有很多的实现，也支持自定义策略，这些策略实现就是一个个策略。 12345678910111213141516171819 /** * 排序会根据具体的排序策略执行 * @since 1.8 */@SuppressWarnings(\"unchecked\")public static &lt;T&gt; void parallelSort(T[] a, Comparator&lt;? super T&gt; cmp) &#123; if (cmp == null) cmp = NaturalOrder.INSTANCE; int n = a.length, p, g; if (n &lt;= MIN_ARRAY_SORT_GRAN || (p = ForkJoinPool.getCommonPoolParallelism()) == 1) TimSort.sort(a, 0, n, cmp, null, 0, 0); else new ArraysParallelSortHelpers.FJObject.Sorter&lt;T&gt; (null, a, (T[])Array.newInstance(a.getClass().getComponentType(), n), 0, n, 0, ((g = n / (p &lt;&lt; 2)) &lt;= MIN_ARRAY_SORT_GRAN) ? MIN_ARRAY_SORT_GRAN : g, cmp).invoke(); &#125; Spring的Resource 1Resource是资源访问接口，它就是一个资源访问相关的策略接口，它有很多的实现类，也就意味着有很多访问资源的策略。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package org.springframework.core.io;import java.io.File;import java.io.IOException;import java.net.URI;import java.net.URL;import java.nio.channels.Channels;import java.nio.channels.ReadableByteChannel;import org.springframework.lang.Nullable;public interface Resource extends InputStreamSource &#123; boolean exists(); default boolean isReadable() &#123; return this.exists(); &#125; default boolean isOpen() &#123; return false; &#125; default boolean isFile() &#123; return false; &#125; URL getURL() throws IOException; URI getURI() throws IOException; File getFile() throws IOException; default ReadableByteChannel readableChannel() throws IOException &#123; return Channels.newChannel(this.getInputStream()); &#125; long contentLength() throws IOException; long lastModified() throws IOException; Resource createRelative(String var1) throws IOException; @Nullable String getFilename(); String getDescription();&#125; Spring的InstantiationStrategy 1Spring初始化策略接口，它的实现类：SimpleInstantiationStrategy和CglibSubclassingInstantiationStrategy初始化策略","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"模版方法模式","slug":"design_pattern/behaviour_type/模版方法模式","date":"2019-09-26T16:00:00.000Z","updated":"2020-08-09T09:27:55.252Z","comments":true,"path":"posts/5029c2a3/","link":"","permalink":"https://gentryhuang.com/posts/5029c2a3/","excerpt":"","text":"定义定义了一个算法的骨架，并允许子类为一个或多个步骤提供实现。模版方法使得子类可以在不改变算法结构的情况下，重新定义算法的某些步骤。 类型行为型 使用场景12◆ 各子类中公共的行为被提取出来并集中到一个公共父类中，从而避免代码重复◆ 一次性实现一个算法的不变的部分，并将可变的行为留给子类来实现 优点123◆提高复用性（将相同代码部分放到抽象父类中）◆提高扩展性◆符合开闭原则 缺点123◆继承关系自身缺点，如果父类添加新的抽象方法，所有子类都要改一遍◆类数目增加◆增加了系统实现的复杂度 模版方法扩展 模版方法中有一个定义：钩子方法。它提供了缺省的行为，子类可以在必要时进行扩展，利用它和父类交互。即构造方法是这个模版对子类更进一步的开放以及扩展。 相关的设计模式模版方法模式和工厂方法模式 工厂方法是模版方法的一种特殊实现 模版方法模式和策略模式 模版方法模式不改变算法流程，策略模式可以改变算法流程，并且策略方法之间是可以相互替换的。策略模式的目的是使不同的算法可以相互替换，并且不影响应用层客户端的使用。模板方法模式是针对定义一个算法的流程，将一些不太一样的具体步骤交给子类去实现。 简单需求某机构要制作一门课程，制作这个课程需要一定的步骤，由于课程的种类不同可能某个步骤不同，但是整体步骤都是一致的。 模版方法演练 抽象课程类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package com.design.pattern.template;import lombok.extern.slf4j.Slf4j;/** * Course 课程抽象类 * * @author shunhua * @date 2019-09-27 */@Slf4jpublic abstract class Course &#123; /** * 模版方法 定义流程的 * 1 该方法的流程是固定的，有些步骤的细节可能因子类不同 * 2 该方法必须申明为final，子类不能重写。 */ protected final void makeCourse()&#123; // 制作PPT makePPT(); // 制作视频 makeVideo(); // 通过构造方法实现所需逻辑 if(needMakeArticle())&#123; // 编写手稿 makeArticle(); &#125; // 打包课程上线 packageCourse(); &#125; /** * 制作PPT是共有的方法，因此是固定的，子类不需要有自己的实现 */ final void makePPT()&#123; log.info(\"制作ppt\"); &#125; /** * 制作视频是共有的方法，因此是固定的，子类不需要有自己的实现 */ final void makeVideo()&#123; log.info(\"制作视频\"); &#125; /** * 编写手记，这个是固定的不需要之类有自己的实现，不过它不一定是共有的，需要看情况 */ final void makeArticle()&#123; log.info(\"编写手记\"); &#125; /** * 钩子方法 子类可以重写用来跟父类交互的。默认是false，不需要手记 */ protected boolean needMakeArticle()&#123; return false; &#125; /** * 打包课程的方法，不同的课程可能包装的不一样，根据子类情况重写 */ abstract void packageCourse();&#125; 课程类1 123456789101112131415161718192021package com.design.pattern.template;import lombok.extern.slf4j.Slf4j;/** * FECourse * * @author shunhua * @date 2019-09-27 */@Slf4jpublic class FECourse extends Course &#123; /** * 重写打包课程的方法 */ @Override void packageCourse() &#123; log.info(\"提供前端课程的源代码和图片素材\"); &#125;&#125; 课程类2 1234567891011121314151617181920212223242526272829303132333435363738package com.design.pattern.template;import lombok.extern.slf4j.Slf4j;/** * JvmCource * * @author shunhua * @date 2019-09-27 */@Slf4jpublic class JvmCource extends Course &#123; private boolean flag = Boolean.FALSE; /** * 通过构造方法设置钩子方法的参数，把钩子方法开放给客户端更加灵活 * * @param flag */ public JvmCource(boolean flag)&#123; this.flag = flag; &#125; @Override void packageCourse() &#123; log.info(\"Jvm课程提供调优工具软件包\"); &#125; /** * 使用钩子方法来和父类交互，增加自己的逻辑 * @return */ @Override protected boolean needMakeArticle() &#123; return flag; &#125;&#125; 客户端 1234567891011121314151617181920212223package com.design.pattern.template;import org.junit.Test;/** * Client * * @author shunhua * @date 2019-09-27 */public class Client &#123; @Test public void test()&#123; Course jvmCourse = new JvmCource(Boolean.TRUE); jvmCourse.makeCourse(); Course feCourse = new FECourse(); feCourse.makeCourse(); &#125;&#125; 模版方法模式源码解析AbstractList(父)-ArrayList(子)AbstractList 1234567public abstract class AbstractList&lt;E&gt; extends AbstractCollection&lt;E&gt; implements List&lt;E&gt; &#123;//get方法为抽象方法，完全交给子类去实现abstract public E get(int index);&#125; ArrayList 12345678910public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable&#123;//子类来实现get方法 public E get(int index) &#123; rangeCheck(index); return elementData(index); &#125;&#125; 同理：AbstractSet、AbstractMap同样采用了模版方法模式 HttpServlet1我们一般继承HttpServlet，然后重写doGet或者doPost等doXxx方法，HttpServlet中定义了一套模版，只要覆写这些方法即可 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; String method = req.getMethod();if (method.equals(METHOD_GET)) &#123; long lastModified = getLastModified(req); if (lastModified == -1) &#123; // servlet doesn't support if-modified-since, no reason // to go through further expensive logic doGet(req, resp); &#125; else &#123; long ifModifiedSince = req.getDateHeader(HEADER_IFMODSINCE); if (ifModifiedSince &lt; (lastModified / 1000 * 1000)) &#123; // If the servlet mod time is later, call doGet() // Round down to the nearest second for a proper compare // A ifModifiedSince of -1 will always be less maybeSetLastModified(resp, lastModified); doGet(req, resp); &#125; else &#123; resp.setStatus(HttpServletResponse.SC_NOT_MODIFIED); &#125; &#125;&#125; else if (method.equals(METHOD_HEAD)) &#123; long lastModified = getLastModified(req); maybeSetLastModified(resp, lastModified); doHead(req, resp);&#125; else if (method.equals(METHOD_POST)) &#123; doPost(req, resp); &#125; else if (method.equals(METHOD_PUT)) &#123; doPut(req, resp); &#125; else if (method.equals(METHOD_DELETE)) &#123; doDelete(req, resp); &#125; else if (method.equals(METHOD_OPTIONS)) &#123; doOptions(req,resp); &#125; else if (method.equals(METHOD_TRACE)) &#123; doTrace(req,resp); &#125; else &#123; // // Note that this means NO servlet supports whatever // method was requested, anywhere on this server. // String errMsg = lStrings.getString(\"http.method_not_implemented\"); Object[] errArgs = new Object[1]; errArgs[0] = method; errMsg = MessageFormat.format(errMsg, errArgs); resp.sendError(HttpServletResponse.SC_NOT_IMPLEMENTED, errMsg);&#125; &#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"迭代器模式","slug":"design_pattern/behaviour_type/迭代器模式","date":"2019-09-26T16:00:00.000Z","updated":"2020-08-09T09:31:35.235Z","comments":true,"path":"posts/9055d217/","link":"","permalink":"https://gentryhuang.com/posts/9055d217/","excerpt":"","text":"定义提供一种方法，顺序访问一个集合对象中的各个元素，而又不暴露该对象的内部细节。 类型行为型 适用场景121 访问一个集合对象的内容而无需暴露它的内部表示2 为遍历不同的集合结构提供一个统一的接口 优点1分离了集合对象的遍历行为，因为抽象出了迭代器来遍历对象，这样就可以通过迭代器来访问集合对象内部元素了。 缺点1类的个数成对增加，由于迭代器模式是将存储数据和遍历数据这个两个职责进行分离，所以当新出现一种集合类就需要增加一种新的对应的迭代器。这样类的个数增加，这在一定程度上增加了系统的复杂性。 迭代器相关的设计模式迭代器模式和访问者模式 121 这两者都是迭代地访问集合对象中的各个元素2 访问者模式中扩展开放的部分在作用于对象的操作上，而在迭代器模式中扩展开放的部分是在集合对象的种类上 说明迭代器模式在日常开发中一般不会自己写，除非我们定义自己的数据结构，然后为这个数据结构实现对应的迭代器。 简单需求课程的增加和删除以及迭代该课程集 迭代器模式演练s 实体类 1234567891011121314151617181920package com.design.pattern.iterator.v2;import lombok.AllArgsConstructor;import lombok.Data;/** * Course 相当于集合中的元素 * * @author shunhua * @date 2019-09-27 */@Data@AllArgsConstructorpublic class Course &#123; /** * 课程的名字 */ private String name;&#125; 集合类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.design.pattern.iterator.v2;import java.util.ArrayList;import java.util.List;/** * MyCollection * * @author shunhua * @date 2019-09-27 */public class MyCollection&lt;T&gt; &#123; /** * 元素集合 */ private final List&lt;T&gt; list = new ArrayList&lt;&gt;(); /** * 增加元素 * @param item */ public void add(T item)&#123; list.add(item); &#125; /** * 移出元素 */ public void remove(T item)&#123; this.list.remove(item); &#125; /** * 删除所有元素 */ public void removeAll()&#123; this.list.removeAll(list); &#125; /** * 获取迭代器，注意需要把实体对象列表传给迭代器 * @return */ public MyIterator iterator()&#123; return new MyIterator(list); &#125;&#125; 迭代器 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.design.pattern.iterator.v2;import java.util.List;/** * MyIterator * * @author shunhua * @date 2019-09-27 */public class MyIterator&lt;T&gt; &#123; /** * 集合 */ private List&lt;T&gt; list ; /** * 游标 */ private int position; /** * 集合中的元素 */ private T item; public MyIterator(List&lt;T&gt; list)&#123; this.list = list; &#125; /** * 是否有下一个元素 * @return */ public boolean hasNext()&#123; if( this.position &lt; list.size())&#123; return true; &#125; return false; &#125; /** * 迭代元素 * @return */ public T next()&#123; T item = list.get(position); position ++; return item; &#125;&#125; 应用层 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.design.pattern.iterator.v2;import com.design.pattern.iterator.v1.Course;import com.design.pattern.iterator.v1.CourseHandler;import com.design.pattern.iterator.v1.CourseHandlerImpl;import com.design.pattern.iterator.v1.CourseIterator;import lombok.extern.slf4j.Slf4j;import org.junit.Test;/** * Client * * @author shunhua * @date 2019-09-27 */@Slf4jpublic class Client &#123; @Test public void test() &#123; Course course1 = new Course(\"Java从入门到放弃\"); Course course2 = new Course(\"MySql从删库到跑路\"); Course course3 = new Course(\"Python从入门到精通\"); MyCollection&lt;Course&gt; collection = new MyCollection(); collection.add(course1); collection.add(course2); collection.add(course3); log.info(\"----------课程列表-------------\"); printCourses(collection); collection.remove(course1); log.info(\"----------删除操作之后的课程---- \"); printCourses(collection); &#125; private void printCourses(MyCollection collection) &#123; MyIterator iterator = collection.iterator(); while (iterator.hasNext()) &#123; Course course = (Course) iterator.next(); log.info(course.toString()); &#125; &#125;&#125; 迭代器模式源码解析ArrayList的迭代器 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667/** ArrayList的内部类实现了Iterator * An optimized version of AbstractList.Itr */private class Itr implements Iterator&lt;E&gt; &#123; int cursor; // index of next element to return int lastRet = -1; // index of last element returned; -1 if no such int expectedModCount = modCount; public boolean hasNext() &#123; return cursor != size; &#125; @SuppressWarnings(\"unchecked\") public E next() &#123; checkForComodification(); int i = cursor; if (i &gt;= size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; return (E) elementData[lastRet = i]; &#125; public void remove() &#123; if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try &#123; ArrayList.this.remove(lastRet); cursor = lastRet; lastRet = -1; expectedModCount = modCount; &#125; catch (IndexOutOfBoundsException ex) &#123; throw new ConcurrentModificationException(); &#125; &#125; @Override @SuppressWarnings(\"unchecked\") public void forEachRemaining(Consumer&lt;? super E&gt; consumer) &#123; Objects.requireNonNull(consumer); final int size = ArrayList.this.size; int i = cursor; if (i &gt;= size) &#123; return; &#125; final Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) &#123; throw new ConcurrentModificationException(); &#125; while (i != size &amp;&amp; modCount == expectedModCount) &#123; consumer.accept((E) elementData[i++]); &#125; // update once at end of iteration to reduce heap write traffic cursor = i; lastRet = i - 1; checkForComodification(); &#125; final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"组合模式","slug":"design_pattern/structure_type/组合模式","date":"2019-09-23T16:00:00.000Z","updated":"2020-08-09T09:36:05.220Z","comments":true,"path":"posts/df879792/","link":"","permalink":"https://gentryhuang.com/posts/df879792/","excerpt":"","text":"定义将对象组合成树形结构以表示“部分-整体”的层次结构。作用是使客户端对单个对象和组合对象保持一致的方式处理。组合模式就是将多个对象组合成一个对象（这些对象具有相同的类型，使用它们的父类型作为统一的对象供客户端访问），简化了对多个对象的访问 类型结构型 使用场景121. 希望客户端可以忽略组合对象与单个对象的差异时2. 处理一个树形结构时 优点1234◆清楚地定义了分层次的复杂对象，表示对象的全部或部分层次◆让客户端忽略了层次的差异，方便对整个层次结构进行控制◆简化客户端代码◆符合开闭原则 缺点121. 限制类型时会较为复杂，因为它们都具有相同的父类型2. 使设计变得更加抽象 相关的设计模式组合模式和访问者模式 可以用访问模式访问组合模式的递归结构 简单需求课程分为不同的类型，每一种类型对应一个课程目录，课程目录下又有很多的课程，要求打印出课程的结构 组合模式的演练 1我们可以通过行为方法进行识别组合模式，组合模式是将相同的抽象类类型或者接口类型转为相同的树状结构，使用抽象作为访问的入口。叶子对象（单个对象）和组合好的对象（包含叶子对象的集合）都要继承或实现相同的父类，这样组合模式才能将它们进行统一处理。 统一抽象类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.design.pattern.composite;/** * 1. 方法中的抛出异常处理，是体现方法不能被使用，因为课程和课程目录使用的方法不同 * 2. 课程和课程目录使用统一类型供客户端访问 * @author shunhua * @date 2019-09-24 */public abstract class CourseComponet &#123; /** * 扩展课程目录 * @param courseComponet */ public void addCatalog(CourseComponet courseComponet)&#123; throw new UnsupportedOperationException(\"不支持添加课程目录操作\"); &#125; /** * 删除课程目录 * @param courseComponet */ public void removeCatalog(CourseComponet courseComponet)&#123; throw new UnsupportedOperationException(\"不支持删除课程目录操作\"); &#125; /** * 获取课程名称 * @param courseComponet * @return */ public String getName(CourseComponet courseComponet)&#123; throw new UnsupportedOperationException(\"不支持获取课程名称操作\"); &#125; /** * 获取课程价格 * @param courseComponet * @return */ public double getPrice(CourseComponet courseComponet)&#123; throw new UnsupportedOperationException(\"不支持获取课程价格操作\"); &#125; /** * 打印信息 */ public void print()&#123; throw new UnsupportedOperationException(\"不支持打印操作\"); &#125;&#125; 课程类 1234567891011121314151617181920212223242526272829303132333435363738394041package com.design.pattern.composite;import lombok.extern.slf4j.Slf4j;&#x2F;** * Course 课程类 * * @author shunhua * @date 2019-09-24 *&#x2F;@Slf4jpublic class Course extends CourseComponet &#123; &#x2F;** * 课程名 *&#x2F; private String courseName; &#x2F;** * 课程价格 *&#x2F; private double price; public Course(String courseName, double price) &#123; this.courseName &#x3D; courseName; this.price &#x3D; price; &#125; @Override public String getName(CourseComponet courseComponet) &#123; return this.courseName; &#125; @Override public double getPrice(CourseComponet courseComponet) &#123; return this.price; &#125; @Override public void print() &#123; log.info(&quot;课程名：&quot; + courseName + &quot;, 课程价格：&quot; + price); &#125;&#125; 课程目录类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package com.design.pattern.composite;import lombok.extern.slf4j.Slf4j;import java.util.ArrayList;import java.util.List;/** * CourseCatalog 课程目录类 * * @author shunhua * @date 2019-09-24 */@Slf4jpublic class CourseCatalog extends CourseComponet &#123; /** * 课程目录下的课程集合 ，这里使用统一抽象类型表示，这里就组合了课程对象 */ private List&lt;CourseComponet&gt; items = new ArrayList&lt;&gt;(); /** * 课程目录名 */ private String catalogName; public CourseCatalog(String catalogName)&#123; this.catalogName = catalogName; &#125; /** * 为课程目录添加课程 * @param courseComponet */ @Override public void addCatalog(CourseComponet courseComponet) &#123; this.items.add(courseComponet); &#125; /** * 删除课程目录中的课程 * @param courseComponet */ @Override public void removeCatalog(CourseComponet courseComponet) &#123; this.items.remove(courseComponet); &#125; @Override public String getName(CourseComponet courseComponet) &#123; return this.catalogName; &#125; /** * 打印目录以及目录下的课程 */ @Override public void print() &#123; log.info(catalogName); for(CourseComponet courseComponet : items)&#123; courseComponet.print(); &#125; &#125;&#125; 客户端 123456789101112131415161718192021222324252627282930313233package com.design.pattern.composite;import org.junit.Test;&#x2F;** * Client 课程目录和课程，对客户端来说都是一个类型的对象 * * @author shunhua * @date 2019-09-24 *&#x2F;public class Client &#123; @Test public void test()&#123; CourseComponet catalog &#x3D; new CourseCatalog(&quot;课程顶级目录&quot;); CourseComponet linuxCourse &#x3D; new Course(&quot;鸟哥私房菜&quot;,80); CourseComponet gitCourse &#x3D; new Course(&quot;Git权威指南&quot;,120); CourseComponet javaCatalog &#x3D; new CourseCatalog(&quot;Java课程目录&quot;); CourseComponet spring &#x3D; new Course(&quot;Spring实战&quot;,70); CourseComponet mybatis &#x3D; new Course(&quot;MyBatis技术内幕&quot;,60); javaCatalog.addCatalog(spring); javaCatalog.addCatalog(mybatis); catalog.addCatalog(linuxCourse); catalog.addCatalog(gitCourse); catalog.addCatalog(javaCatalog); &#x2F;&#x2F; 打印课程目录以及目录下的课程列表 catalog.print(); &#125;&#125; 组合模式源码解析jdk源码之HashMap 1234567891011121314151617181920212223242526272829303132public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable&#123; /** * 方法的入参是Map类型，使用Map类型作为统一的接收参数，不需要关注任何之类型的对象 */ public void putAll(Map&lt;? extends K, ? extends V&gt; m) &#123; int numKeysToBeAdded = m.size(); if (numKeysToBeAdded == 0) return; if (table == EMPTY_TABLE) &#123; inflateTable((int) Math.max(numKeysToBeAdded * loadFactor, threshold)); &#125; if (numKeysToBeAdded &gt; threshold) &#123; int targetCapacity = (int)(numKeysToBeAdded / loadFactor + 1); if (targetCapacity &gt; MAXIMUM_CAPACITY) targetCapacity = MAXIMUM_CAPACITY; int newCapacity = table.length; while (newCapacity &lt; targetCapacity) newCapacity &lt;&lt;= 1; if (newCapacity &gt; table.length) resize(newCapacity); &#125; for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) put(e.getKey(), e.getValue()); &#125;&#125; jdk源码之ArrayList 1234567891011/** * 方法的入参使用统一的父类型Collection，客户端不需要关注具体的子类型对象 */ public boolean addAll(Collection&lt;? extends E&gt; c) &#123; Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount System.arraycopy(a, 0, elementData, size, numNew); size += numNew; return numNew != 0; &#125; MyBatis源码之SqlNode 12MyBatis的sql语句会被解析成不同的SqlNode类型的对象，这些对象都实现了SqlNode。其中MixedSqlNode是联系不同的SqlNode的一个核心对象，组合模式可以统一处理的它们。 12345678910111213141516171819202122package org.apache.ibatis.scripting.xmltags;import java.util.List;public class MixedSqlNode implements SqlNode &#123; /** * SqlNode不同实现的集合 */ private final List&lt;SqlNode&gt; contents; public MixedSqlNode(List&lt;SqlNode&gt; contents) &#123; this.contents = contents; &#125; @Override public boolean apply(DynamicContext context) &#123; for (SqlNode sqlNode : contents) &#123; sqlNode.apply(context); &#125; return true; &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"享元模式","slug":"design_pattern/structure_type/享元模式","date":"2019-09-22T16:00:00.000Z","updated":"2020-08-09T09:33:14.983Z","comments":true,"path":"posts/e19da94a/","link":"","permalink":"https://gentryhuang.com/posts/e19da94a/","excerpt":"","text":"定义提供了减少对象数量从而改善应用的对象结构的方式。运用共享技术有效地支持大量细粒度的对象。即减少创建对象的数量，共享对象，从而减少内存的占用并且提高性能 。注意：享元模式重要的就是共享。 类型结构型 应用场景1234◆ 常常应用于系统底层的开发，以便解决系统的性能问题 如String类型就是使用了享元模式，String对象存在即返回，没有就创建然后放入到字符串常量池中。再比如数据库连接池，里面都是创建好的数据库连接，需要的时候拿来用不需要的时候归还回去。即系统中如果有大量的对象，可能会造成内存溢出，我们可以把共同的部分抽象出来，有相同的业务请求，则返回在内存中的已有对象，避免重新创建◆ 系统有大量相似对象、需要缓冲池的场景 某个对象的复用度越高，越倾向于使用享元模式 优点12◆减少对象的创建，降低内存中对象的数量，降低系统的内存，提高效率◆减少内存之外的其他资源占用(时间资源、文件句柄、窗口句柄等) 缺点1234◆关注内&#x2F;外部状态、关注线程安全问题 我们使用共享模式的时候，大都是使用hashMap，不会用HashTable（因为hashTable会由于同步锁造成效率过低，这样得不偿失），这样就需要在有些场景下关注线程安全问题。同时还要关注内、外部状态。◆使系统、程序的逻辑复杂化 使用了享元对象提高了系统的复杂度，还要分离内外不状态，并且外部状态不应该随着内部状态的变化而变化，否则系统就混乱了。 扩展内部状态 1在享元模式内部并且不会随着环境改变而改变的共享部分；无论外部环境如何变化，我都不变，并且该状态在享元模式内部。可理解为是享元对象的一个属性，这个属性不会与外部交互。 外部状态 1随着环境改变而改变的就是外部状态，这种状态是不可以共享的状态，并且记录在享元模式的外部。可理解为享元对象的一个可以和外界交互的属性，它会随时发生改变。 相关设计模式享元模式和代理模式 1代理模式是代理一个类，如果生成这个代理类花的资源和时间比较多，可以使用享元模式处理这个类的速度 享元模式和单例模式 1容器单例是两种方式的一种结合。享元模式是一种复用对象的思想 简单需求年终了，研发部门Leader可能需要多次地去汇报工作情况，已经有报告结果的就不需要再整理报告了，直接拿到报告就可以去汇报了。没有做过汇报的就需要先整理报告。 享元模式演练 报告 1234567891011121314151617181920212223242526272829303132333435363738package com.design.pattern.flyweight;import lombok.Data;import lombok.extern.slf4j.Slf4j;/** * Presentation 报告类 * * @author shunhua * @date 2019-09-23 */@Data@Slf4jpublic class Presentation &#123; /** * 报告相关部门 */ private String department; /** * 汇报内容 */ private String content; /** * 通过外部状态属性进行构造 * @param department */ public Presentation(String department)&#123; this.department = department; &#125; /** * 报告内容 */ public void report() &#123; log.info(content); &#125;&#125; 报告工厂 1234567891011121314151617181920212223242526272829303132333435363738394041package com.design.pattern.flyweight;import lombok.extern.slf4j.Slf4j;import org.springframework.util.ObjectUtils;import java.util.HashMap;import java.util.Map;/** * PresentationFactory 报告工厂 * * @author shunhua * @date 2019-09-23 */@Slf4jpublic class PresentationFactory &#123; /** * 此处应用了 final修饰 引用成员变量，引用对象的内容可以修改，但是引用地址不可以修改。这里作为报告池。 */ private static final Map&lt;String,Presentation&gt; PRESENTATION_MAP = new HashMap&lt;&gt;(16); /** * 这里不考虑安全问题 * @param department * @return */ public static Presentation getPresentation(String department)&#123; // 先从报告池中获取 Presentation leaderPresentation = PRESENTATION_MAP.get(department); // 报告池中没有再创建一个，然后放到报告池中 if(ObjectUtils.isEmpty(leaderPresentation))&#123; leaderPresentation = new Presentation(department); log.info(\"----------- 报告池中没有需先创建----------\"); PRESENTATION_MAP.put(department,leaderPresentation); leaderPresentation.setContent(\"部门：\" + department +\" 汇报...\"); leaderPresentation.report(); &#125; return leaderPresentation; &#125;&#125; 客户端 12345678910111213141516171819202122package com.design.pattern.flyweight;import org.junit.Test;/** * Client * * @author shunhua * @date 2019-09-23 */public class Client &#123; private final String presentation[] = &#123;\"业务部\",\"研发部\",\"管理部\"&#125;; @Test public void test()&#123; for(int i = 0; i &lt; 20; i++)&#123; String department = presentation[(int)(Math.random() * presentation.length)]; Presentation leaderPresentation = PresentationFactory.getPresentation(department); leaderPresentation.report(); &#125; &#125;&#125; 享元模式源码解析Integer 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public final class Integer extends Number implements Comparable&lt;Integer&gt; &#123; /** * This method will always cache values in the range -128 to 127, * inclusive, and may cache other values outside of this range. * 如果传入的数值在缓存的-127和128之间，那么都会在cache中，否则的话，会new出新的对象，这也是为什么100==100为true，1000==1000为false * @param i an &#123;@code int&#125; value. * @return an &#123;@code Integer&#125; instance representing &#123;@code i&#125;. * @since 1.5 */ public static Integer valueOf(int i) &#123; assert IntegerCache.high &gt;= 127; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); &#125;/** 只要在-128-127，使用 == 判断是可以的，不再这个范围就不能使用==,需要使用equqls * Cache to support the object identity semantics of autoboxing for values between * -128 and 127 (inclusive) as required by JLS. * */ private static class IntegerCache &#123; static final int low = -128; static final int high; static final Integer cache[]; static &#123; // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty(\"java.lang.Integer.IntegerCache.high\"); if (integerCacheHighPropValue != null) &#123; int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); &#125; high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); &#125; private IntegerCache() &#123;&#125; &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"桥接模式","slug":"design_pattern/structure_type/桥接模式","date":"2019-09-20T16:00:00.000Z","updated":"2020-08-09T09:35:41.268Z","comments":true,"path":"posts/563268dc/","link":"","permalink":"https://gentryhuang.com/posts/563268dc/","excerpt":"","text":"定义将抽象部分与它的具体实现部分分离开来，使它们都可以独立地变化（这在一定程度上实现解耦）。桥接模式将继承关系转化成关联关系，它降低了类与类之间的耦合度，减少了系统中类的数量，防止类爆炸。从它的命名可以看出，bridge是桥梁的意思， 将桥两边联系起来。目的就是把两个不同的类之间建立联系，而两个类之间建立联系的方式有很多，而桥接模式是通过组合的方式建立两个不同类之间的关系，而不是继承。这也符合合成复用原则：优先通过组合的方式建立两个类之间联系，而不是继承，继承过多会发生类爆炸的情况。说明一点:这里说的抽象部分和具体实现部分，并不局限一个是抽象的，另一个是具体的实现，这只是从概念上去定义。 1将抽象部分与它的具体实现部分分离，其实这并不是将抽象类与他的派生类分离，而是抽象类和它的派生类用来实现自己的对象。或者说在一个系统的抽象化和实现化之间使用关联关系（组合或者聚合关系）而不是继承关系，从而使两者可以相对独立地变化。 类型结构型 适用场景 抽象和具体实现之间增加更多的灵活性 1使用桥接模式就可以避免在这两个层次之间建立静态的继承关系，而是建立关联关系。此外，抽象部分和具体实现部分，它们都可以分别通过继承关系独立扩展，并且互不影响，就可以动态地将一个抽象化子类的对象和一个具体实现化子类的对象进行组合，这样就把抽象化角色和具体实现化角色实现了解耦。 一个类存在两个（或多个）独立变化的维度，且这两个（或多个）维度都需要独立进行扩展 1抽象的部分可以独立扩展，具体实现也可以独立扩展 不希望使用继承，或因为多层继承导致系统类的个数剧增 优点 分离抽象部分及其具体实现部分 1因为桥接模式使用了组合，使用对象间的关联关系，来解耦了抽象和具体实现之间的固有绑定关系，使抽象和实现可以沿着各自的维度进行扩展、变化。也就是说，抽象和实现不在同一个继承层次结构中，从而通过组合来获得多维度的组合对象。 提高了系统的可扩展性 1在两个变化维度中，扩展任意一个维度都不需要修改原有的系统 符合开闭原则 符合合成复用原则 缺点 增加了系统的理解与设计难度 1由于类之间的关系建立在抽象层，要求我们在编码的时候，一开始就要针对抽象层进行设计和编程 需要正确地识别出系统中两个独立变化的维度 相关设计模式 组合模式 1组合模式更强调的是部分和整体间的组合，而桥接模式强调的是平行级别上不同类的组合 适配器模式 1适配器模式和桥接模式都是为了让两个东西配合工作，但它们两个的目的不一样，适配器模式是改变已有的接口，让它们之间可以相互配合，而桥接模式是分离抽象和具体实现。也就是说，适配器模式可以把功能上相似但是接口不同的类适配起来，而桥接模式是把类的抽象和类的具体实现分离开，然后在此基础上使这些层次结构结合起来。 关键一点桥接模式重要的就是把抽象和具体实现分离开，中间通过组合来搭建它们之间的桥梁 案例分析 场景 121）有两个银行，分别是ABC和ICBC银行，同时有两个账号，分别是定期账号和活期账号。2）使用桥接模式可以 让实现（这里就是账号具体实现）和抽象（这里就是抽象的银行类）分离，银行属性增加修改银行类即可，账号类属性增加修改账号类即可。逻辑清晰，同时也解决了上述类爆炸的情况。 编码 账号接口 Account 12345678910public interface Account &#123; /** * 开户 */ Account openAccount(); /** * 开户类型 */ void showAccountType();&#125; ​ 账号的两个实现类 SavingAccount和 DepositAccount 1234567891011121314151617181920212223242526public class SavingAccount implements Account &#123; @Override public Account openAccount() &#123; System.out.println(\"SavingAccount--开活期账号\"); return new SavingAccount(); &#125; @Override public void showAccountType() &#123; System.out.println(\"SavingAccount--这是一个活期账号\"); &#125;&#125;-----public class DepositAccount implements Account &#123; @Override public Account openAccount() &#123; System.out.println(\"DepositAccount--开定期账号\"); return new DepositAccount(); &#125; @Override public void showAccountType() &#123; System.out.println(\"DepositAccouont--这是一个定期账号\"); &#125;&#125; ​ 银行抽象类 Bank 123456789101112131415161718192021222324252627public abstract class Bank &#123; /** * 这里要写成一个抽象的，因为要把Account引入到Bank里面，通 * 过这种组合的方式，把Account的行为交给Bank的子类来实现，即 * Bank这个抽象类中的某个行为要委托给Account这个接口的实现， * 抽象和具体的实现分离指定的就是这种情况。 */ /** * 要交给子类，声明为protected，这样只有子类能够拿到 */ protected Account account; /** * 通过构造器把Account传过来，也可以通过setter注入的方式赋值 */ public Bank(Account account)&#123; this.account = account; &#125; /** * 这个方法要参照Account接口中的方法，因为Bank里面的具体方法要委托给Account里面 * 的openAccount方法，但这里面方法名不要求一定一致 */ abstract Account openAccount();&#125; ​ 银行抽象类的子类 ABCBank和ICBCBank 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class ABCBank extends Bank &#123; /** * 构造的时候传入的是哪个Account就返回哪一个Account(openAccount方法) * @param account */ public ABCBank(Account account) &#123; super(account); &#125; /** * 这里返回的就是父类中的Account * @return */ @Override Account openAccount() &#123; System.out.println(\"ABCBank--开户中国农业银行账号\"); // 很重要，要使用父类里组合进来的Account，不然桥接模式就没什么意义了 account.openAccount(); return account; &#125;&#125;---public class ICBCBank extends Bank &#123; /** * 构造的时候传入的是哪个Account就返回哪一个Account(openAccount方法) * @param account */ public ICBCBank(Account account) &#123; super(account); &#125; /** * 这里返回的就是父类中的Account * @return */ @Override Account openAccount() &#123; System.out.println(\"ICBC--开户中国工商银行账号\"); // 很重要，要使用父类里组合进来的Account，不然桥接模式就没什么意义了 account.openAccount(); return account; &#125;&#125; 单元测试 TestDemo 1234567891011121314151617181920212223242526272829public class TestDemo &#123; public static void main(String[] args) &#123; // ICBCBank-DepositAccount Bank icbcBank = new ICBCBank(new DepositAccount()); Account icbcAccount = icbcBank.openAccount(); System.out.println(\"**************************\"); icbcAccount.showAccountType(); System.out.println(\"--------------------------\"); // ICBCBank-SavingAccount Bank icbcBank2 = new ICBCBank(new SavingAccount()); Account icbcAccount2 = icbcBank2.openAccount(); System.out.println(\"**************************\"); icbcAccount2.showAccountType(); System.out.println(\"--------------------------\"); // ABCBank-DepositAccount Bank abcBank2 = new ABCBank(new DepositAccount()); Account abcAccount2 = abcBank2.openAccount(); System.out.println(\"**************************\"); abcAccount2.showAccountType(); System.out.println(\"--------------------------\"); // ABCBank-SavingAccount Bank abcBank = new ABCBank(new SavingAccount()); Account abcAccount = abcBank.openAccount(); System.out.println(\"**************************\"); abcAccount.showAccountType(); &#125;&#125; 总结 通过桥接模式，把实现部分Account（Account的具体实现类）和抽象部分Bank（Bank抽象类）进行了桥接，使用组合作为一根线连接它们。当然也有聚合的方式实现桥接。 桥接模式在JDK源码中的应用实现部分1java.sql.Driver接口的实现： 如MySQL的Driver，Oracle的Driver Driver接口 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package java.sql;import java.util.logging.Logger;/** * The interface that every driver class must implement. * &lt;P&gt;The Java SQL framework allows for multiple database drivers. * * &lt;P&gt;Each driver should supply a class that implements * the Driver interface. * * &lt;P&gt;The DriverManager will try to load as many drivers as it can * find and then for any given connection request, it will ask each * driver in turn to try to connect to the target URL. * * &lt;P&gt;It is strongly recommended that each Driver class should be * small and standalone so that the Driver class can be loaded and * queried without bringing in vast quantities of supporting code. * * &lt;P&gt;When a Driver class is loaded, it should create an instance of * itself and register it with the DriverManager. This means that a * user can load and register a driver by calling: * &lt;p&gt; * &#123;@code Class.forName(\"foo.bah.Driver\")&#125; * &lt;p&gt; * A JDBC driver may create a &#123;@linkplain DriverAction&#125; implementation in order * to receive notifications when &#123;@linkplain DriverManager#deregisterDriver&#125; has * been called. * @see DriverManager * @see Connection * @see DriverAction */public interface Driver &#123; Connection connect(String url, java.util.Properties info) throws SQLException; boolean acceptsURL(String url) throws SQLException; DriverPropertyInfo[] getPropertyInfo(String url, java.util.Properties info) throws SQLException; int getMajorVersion(); int getMinorVersion(); boolean jdbcCompliant(); public Logger getParentLogger() throws SQLFeatureNotSupportedException;&#125; Driver接口的MySql驱动实现 123456789101112131415161718192021222324252627282930313233343536373839404142package com.mysql.cj.jdbc;import java.sql.SQLException;/** * The Java SQL framework allows for multiple database drivers. Each driver should supply a class that implements the Driver interface * * &lt;p&gt; * The DriverManager will try to load as many drivers as it can find and then for any given connection request, it will ask each driver in turn to try to * connect to the target URL. * * &lt;p&gt; * It is strongly recommended that each Driver class should be small and standalone so that the Driver class can be loaded and queried without bringing in vast * quantities of supporting code. * * &lt;p&gt; * When a Driver class is loaded, it should create an instance of itself and register it with the DriverManager. This means that a user can load and register a * driver by doing Class.forName(\"foo.bah.Driver\") */public class Driver extends NonRegisteringDriver implements java.sql.Driver &#123; // // Register ourselves with the DriverManager // static &#123; try &#123; // 把驱动注册到DriverManager中 java.sql.DriverManager.registerDriver(new Driver()); &#125; catch (SQLException E) &#123; throw new RuntimeException(\"Can't register driver!\"); &#125; &#125; /** * Construct a new driver and register it with DriverManager * * @throws SQLException * if a database error occurs. */ public Driver() throws SQLException &#123; // Required for Class.forName().newInstance() &#125;&#125; 抽象部分1java.sql.DriverManager这个类作为抽象部分，它并不是抽象类。再次说明，抽象部分并不一定就是抽象类或接口，只是从桥接模式整体看，把它分为两大部分。registeredDrivers作为实现部分组合到抽象部分。 DriverInfo实现部分的父类型接口Driver只是作为DriverInfo的一个属性 123456789101112131415161718192021222324252627282930class DriverInfo &#123; final Driver driver; DriverAction da; DriverInfo(Driver driver, DriverAction action) &#123; this.driver = driver; da = action; &#125; @Override public boolean equals(Object other) &#123; return (other instanceof DriverInfo) &amp;&amp; this.driver == ((DriverInfo) other).driver; &#125; @Override public int hashCode() &#123; return driver.hashCode(); &#125; @Override public String toString() &#123; return (\"driver[className=\" + driver + \"]\"); &#125; DriverAction action() &#123; return da; &#125;&#125; DriverManager 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209 package java.sql; import java.util.Iterator; import java.util.ServiceLoader; import java.security.AccessController; import java.security.PrivilegedAction; import java.util.concurrent.CopyOnWriteArrayList; import sun.reflect.CallerSensitive; import sun.reflect.Reflection; /** * @see Driver * @see Connection */ public class DriverManager &#123; // 注册 JDBC driver 的列表 private final static CopyOnWriteArrayList&lt;DriverInfo&gt; registeredDrivers = new CopyOnWriteArrayList&lt;&gt;(); private static volatile int loginTimeout = 0; private static volatile java.io.PrintWriter logWriter = null; private static volatile java.io.PrintStream logStream = null; // Used in println() to synchronize logWriter private final static Object logSync = new Object(); /* Prevent the DriverManager class from being instantiated. */ private DriverManager()&#123;&#125; /** * Load the initial JDBC drivers by checking the System property * jdbc.properties and then use the &#123;@code ServiceLoader&#125; mechanism */ static &#123; loadInitialDrivers(); println(\"JDBC DriverManager initialized\"); &#125; /** * The &lt;code&gt;SQLPermission&lt;/code&gt; constant that allows the * setting of the logging stream. * @since 1.3 */ final static SQLPermission SET_LOG_PERMISSION = new SQLPermission(\"setLog\"); /** * The &#123;@code SQLPermission&#125; constant that allows the * un-register a registered JDBC driver. * @since 1.8 */ final static SQLPermission DEREGISTER_DRIVER_PERMISSION = new SQLPermission(\"deregisterDriver\"); //--------------------------JDBC 2.0----------------------------- /** * Retrieves the log writer. * * The &lt;code&gt;getLogWriter&lt;/code&gt; and &lt;code&gt;setLogWriter&lt;/code&gt; * methods should be used instead * of the &lt;code&gt;get/setlogStream&lt;/code&gt; methods, which are deprecated. * @return a &lt;code&gt;java.io.PrintWriter&lt;/code&gt; object * @see #setLogWriter * @since 1.2 */ public static java.io.PrintWriter getLogWriter() &#123; return logWriter; &#125; public static void setLogWriter(java.io.PrintWriter out) &#123; SecurityManager sec = System.getSecurityManager(); if (sec != null) &#123; sec.checkPermission(SET_LOG_PERMISSION); &#125; logStream = null; logWriter = out; &#125; @CallerSensitive public static Connection getConnection(String url, java.util.Properties info) throws SQLException &#123; return (getConnection(url, info, Reflection.getCallerClass())); &#125; @CallerSensitive public static Connection getConnection(String url, String user, String password) throws SQLException &#123; java.util.Properties info = new java.util.Properties(); if (user != null) &#123; info.put(\"user\", user); &#125; if (password != null) &#123; info.put(\"password\", password); &#125; return (getConnection(url, info, Reflection.getCallerClass())); &#125; @CallerSensitive public static Connection getConnection(String url) throws SQLException &#123; java.util.Properties info = new java.util.Properties(); return (getConnection(url, info, Reflection.getCallerClass())); &#125; /** * Attempts to locate a driver that understands the given URL. * The &lt;code&gt;DriverManager&lt;/code&gt; attempts to select an appropriate driver from * the set of registered JDBC drivers. * * @param url a database URL of the form * &lt;code&gt;jdbc:&lt;em&gt;subprotocol&lt;/em&gt;:&lt;em&gt;subname&lt;/em&gt;&lt;/code&gt; * @return a &lt;code&gt;Driver&lt;/code&gt; object representing a driver * that can connect to the given URL * @exception SQLException if a database access error occurs */ @CallerSensitive public static Driver getDriver(String url) throws SQLException &#123; println(\"DriverManager.getDriver(\\\"\" + url + \"\\\")\"); Class&lt;?&gt; callerClass = Reflection.getCallerClass(); for (DriverInfo aDriver : registeredDrivers) &#123; // If the caller does not have permission to load the driver then // skip it. if(isDriverAllowed(aDriver.driver, callerClass)) &#123; try &#123; if(aDriver.driver.acceptsURL(url)) &#123; // Success! println(\"getDriver returning \" + aDriver.driver.getClass().getName()); return (aDriver.driver); &#125; &#125; catch(SQLException sqe) &#123; // Drop through and try the next driver. &#125; &#125; else &#123; println(\" skipping: \" + aDriver.driver.getClass().getName()); &#125; &#125; println(\"getDriver: no suitable driver\"); throw new SQLException(\"No suitable driver\", \"08001\"); &#125; /** * Registers the given driver with the &#123;@code DriverManager&#125;. * A newly-loaded driver class should call * the method &#123;@code registerDriver&#125; to make itself * known to the &#123;@code DriverManager&#125;. If the driver is currently * registered, no action is taken. * * @param driver the new JDBC Driver that is to be registered with the * &#123;@code DriverManager&#125; * @exception SQLException if a database access error occurs * @exception NullPointerException if &#123;@code driver&#125; is null */ public static synchronized void registerDriver(java.sql.Driver driver) throws SQLException &#123; registerDriver(driver, null); &#125; /** * Registers the given driver with the &#123;@code DriverManager&#125;. * A newly-loaded driver class should call * the method &#123;@code registerDriver&#125; to make itself * known to the &#123;@code DriverManager&#125;. If the driver is currently * registered, no action is taken. * * @param driver the new JDBC Driver that is to be registered with the * &#123;@code DriverManager&#125; * @param da the &#123;@code DriverAction&#125; implementation to be used when * &#123;@code DriverManager#deregisterDriver&#125; is called * @exception SQLException if a database access error occurs * @exception NullPointerException if &#123;@code driver&#125; is null * @since 1.8 */ public static synchronized void registerDriver(java.sql.Driver driver, DriverAction da) throws SQLException &#123; /* Register the driver if it has not already been added to our list */ if(driver != null) &#123; registeredDrivers.addIfAbsent(new DriverInfo(driver, da)); &#125; else &#123; // This is for compatibility with the original DriverManager throw new NullPointerException(); &#125; println(\"registerDriver: \" + driver); &#125;&#125; ​ ​ ​ ​ ​","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"适配器模式","slug":"design_pattern/structure_type/适配器模式","date":"2019-09-20T16:00:00.000Z","updated":"2020-11-15T09:00:02.919Z","comments":true,"path":"posts/f5c535ea/","link":"","permalink":"https://gentryhuang.com/posts/f5c535ea/","excerpt":"","text":"定义使原本接口不兼容的类（它们的接口不同）可以一起工作（使用同一接口了）。 类型结构型 应用场景12◆已经存在的类，它的方法和需求不匹配时◆不是软件设计阶段考虑的设计模式，是随着软件维护，由于不同产品、不同厂家造成功能类似而接口不相同情况下的解决方案，是软件维护阶段需要考虑的事情 优点123◆能提高类的透明性和复用，现有的类复用但不需要改变，解决了现有类和目标类不匹配的问题◆目标类和适配器类解耦，提高程序扩展性◆符合开闭原则，具体的操作都在适配者中，客户端只知道适配者，扩展只需对适配者扩展即可 缺点12◆适配器编写过程需要全面考虑，可能会增加系统的复杂性◆增加系统代码可读的难度，如我们调用的是A接口实现，其实内部已经被适配成了B接口的实现 扩展12◆对象适配器（符合组合复用原则，并且使用委托机制）◆类适配器（通过类继承实现） 相关的设计模式适配器模式和外观模式 123a 都是现有类现存系统的封装，前者复用原有的接口，后者定义了新的接口b 前者使原有的两个接口协同工作，后者在现有的系统中提供一个更为方便的访问入口c 适配力度不同，后者适配整个子系统 适配器模式演练1类适配器通过 继承关系 达到适配的目的，而对象适配器通过 组合 达到适配目的 类适配器模式 被适配者 12345678910111213141516171819package com.design.pattern.adapter.classadapter;import lombok.extern.slf4j.Slf4j;/** * Adaptee 被适配者 * * @author shunhua * @date 2019-09-21 */@Slf4jpublic class Adaptee &#123; /** * 适配方法，想要和目标类一起工作 */ public void adaptee()&#123; log.info(\"被适配者...run\"); &#125;&#125; 适配器（适配者） 1234567891011121314151617181920212223package com.design.pattern.adapter.classadapter;import lombok.extern.slf4j.Slf4j;/** * Adapter * * @author shunhua * @date 2019-09-21 */@Slf4jpublic class Adapter extends Adaptee implements Target &#123; /** * 1、适配者只是实现目标类的接口，并且继承被适配类，这样使得被适配类拥有目标类相容的接口 * 2、在适配器实现目标接口的方法中调用父类被适配者的方法，这样就可以直接使用被适配者的能力 */ @Override public void run() &#123; // TODO 这里可以添加其他的操作 log.info(\"适配器...run\"); super.adaptee(); &#125;&#125; 目标接口 1234567891011121314package com.design.pattern.adapter.classadapter;/** * Target 目标类接口 * * @author shunhua * @date 2019-09-21 */public interface Target &#123; /** * 目标操作 */ void run();&#125; 目标类 123456789101112131415161718package com.design.pattern.adapter.classadapter;import lombok.extern.slf4j.Slf4j;/** * CurrTarget 目标接口的实现类，可省去，只是作比较 * * @author shunhua * @date 2019-09-21 */@Slf4jpublic class CurrTarget implements Target &#123; @Override public void run() &#123; log.info(\"目标...run\"); &#125;&#125; 客户端 12345678910111213141516171819202122232425package com.design.pattern.adapter.classadapter;import org.junit.Test;/** * Client * * @author shunhua * @date 2019-09-21 */public class Client &#123; @Test public void test()&#123; // 目标类的操作 Target target = new CurrTarget(); // 目标类的方法 target.run(); // 被适配者通过适配器进行适配，可以和目标类一起工作 target = new Adapter(); // 适配者的方法，内部是被适配者的方法 target.run(); &#125;&#125; 对象适配模式 被适配者 12345678910111213141516171819package com.design.pattern.adapter.objectadapter;import lombok.extern.slf4j.Slf4j;/** * Adaptee 被适配者 * * @author shunhua * @date 2019-09-21 */@Slf4jpublic class Adaptee &#123; /** * 适配方法，想要和目标类一起工作 */ public void adaptee()&#123; log.info(\"被适配者...run\"); &#125;&#125; 适配器（适配者） 12345678910111213141516171819202122232425262728package com.design.pattern.adapter.objectadapter;import lombok.extern.slf4j.Slf4j;/** * Adapter * * @author shunhua * @date 2019-09-21 */@Slf4jpublic class Adapter implements Target &#123; /** * 通过组合 （也可以通过注入的方式代替 new 对象的方式，这样方式更常用） */ private Adaptee adaptee = new Adaptee(); /** * 1 适配器是实现了目标类的接口，为了是被适配者和目标类拥有同一接口 * 2 通过组合的方法，直接在适配器实现目标接口的方法中调用被适配者实例的方法 */ @Override public void run() &#123; // TODO 可以根据具体业务增加其他的操作 log.info(\"适配器...run\"); adaptee.adaptee(); &#125;&#125; 目标接口 1234567891011121314package com.design.pattern.adapter.objectadapter;/** * Target 目标类接口 * * @author shunhua * @date 2019-09-21 */public interface Target &#123; /** * 目标操作 */ void run();&#125; 目标类 12345678910111213141516171819package com.design.pattern.adapter.objectadapter;;import lombok.extern.slf4j.Slf4j;/** * CurrTarget 目标接口的实现类，可省去，只是作比较 * * @author shunhua * @date 2019-09-21 */@Slf4jpublic class CurrTarget implements Target &#123; @Override public void run() &#123; log.info(\"目标...run\"); &#125;&#125; 客户端 12345678910111213141516171819202122232425package com.design.pattern.adapter.objectadapter;import org.junit.Test;/** * Client * * @author shunhua * @date 2019-09-22 */public class Client &#123; @Test public void test()&#123; // 目标类 Target target = new CurrTarget(); target.run(); // 通过适配器把被适配者转换成目标接口类型 target = new Adapter(); // 调用适配器实现目标接口的方法，内部调用的是被适配者的方法 target.run(); &#125;&#125; 简单需求1手机电源适配器可以把220v交流电转化为5v直流电 目标接口-5v直流电 123456789101112131415package com.design.pattern.adapter.demand;/** * DC5V 目标电压 * * @author shunhua * @date 2019-09-22 */public interface DC5V &#123; /** * 5V直流电 * @return */ int outPutDC5V();&#125; 需要被适配的类-220v交流电 123456789101112131415161718192021package com.design.pattern.adapter.demand;import lombok.extern.slf4j.Slf4j;/** * AC220V 需要被适配的电压 * * @author shunhua * @date 2019-09-22 */@Slf4jpublic class AC220V &#123; /** * 220V交流电 * @return */ public int outputAC220V()&#123; return 220; &#125;&#125; 变压器-适配器 1234567891011121314151617181920212223242526package com.design.pattern.adapter.demand;import lombok.extern.slf4j.Slf4j;/** * PowerAdapter 电源适配器 * * @author shunhua * @date 2019-09-22 */@Slf4jpublic class PowerAdapter implements DC5V &#123; /** * 通过组合的方式 */ private AC220V ac220V = new AC220V(); @Override public int outPutDC5V() &#123; int ac = ac220V.outputAC220V(); int target = ac/44; // 变压处理 log.info(String.format(\"适配器处理后，%dV电压变为%dV\",220,target)); return 5; &#125;&#125; 客户端 12345678910111213141516171819package com.design.pattern.adapter.demand;import org.junit.Test;/** * Client * * @author shunhua * @date 2019-09-22 */public class Client &#123; @Test public void test() &#123; DC5V dc5V = new PowerAdapter(); // 通过PowerAdapter适配，把220V交流转为5V直流电 dc5V.outPutDC5V(); &#125;&#125; 源码解析12在SpringMVC中，前端控制器接到请求后会通过处理器映射器找处理器，然后返回一个处理器执行链，接着通过匹配处理器适配器来确定哪一个处理器适配器可以适配当前的处理器，确定后执行处理方法，然后返回ModelAndView。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; ModelAndView mv = null; Exception dispatchException = null; try &#123; processedRequest = checkMultipart(request); multipartRequestParsed = (processedRequest != request); // Determine handler for the current request. mappedHandler = getHandler(processedRequest); if (mappedHandler == null) &#123; noHandlerFound(processedRequest, response); return; &#125; // 找到处理器对应的处理器适配器 HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // Process last-modified header, if supported by the handler. String method = request.getMethod(); boolean isGet = \"GET\".equals(method); if (isGet || \"HEAD\".equals(method)) &#123; long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return; &#125; // 实际调用处理器，然后返回ModelAndView mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); if (asyncManager.isConcurrentHandlingStarted()) &#123; return; &#125; applyDefaultViewName(processedRequest, mv); mappedHandler.applyPostHandle(processedRequest, response, mv); &#125; catch (Exception ex) &#123; dispatchException = ex; &#125; catch (Throwable err) &#123; // As of 4.3, we're processing Errors thrown from handler methods as well, // making them available for @ExceptionHandler methods and other scenarios. dispatchException = new NestedServletException(\"Handler dispatch failed\", err); &#125; processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); &#125; catch (Exception ex) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, ex); &#125; catch (Throwable err) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException(\"Handler processing failed\", err)); &#125; finally &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; // Instead of postHandle and afterCompletion if (mappedHandler != null) &#123; mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); &#125; &#125; else &#123; // Clean up any resources used by a multipart request. if (multipartRequestParsed) &#123; cleanupMultipart(processedRequest); &#125; &#125; &#125; &#125; // 处理器映射器找处理器逻辑（返回处理器执行链，包含了处理器）/** * Return the HandlerExecutionChain for this request. * &lt;p&gt;Tries all handler mappings in order. * @param request current HTTP request * @return the HandlerExecutionChain, or &#123;@code null&#125; if no handler could be found */ @Nullable protected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; if (this.handlerMappings != null) &#123; for (HandlerMapping mapping : this.handlerMappings) &#123; HandlerExecutionChain handler = mapping.getHandler(request); if (handler != null) &#123; return handler; &#125; &#125; &#125; return null; &#125; // 匹配合适的处理器适配器逻辑 /** * Return the HandlerAdapter for this handler object. * @param handler the handler object to find an adapter for * @throws ServletException if no HandlerAdapter can be found for the handler. This is a fatal error. */ protected HandlerAdapter getHandlerAdapter(Object handler) throws ServletException &#123; if (this.handlerAdapters != null) &#123; for (HandlerAdapter adapter : this.handlerAdapters) &#123; if (adapter.supports(handler)) &#123; return adapter; &#125; &#125; &#125; throw new ServletException(\"No adapter for handler [\" + handler + \"]: The DispatcherServlet configuration needs to include a HandlerAdapter that supports this handler\"); &#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"装饰者模式","slug":"design_pattern/structure_type/装饰者模式","date":"2019-09-18T16:00:00.000Z","updated":"2020-08-09T09:37:50.231Z","comments":true,"path":"posts/a708a60d/","link":"","permalink":"https://gentryhuang.com/posts/a708a60d/","excerpt":"","text":"定义在不改变原有对象的基础上，将功能附加到对象上。提供了比继承更有弹性的替代方案（扩展原有对象功能）。 类型结构型 应用场景12◆扩展一个类的功能或给一个类添加附加职责◆动态的给一个对象添加功能，这些功能可以再动态的撤销 优点123◆继承的有力补充，比继承灵活，不改变原有对象的情况下给一个对象扩展功能。一般我们可以使用继承实现功能的扩展，如果需要扩展的功能种类繁多，那么势必会生成很多子类，这无疑增加了系统的复杂性。并且使用继承需要提前预知哪些功能，因为继承关系在编译的时候就确定了。而装饰者模式可以动态地加入。其实装饰者模式也是建立在继承的关系基础之上的，注意，这不意味着就不使用继承了，继承也是扩展形式之一，只是某些时候不一定能达到弹性设计的最佳方式。◆通过使用不同装饰类以及这些装饰类的排列组合，可以实现不同效果◆符合开闭原则，装饰者和被装饰者可以独立变化，原有的代码不需要改变。其实装饰者做的是把装饰功能从类中移出去，这样简化了原来被装饰的类，同时把类的核心职责和装饰功能区分开。 缺点12◆会出现更多的代码，更多的类，增加程序复杂性。装饰者模式可能会比继承方式的使用的类要少，但是对象很多，并且这些对象类型是一样的，因为装饰者会继承被装饰类，而被装饰类又有具体的实体，这些实体对象类型又一样，所有排查问题增加了难度。◆动态装饰时，多层装饰时会更复杂 关联的设计模式装饰者模式和代理模式 121 装饰者模式关注动态地添加方法，代理模式关注于控制对对象的访问2 代理模式中的代理类可以对它的客户隐藏一个对象的具体信息，通常在使用代理模式的时候常常在代理类中创建一个对象的实例，装饰者模式通常把原始对象作为一个参数传入装饰者的构造器，这是使用上的不同。 装饰者模式和适配器模式 1231 两者都是包装者模式2 装饰者和被装饰者可以实现相同的接口或者装饰者是被装饰者的子类3 适配器和被适配的类有不同的接口，也有可能是部分接口是重合的 简单需求买煎饼的时候可以根据自身情况要求加鸡蛋或者香肠，卖煎饼的根据需求去做煎饼。 装饰者模式演练非装饰者模式12需求：加一个鸡蛋加一元，一个火腿两元，现在a买一个煎饼，b买加蛋的煎饼，c买加肠的煎饼方案：通过堆积类完成需求，但是面对众多的需求会类爆炸的。 煎饼类 12345678910111213141516171819202122232425package com.design.pattern.decorator.v1;/** * BatterCake 煎饼类 * * @author shunhua * @date 2019-09-19 */public class BatterCake &#123; /** * 获取食品描述 * @return */ public String getDesc()&#123; return \"煎饼\"; &#125; /** * 食品单价 * @return */ public int cost()&#123; return 5; &#125;&#125; 鸡蛋煎饼类 1234567891011121314151617181920package com.design.pattern.decorator.v1;/** * BatterCakeWithEgg 加鸡蛋的煎饼 * * @author shunhua * @date 2019-09-19 */public class BatterCakeWithEgg extends BatterCake &#123; @Override public String getDesc() &#123; return super.getDesc() + \" 加一个鸡蛋\"; &#125; @Override public int cost() &#123; return super.cost() + 1; &#125;&#125; 香肠煎饼类 12345678910111213141516171819package com.design.pattern.decorator.v1;/** * BatterCakeWithSausage 加香肠的煎饼 * * @author shunhua * @date 2019-09-19 */public class BatterCakeWithSausage extends BatterCake &#123; @Override public String getDesc() &#123; return super.getDesc() + \" 加一个香肠\"; &#125; @Override public int cost() &#123; return super.cost() + 2; &#125;&#125; 客户端 1234567891011121314151617181920212223242526272829package com.design.pattern.decorator.v1;import lombok.extern.slf4j.Slf4j;import org.junit.Test;/** * Client * * @author shunhua * @date 2019-09-19 */@Slf4jpublic class Client &#123; @Test public void test()&#123; // 煎饼 BatterCake batterCake = new BatterCake(); log.info(batterCake.getDesc() + \"销售价格为 \" + batterCake.cost()); // 鸡蛋煎饼 BatterCakeWithEgg batterCakeWithEgg = new BatterCakeWithEgg(); log.info(batterCakeWithEgg.getDesc() + \"销售价格为 \" + batterCakeWithEgg.cost()); // 香肠煎饼 BatterCakeWithSausage batterCakeWithSausage = new BatterCakeWithSausage(); log.info(batterCakeWithSausage.getDesc() + \"销售价格为 \" + batterCakeWithEgg.cost()); &#125;&#125; 装饰者模式12需求：现在肠和蛋随机，a 加2蛋2肠 b加1蛋2肠方案：使用装饰类添加功能，为煎饼加鸡蛋、加香肠 要求： 所谓装饰者模式，通用做法要有抽象的实体类和确定的实体类，同时要有抽象的装饰者和确定的装饰者。现在实体类是煎饼，装饰者是鸡蛋和香肠。 关联： 煎饼实体类继承煎饼抽象类，装饰者抽象类也继承煎饼抽象类，通过它们的父类组合来达到煎饼实体类和装饰者抽象类的关系 抽象煎饼类 123456789101112131415161718192021package com.design.pattern.decorator.v2;/** * AbstractBatterCake 抽象煎饼类（也可以是接口） * * @author shunhua * @date 2019-09-19 */public abstract class AbstractBatterCake &#123; /** * 食品描述 * @return */ public abstract String getDesc(); /** * 价格 * @return */ public abstract int cost();&#125; 煎饼类 1234567891011121314151617181920package com.design.pattern.decorator.v2;/** * BatterCake 实体煎饼类 * * @author shunhua * @date 2019-09-19 */public class BatterCake extends AbstractBatterCake &#123; @Override public String getDesc() &#123; return \"煎饼\"; &#125; @Override public int cost() &#123; return 5; &#125;&#125; 抽象装饰类 123456789101112131415161718192021222324252627282930313233343536package com.design.pattern.decorator.v2;/** * * 装饰者同样继承 抽象煎饼类，这是为了方便 ，和煎饼类交互 * * 如果不用构造器的方式，也可以使用set方式 * * @author shunhua * @date 2019-09-19 */public abstract class AbstractDecorator extends AbstractBatterCake &#123; /** * 定义煎饼属性，用于注入 */ private AbstractBatterCake batterCake; public AbstractDecorator(AbstractBatterCake batterCake)&#123; this.batterCake = batterCake; &#125; @Override public String getDesc() &#123; return batterCake.getDesc(); &#125; @Override public int cost() &#123; return batterCake.cost(); &#125; /** * 装饰者实体类特有操作 */ protected abstract void handle();&#125; 鸡蛋装饰类 1234567891011121314151617181920212223242526272829303132package com.design.pattern.decorator.v2;import lombok.extern.slf4j.Slf4j;/** * EggDecorator * * @author shunhua * @date 2019-09-19 */@Slf4jpublic class EggDecorator extends AbstractDecorator &#123; public EggDecorator(AbstractBatterCake batterCake) &#123; super(batterCake); &#125; @Override public String getDesc() &#123; return super.getDesc() + \" 加一个鸡蛋\"; &#125; @Override public int cost() &#123; return super.cost() + 1; &#125; @Override protected void handle() &#123; log.info(\"鸡蛋装饰者特有的处理\"); &#125;&#125; 香肠装饰类 1234567891011121314151617181920212223242526272829303132package com.design.pattern.decorator.v2;import lombok.extern.slf4j.Slf4j;/** * SauseDecorator * * @author shunhua * @date 2019-09-19 */@Slf4jpublic class SauseDecorator extends AbstractDecorator &#123; public SauseDecorator(AbstractBatterCake batterCake) &#123; super(batterCake); &#125; @Override public String getDesc() &#123; return super.getDesc() + \" 加一个香肠\"; &#125; @Override public int cost() &#123; return super.cost() + 2; &#125; @Override protected void handle() &#123; log.info(\"香肠装饰者特有的处理方式\"); &#125;&#125; 客户端 1234567891011121314151617181920212223242526272829package com.design.pattern.decorator.v2;import lombok.extern.slf4j.Slf4j;import org.junit.Test;/** * Client * * @author shunhua * @date 2019-09-19 */@Slf4jpublic class Client &#123; @Test public void test()&#123; AbstractBatterCake batterCake; // 装饰煎饼 batterCake = new BatterCake(); // 鸡蛋装饰 batterCake = new EggDecorator(batterCake); batterCake = new EggDecorator(batterCake); ((EggDecorator) batterCake).handle(); // 香肠装饰 batterCake = new SauseDecorator(batterCake); ((SauseDecorator) batterCake).handle(); log.info(batterCake.getDesc() + \" 一共卖了\" + batterCake.cost() + \"元\"); &#125;&#125; 装饰者模式在源码中的使用BufferedReader 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public class BufferedReader extends Reader &#123; private Reader in; private char cb[]; private int nChars, nextChar; // todo 省略 /** * 对Reader类型的 实例进行包装 */ public BufferedReader(Reader in, int sz) &#123; super(in); if (sz &lt;= 0) throw new IllegalArgumentException(\"Buffer size &lt;= 0\"); this.in = in; cb = new char[sz]; nextChar = nChars = 0; &#125; /** * Creates a buffering character-input stream that uses a default-sized * input buffer. * * @param in A Reader */ public BufferedReader(Reader in) &#123; this(in, defaultCharBufferSize); &#125; /** * 这里使用Reader 类型对象进行操作 */ private void fill() throws IOException &#123; int dst; if (markedChar &lt;= UNMARKED) &#123; /* No mark */ dst = 0; &#125; else &#123; /* Marked */ int delta = nextChar - markedChar; if (delta &gt;= readAheadLimit) &#123; /* Gone past read-ahead limit: Invalidate mark */ markedChar = INVALIDATED; readAheadLimit = 0; dst = 0; &#125; else &#123; if (readAheadLimit &lt;= cb.length) &#123; /* Shuffle in the current buffer */ System.arraycopy(cb, markedChar, cb, 0, delta); markedChar = 0; dst = delta; &#125; else &#123; /* Reallocate buffer to accommodate read-ahead limit */ char ncb[] = new char[readAheadLimit]; System.arraycopy(cb, markedChar, ncb, 0, delta); cb = ncb; markedChar = 0; dst = delta; &#125; nextChar = nChars = delta; &#125; &#125; int n; do &#123; n = in.read(cb, dst, cb.length - dst); &#125; while (n == 0); if (n &gt; 0) &#123; nChars = dst + n; nextChar = dst; &#125; &#125;&#125;/** * 注意Reader是抽象的 */public abstract class Reader implements Readable, Closeable &#123; // todo 省略&#125; InputStream类型作为被装饰类型，它的装饰者有很多，如上图中列出FilerInputStream、BufferedInputStream以及LineInputStream。在装饰者内部本质上都是使用InputStream的实例操作的。 BufferedInputStream 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class BufferedInputStream extends FilterInputStream &#123; private static int DEFAULT_BUFFER_SIZE = 8192; private static int MAX_BUFFER_SIZE = Integer.MAX_VALUE - 8; protected volatile byte buf[]; private static final AtomicReferenceFieldUpdater&lt;BufferedInputStream, byte[]&gt; bufUpdater = AtomicReferenceFieldUpdater.newUpdater (BufferedInputStream.class, byte[].class, \"buf\"); protected int count; protected int pos; protected int markpos = -1; protected int marklimit; private InputStream getInIfOpen() throws IOException &#123; InputStream input = in; if (input == null) throw new IOException(\"Stream closed\"); return input; &#125; /** * 对InputStream类型进行包装 */ public BufferedInputStream(InputStream in) &#123; this(in, DEFAULT_BUFFER_SIZE); &#125; /** * 对InputStream类型进行包装 */ public BufferedInputStream(InputStream in, int size) &#123; super(in); if (size &lt;= 0) &#123; throw new IllegalArgumentException(\"Buffer size &lt;= 0\"); &#125; buf = new byte[size]; &#125;&#125; Servlet的HttpServletRequestWrapper HttpServletRequestWrapper继承了ServletRequestWrapper也实现了HttpServletRequest,它们的公共父类是ServletRequest. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798/** * HttpServletRequestWrapper装饰类 */public class HttpServletRequestWrapper extends ServletRequestWrapper implements HttpServletRequest &#123; /** * 对HttpServletRequest进行装饰，ServletRequestWrapper抽象的装饰者也对HttpServletRequest的父类进行装饰 */ public HttpServletRequestWrapper(HttpServletRequest request) &#123; super(request); &#125; private HttpServletRequest _getHttpServletRequest() &#123; return (HttpServletRequest) super.getRequest(); &#125; /** * The default behavior of this method is to return getAuthType() * on the wrapped request object. */ public String getAuthType() &#123; return this._getHttpServletRequest().getAuthType(); &#125; /** * The default behavior of this method is to return getCookies() * on the wrapped request object. */ public Cookie[] getCookies() &#123; return this._getHttpServletRequest().getCookies(); &#125; /** * The default behavior of this method is to return getDateHeader(String name) * on the wrapped request object. */ public long getDateHeader(String name) &#123; return this._getHttpServletRequest().getDateHeader(name); &#125;&#125;/*** ServletRequestWrapper装饰类*/public class ServletRequestWrapper implements ServletRequest &#123; private ServletRequest request; /** * Creates a ServletRequest adaptor wrapping the given request object. * @throws java.lang.IllegalArgumentException if the request is null */ public ServletRequestWrapper(ServletRequest request) &#123; if (request == null) &#123; throw new IllegalArgumentException(\"Request cannot be null\"); &#125; this.request = request; &#125; /** * Return the wrapped request object. */ public ServletRequest getRequest() &#123; return this.request; &#125; /** * Sets the request object being wrapped. * @throws java.lang.IllegalArgumentException if the request is null. */ public void setRequest(ServletRequest request) &#123; if (request == null) &#123; throw new IllegalArgumentException(\"Request cannot be null\"); &#125; this.request = request; &#125; /** * * The default behavior of this method is to call getAttribute(String name) * on the wrapped request object. */ public Object getAttribute(String name) &#123; return this.request.getAttribute(name); &#125; /** * The default behavior of this method is to return getAttributeNames() * on the wrapped request object. */ public Enumeration getAttributeNames() &#123; return this.request.getAttributeNames(); &#125; &#125; MyBatis的FifoCache MyBatis的Cache模块中使用大量的装饰者模式，在decorators包下都是的，下面列举最近最少使用策略的装饰类。 123456789101112131415161718192021222324252627282930313233343536373839/*** lru算法 最近最少使用*/public class LruCache implements Cache &#123; private final Cache delegate; private Map&lt;Object, Object&gt; keyMap; private Object eldestKey; public LruCache(Cache delegate) &#123; this.delegate = delegate; setSize(1024); &#125; @Override public String getId() &#123; return delegate.getId(); &#125; @Override public int getSize() &#123; return delegate.getSize(); &#125; public void setSize(final int size) &#123; keyMap = new LinkedHashMap&lt;Object, Object&gt;(size, .75F, true) &#123; private static final long serialVersionUID = 4267176411845948333L; @Override protected boolean removeEldestEntry(Map.Entry&lt;Object, Object&gt; eldest) &#123; boolean tooBig = size() &gt; size; if (tooBig) &#123; eldestKey = eldest.getKey(); &#125; return tooBig; &#125; &#125;; &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"外观模式","slug":"design_pattern/structure_type/外观模式","date":"2019-09-16T16:00:00.000Z","updated":"2020-08-09T09:34:58.171Z","comments":true,"path":"posts/f7de8aa8/","link":"","permalink":"https://gentryhuang.com/posts/f7de8aa8/","excerpt":"","text":"定义又叫门面模式，提供了一个统一的接口，用来访问子系统中的一群接口。外观模式定义了一个高层接口，让子系统更容易使用。 类型结构型 使用场景 子系统越来越复杂，增加外观模式提供简单调用接口 构建多层系统结构，利用外观对象作为每层的入口，简化层间调用 优点1234◆简化了调用过程，无需了解深入子系统，防止带来风险(将子系统集成到一起，不去修改子系统)。◆减少系统依赖、松散耦合（客户端与子系统）◆更好的划分访问层次◆符合迪米特法则，即最少知道原则 缺点12◆增加子系统、扩展子系统行为容易引入风险◆增加子系统、扩展子系统行为不符合开闭原则 相关联设计模式对比外观模式和中介者模式 1前者关注外界和子系统的交互，后者关注子系统内部的交互 外观模式和单例模式 1外观模式和单例模式可以结合使用,通常把外观模式中的外观做成单例的 外观模式和抽象工厂模式 1前者可以通过后者获取子系统的实例，子系统可以经内部对外观类进行屏蔽 简单需求 某网站有积分兑换礼物的功能，设计的时候需要校验三步： a 资格校验系统，是木木网会员。 b 积分系统，该系统放的是各个积分的获取支出，需要拿出该用户目前的积分和该礼物所需要的积分进行对比 c 物流系统，如果满足ab，则返回成功，并返回一个订单号。 关注点： 应用层无需知道资格校验类等其他子系统的类 外观模式演练 121. 应用层不关心子系统，应用层只和外观类通信，子系统只和外观类通信2. 如果扩展子系统的，使用实体外观类的话，不符合开闭原则，如果使用抽象外观类或者外观接口，然后用实体继承或实现的话，符合开闭原则。主要看外观对应的子系统群是否变更频繁，不频繁可以使用实体外观，这样更简单。 实体类 1234567891011121314151617181920package com.design.pattern.facade;import lombok.AllArgsConstructor;import lombok.Data;/** * PointsGift 积分兑换礼物 * * @author shunhua * @date 2019-09-17 */@Data@AllArgsConstructorpublic class PointsGift &#123; /** * 礼物名称 */ private String name;&#125; 资格验证系统类 1234567891011121314151617181920212223package com.design.pattern.facade;import lombok.extern.slf4j.Slf4j;/** * QualifyService 校验系统 * * @author shunhua * @date 2019-09-17 */@Slf4jpublic class QualifyService &#123; /** * 校验逻辑，积分是否够 * @param pointsGift * @return */ public boolean isAvailable(PointsGift pointsGift)&#123; log.info(pointsGift.getName() + \"积分通过\"); return true; &#125;&#125; 积分系统类 1234567891011121314151617181920212223package com.design.pattern.facade;import lombok.extern.slf4j.Slf4j;&#x2F;** * PointsPaymentService 积分支付 * * @author shunhua * @date 2019-09-17 *&#x2F;@Slf4jpublic class PointsPaymentService &#123; &#x2F;** * 积分兑换礼物 * @param pointsGift * @return *&#x2F; public boolean pay(PointsGift pointsGift)&#123; log.info(&quot;支付&quot; + pointsGift.getName() + &quot;积分成功&quot;); return true; &#125;&#125; 物流系统类 1234567891011121314151617181920212223package com.design.pattern.facade;import lombok.extern.slf4j.Slf4j;/** * ShippingService * * @author shunhua * @date 2019-09-17 */@Slf4jpublic class ShippingService &#123; /** * 物流系统对接 * @param pointsGift * @return */ public String shipGift(PointsGift pointsGift)&#123; log.info(pointsGift.getName() + \"进入物流系统\"); return \"123456\"; &#125;&#125; 客户端 1234567891011121314151617181920package com.design.pattern.facade;import org.junit.Test;/** * Client * * @author shunhua * @date 2019-09-17 */public class Client &#123; @Test public void test()&#123; PointsGift pointsGift = new PointsGift(\"机械键盘\"); GiftExchangeService giftExchangeService = new GiftExchangeService(); giftExchangeService.giftExchange(pointsGift); &#125;&#125; 外观模式在源码中的使用Spring-jdbc 1Spring对原生的JDBC进行了封装，我们只需要访问Spring提供的接口方法就可以达到目的。 MyBatis的Configuration 123456/** Configuration#newMetaObject方法底层也是对一些列逻辑的封装，我们只需要调用newMetaObject即可，不需关系内部。 * 如果需要修改内部逻辑，这外观接口是不需要改变的 */public MetaObject newMetaObject(Object object) &#123; return MetaObject.forObject(object, objectFactory, objectWrapperFactory, reflectorFactory); &#125; Tomcat源码 12341. Tomcat中大量使用了外观模式，如RequestFacade、ResponseFacade等。2. RequestFacade implements HttpServletRequest，Request implements HttpServletRequest，Request使用了RequestFacade包装了 自己。Request#getRequest在获取HttpServletRequest时，返回的其实是RequestFacade，之后用这个返回的对象完成的操作都是RequestFacade 来完成的。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"原型模式","slug":"design_pattern/creation_type/原型模式","date":"2019-09-15T16:00:00.000Z","updated":"2020-07-04T16:28:45.962Z","comments":true,"path":"posts/91ad9ce3/","link":"","permalink":"https://gentryhuang.com/posts/91ad9ce3/","excerpt":"","text":"定义原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。可以理解为克隆方法克隆对象。 特点不需要知道任何创建的细节，不调用构造函数 类型创建型 适用场景1234◆类初始化消耗较多资源◆new产生的一个对象需要非常繁琐的过程（数据准备、访问权限等）◆构造函数比较复杂◆循环体中生产大量对象时 优点 原型模式性能比直接new一个对象性能高 简化创建对象的过程 缺点 必须配备克隆方法（重写Object的clone方法，否则不会生效，克隆也是原型模式的核心） 对克隆复杂对象或对克隆出的对象进行复杂改造时，容易引入风险 对复杂对象的深拷贝、浅拷贝要运用得当 扩展深克隆1创建一个新对象，本体对象的引用类型属性需要进行深克隆，这样它就不会再指向原有对象地址。 浅克隆1创建一个新对象，新对象的属性和原来对象完全相同，对于非基本类型属性，仍指向原有属性所指向的对象的内存地址。 小结1深浅克隆都会在堆中新分配一块区域，它用来指向本体，区别在于对象属性引用的对象是否需要进行克隆（递归性的） 简单需求某个对象创建的时候相对比较消耗资源，但是这个对象又不得不创建多次，这时可以使用原型模式。原型模式是在内存中进行二进制字节流的拷贝，比new一个对象性能好很多 原型模式实践使用原型模式之前邮件类 12345678910111213141516171819202122232425package com.design.pattern.prototype;import lombok.Data;/** * Mail * * @author shunhua * @date 2019-09-16 */@Datapublic class Mail &#123; /** * 邮件名 */ private String name; /** * 邮件地址 */ private String address; /** * 邮件内容 */ private String content;&#125; 邮件工具类 123456789101112131415161718192021222324252627282930package com.design.pattern.prototype;import lombok.extern.slf4j.Slf4j;import java.text.MessageFormat;/** * MailUtil * * @author shunhua * @date 2019-09-16 */@Slf4jpublic class MailUtil &#123; /** * 发送邮件 * 重点： 占位符赋值的实现 * @param mail */ public static void sendMail(Mail mail)&#123; String content = \"向&#123;0&#125;,邮件地址:&#123;1&#125;,邮件内容：&#123;2&#125;发送邮件\"; log.info(MessageFormat.format(content,mail.getName(),mail.getAddress(),mail.getContent())); &#125; /** * 保存邮件的模版内容 * @param mail */ public static void mailTemplate(Mail mail)&#123; log.info(\"邮件的模版内容：\" + mail.getContent()); &#125;&#125; 客户端 12345678910111213141516171819202122232425package com.design.pattern.prototype;import org.junit.Test;/** * Client * * @author shunhua * @date 2019-09-16 */public class Client &#123; @Test public void test()&#123; Mail mail = new Mail(); mail.setContent(\"邮件模版\"); for(int i = 0; i &lt; 10; i++)&#123; mail.setName(\"姓名\" + i); mail.setAddress(\"姓名\" + i + \"@\" + \"gmail.com\"); mail.setContent(\"你收到一封邮件\"); MailUtil.sendMail(mail); &#125; MailUtil.mailTemplate(mail); &#125;&#125; 使用原型模式默认方式（浅拷贝）邮件类 123456789101112131415161718192021222324252627282930313233343536package com.design.pattern.prototype;import lombok.Data;/** * Mail 想要能被克隆需要实现Cloneable接口 * * @author shunhua * @date 2019-09-16 */@Datapublic class Mail implements Cloneable &#123; /** * 邮件名 */ private String name; /** * 邮件地址 */ private String address; /** * 邮件内容 */ private String content; /** * 重写克隆方法 * @return * @throws CloneNotSupportedException */ @Override protected Object clone() throws CloneNotSupportedException &#123; System.out.println(\"克隆Mail...\"); return super.clone(); &#125;&#125; 邮件工具类 12345678910111213141516171819202122232425262728293031package com.design.pattern.prototype;import lombok.extern.slf4j.Slf4j;import java.text.MessageFormat;/** * MailUtil * * @author shunhua * @date 2019-09-16 */@Slf4jpublic class MailUtil &#123; /** * 发送邮件 * @param mail */ public static void sendMail(Mail mail)&#123; String content = \"向&#123;0&#125;,邮件地址:&#123;1&#125;,邮件内容：&#123;2&#125;发送邮件\"; log.info(MessageFormat.format(content,mail.getName(),mail.getAddress(),mail.getContent())); &#125; /** * 保存邮件的模版内容 * @param mail */ public static void mailTemplate(Mail mail)&#123; log.info(\"邮件的模版内容：\" + mail.getContent()); &#125;&#125; 客户端 12345678910111213141516171819202122232425262728package com.design.pattern.prototype;import org.junit.Test;/** * Client * * @author shunhua * @date 2019-09-16 */public class Client &#123; @Test public void test() throws CloneNotSupportedException &#123; Mail mail = new Mail(); mail.setContent(\"邮件模版\"); for(int i = 0; i &lt; 10; i++)&#123; /** 需要创建多个Mail对象,注意不会调用Mail的构造方法，而是调用了Mail中的clone方法 **/ Mail mailTemp = (Mail) mail.clone(); mailTemp.setName(\"姓名\" + i); mailTemp.setAddress(\"姓名\" + i + \"@\" + \"gmail.com\"); mailTemp.setContent(\"你收到一封邮件\"); MailUtil.sendMail(mailTemp); &#125; // 得到原始的邮件模版 MailUtil.mailTemplate(mail); &#125;&#125; 使用原型模式默认方式（深拷贝）12345678对于被克隆的目标对象中有引用类型的属性时，如果不对该引用类型的属性进行克隆处理，那么该属性对于目标对象和克隆得到的新对象都是同一个，这很容易引起问题，一定要注意。这样情况，只需要对这个属性进行浅拷贝处理即可解决。@Override protected Object clone() throws CloneNotSupportedException &#123; Mail mail = (Mail) super.clone(); //深克隆 mail.date = (Date) pig.date.clone(); return mail; &#125; 原型模式扩展实体类 1234567891011/** * 一种常用的原型模式 * 通过抽象类来实现原型模式 */public abstract class A implements Cloneable&#123; @Override protected Object clone() throws CloneNotSupportedException &#123; return super.clone(); &#125;&#125; 继承类 123456789101112131415/** * 继承A类，直接调用clone接口 */public class B extends A&#123; public static void main(String [] args)&#123; B b = new B(); try &#123; b.clone(); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); System.out.println(\"处理异常\"); &#125; &#125;&#125; 克隆破坏单例123克隆破坏单例的根本原因是，通过反射暴力调用单例类中的clone方法，这样就会得到一个新对象，单例也就变成了多例。防止克隆破坏单例，只需要让单例类不实现克隆接口即可，或者实现了克隆接口但是克隆方法返回的仍然是同一对象，而不是处理克隆。 原型模式在源码中的使用1可以通过观察Cloneable接口的使用，就可以追踪原型模式是怎样使用的 源码解析1(Object) 12//native 调用非java代码接口 protected native Object clone() throws CloneNotSupportedException; 源码解析2(ArrayList实现克隆) 1234567891011121314151617181920212223public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable&#123;/** * Returns a shallow copy of this &lt;tt&gt;ArrayList&lt;/tt&gt; instance. (The * elements themselves are not copied.) * * @return a clone of this &lt;tt&gt;ArrayList&lt;/tt&gt; instance */ public Object clone() &#123; try &#123; @SuppressWarnings(\"unchecked\") ArrayList&lt;E&gt; v = (ArrayList&lt;E&gt;) super.clone(); v.elementData = Arrays.copyOf(elementData, size); v.modCount = 0; return v; &#125; catch (CloneNotSupportedException e) &#123; // this shouldn't happen, since we are Cloneable throw new InternalError(); &#125; &#125;&#125; 源码解析3(MyBatis的cacheKey) 12345678910111213141516171819package org.apache.ibatis.cache;import java.io.Serializable;import java.lang.reflect.Array;import java.util.ArrayList;import java.util.List;/** * @author Clinton Begin */public class CacheKey implements Cloneable, Serializable &#123; @Override public CacheKey clone() throws CloneNotSupportedException &#123; CacheKey clonedCacheKey = (CacheKey) super.clone(); clonedCacheKey.updateList = new ArrayList&lt;Object&gt;(updateList); return clonedCacheKey; &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"建造者模式","slug":"design_pattern/creation_type/建造者模式","date":"2019-09-11T14:33:47.000Z","updated":"2020-08-09T09:16:58.216Z","comments":true,"path":"posts/fe816c3c/","link":"","permalink":"https://gentryhuang.com/posts/fe816c3c/","excerpt":"","text":"定义 将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。用户只需指定需要建造的类型就可以得到它们，建造过程及细节不需要知道。 类型 创建型 适用场景 如果一个对象有非常复杂的内部结构（很多属性） 想把复杂对象的创建和使用分离优点 封装性好，创建和使用分离 扩展性好、建造类之间独立、一定程度上解耦 缺点 产生多余的Builder对象 产品内部发生变化，建造者都需要修改，成本较大 建造者模式和工厂模式比较 建造者模式更注重方法的调用顺序，而工厂模式更注重生产产品 创建对象的粒度不同，建造者模式可以创建复杂的产品，有各种复杂的部件组成。而工程模式创建出来的都几乎一个样子 工厂模式注重把产品创建出来，而建造者不仅要创建出产品，还要知道产品有哪些部件组成的 简单需求说明 有一个课程需要上线在网站，这个课程需要满足以下条件：课程名、课程的课件资源以及视频资源，只有这个三个组件有了 才能组装成上线的课程。这里在创建课时，需要有顺序的执行，最终得到一个符合要求的课程。 v1 通过中间类实现uml类图 课程类 1234567891011121314151617181920212223242526package com.design.pattern.builder;import lombok.Data;/** * Course * * @author shunhua * @date 2019-09-11 */@Datapublic class Course &#123; /** * 课程名 */ private String name; /** * 课程资料 */ private String source; /** * 课程视频 */ private String video;&#125; 建造者抽象类 123456789101112131415161718192021222324252627282930313233package com.design.pattern.builder;/** * CourseBuilder * * @author shunhua * @date 2019-09-11 */public abstract class CourseBuilder &#123; /** * 建造课程名 * @param name */ public abstract void buildName(String name); /** * 建造课程资料 * @param source */ public abstract void buildSource(String source); /** * 建造课程视频 * @param video */ public abstract void buildVideo(String video); /** * 构建课程 * @return */ public abstract Course buildCourse();&#125; 建造者实现类 1234567891011121314151617181920212223242526272829303132package com.design.pattern.builder;/** * ActualCourseBuilder 真正的课程创建者 * * @author shunhua * @date 2019-09-11 */public class ActualCourseBuilder extends CourseBuilder&#123; private Course course = new Course(); @Override public void buildName(String name) &#123; course.setName(name); &#125; @Override public void buildSource(String source) &#123; course.setSource(source); &#125; @Override public void buildVideo(String video) &#123; course.setVideo(video); &#125; @Override public Course buildCourse() &#123; return course; &#125;&#125; 助教（对课程进行组装） 12345678910111213141516171819202122232425262728293031package com.design.pattern.builder;/** * Assistant 课程助教 * * @author shunhua * @date 2019-09-11 */public class Assistant &#123; private CourseBuilder courseBuilder; public void setCourseBuilder(CourseBuilder courseBuilder)&#123; this.courseBuilder = courseBuilder; &#125; /** * 课程助教 组装课程 * @param name * @param source * @param video * @return */ public Course buildCourse(String name,String source,String video)&#123; this.courseBuilder.buildName(name); this.courseBuilder.buildSource(source); this.courseBuilder.buildVideo(video); return this.courseBuilder.buildCourse(); &#125;&#125; 客户端 1234567891011121314151617181920212223package com.design.pattern.builder;import lombok.extern.slf4j.Slf4j;import org.junit.Test;/** * Client * * @author shunhua * @date 2019-09-11 */@Slf4jpublic class Client &#123; @Test public void test()&#123; CourseBuilder courseBuilder = new ActualCourseBuilder(); Assistant assistant = new Assistant(); assistant.setCourseBuilder(courseBuilder); Course course = assistant.buildCourse(\"Java进阶\",\"ppt\",\"Java进阶视频\"); log.info(course.toString()); &#125;&#125; v2 静态内部类演练建造者模式（链式调用）uml类图 1静态内部类builder有3个属性，课程类有相同的3个属性，链式调用的时候，给builder全部或者部分赋值，build的时候，把builder对象传送到course，course获取到builder的属性，然后返回这个course； Course类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package com.design.pattern.builder.v2;import lombok.Data;/** * Course * * @author shunhua * @date 2019-09-11 */@Datapublic class Course &#123; /** * 课程名 */ private String name; /** * 课程资料 */ private String source; /** * 课程视频 */ private String video; public Course(CourseBuilder courseBuilder)&#123; this.name = courseBuilder.name; this.source = courseBuilder.source; this.video = courseBuilder.video; &#125; /** * 把实体类与对应的创建类写在一起，这种使用更常见,使用链式调用 */ public static class CourseBuilder &#123; /** * 课程名 */ private String name; /** * 课程资料 */ private String source; /** * 课程视频 */ private String video; public CourseBuilder buildName(String name) &#123; this.name = name; return this; &#125; public CourseBuilder buildSource(String source) &#123; this.source = source; return this; &#125; public CourseBuilder buildVideo(String video) &#123; this.video = video; return this; &#125; /** * * @return */ public Course build()&#123; return new Course(this); &#125; &#125;&#125; 客户端 1234567891011121314151617181920212223package com.design.pattern.builder.v2;import lombok.extern.slf4j.Slf4j;import org.junit.Test;/** * Client * * @author shunhua * @date 2019-09-11 */@Slf4jpublic class Client &#123; @Test public void test()&#123; Course course = new Course.CourseBuilder() .buildName(\"java进阶\") .buildSource(\"ppt课件\") .buildVideo(\"java进阶视频\") .build(); log.info(course.toString()); &#125;&#125; 建造者模式在源码中的使用jdk的StringBuilder和StringBuffer12345678910111213// 如StringBuilder的append方法 @Override public StringBuilder append(String str) &#123; super.append(str); return this; &#125;// 如StringBuffer的append方法 @Override public synchronized StringBuffer append(String str) &#123; toStringCache = null; super.append(str); return this; &#125; MyBatis的SqlSessionFactoryBuilder1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253 public SqlSessionFactory build(InputStream inputStream, String environment, Properties properties) &#123; try &#123; // XML配置的builder 来创建 Configuration XMLConfigBuilder parser = new XMLConfigBuilder(inputStream, environment, properties); // parse方法创建Configuration ，SqlSessionFactoryBuilder的build方法创建SqlSessionFactory return build(parser.parse()); &#125; catch (Exception e) &#123; throw ExceptionFactory.wrapException(\"Error building SqlSession.\", e); &#125; finally &#123; ErrorContext.instance().reset(); try &#123; inputStream.close(); &#125; catch (IOException e) &#123; // Intentionally ignore. Prefer previous error. &#125; &#125; &#125; // public SqlSessionFactory build(Configuration config) &#123; return new DefaultSqlSessionFactory(config); &#125; // XMLConfigBuilder#parse public Configuration parse() &#123; if (parsed) &#123; throw new BuilderException(\"Each XMLConfigBuilder can only be used once.\"); &#125; parsed = true; parseConfiguration(parser.evalNode(\"/configuration\")); return configuration; &#125; private void parseConfiguration(XNode root) &#123; try &#123; Properties settings = settingsAsPropertiess(root.evalNode(\"settings\")); //issue #117 read properties first propertiesElement(root.evalNode(\"properties\")); loadCustomVfs(settings); typeAliasesElement(root.evalNode(\"typeAliases\")); pluginElement(root.evalNode(\"plugins\")); objectFactoryElement(root.evalNode(\"objectFactory\")); objectWrapperFactoryElement(root.evalNode(\"objectWrapperFactory\")); reflectorFactoryElement(root.evalNode(\"reflectorFactory\")); settingsElement(settings); // read it after objectFactory and objectWrapperFactory issue #631 environmentsElement(root.evalNode(\"environments\")); databaseIdProviderElement(root.evalNode(\"databaseIdProvider\")); typeHandlerElement(root.evalNode(\"typeHandlers\")); mapperElement(root.evalNode(\"mappers\")); &#125; catch (Exception e) &#123; throw new BuilderException(\"Error parsing SQL Mapper Configuration. Cause: \" + e, e); &#125; &#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"抽象工厂","slug":"design_pattern/creation_type/抽象工厂","date":"2019-09-09T16:00:00.000Z","updated":"2020-09-04T06:07:24.449Z","comments":true,"path":"posts/df11d265/","link":"","permalink":"https://gentryhuang.com/posts/df11d265/","excerpt":"","text":"定义 抽象工厂模式提供一个创建一系列相关或相互依赖对象的的接口。无须指定它们具体的类。 类型 创建型 使用场景 客户端（应用层）不依赖于产品实例如何被创建、实现等细节 强调一系列相关的产品对象（属于同一产品族）一起使用创建对象需要大量重复的代码 提供一个产品类的库，所有的产品以同样的接口出现，从而使客户端不依赖于具体实现。 优点 应用层代码不和具体的产品发生依赖，只和具体的产品族工厂发生依赖关系，低耦合，高内聚 从具体的产品工厂取出来的肯定是同一产品族，开发的时候逻辑清晰 对于产品族来说，符合开闭原则，增加新的产品族的时候，对扩展开放 缺点 规定了所有可能被创建的产品集合，产品族中扩展新的产品困难，需要修改抽象工程的接口。增加了系统的抽象性和理解难度。 为何有产品族的业务场景宜用抽象工厂设计模式？而不是工厂设计模式 如果使用工厂设计模式，可能会因为工厂类太多而产生类爆炸的现象 产品族和产品等级 工厂方法针对的就是产品等级结构，它处理的就是同一类型产品（如：产品类型都是冰箱但是有不同品牌） 抽象工厂针对的就是产品族，它处理的就是一系列产品（如：海尔旗下不同的产品） 简单场景说明 一个课程不仅要有视频资料，还需要有对应的笔记,这样两者都存在才是一门课程。 抽象工厂演练 笔记 1234567891011121314package com.design.pattern.abstractfactory;/** * Article * * @author shunhua * @date 2019-09-10 */public abstract class Article &#123; /** * 生产笔记的方法 */ public abstract void produce();&#125; java笔记 123456789101112131415161718package com.design.pattern.abstractfactory;import lombok.extern.slf4j.Slf4j;/** * JavaArticle * * @author shunhua * @date 2019-09-10 */@Slf4jpublic class JavaArticle extends Article &#123; @Override public void produce() &#123; log.info(\"生产Java笔记\"); &#125;&#125; python笔记 123456789101112131415161718package com.design.pattern.abstractfactory;import lombok.extern.slf4j.Slf4j;/** * PythonArticle * * @author shunhua * @date 2019-09-10 */@Slf4jpublic class PythonArticle extends Article &#123; @Override public void produce() &#123; log.info(\"生产python笔记\"); &#125;&#125; 视频资源 1234567891011121314package com.design.pattern.abstractfactory;/** * Video * * @author shunhua * @date 2019-09-10 */public abstract class Video &#123; /** * 生产视频的抽象方法 */ public abstract void produce();&#125; Java视频资源 123456789101112131415161718package com.design.pattern.abstractfactory;import lombok.extern.slf4j.Slf4j;/** * JavaVideo * * @author shunhua * @date 2019-09-10 */@Slf4jpublic class JavaVideo extends Video &#123; @Override public void produce() &#123; log.info(\"生成Java视频资源\"); &#125;&#125; python视频资源 123456789101112131415161718package com.design.pattern.abstractfactory;import lombok.extern.slf4j.Slf4j;/** * PythonVideo * * @author shunhua * @date 2019-09-10 */@Slf4jpublic class PythonVideo extends Video &#123; @Override public void produce() &#123; log.info(\"生产python视频\"); &#125;&#125; 课程工厂（产品族工厂） 1234567891011121314151617181920package com.design.pattern.abstractfactory;/** * CourseFactory * * @author shunhua * @date 2019-09-10 */public interface CourseFactory &#123; /** * 生产视频 * @return */ Video getVideo(); /** * 生产笔记 * @return */ Article getArticle();&#125; Java课程工厂 1234567891011121314151617181920package com.design.pattern.abstractfactory;/** * JavaCourseFactory * * @author shunhua * @date 2019-09-10 */public class JavaCourseFactory implements CourseFactory &#123; @Override public Video getVideo() &#123; return new JavaVideo(); &#125; @Override public Article getArticle() &#123; return new JavaArticle(); &#125;&#125; Python课程工厂 1234567891011121314151617181920package com.design.pattern.abstractfactory;/** * PythonCourseFactory * * @author shunhua * @date 2019-09-10 */public class PythonCourseFactory implements CourseFactory&#123; @Override public Video getVideo() &#123; return new PythonVideo(); &#125; @Override public Article getArticle() &#123; return new PythonArticle(); &#125;&#125; 客户端 123456789101112131415161718192021package com.design.pattern.abstractfactory;import org.junit.Test;/** * Client * * @author shunhua * @date 2019-09-10 */public class Client &#123; @Test public void test()&#123; CourseFactory courseFactory = new JavaCourseFactory(); Video video = courseFactory.getVideo(); Article article = courseFactory.getArticle(); video.produce(); article.produce(); &#125;&#125; 抽象工厂在源码中的使用源码解析Connection的两个方法属性同一个产品族，这是一个父类 1234567891011121314151617181920// mysql和oracle获取的是同一产品族下的statement和同一产品族下的preparestatementpublic interface Connection extends Wrapper, AutoCloseable &#123; Statement createStatement() throws SQLException; PreparedStatement prepareStatement(String sql) throws SQLException; // ... &#125; // executeQuery方法和execureUpdate方法属于同一个产品族public interface Statement extends Wrapper, AutoCloseable &#123; ResultSet executeQuery(String sql) throws SQLException; int executeUpdate(String sql) throws SQLException; &#125; MyBatis的SqlSession源码解析java.sql.Connection/java.sql.Statement/org.apache.ibatis.session.SqlSessionFactory等 接口就是一个抽象工厂（从同一个抽象工厂中返回的产品一定属于同一个产品族）它里面有多个工厂方法，它的实现类通过实现不同的工厂方法，来创建出不同的产品。 SqlSessionFactory 12345678910111213141516171819202122232425package org.apache.ibatis.session;import java.sql.Connection;/** * Creates an &#123;@link SqlSession&#125; out of a connection or a DataSource * * @author Clinton Begin */public interface SqlSessionFactory &#123; SqlSession openSession(); SqlSession openSession(boolean autoCommit); SqlSession openSession(Connection connection); SqlSession openSession(TransactionIsolationLevel level); SqlSession openSession(ExecutorType execType); SqlSession openSession(ExecutorType execType, boolean autoCommit); SqlSession openSession(ExecutorType execType, TransactionIsolationLevel level); SqlSession openSession(ExecutorType execType, Connection connection); Configuration getConfiguration();&#125; SqlSessionFactory子类 SqlSessionManagerSqlSessionFactory子类 DefaultSqlSessionFactory","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"工厂方法","slug":"design_pattern/creation_type/工厂方法","date":"2019-09-08T16:00:00.000Z","updated":"2020-09-04T06:09:12.309Z","comments":true,"path":"posts/a778ad08/","link":"","permalink":"https://gentryhuang.com/posts/a778ad08/","excerpt":"","text":"定义 定义一个创建对象的接口（抽象方法），让实现这个接口的类（实现抽象方法）来决定实例化哪个类，工厂方法让类的实例化推迟到子类中进行，即通过子类实现抽象方法来创建对象。 工厂方法就是用来解决同一产品等级的业务抽象问题。工厂创建对象用的，方法通过子类实现方法来创建对象。 类型 创建型 使用场景 创建对象需要大量的重复代码 客户端（应用层）不依赖于产品类实例如何被创建、实现等细节 一个类通过其子类来指定创建哪个对象优点用户只需要关心所需产品对应的工厂，无须关心创建细节。加入新的产品符合开闭原则，提高了可扩展性。缺点实现类的个数容易过多（增加新产品的时候，不仅需要编写新的产品类还需要编写对应的工厂类，因此类的个数增加）、增加复杂度。工厂方法本身使用了抽象，我们需要引入抽象层，如果想要动态创建可能还会使用反射技术，这都增加了系统的抽象性和理解难度产品等级和产品族 工厂方法是为了决绝同一产品等级的业务抽象问题，抽象工厂是为了解决同一产品族的问题 产品等级相同类型的产品为同一产品等级，如：汽车有大众、长安、奥迪等，它们属于同一产品等级 产品族不同类型的产品，如长安汽车、长安摩托、长安自行车 工厂方法演练 Food类 1234567891011121314package com.design.pattern.factorymethod;/** * 相同类型的产品属于同一产品等级，无论是面包还是沙拉，它们都是同一个等级，这里是Food * * @author shunhua * @date 2019-09-09 */public abstract class Food &#123; /** * 生产产品方法 */ public abstract void produce();&#125; 面包类 123456789101112131415161718192021package com.design.pattern.factorymethod;import lombok.Data;import lombok.ToString;import lombok.extern.slf4j.Slf4j;/** * Bread * * @author shunhua * @date 2019-09-09 */@Slf4j@ToStringpublic class Bread extends Food &#123; @Override public void produce() &#123; log.info(\"生产面包!\"); &#125;&#125; 沙拉类 1234567891011121314151617181920package com.design.pattern.factorymethod;import lombok.ToString;import lombok.extern.slf4j.Slf4j;/** * Salad * * @author shunhua * @date 2019-09-09 */@Slf4j@ToStringpublic class Salad extends Food &#123; @Override public void produce() &#123; log.info(\"生成沙拉!\"); &#125;&#125; 抽象工厂 123456789101112131415package com.design.pattern.factorymethod;/** * 工厂方法,子类继承即可 * 这里使用抽象类主要考虑到在类中有些是已知的，使用抽象类合适。如果全都是未知的使用接口比较合适。 * @author shunhua * @date 2019-09-09 */public abstract class FoodFactory &#123; /** * 工厂方法，起到规约的作用，并不生产具体的产品，具体产品的生成由其实现完成 * @return */ public abstract Food createFood();&#125; 子工厂类-面包工厂 12345678910111213141516171819package com.design.pattern.factorymethod;/** * BreadFactory 只生产Bread * * @author shunhua * @date 2019-09-10 */public class BreadFactory extends FoodFactory &#123; /** * 生产面包的工厂方法 * @return */ @Override public Food createFood() &#123; return new Bread(); &#125;&#125; 子工厂类-沙拉工厂 123456789101112131415161718package com.design.pattern.factorymethod;/** * SaladFactory 只生产Salad * * @author shunhua * @date 2019-09-10 */public class SaladFactory extends FoodFactory &#123; /** * 生产面包的工厂方法 * @return */ @Override public Food createFood() &#123; return new Salad(); &#125;&#125; 客户端 12345678910111213141516171819202122232425262728package com.design.pattern.factorymethod;import lombok.extern.slf4j.Slf4j;import org.junit.Test;/** * Client * * @author shunhua * @date 2019-09-10 */@Slf4jpublic class Client &#123; @Test public void test()&#123; // 面包工厂方法 FoodFactory breadFactory = new BreadFactory(); Food bread = breadFactory.createFood(); log.info(String.valueOf(bread)); // 沙拉工厂方法 FoodFactory saladFactory = new SaladFactory(); Food salad = saladFactory.createFood(); log.info(String.valueOf(salad)); &#125;&#125; 工厂方法在源码中的使用Collection的Iterator解析Collection接口相当于抽象工厂（因为它处理的是等级组问题即多个类型的产品），其中它里面的Iterator iterator()方法相当于工厂方法。ArrayList实现了这个方法，该方法为ArrayList生产Itr，Itr是Iterator类型。还有ILoggerFactory和Logger产品族对应的工厂方法的使用。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public Iterator&lt;E&gt; iterator() &#123; return new Itr(); &#125; /** * An optimized version of AbstractList.Itr */ private class Itr implements Iterator&lt;E&gt; &#123; int cursor; // index of next element to return int lastRet = -1; // index of last element returned; -1 if no such int expectedModCount = modCount; public boolean hasNext() &#123; return cursor != size; &#125; @SuppressWarnings(\"unchecked\") public E next() &#123; checkForComodification(); int i = cursor; if (i &gt;= size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; return (E) elementData[lastRet = i]; &#125; public void remove() &#123; if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try &#123; ArrayList.this.remove(lastRet); cursor = lastRet; lastRet = -1; expectedModCount = modCount; &#125; catch (IndexOutOfBoundsException ex) &#123; throw new ConcurrentModificationException(); &#125; &#125; @Override @SuppressWarnings(\"unchecked\") public void forEachRemaining(Consumer&lt;? super E&gt; consumer) &#123; Objects.requireNonNull(consumer); final int size = ArrayList.this.size; int i = cursor; if (i &gt;= size) &#123; return; &#125; final Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) &#123; throw new ConcurrentModificationException(); &#125; while (i != size &amp;&amp; modCount == expectedModCount) &#123; consumer.accept((E) elementData[i++]); &#125; // update once at end of iteration to reduce heap write traffic cursor = i; lastRet = i - 1; checkForComodification(); &#125; final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125; &#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"合成复用原则","slug":"design_pattern/principle/合成复用原则","date":"2019-09-04T16:00:00.000Z","updated":"2020-07-04T13:42:18.872Z","comments":true,"path":"posts/b91a199d/","link":"","permalink":"https://gentryhuang.com/posts/b91a199d/","excerpt":"","text":"继承关系的选择 继承关系是is a的关系，所以看是否有继承关系，通常要看子类和父类共用的方法，子类是否能够实现父类的方法 起名 合成复用原则，组合复用原则，聚合复用原则 定义 尽量使用组合，聚合，而不是继承关系达到复用软件的目的 组合聚合（黑箱复用） 优点降低耦合，提高系统的灵活性。使一个类的变化对其他类造成的影响较小 缺点会生成较多的对象进行管理 继承（白箱复用） 优点新的扩展性容易实现，修改和扩展相对容易 缺点父类的方法侵入性的带给子类，父类方法的改变，子类也必须改变，相比耦合较高 组合聚合区别关系强弱，组合强，聚合弱","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"里氏替换原则","slug":"design_pattern/principle/里氏替换原则","date":"2019-09-03T16:00:00.000Z","updated":"2020-07-04T13:42:18.873Z","comments":true,"path":"posts/3d1cbe69/","link":"","permalink":"https://gentryhuang.com/posts/3d1cbe69/","excerpt":"","text":"定义 如果对每一个类型为T1的对象o1，都有类型为T2的对象o2，使得以T1定义的所有程序P在所有的对象o1都替换成o2时，程序P的行为没有发生变化，那么类型T2是类型T1的子类型。 定义扩展 一个软件实体如果适用一个父类的话，那一定适用于其子类，所有引用父类的地方必须能透明地使用其子类的对象，子类对象能够替换父类对象，而程序逻辑不变。（反对子类重写父类） 特点123456789◆引申意义：子类可以扩展父类的功能，但不能改变父类原有的功能。◆含义1：子类可以实现父类的抽象方法，但不能覆盖父类的非抽象方法。◆含义2：子类中可以增加自己特有的方法。◆含义3：当子类的方法重载父类的方法时，方法的前置条件（即方法的输入&#x2F;入参）要比父类方法的输入参数更宽松。（入参宽松）◆含义4：当子类的方法实现父类的方法时（重写&#x2F;重载或实现抽象方法），方法的后置条件（即方法的输出&#x2F;返回值）要比父类更严格或相等。（出参严谨）（前两条，约定子类最好不要重写父类的方法，如果一定要重写的话，可以使用组合聚合等方法实现）（后两条,约定了子啊重载或实现父类方法的条件） 优点 约束了继承泛滥，很多非子类父类关系的类，没必要使用继承关系 加强程序的可维护性，降低需求变更时引起的风险 coding里氏替换原则继承关系判别（是否是真正意义的继承）1子类行为规则应与父类行为规则一致，如果子类达不到这一点，则会违背里氏替换原则，违背里氏替换原则会怎样？继承逻辑混乱，代码不便于维护 入参控制1重载的时候入参要更加宽松，可以不引起逻辑混乱 父类 1234567import java.util.HashMap;public class Base &#123; public void method(HashMap hashMap)&#123; System.out.println(\"执行父类HashMap方法\"); &#125;&#125; 子类 12345678910111213141516171819import java.util.HashMap;import java.util.Map;public class Child extends Base&#123; // @Override // public void method(HashMap hashMap) &#123; // System.out.println(\"执行子类的HashMap方法\"); // &#125; /** * 子类重载 * 重载的时候入参 Map比 Hashmap宽松，此时执行的时候会执行父类，不执行重载的类 * @param Map */ public void method(Map Map) &#123; System.out.println(\"执行子类Map方法\"); &#125;&#125; 出参控制1子类的出参如果包含父类，会直接报错 父类 12345678910111213package com.design.pattern.principle.liskovSubstitutation.outputmethod;import java.util.Map;/** * Base * * @author shunhua * @date 2019-09-15 */public abstract class Base &#123; public abstract Map method();&#125; 子类 12345678910111213141516171819202122232425262728293031package com.design.pattern.principle.liskovSubstitutation.outputmethod;import java.util.HashMap;import java.util.Map;/** * Child * * @author shunhua * @date 2019-09-15 */public class Child extends Base &#123; /** * 子类的出参如果包含父类，会直接报错。 * @return */ /* @Override public Object method() &#123; return null; &#125;*/ /** * 父类的出参包含子类的出参是可以的 * @return */ @Override public HashMap method()&#123; return new HashMap(2); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"迪米特法则","slug":"design_pattern/principle/迪米特法则","date":"2019-09-02T16:00:00.000Z","updated":"2020-07-04T13:42:18.870Z","comments":true,"path":"posts/ebdadec7/","link":"","permalink":"https://gentryhuang.com/posts/ebdadec7/","excerpt":"","text":"定义 迪米特法则也叫最少知道原则,一个对象应该对其他对象保持最少的了解（比如包的权限，修饰的关键字）。尽量降低类与类之间的耦合。 优点 降低类之间的耦合。 强调 只关心出现在成员变量、方法的入参和出参中的类，不关心方法体内部的类。 简单需求说明 公司老板想了解某个业务组的项目情况，老板直接找到TeamLeader，不需要关心项目组其他成员。而TeamLeader需要让组内 某个成员进行整理资料，然交给自己，自己再交给老板。 coding迪米特法则反例老板类 123456789101112131415161718import java.util.ArrayList;import java.util.List;/** * 此处设计不合理，只访问朋友类（成员变量中的类，输入中出现的类，输出中出现的类） * 成员方法中的类不需要引入(Member) */public class Boss &#123; public void findMembers()&#123; TeamLeader leader = new TeamLeader(); List&lt;Member&gt; list = new ArrayList&lt;Member&gt;(); for(int i= 0;i&lt;10;i++)&#123; list.add(new Member()); &#125; leader.countMember(list); &#125;&#125; 主管类 12345678import java.util.List;@Slf4jpublic class TeamLeader &#123; public void countMember(List list)&#123; log.info(\"当前项目组的成员数：\"+list.size()); &#125;&#125; 项目组成员类 12345678910111213public class Member &#123; // ..&#125;``` **应用类**```javapublic class Client&#123; public static void main(String[] args)&#123; Boss boss = new Boss(); boss.findMembers(); &#125;&#125; 迪米特法则正例老板类 1234567891011121314151617package com.design.pattern.principle.demeter;/** * Boss * * @author shunhua * @date 2019-09-03 */public class Boss &#123; /** * 对Member不需要见，只关心TeamLeader * @param teamLeader */ public void findProject(TeamLeader teamLeader)&#123; teamLeader.findProject(); &#125;&#125; 主管类 1234567891011121314151617181920package com.design.pattern.principle.demeter;import lombok.extern.slf4j.Slf4j;/** * TeamLeader * * @author shunhua * @date 2019-09-03 */@Slf4jpublic class TeamLeader &#123; /** * 关注Member */ public void findProject()&#123; Member member = new Member(); log.info(String.valueOf(member)); &#125;&#125; 成员类 1234567891011package com.design.pattern.principle.demeter;/** * Member * * @author shunhua * @date 2019-09-03 */public class Member &#123; // ..&#125; 应用 12345678910111213141516171819202122package com.design.pattern.principle;import com.design.pattern.principle.demeter.Boss;import com.design.pattern.principle.demeter.TeamLeader;import org.junit.Test;/** * DemeterTest * * @author shunhua * @date 2019-09-03 */public class DemeterTest &#123; @Test public void test()&#123; Boss boss = new Boss(); TeamLeader teamLeader = new TeamLeader(); boss.findProject(teamLeader); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"接口隔离原则","slug":"design_pattern/principle/接口隔离原则","date":"2019-09-02T16:00:00.000Z","updated":"2020-07-04T13:42:18.871Z","comments":true,"path":"posts/e0ec8882/","link":"","permalink":"https://gentryhuang.com/posts/e0ec8882/","excerpt":"","text":"定义 用多个专门的接口，而不使用单一的总接口，客户端不应该依赖它不需要的接口。 注意点 一个类对一个类的依赖应该建立在最小的接口上（这里的类是泛指，也代表接口）。 建立单一接口，不要建立庞大臃肿的接口 尽量细化接口，接口中的方法尽量少 注意适度原则，一定要适度，虽然接口中的方法尽量少，但是也要有限度。优点符合我们常说的高内聚低耦合的设计思想，从而使得类具有很好的可读性、可扩展性和可维护性。和单一职责原则比较单一职责原则指的是类、接口和方法的职责是单一的，强调的是职责，如果职责是单一的那么在类或者接口中具有多个方法都是可以的，因为它们都是一类的，比如叫声，不同的动物有不同的叫。接口隔离原则注重地是对接口依赖的隔离。简单需求说明使用统一的接口定义多个功能的方法，但是有的实现不一定会全部用到，最好是将这个统一的接口根据不同的维度进行拆分成多个接口，实现根据需要进行接口的实现。 coding接口隔离原则反例接口 12345public interface IAnimalAction &#123; void eat(); void fly(); void swim();&#125; 狗实现类 1234567891011121314151617181920public class DogCaseOne implements IAnimalAction&#123; @Override public void eat() &#123; &#125; /** * 注：这里是空方法，狗不会飞，所以明显设计的不合理，最好不要有太多的空方法 */ @Override public void fly() &#123; &#125; @Override public void swim() &#123; &#125;&#125; 鸟实现类 12345678910111213141516171819public class LarkCaseOne implements IAnimalAction&#123; @Override public void eat() &#123; &#125; @Override public void fly() &#123; &#125; /** * 很明显，百灵鸟不会游泳，此处为空方法，设计不合理 */ @Override public void swim() &#123; &#125;&#125; 接口隔离原则正例吃东西接口 123456public interface IEat&#123; /** * 吃东西 */ void eat();&#125; 飞翔接口 123456public interface IFly&#123; /** * 飞翔 */ void fly();&#125; 游泳接口 123456public interface ISwim&#123; /** * 游泳 */ void swim();&#125; 狗实现类 123456789101112131415/** * 狗只用实现 吃和游泳方法即可 */@Slf4jpublic class DogCaseTwo implements IEat,ISwim&#123; @Override public void eat() &#123; log.info(\"狗吃东西!\"); &#125; @Override public void swim() &#123; log.info(\"狗游泳\"); &#125;&#125; 鸟实现类 123456789101112131415/** * 鸟实现 吃和飞方法即可 */@Slf4jpublic class LarkCaseTwo implements IEat,IFly&#123; @Override public void eat() &#123; log.info(\"鸟吃东西\"); &#125; @Override public void fly() &#123; log.info(\"鸟飞翔\"); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"单一职责原则","slug":"design_pattern/principle/单一职责原则","date":"2019-09-01T16:00:00.000Z","updated":"2020-07-04T13:42:18.868Z","comments":true,"path":"posts/46a1bcf2/","link":"","permalink":"https://gentryhuang.com/posts/46a1bcf2/","excerpt":"","text":"定义 不要存在多于一个导致类变更的原因。体现在一个类/接口/方法只负责一项职责。 优点 降低类的复杂度、提高类的可读性，提高系统的可维护性，降低变更引起的风险。 详解 在类的级别上，可以定义不同的类实现不同的功能，在接口级别上，可以根据功能抽象出不同的接口，然后按需要实现一个或多个接口。方法级别上，可以做到不同的方法实现不同的操作。 要点讲解12341. 实际应用中，类不采用单一职责，接口和方法采用单一职责。2. 定义：单一职责规定 一个类，接口或者方法，只有一个变化的原因3. 优点：降低类的复杂性，提高可读性，维护时风险降低4. 实际应用，受依赖，组合，聚合这些关系影响，同时受控于项目规模，项目周期，技术人员水平，对进度把控等影响。应适当的应用单一职责原则 简单需求说明 完成不同功能，并且使设计模块具有可读性和可维护性。可以使用不同的类或接口或方法去完成某一类功能，这样就显得单一，具有针对性。 类的单一职责原则实体类1 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package com.design.pattern.principle.singleresponsibility;import lombok.extern.slf4j.Slf4j;/** * WalkBird * * @author shunhua * @date 2019-09-02 */@Slf4jpublic class WalkBird &#123; public void moveMode(String birdName)&#123; log.info(birdName + \"陆地奔跑\"); &#125;&#125;``` **实体类2**```javapackage com.design.pattern.principle.singleresponsibility;import lombok.extern.slf4j.Slf4j;/** * FlyBird * * @author shunhua * @date 2019-09-02 */@Slf4jpublic class FlyBird &#123; public void moveMode(String birdName)&#123; log.info(birdName + \"用翅膀飞\"); &#125;&#125;``` **应用**```javapublic class Client &#123; public static void main(String[] args) &#123; WalkBird walkBird = new WalkBird(); walkBird.birdMove(\"鸵鸟\"); FlyBird flyBird = new FlyBird(); flyBird.birdMove(\"大雁\"); &#125;&#125;``` ### 接口的单一职责**接口1**```java/** * 这个接口和获取内容的接口有先后顺序，只有开始学习，才能获取内容，如果退出学习，就不能在获取内容了， * 由于职责不同，所以设计两个接口符合单一职责原则 */public interface IcourseAction &#123; void beginStudy(); void quitStudy();&#125; 接口2 1234567/** * 注，本接口主要是获取课程的内容 */public interface IcourseContent &#123; String getCourseText();//获取课程文本内容 byte[] getCourseVideo();//获取课程的视频&#125; 实体类 12345678910111213141516171819202122@Slf4jpublic class Course implements IcourseAction,IcourseContent&#123; @Override public void beginStudy() &#123; log.info(\"开始学习!\"); &#125; @Override public void quitStudy() &#123; log.info(\"学习完成！\"); &#125; @Override public String getCourseText() &#123; return \"Java 资料\"; &#125; @Override public byte[] getCourseVideo() &#123; return new byte[0]; &#125;&#125; 方法的单一职责12345678910111213141516171819202122232425public class Method &#123; /** * 单一职责原则，修改用户的名称 * @return */ public String updateUserName()&#123; return \"\"; &#125; /** * 单一职责原则,修改用户的密码 * @return */ public String updateUserPassWord()&#123; return \"\"; &#125; /** * 不符合单一职责 * @return */ public String updateUserInfo(String userId,String gender)&#123; return \" \"; &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"依赖倒置原则","slug":"design_pattern/principle/依赖倒置原则","date":"2019-09-01T16:00:00.000Z","updated":"2020-07-04T13:42:18.866Z","comments":true,"path":"posts/91021fa8/","link":"","permalink":"https://gentryhuang.com/posts/91021fa8/","excerpt":"","text":"定义 高层模块不应该依赖低层模块，二者都应该依赖其抽象。 优点 可以减少类间的耦合性、提高系统稳定性，增强代码可读性和可维护性，可降低修改程序造成的风险。 细节描述 抽象不应该依赖细节，细节应该依赖抽象。针对接口编程而不要针对实现编程。 简单需求说明 某同学想要学习某一课程，最简单的方式直接在Person中编写一个方法即可，但是如果以后想要学习其他课程就 需要修改Person类。为了解耦，我们可以把课程抽象出去，高层对底层的依赖，这样Person依赖的就是抽象，我 们针对接口编程，而不是针对实现编程。 coding非面向抽象编程12345678910111213141516171819202122232425缺点：应用依赖具体的实现，对于后续需求变更更加不适用&#96;&#96;&#96; **实体类**&#96;&#96;&#96;javapackage com.design.pattern.principle.dependenceinversion;import lombok.extern.slf4j.Slf4j;&#x2F;** * Person * * @author shunhua * @date 2019-09-02 *&#x2F;@Slf4jpublic class Person &#123; public void learnJavaCourse()&#123; log.info(&quot;学习Java课程&quot;); &#125; public void learnPythonCourse()&#123; log.info(&quot;学习Python课程&quot;); &#125;&#125; 应用 12345678910111213141516171819202122package com.design.pattern.principle;import com.design.pattern.principle.dependenceinversion.PythonCourse;import com.design.pattern.principle.dependenceinversion.JavaCourse;import com.design.pattern.principle.dependenceinversion.Person;import org.junit.Test;/** * DependeceinversionTest * * @author shunhua * @date 2019-09-02 */public class DependeceinversionTest &#123; @Test public void test()&#123; Person person = new Person(); person.studyJava(); person.studyPython(); &#125;&#125; 面向接口编程1这里使用接口方法传参的方式 课程接口 1234567891011121314package com.design.pattern.principle.dependenceinversion;/** * ICourse * * @author shunhua * @date 2019-09-02 */public interface ICourse &#123; /** * 学习课程 */ void learnCourse();&#125; Java课程 123456789101112131415161718package com.design.pattern.principle.dependenceinversion;import lombok.extern.slf4j.Slf4j;/** * JavaCourse * * @author shunhua * @date 2019-09-02 */@Slf4jpublic class JavaCourse implements ICourse &#123; @Override public void learnCourse() &#123; log.info(\"gentryhuang is learning java\"); &#125;&#125; Python课程 123456789101112131415161718package com.design.pattern.principle.dependenceinversion;import lombok.extern.slf4j.Slf4j;/** * PythonCourse * * @author shunhua * @date 2019-09-02 */@Slf4jpublic class PythonCourse implements ICourse &#123; @Override public void learnCourse() &#123; log.info(\"gentryhuang is learning python\"); &#125;&#125; 实体 1234567891011121314151617package com.design.pattern.principle.dependenceinversion;import lombok.extern.slf4j.Slf4j;/** * Person * * @author shunhua * @date 2019-09-02 */@Slf4jpublic class Person &#123; public void learnCource(ICourse course)&#123; course.learnCourse(); &#125;&#125; 应用 123456789101112131415161718192021package com.design.pattern.principle;import com.design.pattern.principle.dependenceinversion.PythonCourse;import com.design.pattern.principle.dependenceinversion.JavaCourse;import com.design.pattern.principle.dependenceinversion.Person;import org.junit.Test;/** * DependeceinversionTest * * @author shunhua * @date 2019-09-02 */public class DependeceinversionTest &#123; @Test public void test()&#123; Person person = new Person(); person.learnCource(new JavaCourse()); person.learnCource(new PythonCourse()); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"开闭原则","slug":"design_pattern/principle/开闭原则","date":"2019-08-31T16:00:00.000Z","updated":"2020-07-04T13:42:18.869Z","comments":true,"path":"posts/f50731fc/","link":"","permalink":"https://gentryhuang.com/posts/f50731fc/","excerpt":"","text":"定义 一个软件实体如类、模块和函数应该对扩展开放，对修改关闭。 强调的是用抽象构建框架，用实现扩展细节。 核心思想 面向抽象编程，因为抽象是稳定的。 理解 不改变原先的业务逻辑，新增的功能点通过重写复用的方法进行编程。 优点 提高软件系统的可复用性以及可维护性 简单需求说明 软件实体ICourse，以及它的实现JavaCource实现了基本功能，如需要额外的功能可以对JavaCourse进行扩展即继承来添加， 这样在不修改底层的ICourse和JavaCourse的前提下，做到功能的添加。即，越基层的模块影响范围越大，越高层的模块影响 范围较小，总体实现了对扩展开放，对修改关闭，这样就可以有效解决影响范围。 codingv1 基类1需求：打印出原价以及课程其他信息 接口 12345678910111213141516171819202122232425package com.design.pattern.principle.openclose;/** * ICourse * * @author shunhua * @date 2019-09-01 */public interface ICourse &#123; /** * 获取课程id * @return */ Integer getId(); /** * 获取课程名称 * @return */ String getName(); /** * 获取课程价格 * @return */ Double getPrice();&#125; 实体类 1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.design.pattern.principle.openclose;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;/** * JavaCourse * * @author shunhua * @date 2019-09-01 */@AllArgsConstructor@NoArgsConstructor@Datapublic class JavaCourse implements ICourse &#123; /** * 课程id */ private Integer id; /** * 课程名称 */ private String name; /** * 课程价格 */ private Double price; @Override public Integer getId() &#123; return this.id; &#125; @Override public String getName() &#123; return this.name; &#125; @Override public Double getPrice() &#123; return this.price; &#125;&#125; 应用 123456789101112131415161718192021222324252627package com.design.pattern.principle;import com.design.pattern.principle.openclose.ICourse;import com.design.pattern.principle.openclose.JavaCourse;import com.design.pattern.principle.openclose.JavaDiscountCourse;import lombok.extern.slf4j.Slf4j;import org.junit.Test;/** * OpencloseTest * * @author shunhua * @date 2019-09-01 */@Slf4jpublic class OpencloseTest &#123; @Test public void testBase()&#123; ICourse javaCourse = new JavaCourse(100,\"Java从入门到放弃\",200d); log.info(String.format(\"课程id: %d,课程名: %s, 课程价格：%f\", javaCourse.getId(), javaCourse.getName(), javaCourse.getPrice()) ); &#125;&#125; v21需求：打印出原价和折扣后的价格以及课程其他信息（接口不应该随意发生变化，面向接口编程） 接口 12345678910111213141516171819202122232425package com.design.pattern.principle.openclose;/** * ICourse * * @author shunhua * @date 2019-09-01 */public interface ICourse &#123; /** * 获取课程id * @return */ Integer getId(); /** * 获取课程名称 * @return */ String getName(); /** * 获取课程价格 * @return */ Double getPrice();&#125; 实体类 1234567891011121314151617181920212223242526272829303132package com.design.pattern.principle.openclose;/** * JavaDiscountCourse * * @author shunhua * @date 2019-09-01 */public class JavaDiscountCourse extends JavaCourse &#123; public JavaDiscountCourse(Integer id, String name, Double price) &#123; super(id, name, price); &#125; /** * 获取折扣价 * @return */ @Override public Double getPrice() &#123; return super.getPrice() * 0.8; &#125; /** * 获取原价 * @return */ public Double getOriginPrice()&#123; return super.getPrice(); &#125;&#125; 应用 123456789101112131415161718192021222324252627282930313233343536373839package com.design.pattern.principle;import com.design.pattern.principle.openclose.ICourse;import com.design.pattern.principle.openclose.JavaCourse;import com.design.pattern.principle.openclose.JavaDiscountCourse;import lombok.extern.slf4j.Slf4j;import org.junit.Test;/** * OpencloseTest * * @author shunhua * @date 2019-09-01 */@Slf4jpublic class OpencloseTest &#123; @Test public void testBase()&#123; ICourse javaCourse = new JavaCourse(100,\"Java从入门到放弃\",200d); log.info(String.format(\"课程id: %d,课程名: %s, 课程价格：%f\", javaCourse.getId(), javaCourse.getName(), javaCourse.getPrice()) ); &#125; @Test public void testEx()&#123; ICourse javaCource = new JavaDiscountCourse(100,\"java从入门到放弃\",200d); log.info(String.format(\"课程id: %d,课程名: %s, 课程原价：%f，课程折扣价格：%f\", javaCource.getId(), javaCource.getName(), ((JavaDiscountCourse) javaCource).getOriginPrice(), javaCource.getPrice()) ); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"简单工厂","slug":"design_pattern/other_type/简单工厂","date":"2019-08-28T16:00:00.000Z","updated":"2020-08-09T09:24:21.833Z","comments":true,"path":"posts/90fd4bf3/","link":"","permalink":"https://gentryhuang.com/posts/90fd4bf3/","excerpt":"","text":"定义 由一个工厂对象决定创建出哪一种产品类的实例 类型 创建型，但不属于GOF23种设计模式。简单工厂模式严格意义上说并不是一种设计模式，它是一种编码上的风格和习惯 使用场景 工厂类负责创建的对象比较少 客户端（应用层）只知道传入工厂类的参数，对于如何创建对象（逻辑）不关心优点只需要传入一个正确的参数，就可以获取所需要的对象而无须知道其创建细节缺点简单工厂类的职责相对过重，增加新的产品需要修改工厂类的判断逻辑，违背了开闭原则。 coding未使用简单工厂模式的代码父类 12345678910111213public abstract class Video&#123; public abstract void printVideo();&#125;``` **子类JavaVideo**```java@Slf4jpublic class JavaVideo extends Video&#123; @Override public void printVideo() &#123; log.info(\"录制java视频\"); &#125;&#125; 子类PythonVideo 1234567@Slf4jpublic class PythonVideo extends Video&#123; @Override public void printVideo() &#123; log.info(\"录制python视频\"); &#125;&#125; 应用 1234567public class client&#123; @Test public void test()&#123; Video video = new JavaVideo(); video.printVideo(); &#125;&#125; 使用简单工厂模式 工厂类 12345678910111213141516171819202122232425262728293031323334353637383940414243package com.design.pattern.simplefactory;/** * 简单工厂 * * @author shunhua * @date 2019-09-09 */public class FoodFactory &#123; /** * 随着要产品增多，以下逻辑必须要修改 * @param type 这里使用字符串根据类型进行创建不同的实例 * @return */ public Food createFood(String type)&#123; if(\"salad\".equalsIgnoreCase(type))&#123; return new Salad(); &#125;else if(\"bread\".equalsIgnoreCase(type))&#123; return new Bread(); &#125; return null; &#125; /** * * @param c 这里使用反射创建不同的实例 * @return */ public Food createFood(Class c)&#123; Food food = null; try &#123; food = (Food) Class.forName(c.getName()).newInstance(); &#125; catch (InstantiationException e) &#123; e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; return food; &#125;&#125; 父类 1234567891011121314package com.design.pattern.simplefactory;/** * Food * * @author shunhua * @date 2019-09-09 */public abstract class Food &#123; /** * 生产产品方法 */ public abstract void produce();&#125; 子类面包 123456789101112131415161718package com.design.pattern.simplefactory;import lombok.extern.slf4j.Slf4j;/** * Bread * * @author shunhua * @date 2019-09-09 */@Slf4jpublic class Bread extends Food &#123; @Override public void produce() &#123; log.info(\"生产面包!\"); &#125;&#125; 子类沙拉 123456789101112131415161718package com.design.pattern.simplefactory;import lombok.extern.slf4j.Slf4j;/** * Salad * * @author shunhua * @date 2019-09-09 */@Slf4jpublic class Salad extends Food &#123; @Override public void produce() &#123; log.info(\"生成沙拉!\"); &#125;&#125; 客户端 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.design.pattern.simplefactory;import com.common.base.ObjectUtils;import com.design.pattern.simplefactory.Bread;import com.design.pattern.simplefactory.Food;import com.design.pattern.simplefactory.FoodFactory;import com.design.pattern.simplefactory.Salad;import org.junit.Test;/** * Client * * @author shunhua * @date 2019-09-09 */public class Client &#123; /* 非简单工厂模式 @Test public void simpleFactoryBefore()&#123; // 这里需要依赖具体的生产类 Food food = new Bread(); Food food1 = new Salad(); food.produce(); food1.produce(); &#125;*/ /* @Test public void simpleFactoryByType()&#123; // 创建一个简单工厂 FoodFactory factory = new FoodFactory(); // 由工厂创建实例对象 Food food = factory.createFood(\"salad\"); food.produce(); &#125; */ @Test public void simpleFactoryByClass()&#123; FoodFactory factory = new FoodFactory(); Food food = factory.createFood(Bread.class); if(ObjectUtils.isNotNull(food))&#123; food.produce(); &#125; &#125;&#125; 简单工厂在源码中的使用jdk的Calendar源码解析123456789101112131415161718192021222324252627282930313233343536373839404142434445// 这里使用的是静态方法，因为不需要再通过继承进行扩展。如需扩展就不使用static关键字public static Calendar getInstance(TimeZone zone, Locale aLocale)&#123; return createCalendar(zone, aLocale); &#125; private static Calendar createCalendar(TimeZone zone, Locale aLocale) &#123; CalendarProvider provider = LocaleProviderAdapter.getAdapter(CalendarProvider.class, aLocale).getCalendarProvider(); if (provider != null) &#123; try &#123; return provider.getInstance(zone, aLocale); &#125; catch (IllegalArgumentException iae) &#123; // fall back to the default instantiation &#125; &#125; Calendar cal = null; if (aLocale.hasExtensions()) &#123; String caltype = aLocale.getUnicodeLocaleType(\"ca\"); if (caltype != null) &#123; // 根据不同的类型创建日期对象 switch (caltype) &#123; case \"buddhist\": cal = new BuddhistCalendar(zone, aLocale); break; case \"japanese\": cal = new JapaneseImperialCalendar(zone, aLocale); break; case \"gregory\": cal = new GregorianCalendar(zone, aLocale); break; &#125; &#125; &#125; if (cal == null) &#123; if (aLocale.getLanguage() == \"th\" &amp;&amp; aLocale.getCountry() == \"TH\") &#123; cal = new BuddhistCalendar(zone, aLocale); &#125; else if (aLocale.getVariant() == \"JP\" &amp;&amp; aLocale.getLanguage() == \"ja\" &amp;&amp; aLocale.getCountry() == \"JP\") &#123; cal = new JapaneseImperialCalendar(zone, aLocale); &#125; else &#123; cal = new GregorianCalendar(zone, aLocale); &#125; &#125; return cal; &#125; DriverManager源码解析（通过classForName获取）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public static Connection getConnection(String url, java.util.Properties info) throws SQLException &#123; // Gets the classloader of the code that called this method, may // be null. ClassLoader callerCL = DriverManager.getCallerClassLoader(); return (getConnection(url, info, callerCL)); &#125;// Worker method called by the public getConnection() methods. private static Connection getConnection( String url, java.util.Properties info, ClassLoader callerCL) throws SQLException &#123; java.util.Vector drivers = null; /* * When callerCl is null, we should check the application's * (which is invoking this class indirectly) * classloader, so that the JDBC driver class outside rt.jar * can be loaded from here. */ synchronized(DriverManager.class) &#123; // synchronize loading of the correct classloader. if(callerCL == null) &#123; callerCL = Thread.currentThread().getContextClassLoader(); &#125; &#125; if(url == null) &#123; throw new SQLException(\"The url cannot be null\", \"08001\"); &#125; println(\"DriverManager.getConnection(\\\"\" + url + \"\\\")\"); if (!initialized) &#123; initialize(); &#125; synchronized (DriverManager.class)&#123; // use the readcopy of drivers drivers = readDrivers; &#125; // Walk through the loaded drivers attempting to make a connection. // Remember the first exception that gets raised so we can reraise it. SQLException reason = null; for (int i = 0; i &lt; drivers.size(); i++) &#123; DriverInfo di = (DriverInfo)drivers.elementAt(i); // If the caller does not have permission to load the driver then // skip it. if ( getCallerClass(callerCL, di.driverClassName ) != di.driverClass ) &#123; println(\" skipping: \" + di); continue; &#125; try &#123; println(\" trying \" + di); Connection result = di.driver.connect(url, info); if (result != null) &#123; // Success! println(\"getConnection returning \" + di); return (result); &#125; &#125; catch (SQLException ex) &#123; if (reason == null) &#123; reason = ex; &#125; &#125; &#125; // if we got here nobody could connect. if (reason != null) &#123; println(\"getConnection failed: \" + reason); throw reason; &#125; println(\"getConnection: no suitable driver found for \"+ url); throw new SQLException(\"No suitable driver found for \"+ url, \"08001\"); &#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"uml基础","slug":"design_pattern/uml","date":"2019-08-27T16:00:00.000Z","updated":"2020-08-09T09:14:31.577Z","comments":true,"path":"posts/cadc5d6c/","link":"","permalink":"https://gentryhuang.com/posts/cadc5d6c/","excerpt":"","text":"定义统一建模语言（缩写UML），非专利的第三代建模和规约语言 特点 UML是一种开放的方法 UML用于说明、可视化、构建和编写一个正在开发的面向对象的、软件密集系统的制品的开放方法 UML展现了一系列最佳工程的实践，这些最佳实践在对大规模，复杂系统进行建模方面，特别是在软件架构层面已经被验证有效 UML分类 结构式图形 强调的是系统式的建模，具体包含静态图（类图、对象图、包图）、实现图（组件图、部署图）、剖面图以及复合结构图 行为式图形 强调系统模型中触发的事件，具体包含活动图、状态图以及用例图 交互式图形 属于行为式图形子集合，强调系统模型中资源流程。具体包含通信图、交互概念图、时序图 以及时间图 ​ UML类图用于表示类、接口、实例等之间相互的静态关系。虽然名字叫类图，但类图中并不只有类，还可能包括权限、属性、方法等 UML记忆方式12341. uml箭头：从子类指向父类，只有知道对方信息时才能指向对方方向2. 空心三角箭头：继承或实现，实线-继承：积极的，强关联，关联，通常一个类中有一个类的对象做属性；虚线-实现：消极的，弱关联，依赖3. 空心菱形：聚合，（注：可以看作一个盘子，可以放很多相同的东西（箭头方向所指的类），聚在一起。是has a的关系）弱关联4. 实心菱形：组合，（注：代表器皿里有实体结构存在，组合起来成为一个。是contains-a的关系）强关联 uml箭头：从子类指向父类，定义子类时需要通过extends关键字指定父类，只有知道对方信息时才能指向对方方向 实线-继承 | 虚线-实现 ​ 空心菱形-聚合 实心菱形-组合 组合关系中常见的数字表达 123456◆常见数字表达及含义，假设有A类和B类，数字标记在A类侧◆0..1：0或1个实例 在系统某一时刻，b的实例可以与0个或1个A实例相关◆0..*：0或多个实例 在系统某一时刻，b的实例可以与0个或多个A实例相关◆1..1：1个实例. b的实例可以和1个A实例相关◆1只能有一个实例. b的实例可以和1个A实例相关◆1..*：至少有一个实例. b实例可以与一个或多个A实例相关 UML时序图 是显示对象之间交互的图，这些对象是按照时间顺序排列的 时序图中 包含的建模元素 对象（Actor）、生命线（lifeline）、控制焦点（Focus of control）、消息（Message）等 时序图示例 12345678910111213竖线代表生命线对象：c：client ，s：server，d：device 代表实例消息：箭头代表的元素(open,work等)竖矩形代表实例处于某种活动中，实线实心箭头：代表方法调用，同步调用实线非实心箭头：代表异步调用虚线：代表返回 UML类图讲解123456789101112131415+ 公共方法- private权限# protected权限 包内和包外继承的子类都能引用~ default权限（包权限）只有包内能引用下划线 静态 Static斜体 抽象类（或抽象方法）（包含抽象方法的必是抽象类）（类和至少一个方法都是斜体）方法 可以带参，可以不带参 返回值写到冒号后边，void不用加 UML整体讲解12345678910设计模式中的对象关系: 依赖关系 虚线箭头，箭头方向指向被依赖的部分 组合关系 实心菱形 聚合关系 空心菱形（想象成盘子，盛东西，盘子的多，另一方少） 关联关系 实线箭头，箭头指向被关联的部分 类与类的连接，（它使一个类知道另一个类的属性和方法，关联关 系一般用成员变量实现） 继承 空心三角形实线 实现 空心三角形虚线注意： 实现接口有两种方式，一种是棒棒糖的形式，另一种是虚线空心三角形的方式 UML中部分对比1234567891.1 关联和依赖的对比关联是a类中存在b类对象，企鹅类中有气候类的属性依赖是a类成员方法中有b类的属性，动物新陈代谢方法中有水和空气的属性，只有调这个方法的时候，才可能临时用一下1.2 组合和聚合的对比组合有相同的生命周期，鸟有翅膀，鸟死了，翅膀不复存在大雁群有大雁，一只大雁挂了，大雁群不会消失1.3 继承和实现的对实线：继承虚线：实现","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]}],"categories":[{"name":"JDK","slug":"JDK","permalink":"https://gentryhuang.com/categories/JDK/"},{"name":"网络通信","slug":"网络通信","permalink":"https://gentryhuang.com/categories/%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1/"},{"name":"任务调度","slug":"任务调度","permalink":"https://gentryhuang.com/categories/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6/"},{"name":"Redis","slug":"Redis","permalink":"https://gentryhuang.com/categories/Redis/"},{"name":"MySQL","slug":"MySQL","permalink":"https://gentryhuang.com/categories/MySQL/"},{"name":"分布式","slug":"分布式","permalink":"https://gentryhuang.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/categories/RPC/"},{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"JMM","slug":"JMM","permalink":"https://gentryhuang.com/tags/JMM/"},{"name":"Thread","slug":"Thread","permalink":"https://gentryhuang.com/tags/Thread/"},{"name":"HashedWheelTimer","slug":"HashedWheelTimer","permalink":"https://gentryhuang.com/tags/HashedWheelTimer/"},{"name":"JUC","slug":"JUC","permalink":"https://gentryhuang.com/tags/JUC/"},{"name":"AQS","slug":"AQS","permalink":"https://gentryhuang.com/tags/AQS/"},{"name":"Lock","slug":"Lock","permalink":"https://gentryhuang.com/tags/Lock/"},{"name":"I/O","slug":"I-O","permalink":"https://gentryhuang.com/tags/I-O/"},{"name":"慢查询日志","slug":"慢查询日志","permalink":"https://gentryhuang.com/tags/%E6%85%A2%E6%9F%A5%E8%AF%A2%E6%97%A5%E5%BF%97/"},{"name":"缓存","slug":"缓存","permalink":"https://gentryhuang.com/tags/%E7%BC%93%E5%AD%98/"},{"name":"Dubbo","slug":"Dubbo","permalink":"https://gentryhuang.com/tags/Dubbo/"},{"name":"Gossip","slug":"Gossip","permalink":"https://gentryhuang.com/tags/Gossip/"},{"name":"Raft","slug":"Raft","permalink":"https://gentryhuang.com/tags/Raft/"},{"name":"共识算法","slug":"共识算法","permalink":"https://gentryhuang.com/tags/%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95/"},{"name":"Redis数据结构","slug":"Redis数据结构","permalink":"https://gentryhuang.com/tags/Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"CopyOnWrite","slug":"CopyOnWrite","permalink":"https://gentryhuang.com/tags/CopyOnWrite/"},{"name":"ConcurrentHashMap","slug":"ConcurrentHashMap","permalink":"https://gentryhuang.com/tags/ConcurrentHashMap/"},{"name":"HashMap","slug":"HashMap","permalink":"https://gentryhuang.com/tags/HashMap/"},{"name":"代理","slug":"代理","permalink":"https://gentryhuang.com/tags/%E4%BB%A3%E7%90%86/"},{"name":"Spring","slug":"Spring","permalink":"https://gentryhuang.com/tags/Spring/"},{"name":"Protocol","slug":"Protocol","permalink":"https://gentryhuang.com/tags/Protocol/"},{"name":"Filter","slug":"Filter","permalink":"https://gentryhuang.com/tags/Filter/"},{"name":"Mina","slug":"Mina","permalink":"https://gentryhuang.com/tags/Mina/"},{"name":"Netty","slug":"Netty","permalink":"https://gentryhuang.com/tags/Netty/"},{"name":"Javassist","slug":"Javassist","permalink":"https://gentryhuang.com/tags/Javassist/"},{"name":"Redis","slug":"Redis","permalink":"https://gentryhuang.com/tags/Redis/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://gentryhuang.com/tags/Zookeeper/"},{"name":"RPC","slug":"RPC","permalink":"https://gentryhuang.com/tags/RPC/"},{"name":"SPI","slug":"SPI","permalink":"https://gentryhuang.com/tags/SPI/"},{"name":"设计模式","slug":"设计模式","permalink":"https://gentryhuang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]}